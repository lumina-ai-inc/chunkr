{
  "file_name": "Instant Loading for Main Memory Databases - VLDB - 2013, Vol 6, No 14 (p1702-muehlbauer).pdf",
  "task_id": "1f24fd9e-4896-4b1e-bb60-da91b8518cb8",
  "output": {
    "chunks": [
      {
        "segments": [
          {
            "segment_id": "a2c07deb-74f3-46af-ab18-04305023c24f",
            "bbox": {
              "left": 240.66666,
              "top": 149,
              "width": 787.4166,
              "height": 35.333332
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Instant Loading for Main Memory Databases",
            "segment_type": "Title",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/a2c07deb-74f3-46af-ab18-04305023c24f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5d4afb8f04ddf26d1501aac8e386ce436ba37c99134176ac15f368d766c132c9",
            "html": "<h1>Instant Loading for Main Memory Databases</h1>",
            "markdown": "# Instant Loading for Main Memory Databases\n\n"
          }
        ],
        "chunk_length": 6
      },
      {
        "segments": [
          {
            "segment_id": "f108c60c-638d-4f95-9770-cdcaeaae50d1",
            "bbox": {
              "left": 196.91666,
              "top": 223.99998,
              "width": 264.5,
              "height": 191.58333
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Tobias M ¨uhlbauer Technische Universit¨ at M¨ unchen Munich, Germany muehlbau@in.tum.de Angelika Reiser Technische Universit¨ at M¨ unchen Munich, Germany reiser@in.tum.de",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/f108c60c-638d-4f95-9770-cdcaeaae50d1.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=6d0cd9a1770ee63e319aa783b7846d0c121fc8de766ad9be32727c11d98241d5",
            "html": "<p>Tobias M ¨uhlbauer Technische Universit¨ at M¨ unchen Munich, Germany muehlbau@in.tum.de Angelika Reiser Technische Universit¨ at M¨ unchen Munich, Germany reiser@in.tum.de</p>",
            "markdown": "Tobias M ¨uhlbauer Technische Universit¨ at M¨ unchen Munich, Germany muehlbau@in.tum.de Angelika Reiser Technische Universit¨ at M¨ unchen Munich, Germany reiser@in.tum.de\n\n"
          },
          {
            "segment_id": "e5f5f050-52ff-4963-8f8f-431b6f77efd2",
            "bbox": {
              "left": 807.3333,
              "top": 226.08333,
              "width": 260.3333,
              "height": 87.416664
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Robert Seilbeck Technische Universit¨ at M¨ unchen Munich, Germany seilbeck@in.tum.de",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/e5f5f050-52ff-4963-8f8f-431b6f77efd2.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=bffb7190cd4caecc21bce43d840592ecab5c67ad45bca812e708a13f2c94c587",
            "html": "<p>Robert Seilbeck Technische Universit¨ at M¨ unchen Munich, Germany seilbeck@in.tum.de</p>",
            "markdown": "Robert Seilbeck Technische Universit¨ at M¨ unchen Munich, Germany seilbeck@in.tum.de\n\n"
          },
          {
            "segment_id": "0c076419-08e4-4b33-a9e5-de377747e128",
            "bbox": {
              "left": 501.0833,
              "top": 223.99998,
              "width": 262.41666,
              "height": 191.58333
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Wolf R ¨odiger Technische Universit¨ at M¨ unchen Munich, Germany roediger@in.tum.de Alfons Kemper Technische Universit¨ at M¨ unchen Munich, Germany kemper@in.tum.de",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/0c076419-08e4-4b33-a9e5-de377747e128.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d6063256e8cecc5d9662847d1216879427d8b3a430c5c30a9ce2b36ec769e814",
            "html": "<p>Wolf R ¨odiger Technische Universit¨ at M¨ unchen Munich, Germany roediger@in.tum.de Alfons Kemper Technische Universit¨ at M¨ unchen Munich, Germany kemper@in.tum.de</p>",
            "markdown": "Wolf R ¨odiger Technische Universit¨ at M¨ unchen Munich, Germany roediger@in.tum.de Alfons Kemper Technische Universit¨ at M¨ unchen Munich, Germany kemper@in.tum.de\n\n"
          },
          {
            "segment_id": "1a2ec7a1-34b3-4a49-b945-2621c5bfaa0c",
            "bbox": {
              "left": 807.3333,
              "top": 328.16666,
              "width": 262.41666,
              "height": 89.5
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Thomas Neumann Technische Universit¨ at M¨ unchen Munich, Germany neumann@in.tum.de",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/1a2ec7a1-34b3-4a49-b945-2621c5bfaa0c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=3c0237d87b6d328d3fab9b5d3b8f8aeafd9710bd5fe9a8a7e6fe621e08c18d2b",
            "html": "<p>Thomas Neumann Technische Universit¨ at M¨ unchen Munich, Germany neumann@in.tum.de</p>",
            "markdown": "Thomas Neumann Technische Universit¨ at M¨ unchen Munich, Germany neumann@in.tum.de\n\n"
          }
        ],
        "chunk_length": 62
      },
      {
        "segments": [
          {
            "segment_id": "da57efa0-707f-4faf-abf5-6305ebf358d4",
            "bbox": {
              "left": 109.416664,
              "top": 451.0833,
              "width": 135.33333,
              "height": 22.833332
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "ABSTRACT",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/da57efa0-707f-4faf-abf5-6305ebf358d4.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2d09d3c88c0b753a6673d72bebc062c01ab382483273bf0f4342724fd2ff58b2",
            "html": "<h2>ABSTRACT</h2>",
            "markdown": "## ABSTRACT\n\n"
          },
          {
            "segment_id": "53a148c3-a448-4ef8-abaf-e768b6a4104e",
            "bbox": {
              "left": 109.416664,
              "top": 486.49997,
              "width": 501.99997,
              "height": 233.24998
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "eScience and big data analytics applications are facing the challenge of efficiently evaluating complex queries over vast amounts of structured text data archived in network storage solutions. To analyze such data in traditional disk-based database systems, it needs to be bulk loaded , an operation whose performance largely depends on the wire speed of the data source and the speed of the data sink, i.e., the disk. As the speed of network adapters and disks has stagnated in the past, loading has become a major bottleneck. The delays it is causing are now ubiquitous as text formats are a preferred storage format for reasons of portability.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/53a148c3-a448-4ef8-abaf-e768b6a4104e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=cf1ec9ddca3b16a2a352494c04f934fe53e5c4d2b2d61d3af16883d239a8708f",
            "html": "<p>eScience and big data analytics applications are facing the challenge of efficiently evaluating complex queries over vast amounts of structured text data archived in network storage solutions. To analyze such data in traditional disk-based database systems, it needs to be bulk loaded , an operation whose performance largely depends on the wire speed of the data source and the speed of the data sink, i.e., the disk. As the speed of network adapters and disks has stagnated in the past, loading has become a major bottleneck. The delays it is causing are now ubiquitous as text formats are a preferred storage format for reasons of portability.</p>",
            "markdown": "eScience and big data analytics applications are facing the challenge of efficiently evaluating complex queries over vast amounts of structured text data archived in network storage solutions. To analyze such data in traditional disk-based database systems, it needs to be bulk loaded , an operation whose performance largely depends on the wire speed of the data source and the speed of the data sink, i.e., the disk. As the speed of network adapters and disks has stagnated in the past, loading has become a major bottleneck. The delays it is causing are now ubiquitous as text formats are a preferred storage format for reasons of portability.\n\n"
          },
          {
            "segment_id": "6249ddaa-f107-4e8a-9472-f8d973738b00",
            "bbox": {
              "left": 109.416664,
              "top": 726.0833,
              "width": 501.99997,
              "height": 343.66666
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "But the game has changed: Ever increasing main mem- ory capacities have fostered the development of in-memory database systems and very fast network infrastructures are on the verge of becoming economical. While hardware limi- tations for fast loading have disappeared, current approaches for main memory databases fail to saturate the now available wire speeds of tens of Gbit/s. With Instant Loading , we con- tribute a novel CSV loading approach that allows scalable bulk loading at wire speed . This is achieved by optimizing all phases of loading for modern super-scalar multi-core CPUs. Large main memory capacities and Instant Loading thereby facilitate a very efficient data staging processing model con- sisting of instantaneous load -work-unload cycles across data archives on a single node. Once data is loaded, updates and queries are efficiently processed with the flexibility, security, and high performance of relational main memory databases.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6249ddaa-f107-4e8a-9472-f8d973738b00.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d80750767a9c517c64a17a8d5b53b211c4b0d5314affd83b3dfea14b5e7acc9b",
            "html": "<p>But the game has changed: Ever increasing main mem- ory capacities have fostered the development of in-memory database systems and very fast network infrastructures are on the verge of becoming economical. While hardware limi- tations for fast loading have disappeared, current approaches for main memory databases fail to saturate the now available wire speeds of tens of Gbit/s. With Instant Loading , we con- tribute a novel CSV loading approach that allows scalable bulk loading at wire speed . This is achieved by optimizing all phases of loading for modern super-scalar multi-core CPUs. Large main memory capacities and Instant Loading thereby facilitate a very efficient data staging processing model con- sisting of instantaneous load -work-unload cycles across data archives on a single node. Once data is loaded, updates and queries are efficiently processed with the flexibility, security, and high performance of relational main memory databases.</p>",
            "markdown": "But the game has changed: Ever increasing main mem- ory capacities have fostered the development of in-memory database systems and very fast network infrastructures are on the verge of becoming economical. While hardware limi- tations for fast loading have disappeared, current approaches for main memory databases fail to saturate the now available wire speeds of tens of Gbit/s. With Instant Loading , we con- tribute a novel CSV loading approach that allows scalable bulk loading at wire speed . This is achieved by optimizing all phases of loading for modern super-scalar multi-core CPUs. Large main memory capacities and Instant Loading thereby facilitate a very efficient data staging processing model con- sisting of instantaneous load -work-unload cycles across data archives on a single node. Once data is loaded, updates and queries are efficiently processed with the flexibility, security, and high performance of relational main memory databases.\n\n"
          }
        ],
        "chunk_length": 252
      },
      {
        "segments": [
          {
            "segment_id": "05af65a8-f9fc-4c28-b998-1fd66c41faa2",
            "bbox": {
              "left": 109.416664,
              "top": 1105.25,
              "width": 243.66666,
              "height": 22.833332
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "1. INTRODUCTION",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/05af65a8-f9fc-4c28-b998-1fd66c41faa2.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c735668cee2cec54ba8e97b7396179b1c3beb4ebab3d63f4052fb44e3acbeb67",
            "html": "<h2>1. INTRODUCTION</h2>",
            "markdown": "## 1. INTRODUCTION\n\n"
          },
          {
            "segment_id": "6a2cd155-7a62-4b9b-8150-ad52bd137c8b",
            "bbox": {
              "left": 109.416664,
              "top": 1136.5,
              "width": 501.99997,
              "height": 147.83333
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "The volume of data archived in structured text formats like comma-separated values (CSV) has grown rapidly and continues to do so at an unprecedented rate. Scientific data sets such as the Sloan Digital Sky Survey and Pan-STARRS are stored as image files and, for reasons of portability and debugability, as multi-terabyte archives of derived CSV files that are frequently loaded to databases to evaluate complex",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6a2cd155-7a62-4b9b-8150-ad52bd137c8b.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=ecda08cb9fad76b3ab452f8e809c8c4dcd8a2b37da9c4e2d52f942ea519ff438",
            "html": "<p>The volume of data archived in structured text formats like comma-separated values (CSV) has grown rapidly and continues to do so at an unprecedented rate. Scientific data sets such as the Sloan Digital Sky Survey and Pan-STARRS are stored as image files and, for reasons of portability and debugability, as multi-terabyte archives of derived CSV files that are frequently loaded to databases to evaluate complex</p>",
            "markdown": "The volume of data archived in structured text formats like comma-separated values (CSV) has grown rapidly and continues to do so at an unprecedented rate. Scientific data sets such as the Sloan Digital Sky Survey and Pan-STARRS are stored as image files and, for reasons of portability and debugability, as multi-terabyte archives of derived CSV files that are frequently loaded to databases to evaluate complex\n\n"
          },
          {
            "segment_id": "ef6c4894-f5fb-4a77-834f-7b878be3ad4b",
            "bbox": {
              "left": 109.416664,
              "top": 1317.75,
              "width": 501.99997,
              "height": 183.25
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Articles from this volume were invited to present their results at The 39th International Conference on Very Large Data Bases, August 26th - 30th 2013, Riva del Garda, Trento, Italy. Proceedings of the VLDB Endowment, Vol. 6, No. 14 Copyright 2013 VLDB Endowment 2150-8097/13/14... $ 10.00.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ef6c4894-f5fb-4a77-834f-7b878be3ad4b.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f99a94d5d0d3349dc8ab08003346c5ecb333cad7809af27edf7d4ce92c9b4774",
            "html": "<p>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Articles from this volume were invited to present their results at The 39th International Conference on Very Large Data Bases, August 26th - 30th 2013, Riva del Garda, Trento, Italy. Proceedings of the VLDB Endowment, Vol. 6, No. 14 Copyright 2013 VLDB Endowment 2150-8097/13/14... $ 10.00.</p>",
            "markdown": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Articles from this volume were invited to present their results at The 39th International Conference on Very Large Data Bases, August 26th - 30th 2013, Riva del Garda, Trento, Italy. Proceedings of the VLDB Endowment, Vol. 6, No. 14 Copyright 2013 VLDB Endowment 2150-8097/13/14... $ 10.00.\n\n"
          },
          {
            "segment_id": "01bec2a2-dc3c-4648-a4c9-86e6e1ce95b7",
            "bbox": {
              "left": 661.5,
              "top": 446.91666,
              "width": 481.16666,
              "height": 266.5833
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "1 GbE HDD SSD ∼ 4 Gbit/s 10 GbE Infiniband 4 × QDR DDR3-1600 (2 channels) 0 % 25 % 50 % 75 % 100 % 10 × improved estimated Instant Loading /w more cores Instant Loading /w indexes Instant Loading Current CSV bulk loading wire speed of CSV source in terms of I/O devices wire sp eed saturation 4 CPU co res (8 threads)",
            "segment_type": "Picture",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/01bec2a2-dc3c-4648-a4c9-86e6e1ce95b7.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=014405df94b268e7da01391b45653d6721497c78f79b71a6135478dd7051c02d",
            "html": "<img src=\"https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/01bec2a2-dc3c-4648-a4c9-86e6e1ce95b7.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=014405df94b268e7da01391b45653d6721497c78f79b71a6135478dd7051c02d\" />",
            "markdown": "![Image](https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/01bec2a2-dc3c-4648-a4c9-86e6e1ce95b7.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=014405df94b268e7da01391b45653d6721497c78f79b71a6135478dd7051c02d)"
          },
          {
            "segment_id": "9d5fe7c0-2413-40fd-a1d9-aee9b60bd0ed",
            "bbox": {
              "left": 657.3333,
              "top": 734.4166,
              "width": 501.99997,
              "height": 37.416664
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Figure 1: Pushing the envelope: wire speed satura- tion of current bulk loading vs. Instant Loading.",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/9d5fe7c0-2413-40fd-a1d9-aee9b60bd0ed.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=26bbea729e691a4db5f4be2fbfed4c97de1e93d7904880b4dea27502950aeca7",
            "html": "<span class=\"caption\">Figure 1: Pushing the envelope: wire speed satura- tion of current bulk loading vs. Instant Loading.</span>",
            "markdown": "Figure 1: Pushing the envelope: wire speed satura- tion of current bulk loading vs. Instant Loading.\n\n"
          },
          {
            "segment_id": "c4ffb272-a381-4201-973d-d2c87f32a1ec",
            "bbox": {
              "left": 657.3333,
              "top": 805.24994,
              "width": 501.99997,
              "height": 124.916664
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "queries [27, 26]. Other big data analytics and business ap- plications are equally faced with the need to analyze similar archives of CSV and CSV-like data [25, 26]. These archives are usually stored externally from the database server in a network-attached storage (NAS) or distributed file system (DFS) or locally in a SSD/RAID storage.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/c4ffb272-a381-4201-973d-d2c87f32a1ec.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=6fa5ba2b4ef134662635801c0d5c4d95dc311a4b6701ee4c780b1e8ea380b71a",
            "html": "<p>queries [27, 26]. Other big data analytics and business ap- plications are equally faced with the need to analyze similar archives of CSV and CSV-like data [25, 26]. These archives are usually stored externally from the database server in a network-attached storage (NAS) or distributed file system (DFS) or locally in a SSD/RAID storage.</p>",
            "markdown": "queries [27, 26]. Other big data analytics and business ap- plications are equally faced with the need to analyze similar archives of CSV and CSV-like data [25, 26]. These archives are usually stored externally from the database server in a network-attached storage (NAS) or distributed file system (DFS) or locally in a SSD/RAID storage.\n\n"
          },
          {
            "segment_id": "4a6189c2-0322-4ae1-a3d6-0b994115f77f",
            "bbox": {
              "left": 657.3333,
              "top": 934.4166,
              "width": 501.99997,
              "height": 212.41666
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "To efficiently analyze CSV archives, traditional databases can do little to overcome the premise of loading. The cost of parsing, deserializing, validating, and indexing structured text data needs to be paid either up front during a bulk load or lazily during query processing on external tables. The performance of loading largely depends on the wire speed of the data source and the speed of the data sink, i.e., the disk. As the speed of network adapters and disks has stagnated in the past, loading has become a major bottleneck and the delays it is causing are now ubiquitous.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/4a6189c2-0322-4ae1-a3d6-0b994115f77f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=b617d2549271c8e853d7a1c545b7be75f9b1a7078e483448888e37a9c35f50a7",
            "html": "<p>To efficiently analyze CSV archives, traditional databases can do little to overcome the premise of loading. The cost of parsing, deserializing, validating, and indexing structured text data needs to be paid either up front during a bulk load or lazily during query processing on external tables. The performance of loading largely depends on the wire speed of the data source and the speed of the data sink, i.e., the disk. As the speed of network adapters and disks has stagnated in the past, loading has become a major bottleneck and the delays it is causing are now ubiquitous.</p>",
            "markdown": "To efficiently analyze CSV archives, traditional databases can do little to overcome the premise of loading. The cost of parsing, deserializing, validating, and indexing structured text data needs to be paid either up front during a bulk load or lazily during query processing on external tables. The performance of loading largely depends on the wire speed of the data source and the speed of the data sink, i.e., the disk. As the speed of network adapters and disks has stagnated in the past, loading has become a major bottleneck and the delays it is causing are now ubiquitous.\n\n"
          }
        ],
        "chunk_length": 417
      },
      {
        "segments": [
          {
            "segment_id": "51c676b3-26bb-4b1d-8ce3-52f39729464c",
            "bbox": {
              "left": 657.3333,
              "top": 1153.1666,
              "width": 501.99997,
              "height": 343.66666
            },
            "page_number": 1,
            "page_width": 1275,
            "page_height": 1650,
            "content": "But the game has changed: Ever increasing main mem- ory capacities have fostered the development of in-memory database systems and modern network infrastructures as well as faster disks are on the verge of becoming economical. Servers with 1 TB of main memory and a 10 GbE adapter (10 Gbit/s ≈ 1.25 GB/s wire speed) already retail for less than $30,000. On this modern hardware, the loading source and sink are no longer the bottleneck. Rather, current load- ing approaches for main memory databases fail to saturate the now available wire speeds. With Instant Loading , we contribute a novel CSV loading approach that allows scal- able bulk loading at wire speed (see Fig. 1). This makes the delays caused by loading unobtrusive and relational main memory databases attractive for a very efficient data stag- ing processing model consisting of instantaneous load -work- unload cycles across CSV data archives on a single node.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/51c676b3-26bb-4b1d-8ce3-52f39729464c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2f8eee060c2c9f70e7fdfcfdbfd20bb19143fd46a34a0f0687ddde5396523ce1",
            "html": "<p>But the game has changed: Ever increasing main mem- ory capacities have fostered the development of in-memory database systems and modern network infrastructures as well as faster disks are on the verge of becoming economical. Servers with 1 TB of main memory and a 10 GbE adapter (10 Gbit/s ≈ 1.25 GB/s wire speed) already retail for less than $30,000. On this modern hardware, the loading source and sink are no longer the bottleneck. Rather, current load- ing approaches for main memory databases fail to saturate the now available wire speeds. With Instant Loading , we contribute a novel CSV loading approach that allows scal- able bulk loading at wire speed (see Fig. 1). This makes the delays caused by loading unobtrusive and relational main memory databases attractive for a very efficient data stag- ing processing model consisting of instantaneous load -work- unload cycles across CSV data archives on a single node.</p>",
            "markdown": "But the game has changed: Ever increasing main mem- ory capacities have fostered the development of in-memory database systems and modern network infrastructures as well as faster disks are on the verge of becoming economical. Servers with 1 TB of main memory and a 10 GbE adapter (10 Gbit/s ≈ 1.25 GB/s wire speed) already retail for less than $30,000. On this modern hardware, the loading source and sink are no longer the bottleneck. Rather, current load- ing approaches for main memory databases fail to saturate the now available wire speeds. With Instant Loading , we contribute a novel CSV loading approach that allows scal- able bulk loading at wire speed (see Fig. 1). This makes the delays caused by loading unobtrusive and relational main memory databases attractive for a very efficient data stag- ing processing model consisting of instantaneous load -work- unload cycles across CSV data archives on a single node.\n\n"
          },
          {
            "segment_id": "4751bce5-ad70-4ffb-8086-a1df55c3628f",
            "bbox": {
              "left": 121.916664,
              "top": 109.416664,
              "width": 464.49997,
              "height": 235.33333
            },
            "page_number": 2,
            "page_width": 1275,
            "page_height": 1650,
            "content": "queries high-speed NAS/DFS or SSD/RAID u n lo ad ... ... CSV CSV or binary 3 2 Load CSV Work: OLTP and OLAP in full-featured database Unload window of interest updates loading/unloading at wire speed lo ad m ai n m em o ry 1",
            "segment_type": "Picture",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/4751bce5-ad70-4ffb-8086-a1df55c3628f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=40c268761340d9f08659aa4be5f4e7f85d0c30f627ac20ea359734105c426a08",
            "html": "<img src=\"https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/4751bce5-ad70-4ffb-8086-a1df55c3628f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=40c268761340d9f08659aa4be5f4e7f85d0c30f627ac20ea359734105c426a08\" />",
            "markdown": "![Image](https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/4751bce5-ad70-4ffb-8086-a1df55c3628f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=40c268761340d9f08659aa4be5f4e7f85d0c30f627ac20ea359734105c426a08)"
          },
          {
            "segment_id": "43e9b15d-879d-46dd-a0e5-68bee071710d",
            "bbox": {
              "left": 109.416664,
              "top": 355.25,
              "width": 499.91666,
              "height": 39.5
            },
            "page_number": 2,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Figure 2: Instant Loading for data staging process- ing: load-work-unload cycles across CSV data.",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/43e9b15d-879d-46dd-a0e5-68bee071710d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e033dd1f2166e3460757217374aaf9b0d4d4e663aaac600d88258e7cb2324429",
            "html": "<span class=\"caption\">Figure 2: Instant Loading for data staging process- ing: load-work-unload cycles across CSV data.</span>",
            "markdown": "Figure 2: Instant Loading for data staging process- ing: load-work-unload cycles across CSV data.\n\n"
          },
          {
            "segment_id": "40787ae0-7e7b-45db-a15d-3f16c1af55a3",
            "bbox": {
              "left": 109.416664,
              "top": 430.24997,
              "width": 501.99997,
              "height": 279.0833
            },
            "page_number": 2,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Contributions. To achieve instantaneous loading, we optimize CSV bulk loading for modern super-scalar multi- core CPUs by task- and data-parallelizing all phases of load- ing. In particular, we propose a task-parallel CSV process- ing pipeline and present generic high-performance parsing, deserialization, and input validation methods based on SSE 4.2 SIMD instructions. While these already improve load- ing time significantly, other phases of loading become the bottleneck. We thus further show how copying deserialized tuples into the storage backend can be sped up and how in- dex creation can efficiently be interleaved with parallelized bulk loading using merge-able index structures (e.g., hash- ing with chaining and the adaptive radix tree (ART) [20]).",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/40787ae0-7e7b-45db-a15d-3f16c1af55a3.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5634cce0107dfc520677967d6d18fc68ae4e30ef63a25b2312c917491bfb1fec",
            "html": "<p>Contributions. To achieve instantaneous loading, we optimize CSV bulk loading for modern super-scalar multi- core CPUs by task- and data-parallelizing all phases of load- ing. In particular, we propose a task-parallel CSV process- ing pipeline and present generic high-performance parsing, deserialization, and input validation methods based on SSE 4.2 SIMD instructions. While these already improve load- ing time significantly, other phases of loading become the bottleneck. We thus further show how copying deserialized tuples into the storage backend can be sped up and how in- dex creation can efficiently be interleaved with parallelized bulk loading using merge-able index structures (e.g., hash- ing with chaining and the adaptive radix tree (ART) [20]).</p>",
            "markdown": "Contributions. To achieve instantaneous loading, we optimize CSV bulk loading for modern super-scalar multi- core CPUs by task- and data-parallelizing all phases of load- ing. In particular, we propose a task-parallel CSV process- ing pipeline and present generic high-performance parsing, deserialization, and input validation methods based on SSE 4.2 SIMD instructions. While these already improve load- ing time significantly, other phases of loading become the bottleneck. We thus further show how copying deserialized tuples into the storage backend can be sped up and how in- dex creation can efficiently be interleaved with parallelized bulk loading using merge-able index structures (e.g., hash- ing with chaining and the adaptive radix tree (ART) [20]).\n\n"
          },
          {
            "segment_id": "ad413be4-8e16-4992-be4f-92f63c3e6c6c",
            "bbox": {
              "left": 109.416664,
              "top": 711.5,
              "width": 499.91666,
              "height": 299.91666
            },
            "page_number": 2,
            "page_width": 1275,
            "page_height": 1650,
            "content": "To prove the feasibility of our generic Instant Loading approach, we integrate it in our main memory database sys- tem HyPer [19] and evaluate our implementation using the industry-standard TPC benchmarks. Results show improve- ments of up to a factor of 10 on a quad-core commodity ma- chine compared to current CSV bulk loading in main mem- ory databases like MonetDB [4] and Vectorwise. Our imple- mentation of the Instant Loading approach aims at highest performance in an in-memory computation setting where raw CPU costs dominate. We therefore strive for good code and data locality and use light-weight synchronization prim- itives such as atomic instructions. As the proportion of se- quential code is minimized, we expect our approach to scale with faster data sources and CPUs with ever more cores.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ad413be4-8e16-4992-be4f-92f63c3e6c6c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=ffa3d60e546303eff1ff9be969529a9c7f7946d4cba482f13a704d92efeb8e6f",
            "html": "<p>To prove the feasibility of our generic Instant Loading approach, we integrate it in our main memory database sys- tem HyPer [19] and evaluate our implementation using the industry-standard TPC benchmarks. Results show improve- ments of up to a factor of 10 on a quad-core commodity ma- chine compared to current CSV bulk loading in main mem- ory databases like MonetDB [4] and Vectorwise. Our imple- mentation of the Instant Loading approach aims at highest performance in an in-memory computation setting where raw CPU costs dominate. We therefore strive for good code and data locality and use light-weight synchronization prim- itives such as atomic instructions. As the proportion of se- quential code is minimized, we expect our approach to scale with faster data sources and CPUs with ever more cores.</p>",
            "markdown": "To prove the feasibility of our generic Instant Loading approach, we integrate it in our main memory database sys- tem HyPer [19] and evaluate our implementation using the industry-standard TPC benchmarks. Results show improve- ments of up to a factor of 10 on a quad-core commodity ma- chine compared to current CSV bulk loading in main mem- ory databases like MonetDB [4] and Vectorwise. Our imple- mentation of the Instant Loading approach aims at highest performance in an in-memory computation setting where raw CPU costs dominate. We therefore strive for good code and data locality and use light-weight synchronization prim- itives such as atomic instructions. As the proportion of se- quential code is minimized, we expect our approach to scale with faster data sources and CPUs with ever more cores.\n\n"
          }
        ],
        "chunk_length": 452
      },
      {
        "segments": [
          {
            "segment_id": "02a98ac2-6347-4996-abbf-1bdcc30ac552",
            "bbox": {
              "left": 109.416664,
              "top": 1021.9166,
              "width": 501.99997,
              "height": 193.66666
            },
            "page_number": 2,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Instant Loading in action: the (lwu)* data staging processing model. Servers with 1 TB of main memory and more offer enough space to facilitate an in-memory analysis of large sets of structured text data. However, currently the adoption of databases for such analysis tasks is hindered by the inefficiency of bulk loading (cf., Sect. 3.1). With Instant Loading we remove this obstacle and allow a novel data staging processing model consisting of instantaneous load -work-unload cycles (lwu)* across windows of interest.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/02a98ac2-6347-4996-abbf-1bdcc30ac552.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2693891bdac96cc9694a7225e93bd4968c2e02fc77420f4ff133dadb6c0f0c37",
            "html": "<p>Instant Loading in action: the (lwu)* data staging processing model. Servers with 1 TB of main memory and more offer enough space to facilitate an in-memory analysis of large sets of structured text data. However, currently the adoption of databases for such analysis tasks is hindered by the inefficiency of bulk loading (cf., Sect. 3.1). With Instant Loading we remove this obstacle and allow a novel data staging processing model consisting of instantaneous load -work-unload cycles (lwu)* across windows of interest.</p>",
            "markdown": "Instant Loading in action: the (lwu)* data staging processing model. Servers with 1 TB of main memory and more offer enough space to facilitate an in-memory analysis of large sets of structured text data. However, currently the adoption of databases for such analysis tasks is hindered by the inefficiency of bulk loading (cf., Sect. 3.1). With Instant Loading we remove this obstacle and allow a novel data staging processing model consisting of instantaneous load -work-unload cycles (lwu)* across windows of interest.\n\n"
          },
          {
            "segment_id": "b08cd880-a755-49fc-bca7-188b681587ef",
            "bbox": {
              "left": 109.416664,
              "top": 1217.75,
              "width": 501.99997,
              "height": 279.0833
            },
            "page_number": 2,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Data staging workflows exist in eScience (e.g., astronomy and genetics [27, 26]) and other big data analytics appli- cations. For example, Netflix, a popular on-demand media streaming service, reported that they are collecting 0.6 TB of CSV-like log data in a DFS per day [11]. Each hour, the last hour’s structured log data is loaded to a 50+ node Hadoop/Hive-based data warehouse, which is used for the extraction of performance indicators and for ad-hoc queries. Our vision is to use Instant Loading in a single-node main memory database for these kinds of recurring load-work- unload workflows. Fig. 2 illustrates our three-step (lwu)* approach. 1 : A window of interest of hot CSV files is loaded from a NAS/DFS or a local high-performance SSD/RAID",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/b08cd880-a755-49fc-bca7-188b681587ef.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=4fa81af6e6fe990e422ac6ab09ac93241e285b37f9f63b782007cbdcbc81ab1a",
            "html": "<p>Data staging workflows exist in eScience (e.g., astronomy and genetics [27, 26]) and other big data analytics appli- cations. For example, Netflix, a popular on-demand media streaming service, reported that they are collecting 0.6 TB of CSV-like log data in a DFS per day [11]. Each hour, the last hour’s structured log data is loaded to a 50+ node Hadoop/Hive-based data warehouse, which is used for the extraction of performance indicators and for ad-hoc queries. Our vision is to use Instant Loading in a single-node main memory database for these kinds of recurring load-work- unload workflows. Fig. 2 illustrates our three-step (lwu)* approach. 1 : A window of interest of hot CSV files is loaded from a NAS/DFS or a local high-performance SSD/RAID</p>",
            "markdown": "Data staging workflows exist in eScience (e.g., astronomy and genetics [27, 26]) and other big data analytics appli- cations. For example, Netflix, a popular on-demand media streaming service, reported that they are collecting 0.6 TB of CSV-like log data in a DFS per day [11]. Each hour, the last hour’s structured log data is loaded to a 50+ node Hadoop/Hive-based data warehouse, which is used for the extraction of performance indicators and for ad-hoc queries. Our vision is to use Instant Loading in a single-node main memory database for these kinds of recurring load-work- unload workflows. Fig. 2 illustrates our three-step (lwu)* approach. 1 : A window of interest of hot CSV files is loaded from a NAS/DFS or a local high-performance SSD/RAID\n\n"
          },
          {
            "segment_id": "6b79b632-73d0-493b-9afd-577232c87f99",
            "bbox": {
              "left": 669.8333,
              "top": 117.74999,
              "width": 464.49997,
              "height": 270.75
            },
            "page_number": 2,
            "page_width": 1275,
            "page_height": 1650,
            "content": "1,Africa\\n 2,Antarctica\\n 3,Asia\\n 4,Australia\\n 5,Europe\\n 6,North America\\n 7,South America\\n (a) CSV id name 1 Africa 2 Antarctica 3 Asia 4 Australia 5 Europe 6 North America 7 South America (b) relational 1 Africa 2 Antarctica 3 Asia 4 Australia vector chunk Partition 1 Partition 2 5 Europe 6 North America 7 South America (c) physical (chunk-based column-store)",
            "segment_type": "Picture",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6b79b632-73d0-493b-9afd-577232c87f99.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=b89d914e5757e432a28433b817447a415fc7e30a4201476e1159173c42727294",
            "html": "<img src=\"https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6b79b632-73d0-493b-9afd-577232c87f99.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=b89d914e5757e432a28433b817447a415fc7e30a4201476e1159173c42727294\" />",
            "markdown": "![Image](https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6b79b632-73d0-493b-9afd-577232c87f99.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=b89d914e5757e432a28433b817447a415fc7e30a4201476e1159173c42727294)"
          },
          {
            "segment_id": "78a8aa42-5fbf-432a-90d5-6436c33dfc5a",
            "bbox": {
              "left": 657.3333,
              "top": 403.16666,
              "width": 501.99997,
              "height": 39.5
            },
            "page_number": 2,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Figure 3: Continent names in three representations: (a) CSV, (b) relational, and (c) physical.",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/78a8aa42-5fbf-432a-90d5-6436c33dfc5a.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c13a816505d7833adf1022006d77fed419305a08762be47b4b30971dd7846017",
            "html": "<span class=\"caption\">Figure 3: Continent names in three representations: (a) CSV, (b) relational, and (c) physical.</span>",
            "markdown": "Figure 3: Continent names in three representations: (a) CSV, (b) relational, and (c) physical.\n\n"
          },
          {
            "segment_id": "fac0b671-fbe9-4f7b-a7e0-9b40e68114c5",
            "bbox": {
              "left": 657.3333,
              "top": 476.0833,
              "width": 501.99997,
              "height": 256.16666
            },
            "page_number": 2,
            "page_width": 1275,
            "page_height": 1650,
            "content": "to a main memory database at wire speed. The window of interest can even be bigger than the size of the main memory as selection predicates can be pushed into the loading pro- cess. Further, data can be compressed at load time. 2 : The full set of features of a relational main memory database— including efficient support for queries (OLAP) and transac- tional updates (OLTP)—can then be used by multiple users to work on the window of interest. 3 : Prior to loading new data, the potentially modified data is unloaded in either a (compressed) binary format or, for portability and debuga- bility, as CSV. Instant Loading is the essential backbone that facilitates the (lwu)* approach.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/fac0b671-fbe9-4f7b-a7e0-9b40e68114c5.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=786a5a231e5948b4a28610f04ab789fcce539e81a35d046cfddb383477ae37b9",
            "html": "<p>to a main memory database at wire speed. The window of interest can even be bigger than the size of the main memory as selection predicates can be pushed into the loading pro- cess. Further, data can be compressed at load time. 2 : The full set of features of a relational main memory database— including efficient support for queries (OLAP) and transac- tional updates (OLTP)—can then be used by multiple users to work on the window of interest. 3 : Prior to loading new data, the potentially modified data is unloaded in either a (compressed) binary format or, for portability and debuga- bility, as CSV. Instant Loading is the essential backbone that facilitates the (lwu)* approach.</p>",
            "markdown": "to a main memory database at wire speed. The window of interest can even be bigger than the size of the main memory as selection predicates can be pushed into the loading pro- cess. Further, data can be compressed at load time. 2 : The full set of features of a relational main memory database— including efficient support for queries (OLAP) and transac- tional updates (OLTP)—can then be used by multiple users to work on the window of interest. 3 : Prior to loading new data, the potentially modified data is unloaded in either a (compressed) binary format or, for portability and debuga- bility, as CSV. Instant Loading is the essential backbone that facilitates the (lwu)* approach.\n\n"
          }
        ],
        "chunk_length": 392
      },
      {
        "segments": [
          {
            "segment_id": "353175a6-4901-4f40-9374-da7624320dfa",
            "bbox": {
              "left": 657.3333,
              "top": 740.6666,
              "width": 501.99997,
              "height": 433.24997
            },
            "page_number": 2,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Comparison to MapReduce approaches. Google’s MapReduce [5] (MR) and its open-source implementation Hadoop brought along new analysis approaches for struc- tured text files. While we focus on analyzing such files on a single node, these approaches scale jobs out to a clus- ter of nodes. By working on raw files, MR requires no ex- plicit loading like relational databases. On the downside, a comparison of databases and MR [23] has shown that databases are, in general, much easier to query and sig- nificantly faster at data analysis. Extensions of MR and Hadoop like Hive [28] and HAIL [7] try to close this gap by, e.g., adding support for declarative query languages, in- dexes, and data preprocessing. As for comparison of MR with our approach, Instant Loading in its current state aims at accelerating bulk loading on a single database node— that could be part of a cluster of servers. We see scaleout of query and transaction processing as an orthogonal direction of research. Nevertheless, MR-based systems can as well profit from the generic high-performance CSV parsing and deserialization methods proposed in this work.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/353175a6-4901-4f40-9374-da7624320dfa.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=05d123642760b76344103143dd62bb1fc53c267f405a22f136435a04f5cc2d43",
            "html": "<p>Comparison to MapReduce approaches. Google’s MapReduce [5] (MR) and its open-source implementation Hadoop brought along new analysis approaches for struc- tured text files. While we focus on analyzing such files on a single node, these approaches scale jobs out to a clus- ter of nodes. By working on raw files, MR requires no ex- plicit loading like relational databases. On the downside, a comparison of databases and MR [23] has shown that databases are, in general, much easier to query and sig- nificantly faster at data analysis. Extensions of MR and Hadoop like Hive [28] and HAIL [7] try to close this gap by, e.g., adding support for declarative query languages, in- dexes, and data preprocessing. As for comparison of MR with our approach, Instant Loading in its current state aims at accelerating bulk loading on a single database node— that could be part of a cluster of servers. We see scaleout of query and transaction processing as an orthogonal direction of research. Nevertheless, MR-based systems can as well profit from the generic high-performance CSV parsing and deserialization methods proposed in this work.</p>",
            "markdown": "Comparison to MapReduce approaches. Google’s MapReduce [5] (MR) and its open-source implementation Hadoop brought along new analysis approaches for struc- tured text files. While we focus on analyzing such files on a single node, these approaches scale jobs out to a clus- ter of nodes. By working on raw files, MR requires no ex- plicit loading like relational databases. On the downside, a comparison of databases and MR [23] has shown that databases are, in general, much easier to query and sig- nificantly faster at data analysis. Extensions of MR and Hadoop like Hive [28] and HAIL [7] try to close this gap by, e.g., adding support for declarative query languages, in- dexes, and data preprocessing. As for comparison of MR with our approach, Instant Loading in its current state aims at accelerating bulk loading on a single database node— that could be part of a cluster of servers. We see scaleout of query and transaction processing as an orthogonal direction of research. Nevertheless, MR-based systems can as well profit from the generic high-performance CSV parsing and deserialization methods proposed in this work.\n\n"
          }
        ],
        "chunk_length": 183
      },
      {
        "segments": [
          {
            "segment_id": "59ee73e4-c0f5-4a26-b5fc-935f78b5c865",
            "bbox": {
              "left": 659.4166,
              "top": 1203.1666,
              "width": 356.16666,
              "height": 22.833332
            },
            "page_number": 2,
            "page_width": 1275,
            "page_height": 1650,
            "content": "2. DATA REPRESENTATIONS",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/59ee73e4-c0f5-4a26-b5fc-935f78b5c865.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=aaab5f2af4460a6a67bb915d2024cc0b8e8d16d4dcf88b4f0d62575a0e7bd12f",
            "html": "<h2>2. DATA REPRESENTATIONS</h2>",
            "markdown": "## 2. DATA REPRESENTATIONS\n\n"
          },
          {
            "segment_id": "ef067f1e-af92-454e-b681-2c86d4d632c9",
            "bbox": {
              "left": 657.3333,
              "top": 1232.3333,
              "width": 501.99997,
              "height": 106.166664
            },
            "page_number": 2,
            "page_width": 1275,
            "page_height": 1650,
            "content": "An important part of bulk loading is the transformation and reorganization of data from one format into another. This paper focuses on the comma separated values (CSV), relational, and common physical representations in main memory database systems; Fig. 3 illustrates these three.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ef067f1e-af92-454e-b681-2c86d4d632c9.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=75c39fb633675bdf06a576d83ac15c97524eac191ebf8a28453f5e2e7d70785a",
            "html": "<p>An important part of bulk loading is the transformation and reorganization of data from one format into another. This paper focuses on the comma separated values (CSV), relational, and common physical representations in main memory database systems; Fig. 3 illustrates these three.</p>",
            "markdown": "An important part of bulk loading is the transformation and reorganization of data from one format into another. This paper focuses on the comma separated values (CSV), relational, and common physical representations in main memory database systems; Fig. 3 illustrates these three.\n\n"
          },
          {
            "segment_id": "9f3e43d1-3967-4c15-9417-814393254a97",
            "bbox": {
              "left": 657.3333,
              "top": 1346.9166,
              "width": 501.99997,
              "height": 149.91666
            },
            "page_number": 2,
            "page_width": 1275,
            "page_height": 1650,
            "content": "CSV representation. CSV is a simple, yet widely used data format that represents tabular data as a sequence of characters in a human readable format. It is in many cases the least common denominator of information exchange. As such, tera-scale archives of CSV and CSV-like data exist in eScience and other big data analytics applications [27, 26, 25]. Physically, each character is encoded in one or several",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/9f3e43d1-3967-4c15-9417-814393254a97.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=195d8d7ce338cf2ec4f8b8fe031d365e298afebb1022cba63e4950b8d85902f3",
            "html": "<p>CSV representation. CSV is a simple, yet widely used data format that represents tabular data as a sequence of characters in a human readable format. It is in many cases the least common denominator of information exchange. As such, tera-scale archives of CSV and CSV-like data exist in eScience and other big data analytics applications [27, 26, 25]. Physically, each character is encoded in one or several</p>",
            "markdown": "CSV representation. CSV is a simple, yet widely used data format that represents tabular data as a sequence of characters in a human readable format. It is in many cases the least common denominator of information exchange. As such, tera-scale archives of CSV and CSV-like data exist in eScience and other big data analytics applications [27, 26, 25]. Physically, each character is encoded in one or several\n\n"
          },
          {
            "segment_id": "cdfc809b-d38e-42f3-9830-945fd11b4493",
            "bbox": {
              "left": 109.416664,
              "top": 117.74999,
              "width": 501.99997,
              "height": 474.91666
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "bytes of a character encoding scheme, commonly ASCII or UTF-8. ASCII is a subset of UTF-8, where the 128 ASCII characters correspond to the first 128 UTF-8 characters. ASCII characters are stored in a single byte where the high bit is not set. Other characters in UTF-8 are represented by sequences of up to 6 bytes where for each byte the high bit is set. Thus, an ASCII byte cannot be part of a multi-byte sequence that represents a UTF-8 character. Even though CSV is widely used, it has never been fully standardized. A first approach in this direction is the RFC 4180 [30] proposal which closely resembles our understanding of CSV. Data is structured in records, which are separated by a record delim- iter (usually ’ \\ n’ or \" \\ r \\ n\" ). Each record contains fields, which are again separated by a field delimiter (e.g., ’,’ ). Fields can be quoted, i.e., enclosed by a quotation character (e.g., ’\"’ ). Inside a quoted field, record and field delimiters are not treated as such. Quotation characters that are part of a quoted field have to be escaped by an escape charac- ter (e.g., ’ \\ ’ ). If the aforementioned special characters are user-definable, the CSV format is highly portable. Due to its tabular form, it can naturally represent relations, where tuples and attribute values are mapped to records and fields.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/cdfc809b-d38e-42f3-9830-945fd11b4493.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=be9aedbe6b2c54498dc26b34b78f7263cecc4de3c416872cfe3a3002ff5d70f5",
            "html": "<p>bytes of a character encoding scheme, commonly ASCII or UTF-8. ASCII is a subset of UTF-8, where the 128 ASCII characters correspond to the first 128 UTF-8 characters. ASCII characters are stored in a single byte where the high bit is not set. Other characters in UTF-8 are represented by sequences of up to 6 bytes where for each byte the high bit is set. Thus, an ASCII byte cannot be part of a multi-byte sequence that represents a UTF-8 character. Even though CSV is widely used, it has never been fully standardized. A first approach in this direction is the RFC 4180 [30] proposal which closely resembles our understanding of CSV. Data is structured in records, which are separated by a record delim- iter (usually ’ \\ n’ or \" \\ r \\ n\" ). Each record contains fields, which are again separated by a field delimiter (e.g., ’,’ ). Fields can be quoted, i.e., enclosed by a quotation character (e.g., ’\"’ ). Inside a quoted field, record and field delimiters are not treated as such. Quotation characters that are part of a quoted field have to be escaped by an escape charac- ter (e.g., ’ \\ ’ ). If the aforementioned special characters are user-definable, the CSV format is highly portable. Due to its tabular form, it can naturally represent relations, where tuples and attribute values are mapped to records and fields.</p>",
            "markdown": "bytes of a character encoding scheme, commonly ASCII or UTF-8. ASCII is a subset of UTF-8, where the 128 ASCII characters correspond to the first 128 UTF-8 characters. ASCII characters are stored in a single byte where the high bit is not set. Other characters in UTF-8 are represented by sequences of up to 6 bytes where for each byte the high bit is set. Thus, an ASCII byte cannot be part of a multi-byte sequence that represents a UTF-8 character. Even though CSV is widely used, it has never been fully standardized. A first approach in this direction is the RFC 4180 [30] proposal which closely resembles our understanding of CSV. Data is structured in records, which are separated by a record delim- iter (usually ’ \\ n’ or \" \\ r \\ n\" ). Each record contains fields, which are again separated by a field delimiter (e.g., ’,’ ). Fields can be quoted, i.e., enclosed by a quotation character (e.g., ’\"’ ). Inside a quoted field, record and field delimiters are not treated as such. Quotation characters that are part of a quoted field have to be escaped by an escape charac- ter (e.g., ’ \\ ’ ). If the aforementioned special characters are user-definable, the CSV format is highly portable. Due to its tabular form, it can naturally represent relations, where tuples and attribute values are mapped to records and fields.\n\n"
          },
          {
            "segment_id": "2cd994d6-b613-4a75-b5e6-a49f40096edc",
            "bbox": {
              "left": 109.416664,
              "top": 601.0833,
              "width": 501.99997,
              "height": 389.5
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Physical representations. Databases store relations in a storage backend that is optimized for efficient update and query processing. In our HyPer main memory database system, a relation can be stored in a row- or a column- store backend. A storage backend is structured in par- titions, which horizontally split the relation into disjoint subsets. These partitons store the rows or columns in ei- ther contiguous blocks of memory or are again horizontally partitioned into multiple chunks ( chunked backend , cf., Fig 3(c)), a technique first proposed by MonetDB/X100 [4]. The combination of these options gives four possibile types of storage backends: contiguous memory-based/chunked row- /column-store. Most, if not all, main memory database sys- tems, including MonetDB, Vectorwise, and SAP HANA im- plement similar storage backends. Instant Loading is de- signed for all of the aforementioned types of storage back- ends and is therefore a generic approach that can be inte- grated into various main memory database systems.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/2cd994d6-b613-4a75-b5e6-a49f40096edc.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=6a7a7f10c5b4332a576b79028633df7b0a1307332480def95a016aa61521a0d6",
            "html": "<p>Physical representations. Databases store relations in a storage backend that is optimized for efficient update and query processing. In our HyPer main memory database system, a relation can be stored in a row- or a column- store backend. A storage backend is structured in par- titions, which horizontally split the relation into disjoint subsets. These partitons store the rows or columns in ei- ther contiguous blocks of memory or are again horizontally partitioned into multiple chunks ( chunked backend , cf., Fig 3(c)), a technique first proposed by MonetDB/X100 [4]. The combination of these options gives four possibile types of storage backends: contiguous memory-based/chunked row- /column-store. Most, if not all, main memory database sys- tems, including MonetDB, Vectorwise, and SAP HANA im- plement similar storage backends. Instant Loading is de- signed for all of the aforementioned types of storage back- ends and is therefore a generic approach that can be inte- grated into various main memory database systems.</p>",
            "markdown": "Physical representations. Databases store relations in a storage backend that is optimized for efficient update and query processing. In our HyPer main memory database system, a relation can be stored in a row- or a column- store backend. A storage backend is structured in par- titions, which horizontally split the relation into disjoint subsets. These partitons store the rows or columns in ei- ther contiguous blocks of memory or are again horizontally partitioned into multiple chunks ( chunked backend , cf., Fig 3(c)), a technique first proposed by MonetDB/X100 [4]. The combination of these options gives four possibile types of storage backends: contiguous memory-based/chunked row- /column-store. Most, if not all, main memory database sys- tems, including MonetDB, Vectorwise, and SAP HANA im- plement similar storage backends. Instant Loading is de- signed for all of the aforementioned types of storage back- ends and is therefore a generic approach that can be inte- grated into various main memory database systems.\n\n"
          }
        ],
        "chunk_length": 504
      },
      {
        "segments": [
          {
            "segment_id": "d0eb03a7-0068-498b-8aa2-8950e4656535",
            "bbox": {
              "left": 109.416664,
              "top": 994.8333,
              "width": 499.91666,
              "height": 60.333332
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "This work focuses on bulk loading to uncompressed phys- ical representations. Dictionary encoding can, however, be used in the CSV data or created on the fly at load time.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/d0eb03a7-0068-498b-8aa2-8950e4656535.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a594bf54545f7f36e6c7134849aa1aea24a5e2300bce78bac83d3e9a531e101b",
            "html": "<p>This work focuses on bulk loading to uncompressed phys- ical representations. Dictionary encoding can, however, be used in the CSV data or created on the fly at load time.</p>",
            "markdown": "This work focuses on bulk loading to uncompressed phys- ical representations. Dictionary encoding can, however, be used in the CSV data or created on the fly at load time.\n\n"
          }
        ],
        "chunk_length": 29
      },
      {
        "segments": [
          {
            "segment_id": "0f4ce30b-18b7-4df5-ad9e-fbef32914781",
            "bbox": {
              "left": 109.416664,
              "top": 1084.4166,
              "width": 277,
              "height": 22.833332
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "3. INSTANT LOADING",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/0f4ce30b-18b7-4df5-ad9e-fbef32914781.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=908e721b14b630d9fe7a368987e018b5cdc45ecbcc22af5ed0f73e0413c4146c",
            "html": "<h2>3. INSTANT LOADING</h2>",
            "markdown": "## 3. INSTANT LOADING\n\n"
          },
          {
            "segment_id": "eee87780-9173-4230-b9ec-7cc65a5f1f75",
            "bbox": {
              "left": 109.416664,
              "top": 1119.8333,
              "width": 356.16666,
              "height": 22.833332
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "3.1 CSV Bulk Loading Analysis",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/eee87780-9173-4230-b9ec-7cc65a5f1f75.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e209a974144f15185e2083c76694a42612f3bf4d0515adf816d025a8b9b607bb",
            "html": "<h2>3.1 CSV Bulk Loading Analysis</h2>",
            "markdown": "## 3.1 CSV Bulk Loading Analysis\n\n"
          },
          {
            "segment_id": "f1511782-a8ea-4937-bdcc-2b913c0a4957",
            "bbox": {
              "left": 109.416664,
              "top": 1151.0833,
              "width": 499.91666,
              "height": 256.16666
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "To better understand how bulk loading of CSV data on modern hardware can be optimized, we first analyzed why it currently cannot saturate available wire speeds. The stan- dard single-threaded implementation of CSV bulk loading in our HyPer [19] main memory database system achieves a loading throughput of around 100 MB/s for 10 GB of CSV data stored in an in-memory file system 1 . This is compara- ble to the CSV loading throughput of other state of the art main memory databases like MonetDB [4] and Vectorwise, which we also evaluated. The measured loading throughputs of 100 MB/s, however, do not saturate the available wire speed of the in-memory file system. In fact, not even a SSD",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/f1511782-a8ea-4937-bdcc-2b913c0a4957.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=ee684d6771ff816bda1d9e4e1e855b3dd3a90390fda88e35ddf60a5aca09a088",
            "html": "<p>To better understand how bulk loading of CSV data on modern hardware can be optimized, we first analyzed why it currently cannot saturate available wire speeds. The stan- dard single-threaded implementation of CSV bulk loading in our HyPer [19] main memory database system achieves a loading throughput of around 100 MB/s for 10 GB of CSV data stored in an in-memory file system 1 . This is compara- ble to the CSV loading throughput of other state of the art main memory databases like MonetDB [4] and Vectorwise, which we also evaluated. The measured loading throughputs of 100 MB/s, however, do not saturate the available wire speed of the in-memory file system. In fact, not even a SSD</p>",
            "markdown": "To better understand how bulk loading of CSV data on modern hardware can be optimized, we first analyzed why it currently cannot saturate available wire speeds. The stan- dard single-threaded implementation of CSV bulk loading in our HyPer [19] main memory database system achieves a loading throughput of around 100 MB/s for 10 GB of CSV data stored in an in-memory file system 1 . This is compara- ble to the CSV loading throughput of other state of the art main memory databases like MonetDB [4] and Vectorwise, which we also evaluated. The measured loading throughputs of 100 MB/s, however, do not saturate the available wire speed of the in-memory file system. In fact, not even a SSD\n\n"
          },
          {
            "segment_id": "7f60fd27-7a5e-4f6b-a2a9-3d2dca210820",
            "bbox": {
              "left": 657.3333,
              "top": 117.74999,
              "width": 501.99997,
              "height": 83.25
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "(500 MB/s) or 1 GbE (128 MB/s) can be saturated. A perf analysis shows that about 50% of CPU cycles are spent on parsing the input, 20% on deserialization, 10% on inserting tuples into the relation, and finally 20% on updating indexes.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/7f60fd27-7a5e-4f6b-a2a9-3d2dca210820.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=02cb0cc5cfeef00afa6da0edd1e37928017628bf21037bb115ef2abfcb9b50cf",
            "html": "<p>(500 MB/s) or 1 GbE (128 MB/s) can be saturated. A perf analysis shows that about 50% of CPU cycles are spent on parsing the input, 20% on deserialization, 10% on inserting tuples into the relation, and finally 20% on updating indexes.</p>",
            "markdown": "(500 MB/s) or 1 GbE (128 MB/s) can be saturated. A perf analysis shows that about 50% of CPU cycles are spent on parsing the input, 20% on deserialization, 10% on inserting tuples into the relation, and finally 20% on updating indexes.\n\n"
          },
          {
            "segment_id": "32fb1210-23b9-44da-9808-83e123a3733c",
            "bbox": {
              "left": 657.3333,
              "top": 203.16666,
              "width": 501.99997,
              "height": 237.41666
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "In our standard approach, parsing is expensive as it is based on a character at a time comparison of CSV input and special characters, where each comparison is implemented as an if-then conditional branch. Due to their pipelined ar- chitecture, current general purpose CPUs try to predict the outcome of such branches. Thereby, a mispredicted branch requires the entire pipeline to be flushed and ever deeper pipelines in modern CPUs lead to huge branch miss penal- ties [2]. For CSV parsing, however, the comparison branches can hardly be predicted, which leads to almost one mispre- diction per field and record delimiter of the CSV input.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/32fb1210-23b9-44da-9808-83e123a3733c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0d25013ba9a5d4570c4d4f2a75c616da6847d324bf26baf229f0a870e53e2b85",
            "html": "<p>In our standard approach, parsing is expensive as it is based on a character at a time comparison of CSV input and special characters, where each comparison is implemented as an if-then conditional branch. Due to their pipelined ar- chitecture, current general purpose CPUs try to predict the outcome of such branches. Thereby, a mispredicted branch requires the entire pipeline to be flushed and ever deeper pipelines in modern CPUs lead to huge branch miss penal- ties [2]. For CSV parsing, however, the comparison branches can hardly be predicted, which leads to almost one mispre- diction per field and record delimiter of the CSV input.</p>",
            "markdown": "In our standard approach, parsing is expensive as it is based on a character at a time comparison of CSV input and special characters, where each comparison is implemented as an if-then conditional branch. Due to their pipelined ar- chitecture, current general purpose CPUs try to predict the outcome of such branches. Thereby, a mispredicted branch requires the entire pipeline to be flushed and ever deeper pipelines in modern CPUs lead to huge branch miss penal- ties [2]. For CSV parsing, however, the comparison branches can hardly be predicted, which leads to almost one mispre- diction per field and record delimiter of the CSV input.\n\n"
          },
          {
            "segment_id": "73c3d4b9-ec6f-48db-bf04-8e0ef6ed7496",
            "bbox": {
              "left": 657.3333,
              "top": 444.8333,
              "width": 501.99997,
              "height": 104.08333
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Each value found by the parser needs to be deserialized. The deserialization method validates the string input and transforms the string value into its data type representation in the database. Again, several conditional branches lead to a significant number of branch miss penalties.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/73c3d4b9-ec6f-48db-bf04-8e0ef6ed7496.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f112331d446c58ead111f79fd9b31ee70498c395143a984f873b666814ab0460",
            "html": "<p>Each value found by the parser needs to be deserialized. The deserialization method validates the string input and transforms the string value into its data type representation in the database. Again, several conditional branches lead to a significant number of branch miss penalties.</p>",
            "markdown": "Each value found by the parser needs to be deserialized. The deserialization method validates the string input and transforms the string value into its data type representation in the database. Again, several conditional branches lead to a significant number of branch miss penalties.\n\n"
          },
          {
            "segment_id": "bbd4db2a-786d-4ca7-a451-b5b31424134e",
            "bbox": {
              "left": 657.3333,
              "top": 553.1666,
              "width": 501.99997,
              "height": 170.75
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Parsed and deserialized tuples are inserted into the rela- tion and are indexed in the relation’s indexes. Inserting and indexing of tuples accounts for 30% of loading time and is not the bottleneck in our standard loading approach. In- stead, our experiment revealed that the insertion and in- dexing speed of HyPer’s partitioned column-store backend exceeds the speed at which standard parsing and deserial- ization methods are able to produce new tuples.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/bbd4db2a-786d-4ca7-a451-b5b31424134e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=6b8716d4b97e40ec0c4274ead06a6c9f886cb75aa31c13e1682df2b81ec12a8f",
            "html": "<p>Parsed and deserialized tuples are inserted into the rela- tion and are indexed in the relation’s indexes. Inserting and indexing of tuples accounts for 30% of loading time and is not the bottleneck in our standard loading approach. In- stead, our experiment revealed that the insertion and in- dexing speed of HyPer’s partitioned column-store backend exceeds the speed at which standard parsing and deserial- ization methods are able to produce new tuples.</p>",
            "markdown": "Parsed and deserialized tuples are inserted into the rela- tion and are indexed in the relation’s indexes. Inserting and indexing of tuples accounts for 30% of loading time and is not the bottleneck in our standard loading approach. In- stead, our experiment revealed that the insertion and in- dexing speed of HyPer’s partitioned column-store backend exceeds the speed at which standard parsing and deserial- ization methods are able to produce new tuples.\n\n"
          }
        ],
        "chunk_length": 388
      },
      {
        "segments": [
          {
            "segment_id": "9632d5dc-78da-413c-b5d9-d8d94e58259c",
            "bbox": {
              "left": 657.3333,
              "top": 751.0833,
              "width": 466.5833,
              "height": 22.833332
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "3.2 Design of the Instant Loading Pipeline",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/9632d5dc-78da-413c-b5d9-d8d94e58259c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8b82acb79b80fcdaab2a4dd1705adf0700c337d320ab2ad7d5f492d82924f078",
            "html": "<h2>3.2 Design of the Instant Loading Pipeline</h2>",
            "markdown": "## 3.2 Design of the Instant Loading Pipeline\n\n"
          },
          {
            "segment_id": "7a4f9174-6356-4083-af8f-1fb0fd674201",
            "bbox": {
              "left": 657.3333,
              "top": 780.25,
              "width": 501.99997,
              "height": 126.99999
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "The aforementioned standard CSV bulk loading approach follows a single-threaded execution model. To fully exploit the performance of modern super-scalar multi-core CPUs, applications need to be highly parallelized [17]. Following Amdahl’s law the proportion of sequential code needs to be reduced to a minimum to achieve maximum speedup.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/7a4f9174-6356-4083-af8f-1fb0fd674201.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=9f45243deb4b18033942d321c7c1e8789a380502fedf23dc8fe1282ddb3d2545",
            "html": "<p>The aforementioned standard CSV bulk loading approach follows a single-threaded execution model. To fully exploit the performance of modern super-scalar multi-core CPUs, applications need to be highly parallelized [17]. Following Amdahl’s law the proportion of sequential code needs to be reduced to a minimum to achieve maximum speedup.</p>",
            "markdown": "The aforementioned standard CSV bulk loading approach follows a single-threaded execution model. To fully exploit the performance of modern super-scalar multi-core CPUs, applications need to be highly parallelized [17]. Following Amdahl’s law the proportion of sequential code needs to be reduced to a minimum to achieve maximum speedup.\n\n"
          },
          {
            "segment_id": "0de52b92-9abb-484c-8c12-ea4f505d4318",
            "bbox": {
              "left": 657.3333,
              "top": 911.49994,
              "width": 501.99997,
              "height": 193.66666
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "We base our implementation of Instant Loading on the programming model of the Intel Threading Building Blocks (TBB) [24] library. In TBB, parallelism is exposed by the definition of tasks rather than threads. Tasks are dynami- cally scheduled and executed on available hardware threads by a run-time engine. The engine implements task stealing for workload balancing and reuses threads to avoid initial- ization overhead. Task-based programming allows to expose parallelism to a great extent.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/0de52b92-9abb-484c-8c12-ea4f505d4318.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=4da544a70d9b429b327019b9c9f6cc7c134ed8a8c2828b5f4c03b86cedd09e44",
            "html": "<p>We base our implementation of Instant Loading on the programming model of the Intel Threading Building Blocks (TBB) [24] library. In TBB, parallelism is exposed by the definition of tasks rather than threads. Tasks are dynami- cally scheduled and executed on available hardware threads by a run-time engine. The engine implements task stealing for workload balancing and reuses threads to avoid initial- ization overhead. Task-based programming allows to expose parallelism to a great extent.</p>",
            "markdown": "We base our implementation of Instant Loading on the programming model of the Intel Threading Building Blocks (TBB) [24] library. In TBB, parallelism is exposed by the definition of tasks rather than threads. Tasks are dynami- cally scheduled and executed on available hardware threads by a run-time engine. The engine implements task stealing for workload balancing and reuses threads to avoid initial- ization overhead. Task-based programming allows to expose parallelism to a great extent.\n\n"
          },
          {
            "segment_id": "1b90e742-4fcb-4848-942d-f04c24d0206d",
            "bbox": {
              "left": 657.3333,
              "top": 1107.3333,
              "width": 501.99997,
              "height": 389.5
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Instant Loading is designed for high scalability and pro- ceeds in two steps (see Fig. 4). 1 st, CSV input is chunked and CSV chunks are processed by unsynchronized tasks. Each task parses and deserializes the tuples in its chunk. It further determines a tuple’s corresponding partition (see Sect. 2 for a description of our partitioned storage backend) and stores tuples that belong to the same partition in a com- mon buffer which we refer to as a partition buffer. Partition buffers have the same physical layout (e.g., row or colum- nar) as the relation partition, such that no further transfor- mation is necessary when inserting tuples from the buffer into the relation partition. Additionally, tuples in partition buffers are indexed according to the indexes defined for the relation. In a 2 nd step, partition buffers are merged with the corresponding relation partitions. This includes merg- ing of tuples and indexes. While CSV chunk processing is performed in parallel for each CSV chunk, merging with re- lation partitions is performed in parallel for each partition.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/1b90e742-4fcb-4848-942d-f04c24d0206d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2619d13079846222d9efea09bb439c82bb277a015e5ebd3040ed126295e656c8",
            "html": "<p>Instant Loading is designed for high scalability and pro- ceeds in two steps (see Fig. 4). 1 st, CSV input is chunked and CSV chunks are processed by unsynchronized tasks. Each task parses and deserializes the tuples in its chunk. It further determines a tuple’s corresponding partition (see Sect. 2 for a description of our partitioned storage backend) and stores tuples that belong to the same partition in a com- mon buffer which we refer to as a partition buffer. Partition buffers have the same physical layout (e.g., row or colum- nar) as the relation partition, such that no further transfor- mation is necessary when inserting tuples from the buffer into the relation partition. Additionally, tuples in partition buffers are indexed according to the indexes defined for the relation. In a 2 nd step, partition buffers are merged with the corresponding relation partitions. This includes merg- ing of tuples and indexes. While CSV chunk processing is performed in parallel for each CSV chunk, merging with re- lation partitions is performed in parallel for each partition.</p>",
            "markdown": "Instant Loading is designed for high scalability and pro- ceeds in two steps (see Fig. 4). 1 st, CSV input is chunked and CSV chunks are processed by unsynchronized tasks. Each task parses and deserializes the tuples in its chunk. It further determines a tuple’s corresponding partition (see Sect. 2 for a description of our partitioned storage backend) and stores tuples that belong to the same partition in a com- mon buffer which we refer to as a partition buffer. Partition buffers have the same physical layout (e.g., row or colum- nar) as the relation partition, such that no further transfor- mation is necessary when inserting tuples from the buffer into the relation partition. Additionally, tuples in partition buffers are indexed according to the indexes defined for the relation. In a 2 nd step, partition buffers are merged with the corresponding relation partitions. This includes merg- ing of tuples and indexes. While CSV chunk processing is performed in parallel for each CSV chunk, merging with re- lation partitions is performed in parallel for each partition.\n\n"
          },
          {
            "segment_id": "0e3a6209-4cbb-4f33-b9c8-af6b3db8319b",
            "bbox": {
              "left": 109.416664,
              "top": 1421.9166,
              "width": 499.91666,
              "height": 74.916664
            },
            "page_number": 3,
            "page_width": 1275,
            "page_height": 1650,
            "content": "1 For lack of a high-speed network-attached storage or dis- tributed file system in our lab, we used the in-memory file system ramfs as the loading source to emulate a CSV source wire speed of multiple GB/s.",
            "segment_type": "Footnote",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/0e3a6209-4cbb-4f33-b9c8-af6b3db8319b.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e7ffabedba18f4aba4002959a16b336dfd6848ded374107d25d402ead5c777ad",
            "html": "<span class=\"footnote\">1 For lack of a high-speed network-attached storage or dis- tributed file system in our lab, we used the in-memory file system ramfs as the loading source to emulate a CSV source wire speed of multiple GB/s.</span>",
            "markdown": "1 For lack of a high-speed network-attached storage or dis- tributed file system in our lab, we used the in-memory file system ramfs as the loading source to emulate a CSV source wire speed of multiple GB/s.\n\n"
          },
          {
            "segment_id": "ac543786-0b44-440a-8254-dcc8a9184ae6",
            "bbox": {
              "left": 136.5,
              "top": 105.24999,
              "width": 989.49994,
              "height": 218.66666
            },
            "page_number": 4,
            "page_width": 1275,
            "page_height": 1650,
            "content": "buffer 1 chunk n Relation Partition 1 Partition m buffer 1 buffer m ... ... chunk n ... chunk 1 chunk 2 Merge buffers with relation partitions: merge tuples and indexes (partition-parallel) task 1 task m 1 2 Process CSV chunks: determine orphan and parse, deserialize, partition, index each tuple (chunk-parallel) chunk 2 chunk 1 task 1 widow orphan CSV input  . \\n 3 , A s i a \\n 4 , A u s t r a l i a \\n 5 , ... ... ... task 2 task n buffer 1 buffer m buffer m",
            "segment_type": "Picture",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ac543786-0b44-440a-8254-dcc8a9184ae6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=74aec00ba98d0a70c4d8ebc045e8ede1a9a5b2d313ad7b0a23c57d665759a16d",
            "html": "<img src=\"https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ac543786-0b44-440a-8254-dcc8a9184ae6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=74aec00ba98d0a70c4d8ebc045e8ede1a9a5b2d313ad7b0a23c57d665759a16d\" />",
            "markdown": "![Image](https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ac543786-0b44-440a-8254-dcc8a9184ae6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=74aec00ba98d0a70c4d8ebc045e8ede1a9a5b2d313ad7b0a23c57d665759a16d)"
          },
          {
            "segment_id": "f7f06908-6ec7-4ef6-8d70-8f1f859ee696",
            "bbox": {
              "left": 203.16666,
              "top": 338.5833,
              "width": 862.4166,
              "height": 16.583332
            },
            "page_number": 4,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Figure 4: Schematic overview of Instant Loading: from CSV input to relation partitions.",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/f7f06908-6ec7-4ef6-8d70-8f1f859ee696.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=bd6bdd015b88213554a86173b62240af1675cb0f890053a5e5ac761f0ebc4a78",
            "html": "<span class=\"caption\">Figure 4: Schematic overview of Instant Loading: from CSV input to relation partitions.</span>",
            "markdown": "Figure 4: Schematic overview of Instant Loading: from CSV input to relation partitions.\n\n"
          }
        ],
        "chunk_length": 451
      },
      {
        "segments": [
          {
            "segment_id": "b524174e-da26-46e6-8493-4db82bbd65f6",
            "bbox": {
              "left": 109.416664,
              "top": 380.25,
              "width": 270.75,
              "height": 24.916666
            },
            "page_number": 4,
            "page_width": 1275,
            "page_height": 1650,
            "content": "3.3 Task-Parallelization",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/b524174e-da26-46e6-8493-4db82bbd65f6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=48412951ce49332a924614cf5f91ce4525810b4d707717ecb0009fe9e9e4d6f8",
            "html": "<h2>3.3 Task-Parallelization</h2>",
            "markdown": "## 3.3 Task-Parallelization\n\n"
          },
          {
            "segment_id": "a0e01248-de12-40c9-9147-4b9d262ff250",
            "bbox": {
              "left": 109.416664,
              "top": 411.49997,
              "width": 501.99997,
              "height": 518.6666
            },
            "page_number": 4,
            "page_width": 1275,
            "page_height": 1650,
            "content": "To allow synchronization-free task-parallelization of pars- ing, deserialization, partition classification, and indexing, we split CSV input into independent CSV chunks that can be processed in parallel. The choice of the chunk size granu- larity is challenging and impacts the parallelizability of the bulk loading process. The smaller the chunk size, the more chunk processing and merge steps can be interleaved. How- ever, chunks should not be too small, as otherwise the over- head of dealing with incomplete tuples at chunk borders increases. Instant Loading splits the input according to a size for which it can at least be guaranteed that, assuming the input is well-formed, one complete tuple fits into a CSV chunk. Otherwise, parallelized parsing would be hindered. To identify chunk sizes that allow for high-performance load- ing, we evaluated our Instant Loading implementation with varying chunk sizes (see Fig. 13). The evaluation leads us to the conclusion that on a CPU with a last-level cache of size l and n hardware threads, the highest loading throughput can be achieved with a CSV chunk size in the range of 0 . 25 × l/n to 1 . 0 × l/n . E.g., a good chunk size on a current Intel Ivy Bridge CPU with a 8 MB L3 cache and 8 hardware threads is in the range of 256 kB to 1 MB. When loading from a local I/O device, we use madvise to advise the kernel to prefetch the CSV chunks.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/a0e01248-de12-40c9-9147-4b9d262ff250.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=4fe63122d28390eb040349b363950c517713cdf42c7ceb8cab65ff0c4119d757",
            "html": "<p>To allow synchronization-free task-parallelization of pars- ing, deserialization, partition classification, and indexing, we split CSV input into independent CSV chunks that can be processed in parallel. The choice of the chunk size granu- larity is challenging and impacts the parallelizability of the bulk loading process. The smaller the chunk size, the more chunk processing and merge steps can be interleaved. How- ever, chunks should not be too small, as otherwise the over- head of dealing with incomplete tuples at chunk borders increases. Instant Loading splits the input according to a size for which it can at least be guaranteed that, assuming the input is well-formed, one complete tuple fits into a CSV chunk. Otherwise, parallelized parsing would be hindered. To identify chunk sizes that allow for high-performance load- ing, we evaluated our Instant Loading implementation with varying chunk sizes (see Fig. 13). The evaluation leads us to the conclusion that on a CPU with a last-level cache of size l and n hardware threads, the highest loading throughput can be achieved with a CSV chunk size in the range of 0 . 25 × l/n to 1 . 0 × l/n . E.g., a good chunk size on a current Intel Ivy Bridge CPU with a 8 MB L3 cache and 8 hardware threads is in the range of 256 kB to 1 MB. When loading from a local I/O device, we use madvise to advise the kernel to prefetch the CSV chunks.</p>",
            "markdown": "To allow synchronization-free task-parallelization of pars- ing, deserialization, partition classification, and indexing, we split CSV input into independent CSV chunks that can be processed in parallel. The choice of the chunk size granu- larity is challenging and impacts the parallelizability of the bulk loading process. The smaller the chunk size, the more chunk processing and merge steps can be interleaved. How- ever, chunks should not be too small, as otherwise the over- head of dealing with incomplete tuples at chunk borders increases. Instant Loading splits the input according to a size for which it can at least be guaranteed that, assuming the input is well-formed, one complete tuple fits into a CSV chunk. Otherwise, parallelized parsing would be hindered. To identify chunk sizes that allow for high-performance load- ing, we evaluated our Instant Loading implementation with varying chunk sizes (see Fig. 13). The evaluation leads us to the conclusion that on a CPU with a last-level cache of size l and n hardware threads, the highest loading throughput can be achieved with a CSV chunk size in the range of 0 . 25 × l/n to 1 . 0 × l/n . E.g., a good chunk size on a current Intel Ivy Bridge CPU with a 8 MB L3 cache and 8 hardware threads is in the range of 256 kB to 1 MB. When loading from a local I/O device, we use madvise to advise the kernel to prefetch the CSV chunks.\n\n"
          },
          {
            "segment_id": "6f435811-b0e5-459d-af92-c9c7fe36cba4",
            "bbox": {
              "left": 109.416664,
              "top": 934.4166,
              "width": 501.99997,
              "height": 62.416664
            },
            "page_number": 4,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Chunking CSV input according to a fixed size produces incomplete tuples at CSV chunk borders. We refer to these tuples as widows and orphans (cf., Fig. 4):",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6f435811-b0e5-459d-af92-c9c7fe36cba4.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d28802412610b539317c7fefcc087d0fb18c90fa9a334cd89e7c1055215029a2",
            "html": "<p>Chunking CSV input according to a fixed size produces incomplete tuples at CSV chunk borders. We refer to these tuples as widows and orphans (cf., Fig. 4):</p>",
            "markdown": "Chunking CSV input according to a fixed size produces incomplete tuples at CSV chunk borders. We refer to these tuples as widows and orphans (cf., Fig. 4):\n\n"
          },
          {
            "segment_id": "05c3ad52-e736-4b78-9a8f-6f1ae6a5d9ed",
            "bbox": {
              "left": 109.416664,
              "top": 1003.1666,
              "width": 501.99997,
              "height": 191.58333
            },
            "page_number": 4,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Definition (Widow and orphan). “An orphan has no past, a widow has no future” is a famous mnemonic in typesetting. In typesetting, a widow is a line that ends and an orphan is a line that opens a paragraph and is separated from the rest of the paragraph by a page break, respectively. Chunking CSV input creates a similar effect. A widow of a CSV chunk is an incomplete tuple at the end of a chunk that is separated from the part that would make it complete, i.e., the orphan, by a chunk border.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/05c3ad52-e736-4b78-9a8f-6f1ae6a5d9ed.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=670cbfd9d8c3535fdbdbc9e19424f27d314f8883f427636a678f335507e99ff6",
            "html": "<p>Definition (Widow and orphan). “An orphan has no past, a widow has no future” is a famous mnemonic in typesetting. In typesetting, a widow is a line that ends and an orphan is a line that opens a paragraph and is separated from the rest of the paragraph by a page break, respectively. Chunking CSV input creates a similar effect. A widow of a CSV chunk is an incomplete tuple at the end of a chunk that is separated from the part that would make it complete, i.e., the orphan, by a chunk border.</p>",
            "markdown": "Definition (Widow and orphan). “An orphan has no past, a widow has no future” is a famous mnemonic in typesetting. In typesetting, a widow is a line that ends and an orphan is a line that opens a paragraph and is separated from the rest of the paragraph by a page break, respectively. Chunking CSV input creates a similar effect. A widow of a CSV chunk is an incomplete tuple at the end of a chunk that is separated from the part that would make it complete, i.e., the orphan, by a chunk border.\n\n"
          },
          {
            "segment_id": "60ba9b5e-fbf6-45a3-82f5-10a1286307a3",
            "bbox": {
              "left": 109.416664,
              "top": 1205.25,
              "width": 501.99997,
              "height": 279.0833
            },
            "page_number": 4,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Unfortunately, if chunk borders are chosen according to a fixed size, CSV chunk-processing tasks can no longer dis- tinguish between real record delimiters and record delim- iters inside quoted fields, which are allowed in the RFC pro- posal [30]. It is thus impossible to determine the widow and orphan of a CSV chunk only by analyzing the data in the chunk. However, under the restriction that record delim- iters inside quoted fields need to be escaped, widows and orphans can again be determined. In fact, as many appli- cations produce CSV data that escapes the record delimiter inside quoted fields, we propose two loading options: a fast and a safe mode. The fast mode is intended for files that adhere to the restriction and splits the CSV input according",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/60ba9b5e-fbf6-45a3-82f5-10a1286307a3.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a03036414fc72d5bbd49907ac05b252cf6ec3d92f1506402ff7cfe8d52f45168",
            "html": "<p>Unfortunately, if chunk borders are chosen according to a fixed size, CSV chunk-processing tasks can no longer dis- tinguish between real record delimiters and record delim- iters inside quoted fields, which are allowed in the RFC pro- posal [30]. It is thus impossible to determine the widow and orphan of a CSV chunk only by analyzing the data in the chunk. However, under the restriction that record delim- iters inside quoted fields need to be escaped, widows and orphans can again be determined. In fact, as many appli- cations produce CSV data that escapes the record delimiter inside quoted fields, we propose two loading options: a fast and a safe mode. The fast mode is intended for files that adhere to the restriction and splits the CSV input according</p>",
            "markdown": "Unfortunately, if chunk borders are chosen according to a fixed size, CSV chunk-processing tasks can no longer dis- tinguish between real record delimiters and record delim- iters inside quoted fields, which are allowed in the RFC pro- posal [30]. It is thus impossible to determine the widow and orphan of a CSV chunk only by analyzing the data in the chunk. However, under the restriction that record delim- iters inside quoted fields need to be escaped, widows and orphans can again be determined. In fact, as many appli- cations produce CSV data that escapes the record delimiter inside quoted fields, we propose two loading options: a fast and a safe mode. The fast mode is intended for files that adhere to the restriction and splits the CSV input according\n\n"
          }
        ],
        "chunk_length": 495
      },
      {
        "segments": [
          {
            "segment_id": "22eee2df-d539-46c4-919d-cd86666fbedf",
            "bbox": {
              "left": 657.3333,
              "top": 384.41666,
              "width": 501.99997,
              "height": 279.0833
            },
            "page_number": 4,
            "page_width": 1275,
            "page_height": 1650,
            "content": "to a fixed chunk size. A CSV chunk-processing task initially scans for the first unescaped record delimiter in its chunk 2 and starts processing the chunk data from there. When the task reaches the end of its chunk, it continues processing by reading data from its subsequent chunk until it again finds an unescaped record delimiter. In safe mode, a serial task scans the CSV input and splits it into CSV chunks of at least a certain chunk size. The task keeps track of quotation scopes and splits the input at record delimiters, such that no widows and orphans are created. However, the performance of the safe mode is determined by the speed of the sequential task. For our implementation, at a multiprogramming level of 8, the safe mode is 10% slower than the fast mode.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/22eee2df-d539-46c4-919d-cd86666fbedf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=551fa540a3e78505d7dc0ea7caf6ac806c421d95ff5d09ba03d017fb5091dc78",
            "html": "<p>to a fixed chunk size. A CSV chunk-processing task initially scans for the first unescaped record delimiter in its chunk 2 and starts processing the chunk data from there. When the task reaches the end of its chunk, it continues processing by reading data from its subsequent chunk until it again finds an unescaped record delimiter. In safe mode, a serial task scans the CSV input and splits it into CSV chunks of at least a certain chunk size. The task keeps track of quotation scopes and splits the input at record delimiters, such that no widows and orphans are created. However, the performance of the safe mode is determined by the speed of the sequential task. For our implementation, at a multiprogramming level of 8, the safe mode is 10% slower than the fast mode.</p>",
            "markdown": "to a fixed chunk size. A CSV chunk-processing task initially scans for the first unescaped record delimiter in its chunk 2 and starts processing the chunk data from there. When the task reaches the end of its chunk, it continues processing by reading data from its subsequent chunk until it again finds an unescaped record delimiter. In safe mode, a serial task scans the CSV input and splits it into CSV chunks of at least a certain chunk size. The task keeps track of quotation scopes and splits the input at record delimiters, such that no widows and orphans are created. However, the performance of the safe mode is determined by the speed of the sequential task. For our implementation, at a multiprogramming level of 8, the safe mode is 10% slower than the fast mode.\n\n"
          }
        ],
        "chunk_length": 136
      },
      {
        "segments": [
          {
            "segment_id": "553b7c7f-efc1-4ba5-9a8f-ad3bab813af9",
            "bbox": {
              "left": 657.3333,
              "top": 692.75,
              "width": 199.91666,
              "height": 24.916666
            },
            "page_number": 4,
            "page_width": 1275,
            "page_height": 1650,
            "content": "3.4 Vectorization",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/553b7c7f-efc1-4ba5-9a8f-ad3bab813af9.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=86cb6770910a6add3509232e67fae0f15bce4a4757785e50e6aebb75496b7d75",
            "html": "<h2>3.4 Vectorization</h2>",
            "markdown": "## 3.4 Vectorization\n\n"
          },
          {
            "segment_id": "3acee615-f6fc-492b-8c06-4fe94bd8f111",
            "bbox": {
              "left": 657.3333,
              "top": 724,
              "width": 501.99997,
              "height": 279.0833
            },
            "page_number": 4,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Parsing, i.e., finding delimiters and other special charac- ters, and input validation are commonly based on a char- acter at a time comparison of CSV input with certain spe- cial characters. These comparisons are usually implemented as if-then conditional branches. For efficient processing, current general purpose CPUs need multiple instructions in their instruction pipeline. To fill this pipeline, the hardware tries to predict upcoming branches. However, in the case of parsing and deserialization, this is not efficiently possible, which leads to a significant number of branch miss penal- ties [2]. It is thus desirable to reduce the number of control flow branches in the parsing and deserialization methods. One such possibility is data-parallelization.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/3acee615-f6fc-492b-8c06-4fe94bd8f111.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=b79ab4a8fb4e6db14b57ee670feb2d8e7b87cf394da7c275f4e5f29997bd65a0",
            "html": "<p>Parsing, i.e., finding delimiters and other special charac- ters, and input validation are commonly based on a char- acter at a time comparison of CSV input with certain spe- cial characters. These comparisons are usually implemented as if-then conditional branches. For efficient processing, current general purpose CPUs need multiple instructions in their instruction pipeline. To fill this pipeline, the hardware tries to predict upcoming branches. However, in the case of parsing and deserialization, this is not efficiently possible, which leads to a significant number of branch miss penal- ties [2]. It is thus desirable to reduce the number of control flow branches in the parsing and deserialization methods. One such possibility is data-parallelization.</p>",
            "markdown": "Parsing, i.e., finding delimiters and other special charac- ters, and input validation are commonly based on a char- acter at a time comparison of CSV input with certain spe- cial characters. These comparisons are usually implemented as if-then conditional branches. For efficient processing, current general purpose CPUs need multiple instructions in their instruction pipeline. To fill this pipeline, the hardware tries to predict upcoming branches. However, in the case of parsing and deserialization, this is not efficiently possible, which leads to a significant number of branch miss penal- ties [2]. It is thus desirable to reduce the number of control flow branches in the parsing and deserialization methods. One such possibility is data-parallelization.\n\n"
          },
          {
            "segment_id": "ed7814ed-17c8-4f8d-a41d-09b855616d17",
            "bbox": {
              "left": 657.3333,
              "top": 1007.3333,
              "width": 501.99997,
              "height": 258.25
            },
            "page_number": 4,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Modern general purpose CPUs are super-scalar multi-core processors that allow not only parallelization at the task level but also at the data level—via single instruction multi- ple data (SIMD) instructions and dedicated execution units. Data parallelization is also referred to as vectorization where a single instruction is performed simultaneously on multiple operands, referred to as a vector. Vectorization in general benefits performance and energy efficiency [15]. In the past, SIMD extensions of x86 CPUs like SSE and 3DNow! mostly targeted multimedia and scientific computing applications. SSE 4.2 [15] adds additional byte-comparing instructions for string and text processing.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ed7814ed-17c8-4f8d-a41d-09b855616d17.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a48069226eeafd89b3542f518481ef78e07386ccc4c83b469fb70d3c54356d50",
            "html": "<p>Modern general purpose CPUs are super-scalar multi-core processors that allow not only parallelization at the task level but also at the data level—via single instruction multi- ple data (SIMD) instructions and dedicated execution units. Data parallelization is also referred to as vectorization where a single instruction is performed simultaneously on multiple operands, referred to as a vector. Vectorization in general benefits performance and energy efficiency [15]. In the past, SIMD extensions of x86 CPUs like SSE and 3DNow! mostly targeted multimedia and scientific computing applications. SSE 4.2 [15] adds additional byte-comparing instructions for string and text processing.</p>",
            "markdown": "Modern general purpose CPUs are super-scalar multi-core processors that allow not only parallelization at the task level but also at the data level—via single instruction multi- ple data (SIMD) instructions and dedicated execution units. Data parallelization is also referred to as vectorization where a single instruction is performed simultaneously on multiple operands, referred to as a vector. Vectorization in general benefits performance and energy efficiency [15]. In the past, SIMD extensions of x86 CPUs like SSE and 3DNow! mostly targeted multimedia and scientific computing applications. SSE 4.2 [15] adds additional byte-comparing instructions for string and text processing.\n\n"
          },
          {
            "segment_id": "56fdf636-6eba-4aa1-a6a7-89926984ee81",
            "bbox": {
              "left": 657.3333,
              "top": 1267.75,
              "width": 501.99997,
              "height": 170.75
            },
            "page_number": 4,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Programmers can use vectorization instructions manually via intrinsics. Modern compilers such as GCC also try to automatically vectorize source code. This is, however, re- stricted to specific code patterns. To the best of our knowl- edge, no compiler can (yet) automatically vectorize code us- ing SSE 4.2 instructions. This is due to the fact that using these instructions requires non-trivial changes to the design of algorithms.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/56fdf636-6eba-4aa1-a6a7-89926984ee81.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=6821fa8d4dcdf4be3557154a62f719b2b270d01334c931c5585f4fa2bbbecb7d",
            "html": "<p>Programmers can use vectorization instructions manually via intrinsics. Modern compilers such as GCC also try to automatically vectorize source code. This is, however, re- stricted to specific code patterns. To the best of our knowl- edge, no compiler can (yet) automatically vectorize code us- ing SSE 4.2 instructions. This is due to the fact that using these instructions requires non-trivial changes to the design of algorithms.</p>",
            "markdown": "Programmers can use vectorization instructions manually via intrinsics. Modern compilers such as GCC also try to automatically vectorize source code. This is, however, re- stricted to specific code patterns. To the best of our knowl- edge, no compiler can (yet) automatically vectorize code us- ing SSE 4.2 instructions. This is due to the fact that using these instructions requires non-trivial changes to the design of algorithms.\n\n"
          },
          {
            "segment_id": "6e88e06c-6e6c-4628-b03a-300c66191591",
            "bbox": {
              "left": 657.3333,
              "top": 1478.1666,
              "width": 499.91666,
              "height": 18.666666
            },
            "page_number": 4,
            "page_width": 1275,
            "page_height": 1650,
            "content": "2 This might require reading data from the preceeding chunk.",
            "segment_type": "Footnote",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6e88e06c-6e6c-4628-b03a-300c66191591.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=3c5b81efd3b029054c0caef5b23a8ce2f76279f0f02b41337a021d0d1d334a43",
            "html": "<span class=\"footnote\">2 This might require reading data from the preceeding chunk.</span>",
            "markdown": "2 This might require reading data from the preceeding chunk.\n\n"
          },
          {
            "segment_id": "6c65de04-de3b-4303-a392-943c4f43b93c",
            "bbox": {
              "left": 130.25,
              "top": 113.58333,
              "width": 451.99997,
              "height": 206.16666
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 \\c \\n \" | o p er an d 1 0 3 \\n | 2 4 operand 2 3 0 1 1 0 0 2 mask index O R re su lt (a) EQUAL ANY 1 1 1 1 1 0 1 1 9 0 o p er an d 1 0 3 7 E 5 7 operand 2 3 0 0 1 0 0 2 mask (negated) index GE LE AND (b) RANGES",
            "segment_type": "Picture",
            "ocr": [
              {
                "bbox": {
                  "left": 36,
                  "top": 10,
                  "width": 9,
                  "height": 13
                },
                "text": "3",
                "confidence": 0.9991597
              },
              {
                "bbox": {
                  "left": 56,
                  "top": 1,
                  "width": 61,
                  "height": 21
                },
                "text": "operand",
                "confidence": 0.99614525
              },
              {
                "bbox": {
                  "left": 129,
                  "top": 9,
                  "width": 8,
                  "height": 14
                },
                "text": "0",
                "confidence": 0.63243747
              },
              {
                "bbox": {
                  "left": 253,
                  "top": 14,
                  "width": 9,
                  "height": 13
                },
                "text": "3",
                "confidence": 0.9979367
              },
              {
                "bbox": {
                  "left": 274,
                  "top": 9,
                  "width": 58,
                  "height": 15
                },
                "text": "operand",
                "confidence": 0.99137676
              },
              {
                "bbox": {
                  "left": 347,
                  "top": 16,
                  "width": 5,
                  "height": 8
                },
                "text": ".",
                "confidence": 0.09120136
              },
              {
                "bbox": {
                  "left": 8,
                  "top": 34,
                  "width": 14,
                  "height": 15
                },
                "text": "0",
                "confidence": 0.34956077
              },
              {
                "bbox": {
                  "left": 49,
                  "top": 23,
                  "width": 39,
                  "height": 19
                },
                "text": "\\n",
                "confidence": 0.8728769
              },
              {
                "bbox": {
                  "left": 88,
                  "top": 26,
                  "width": 34,
                  "height": 15
                },
                "text": "24",
                "confidence": 0.99839056
              },
              {
                "bbox": {
                  "left": 268,
                  "top": 30,
                  "width": 67,
                  "height": 15
                },
                "text": "7E57",
                "confidence": 0.9860017
              },
              {
                "bbox": {
                  "left": 224,
                  "top": 40,
                  "width": 15,
                  "height": 15
                },
                "text": "0",
                "confidence": 0.49769184
              },
              {
                "bbox": {
                  "left": 3,
                  "top": 57,
                  "width": 16,
                  "height": 62
                },
                "text": "tpueaedo",
                "confidence": 0.17712906
              },
              {
                "bbox": {
                  "left": 52,
                  "top": 52,
                  "width": 14,
                  "height": 71
                },
                "text": "0010",
                "confidence": 0.9870863
              },
              {
                "bbox": {
                  "left": 68,
                  "top": 50,
                  "width": 19,
                  "height": 74
                },
                "text": "1000",
                "confidence": 0.9689803
              },
              {
                "bbox": {
                  "left": 90,
                  "top": 52,
                  "width": 14,
                  "height": 55
                },
                "text": "000",
                "confidence": 0.7614949
              },
              {
                "bbox": {
                  "left": 105,
                  "top": 49,
                  "width": 19,
                  "height": 58
                },
                "text": "000",
                "confidence": 0.940114
              },
              {
                "bbox": {
                  "left": 242,
                  "top": 57,
                  "width": 15,
                  "height": 32
                },
                "text": "06",
                "confidence": 0.9960122
              },
              {
                "bbox": {
                  "left": 268,
                  "top": 56,
                  "width": 15,
                  "height": 35
                },
                "text": "11",
                "confidence": 0.99108404
              },
              {
                "bbox": {
                  "left": 285,
                  "top": 55,
                  "width": 20,
                  "height": 37
                },
                "text": "10",
                "confidence": 0.83541065
              },
              {
                "bbox": {
                  "left": 308,
                  "top": 57,
                  "width": 11,
                  "height": 32
                },
                "text": "11",
                "confidence": 0.996191
              },
              {
                "bbox": {
                  "left": 326,
                  "top": 57,
                  "width": 10,
                  "height": 33
                },
                "text": "11",
                "confidence": 0.9937116
              },
              {
                "bbox": {
                  "left": 343,
                  "top": 49,
                  "width": 45,
                  "height": 53
                },
                "text": "",
                "confidence": 0
              },
              {
                "bbox": {
                  "left": 23,
                  "top": 69,
                  "width": 18,
                  "height": 55
                },
                "text": "",
                "confidence": 0
              },
              {
                "bbox": {
                  "left": 218,
                  "top": 62,
                  "width": 20,
                  "height": 64
                },
                "text": "peeendn",
                "confidence": 0.14316265
              },
              {
                "bbox": {
                  "left": 135,
                  "top": 72,
                  "width": 21,
                  "height": 26
                },
                "text": "O",
                "confidence": 0.37389296
              },
              {
                "bbox": {
                  "left": 385,
                  "top": 68,
                  "width": 30,
                  "height": 17
                },
                "text": "AND",
                "confidence": 0.99569565
              },
              {
                "bbox": {
                  "left": 92,
                  "top": 105,
                  "width": 13,
                  "height": 16
                },
                "text": "0",
                "confidence": 0.9107212
              },
              {
                "bbox": {
                  "left": 107,
                  "top": 106,
                  "width": 14,
                  "height": 16
                },
                "text": "0",
                "confidence": 0.98359317
              },
              {
                "bbox": {
                  "left": 8,
                  "top": 128,
                  "width": 13,
                  "height": 14
                },
                "text": "3",
                "confidence": 0.9823179
              },
              {
                "bbox": {
                  "left": 20,
                  "top": 132,
                  "width": 15,
                  "height": 44
                },
                "text": "etee",
                "confidence": 0.17268503
              },
              {
                "bbox": {
                  "left": 38,
                  "top": 134,
                  "width": 8,
                  "height": 10
                },
                "text": "7",
                "confidence": 0.11137211
              },
              {
                "bbox": {
                  "left": 54,
                  "top": 134,
                  "width": 10,
                  "height": 16
                },
                "text": "1",
                "confidence": 0.97685313
              },
              {
                "bbox": {
                  "left": 68,
                  "top": 133,
                  "width": 22,
                  "height": 17
                },
                "text": "1",
                "confidence": 0.9958496
              },
              {
                "bbox": {
                  "left": 86,
                  "top": 134,
                  "width": 36,
                  "height": 16
                },
                "text": "00",
                "confidence": 0.9885352
              },
              {
                "bbox": {
                  "left": 137,
                  "top": 134,
                  "width": 36,
                  "height": 15
                },
                "text": "mask",
                "confidence": 0.99207693
              },
              {
                "bbox": {
                  "left": 224,
                  "top": 131,
                  "width": 15,
                  "height": 13
                },
                "text": "3",
                "confidence": 0.96253276
              },
              {
                "bbox": {
                  "left": 269,
                  "top": 138,
                  "width": 13,
                  "height": 16
                },
                "text": "0",
                "confidence": 0.9651277
              },
              {
                "bbox": {
                  "left": 286,
                  "top": 137,
                  "width": 18,
                  "height": 19
                },
                "text": "1",
                "confidence": 0.9835616
              },
              {
                "bbox": {
                  "left": 308,
                  "top": 139,
                  "width": 14,
                  "height": 14
                },
                "text": "0",
                "confidence": 0.96861637
              },
              {
                "bbox": {
                  "left": 326,
                  "top": 141,
                  "width": 9,
                  "height": 11
                },
                "text": "0",
                "confidence": 0.9750504
              },
              {
                "bbox": {
                  "left": 354,
                  "top": 139,
                  "width": 95,
                  "height": 15
                },
                "text": "mask(negated",
                "confidence": 0.9556579
              },
              {
                "bbox": {
                  "left": 73,
                  "top": 163,
                  "width": 10,
                  "height": 13
                },
                "text": "2",
                "confidence": 0.9987764
              },
              {
                "bbox": {
                  "left": 136,
                  "top": 162,
                  "width": 38,
                  "height": 15
                },
                "text": "index",
                "confidence": 0.9948309
              },
              {
                "bbox": {
                  "left": 288,
                  "top": 166,
                  "width": 13,
                  "height": 17
                },
                "text": "2",
                "confidence": 0.99764305
              },
              {
                "bbox": {
                  "left": 353,
                  "top": 166,
                  "width": 38,
                  "height": 15
                },
                "text": "index",
                "confidence": 0.9931024
              },
              {
                "bbox": {
                  "left": 18,
                  "top": 191,
                  "width": 16,
                  "height": 9
                },
                "text": "a",
                "confidence": 0.995539
              },
              {
                "bbox": {
                  "left": 41,
                  "top": 188,
                  "width": 71,
                  "height": 15
                },
                "text": "EQUAL",
                "confidence": 0.99084103
              },
              {
                "bbox": {
                  "left": 118,
                  "top": 188,
                  "width": 44,
                  "height": 15
                },
                "text": "ANY",
                "confidence": 0.9976297
              },
              {
                "bbox": {
                  "left": 283,
                  "top": 190,
                  "width": 22,
                  "height": 13
                },
                "text": "b）",
                "confidence": 0.8566081
              },
              {
                "bbox": {
                  "left": 308,
                  "top": 185,
                  "width": 84,
                  "height": 19
                },
                "text": "RANGES",
                "confidence": 0.9966367
              }
            ],
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6c65de04-de3b-4303-a392-943c4f43b93c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8c227a2008d28ed5b86281e69bd2b98faa3a89e78b097e014b7fcd53e76f3e1a",
            "html": "<img src=\"https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6c65de04-de3b-4303-a392-943c4f43b93c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8c227a2008d28ed5b86281e69bd2b98faa3a89e78b097e014b7fcd53e76f3e1a\" />",
            "markdown": "![Image](https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6c65de04-de3b-4303-a392-943c4f43b93c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8c227a2008d28ed5b86281e69bd2b98faa3a89e78b097e014b7fcd53e76f3e1a)"
          },
          {
            "segment_id": "4a46561c-0306-41a4-8e0f-ab2f7d2db893",
            "bbox": {
              "left": 109.416664,
              "top": 332.3333,
              "width": 504.0833,
              "height": 39.5
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Figure 5: SSE 4.2 comparisons: (a) searching for special characters and (b) validating characters.",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/4a46561c-0306-41a4-8e0f-ab2f7d2db893.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2da1ede122fb26ed1202082dab68c97c58f496135e4f530352440d201b4c9e78",
            "html": "<span class=\"caption\">Figure 5: SSE 4.2 comparisons: (a) searching for special characters and (b) validating characters.</span>",
            "markdown": "Figure 5: SSE 4.2 comparisons: (a) searching for special characters and (b) validating characters.\n\n"
          },
          {
            "segment_id": "c9acf6bd-e224-46fb-bb85-c813e9bdb1e8",
            "bbox": {
              "left": 109.416664,
              "top": 392.75,
              "width": 501.99997,
              "height": 170.75
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Current x86 CPUs work on 128 bit SSE registers, i.e., 16 8 bit characters per register. While the AVX instruction set increased SIMD register sizes to 256 bit, the SSE 4.2 in- structions still work on 128 bit registers. It is of note that we do not assume 16 byte aligned input for our SSE-optimized methods. Even though aligned loads to SIMD registers had been significantly faster than unaligned loads in the past, current generations of CPUs alleviate this penalty.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/c9acf6bd-e224-46fb-bb85-c813e9bdb1e8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=fddc2c07f008c1e8e03d78abd7285c7ba21a561e2841633424b8174f2de3a5ee",
            "html": "<p>Current x86 CPUs work on 128 bit SSE registers, i.e., 16 8 bit characters per register. While the AVX instruction set increased SIMD register sizes to 256 bit, the SSE 4.2 in- structions still work on 128 bit registers. It is of note that we do not assume 16 byte aligned input for our SSE-optimized methods. Even though aligned loads to SIMD registers had been significantly faster than unaligned loads in the past, current generations of CPUs alleviate this penalty.</p>",
            "markdown": "Current x86 CPUs work on 128 bit SSE registers, i.e., 16 8 bit characters per register. While the AVX instruction set increased SIMD register sizes to 256 bit, the SSE 4.2 in- structions still work on 128 bit registers. It is of note that we do not assume 16 byte aligned input for our SSE-optimized methods. Even though aligned loads to SIMD registers had been significantly faster than unaligned loads in the past, current generations of CPUs alleviate this penalty.\n\n"
          }
        ],
        "chunk_length": 472
      },
      {
        "segments": [
          {
            "segment_id": "435d6d5e-ac68-474b-ba3f-c15e592e1380",
            "bbox": {
              "left": 109.416664,
              "top": 567.75,
              "width": 501.99997,
              "height": 304.0833
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "SSE 4.2 includes instructions for the comparison of two 16 byte operands of explicit or implicit lengths. We use the EQUAL ANY and RANGES comparison modes to speed up parsing and deserialization in Instant Loading: In EQUAL ANY mode, each character in the second operand is checked whether it is equal to any character in the first operand. In the RANGES mode, each character in the second operand is checked whether it is in the ranges defined in the first operand. Each range is defined in pairs of two entries where the first specifies the lower and the second the upper bound of the range. The result of intrinsics can either be a bitmask or an index that marks the first position of a hit. Results can further be negated. Fig. 5 illustrates the two modes. For presentation purposes we narrowed the register size to 32 bit.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/435d6d5e-ac68-474b-ba3f-c15e592e1380.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=ad3ba02bd6236f64f1453583a86eebb70fca3a444481bd2d11655f07d0a0ea0f",
            "html": "<p>SSE 4.2 includes instructions for the comparison of two 16 byte operands of explicit or implicit lengths. We use the EQUAL ANY and RANGES comparison modes to speed up parsing and deserialization in Instant Loading: In EQUAL ANY mode, each character in the second operand is checked whether it is equal to any character in the first operand. In the RANGES mode, each character in the second operand is checked whether it is in the ranges defined in the first operand. Each range is defined in pairs of two entries where the first specifies the lower and the second the upper bound of the range. The result of intrinsics can either be a bitmask or an index that marks the first position of a hit. Results can further be negated. Fig. 5 illustrates the two modes. For presentation purposes we narrowed the register size to 32 bit.</p>",
            "markdown": "SSE 4.2 includes instructions for the comparison of two 16 byte operands of explicit or implicit lengths. We use the EQUAL ANY and RANGES comparison modes to speed up parsing and deserialization in Instant Loading: In EQUAL ANY mode, each character in the second operand is checked whether it is equal to any character in the first operand. In the RANGES mode, each character in the second operand is checked whether it is in the ranges defined in the first operand. Each range is defined in pairs of two entries where the first specifies the lower and the second the upper bound of the range. The result of intrinsics can either be a bitmask or an index that marks the first position of a hit. Results can further be negated. Fig. 5 illustrates the two modes. For presentation purposes we narrowed the register size to 32 bit.\n\n"
          },
          {
            "segment_id": "b1f9e6ce-055d-4387-a434-7fc1d0cbfbd5",
            "bbox": {
              "left": 109.416664,
              "top": 873.99994,
              "width": 501.99997,
              "height": 83.25
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "To improve parsing, we use EQUAL ANY to search for de- limiters on a 16 byte at a time basis (cf., Fig. 5(a)). Branch- ing is performed only if a special character is found. The following pseudocode illustrates our method:",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/b1f9e6ce-055d-4387-a434-7fc1d0cbfbd5.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=be1b29cf25deec6c643752ea010135006035e92c34e307f96ae44a94abf00aa6",
            "html": "<p>To improve parsing, we use EQUAL ANY to search for de- limiters on a 16 byte at a time basis (cf., Fig. 5(a)). Branch- ing is performed only if a special character is found. The following pseudocode illustrates our method:</p>",
            "markdown": "To improve parsing, we use EQUAL ANY to search for de- limiters on a 16 byte at a time basis (cf., Fig. 5(a)). Branch- ing is performed only if a special character is found. The following pseudocode illustrates our method:\n\n"
          },
          {
            "segment_id": "8e62541f-afd2-4c9f-864f-6859eea5451e",
            "bbox": {
              "left": 119.83333,
              "top": 961.49994,
              "width": 404.0833,
              "height": 18.666666
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "1: procedure (input,specialChars)",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/8e62541f-afd2-4c9f-864f-6859eea5451e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8a058a16ab44ab8830d8ca6fb94ff1033a2d4a2a889f787538a24e14a49288f3",
            "html": "<p>1: procedure (input,specialChars)</p>",
            "markdown": "1: procedure (input,specialChars)\n\n"
          },
          {
            "segment_id": "2981971b-a5fc-43ad-a329-6655609568e8",
            "bbox": {
              "left": 119.83333,
              "top": 980.24994,
              "width": 272.8333,
              "height": 16.583332
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "nextDelimiter 2: while !endOfInput(input) do",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/2981971b-a5fc-43ad-a329-6655609568e8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=1e01190263bfd56a99ee7ee20add37cbc44187fc10a4f12c6ad84afabce09b93",
            "html": "<ul><li>nextDelimiter 2: while !endOfInput(input) do</li></ul>",
            "markdown": "- nextDelimiter 2: while !endOfInput(input) do\n\n"
          },
          {
            "segment_id": "4c1493e1-af7e-4765-9edd-d83fa81ada89",
            "bbox": {
              "left": 119.83333,
              "top": 996.9166,
              "width": 362.41666,
              "height": 18.666666
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "3: special = mm set epi8(specialChars)",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/4c1493e1-af7e-4765-9edd-d83fa81ada89.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a821fe17348e3f0819837d8258054122eb564bb7ebab494450a5b722eb68eada",
            "html": "<ul><li>3: special = mm set epi8(specialChars)</li></ul>",
            "markdown": "- 3: special = mm set epi8(specialChars)\n\n"
          },
          {
            "segment_id": "c5314981-c0b1-4131-b859-ed633e62cd7c",
            "bbox": {
              "left": 119.83333,
              "top": 1017.74994,
              "width": 299.91666,
              "height": 14.5
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "4: data = mm loadu si128(input)",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/c5314981-c0b1-4131-b859-ed633e62cd7c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=b758729f56f2e4044de78e132982b6cc3fdf9c2ece16002c87e912def72a05a3",
            "html": "<ul><li>4: data = mm loadu si128(input)</li></ul>",
            "markdown": "- 4: data = mm loadu si128(input)\n\n"
          },
          {
            "segment_id": "18de2b99-c5d8-4f32-98c4-a5b7db83e437",
            "bbox": {
              "left": 117.74999,
              "top": 1034.4166,
              "width": 268.66666,
              "height": 16.583332
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "5: mode = SIDD CMP EQUAL ANY",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/18de2b99-c5d8-4f32-98c4-a5b7db83e437.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=b2a4a7ddfa42ac35cffb1d60f8e41567163d6f758edfbc679d87eaac54cd89ad",
            "html": "<ul><li>5: mode = SIDD CMP EQUAL ANY</li></ul>",
            "markdown": "- 5: mode = SIDD CMP EQUAL ANY\n\n"
          },
          {
            "segment_id": "07383f14-3447-4bd3-89b5-84d112502d26",
            "bbox": {
              "left": 117.74999,
              "top": 1053.1666,
              "width": 393.66666,
              "height": 14.5
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "6: index = mm cmpistri(special,data,mode)",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/07383f14-3447-4bd3-89b5-84d112502d26.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e7588d0a47ecbd8d8367fde562cfb1b0eb410381f3ddfc7a09ba72b949985474",
            "html": "<ul><li>6: index = mm cmpistri(special,data,mode)</li></ul>",
            "markdown": "- 6: index = mm cmpistri(special,data,mode)\n\n"
          },
          {
            "segment_id": "91abda08-5e8c-404b-9b75-dfced2354216",
            "bbox": {
              "left": 119.83333,
              "top": 1067.75,
              "width": 212.41666,
              "height": 16.583332
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "7: if index < 16 then",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/91abda08-5e8c-404b-9b75-dfced2354216.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=37210ee0f990b1eac6df1b52e1386ea13f5770333e868c4070a8f143d22f22ee",
            "html": "<ul><li>7: if index < 16 then</li></ul>",
            "markdown": "- 7: if index < 16 then\n\n"
          },
          {
            "segment_id": "9b09ac71-f476-4c44-804b-6d6a56ef25c6",
            "bbox": {
              "left": 119.83333,
              "top": 1086.5,
              "width": 289.5,
              "height": 16.583332
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "8: // handle special character",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/9b09ac71-f476-4c44-804b-6d6a56ef25c6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=dee6a2745f1b847d50ebecf82fae976e3dc2e1656589de38e802aefe43872823",
            "html": "<ul><li>8: // handle special character</li></ul>",
            "markdown": "- 8: // handle special character\n\n"
          },
          {
            "segment_id": "b7df7da8-085f-4dfb-91ee-b0441950e399",
            "bbox": {
              "left": 119.83333,
              "top": 1105.25,
              "width": 193.66666,
              "height": 16.583332
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "9: input = input +16",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/b7df7da8-085f-4dfb-91ee-b0441950e399.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=fe27610712e496aeb27b8381a7f628de9fa47f03a65836091ace1b26cfd4e58f",
            "html": "<ul><li>9: input = input +16</li></ul>",
            "markdown": "- 9: input = input +16\n\n"
          },
          {
            "segment_id": "5eaedbde-3822-4de0-9234-97197679624b",
            "bbox": {
              "left": 109.416664,
              "top": 1130.25,
              "width": 501.99997,
              "height": 302
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "For long fields, e.g., strings of variable length, finding the next delimiter often requires to scan a lot more than 16 char- acters. To improve parsing of these fields, we adapted the method shown above to compare 64 characters at a time: First, 64 byte (typically one cache line) are loaded into four 128 bit SSE registers. For each of the registers a compar- ison mask is generated using the _mm_cmpistrm intrinsic. The four masks are interpreted as four 16 bit masks and are stored consecutively in one 64 bit integer where each bit indi- cates if a special character is found at the position of the bit. If the integer is 0, no special character was found. Otherwise, the position of the first special byte is retrieved by count- ing the number of trailing zeros. This operation is again available as a CPU instruction and is thus highly efficient.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/5eaedbde-3822-4de0-9234-97197679624b.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=ce8b8133755ab41ccc8dd843f792de9bc3372cf8ff6a0fdfc581b39f98455eb0",
            "html": "<p>For long fields, e.g., strings of variable length, finding the next delimiter often requires to scan a lot more than 16 char- acters. To improve parsing of these fields, we adapted the method shown above to compare 64 characters at a time: First, 64 byte (typically one cache line) are loaded into four 128 bit SSE registers. For each of the registers a compar- ison mask is generated using the _mm_cmpistrm intrinsic. The four masks are interpreted as four 16 bit masks and are stored consecutively in one 64 bit integer where each bit indi- cates if a special character is found at the position of the bit. If the integer is 0, no special character was found. Otherwise, the position of the first special byte is retrieved by count- ing the number of trailing zeros. This operation is again available as a CPU instruction and is thus highly efficient.</p>",
            "markdown": "For long fields, e.g., strings of variable length, finding the next delimiter often requires to scan a lot more than 16 char- acters. To improve parsing of these fields, we adapted the method shown above to compare 64 characters at a time: First, 64 byte (typically one cache line) are loaded into four 128 bit SSE registers. For each of the registers a compar- ison mask is generated using the _mm_cmpistrm intrinsic. The four masks are interpreted as four 16 bit masks and are stored consecutively in one 64 bit integer where each bit indi- cates if a special character is found at the position of the bit. If the integer is 0, no special character was found. Otherwise, the position of the first special byte is retrieved by count- ing the number of trailing zeros. This operation is again available as a CPU instruction and is thus highly efficient.\n\n"
          },
          {
            "segment_id": "78b00471-323e-4511-9f57-1eb1f02c521a",
            "bbox": {
              "left": 109.416664,
              "top": 1434.4166,
              "width": 499.91666,
              "height": 62.416664
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "To improve deserialization methods, we use the RANGES mode for input validation (cf., Fig. 5(b)). We again illustrate our approach in form of pseudocode:",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/78b00471-323e-4511-9f57-1eb1f02c521a.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=1ac951bcf0779dea59fc2cc8ed3eb3fcad60a136908ef5e7e3e470040bfaa51f",
            "html": "<p>To improve deserialization methods, we use the RANGES mode for input validation (cf., Fig. 5(b)). We again illustrate our approach in form of pseudocode:</p>",
            "markdown": "To improve deserialization methods, we use the RANGES mode for input validation (cf., Fig. 5(b)). We again illustrate our approach in form of pseudocode:\n\n"
          },
          {
            "segment_id": "3f9d692d-8505-4662-a66e-83b43a709602",
            "bbox": {
              "left": 659.4166,
              "top": 101.08333,
              "width": 491.5833,
              "height": 220.74998
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Partition Partition Partition 1 Africa 1 Africa chunks 2 Antarctica 2 Antarctica 3 Asia 3 Asia # Africa Australia 4 Australia Antarctica insert memcpy memcpy add chunk reference 3 Asia  3 Asia Asia 4Australia 4 Australia Australia Partition Buffer Partition Buffer Partition Buffer (a)insert-based （b)copy-based (c）chunk-based",
            "segment_type": "Picture",
            "ocr": [
              {
                "bbox": {
                  "left": 45,
                  "top": 22,
                  "width": 56,
                  "height": 16
                },
                "text": "Partition",
                "confidence": 0.9888682
              },
              {
                "bbox": {
                  "left": 216,
                  "top": 22,
                  "width": 55,
                  "height": 16
                },
                "text": "Partition",
                "confidence": 0.9894833
              },
              {
                "bbox": {
                  "left": 374,
                  "top": 24,
                  "width": 75,
                  "height": 13
                },
                "text": "Partition",
                "confidence": 0.9899366
              },
              {
                "bbox": {
                  "left": 26,
                  "top": 45,
                  "width": 9,
                  "height": 12
                },
                "text": "1",
                "confidence": 0.9977564
              },
              {
                "bbox": {
                  "left": 53,
                  "top": 41,
                  "width": 40,
                  "height": 18
                },
                "text": "Africa",
                "confidence": 0.9894056
              },
              {
                "bbox": {
                  "left": 194,
                  "top": 42,
                  "width": 14,
                  "height": 16
                },
                "text": "1",
                "confidence": 0.9970811
              },
              {
                "bbox": {
                  "left": 224,
                  "top": 41,
                  "width": 41,
                  "height": 18
                },
                "text": "Africa",
                "confidence": 0.9924237
              },
              {
                "bbox": {
                  "left": 425,
                  "top": 41,
                  "width": 48,
                  "height": 18
                },
                "text": "chunks",
                "confidence": 0.99318844
              },
              {
                "bbox": {
                  "left": 26,
                  "top": 58,
                  "width": 10,
                  "height": 15
                },
                "text": "2",
                "confidence": 0.9863282
              },
              {
                "bbox": {
                  "left": 54,
                  "top": 57,
                  "width": 66,
                  "height": 17
                },
                "text": "Antarctica",
                "confidence": 0.9927028
              },
              {
                "bbox": {
                  "left": 194,
                  "top": 57,
                  "width": 14,
                  "height": 17
                },
                "text": "2",
                "confidence": 0.9971631
              },
              {
                "bbox": {
                  "left": 224,
                  "top": 55,
                  "width": 68,
                  "height": 20
                },
                "text": "Antarctica",
                "confidence": 0.99472636
              },
              {
                "bbox": {
                  "left": 26,
                  "top": 77,
                  "width": 8,
                  "height": 10
                },
                "text": "3",
                "confidence": 0.9960692
              },
              {
                "bbox": {
                  "left": 53,
                  "top": 73,
                  "width": 31,
                  "height": 18
                },
                "text": "Asia",
                "confidence": 0.97110564
              },
              {
                "bbox": {
                  "left": 194,
                  "top": 75,
                  "width": 13,
                  "height": 13
                },
                "text": "3",
                "confidence": 0.9947483
              },
              {
                "bbox": {
                  "left": 224,
                  "top": 74,
                  "width": 30,
                  "height": 15
                },
                "text": "Asia",
                "confidence": 0.98496926
              },
              {
                "bbox": {
                  "left": 368,
                  "top": 69,
                  "width": 25,
                  "height": 37
                },
                "text": "#",
                "confidence": 0.8030219
              },
              {
                "bbox": {
                  "left": 402,
                  "top": 71,
                  "width": 42,
                  "height": 18
                },
                "text": "Africa",
                "confidence": 0.98818135
              },
              {
                "bbox": {
                  "left": 54,
                  "top": 89,
                  "width": 56,
                  "height": 17
                },
                "text": "Australia",
                "confidence": 0.9790306
              },
              {
                "bbox": {
                  "left": 195,
                  "top": 93,
                  "width": 11,
                  "height": 10
                },
                "text": "4",
                "confidence": 0.97236663
              },
              {
                "bbox": {
                  "left": 224,
                  "top": 89,
                  "width": 57,
                  "height": 17
                },
                "text": "Australia",
                "confidence": 0.9800889
              },
              {
                "bbox": {
                  "left": 403,
                  "top": 86,
                  "width": 71,
                  "height": 18
                },
                "text": "Antarctica",
                "confidence": 0.99011403
              },
              {
                "bbox": {
                  "left": 77,
                  "top": 112,
                  "width": 42,
                  "height": 19
                },
                "text": "insert",
                "confidence": 0.9902978
              },
              {
                "bbox": {
                  "left": 165,
                  "top": 111,
                  "width": 58,
                  "height": 21
                },
                "text": "memcpy",
                "confidence": 0.9811404
              },
              {
                "bbox": {
                  "left": 260,
                  "top": 111,
                  "width": 57,
                  "height": 21
                },
                "text": "memcpy",
                "confidence": 0.9858911
              },
              {
                "bbox": {
                  "left": 355,
                  "top": 113,
                  "width": 125,
                  "height": 17
                },
                "text": "add chunk reference",
                "confidence": 0.9682522
              },
              {
                "bbox": {
                  "left": 18,
                  "top": 138,
                  "width": 24,
                  "height": 15
                },
                "text": "3",
                "confidence": 0.99112916
              },
              {
                "bbox": {
                  "left": 51,
                  "top": 137,
                  "width": 36,
                  "height": 17
                },
                "text": "Asia",
                "confidence": 0.9925018
              },
              {
                "bbox": {
                  "left": 90,
                  "top": 139,
                  "width": 23,
                  "height": 11
                },
                "text": "",
                "confidence": 0
              },
              {
                "bbox": {
                  "left": 192,
                  "top": 138,
                  "width": 14,
                  "height": 14
                },
                "text": "3",
                "confidence": 0.98972195
              },
              {
                "bbox": {
                  "left": 221,
                  "top": 137,
                  "width": 34,
                  "height": 18
                },
                "text": "Asia",
                "confidence": 0.9935785
              },
              {
                "bbox": {
                  "left": 400,
                  "top": 137,
                  "width": 34,
                  "height": 18
                },
                "text": "Asia",
                "confidence": 0.9934778
              },
              {
                "bbox": {
                  "left": 23,
                  "top": 156,
                  "width": 103,
                  "height": 13
                },
                "text": "4Australia",
                "confidence": 0.9846059
              },
              {
                "bbox": {
                  "left": 192,
                  "top": 155,
                  "width": 15,
                  "height": 14
                },
                "text": "4",
                "confidence": 0.99888533
              },
              {
                "bbox": {
                  "left": 223,
                  "top": 154,
                  "width": 57,
                  "height": 14
                },
                "text": "Australia",
                "confidence": 0.99110156
              },
              {
                "bbox": {
                  "left": 402,
                  "top": 155,
                  "width": 59,
                  "height": 14
                },
                "text": "Australia",
                "confidence": 0.9913222
              },
              {
                "bbox": {
                  "left": 24,
                  "top": 176,
                  "width": 108,
                  "height": 14
                },
                "text": "Partition Buffer",
                "confidence": 0.97351575
              },
              {
                "bbox": {
                  "left": 190,
                  "top": 176,
                  "width": 111,
                  "height": 14
                },
                "text": "Partition Buffer",
                "confidence": 0.9721359
              },
              {
                "bbox": {
                  "left": 361,
                  "top": 175,
                  "width": 119,
                  "height": 14
                },
                "text": "Partition Buffer",
                "confidence": 0.9643347
              },
              {
                "bbox": {
                  "left": 5,
                  "top": 196,
                  "width": 133,
                  "height": 23
                },
                "text": "(a)insert-based",
                "confidence": 0.93637115
              },
              {
                "bbox": {
                  "left": 179,
                  "top": 197,
                  "width": 126,
                  "height": 21
                },
                "text": "（b)copy-based",
                "confidence": 0.93132937
              },
              {
                "bbox": {
                  "left": 352,
                  "top": 195,
                  "width": 133,
                  "height": 24
                },
                "text": "(c）chunk-based",
                "confidence": 0.9168542
              }
            ],
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/3f9d692d-8505-4662-a66e-83b43a709602.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d6ac6e5861d185c45160aa574a36e05f1157ac580327b832bae0a6ecae363f94",
            "html": "<img src=\"https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/3f9d692d-8505-4662-a66e-83b43a709602.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d6ac6e5861d185c45160aa574a36e05f1157ac580327b832bae0a6ecae363f94\" />",
            "markdown": "![Image](https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/3f9d692d-8505-4662-a66e-83b43a709602.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d6ac6e5861d185c45160aa574a36e05f1157ac580327b832bae0a6ecae363f94)"
          },
          {
            "segment_id": "f1c88cbf-c780-4ceb-9f4b-47ef628933d3",
            "bbox": {
              "left": 665.6666,
              "top": 332.3333,
              "width": 483.24997,
              "height": 16.583332
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Figure 6: Merging buffers with relation paritions.",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/f1c88cbf-c780-4ceb-9f4b-47ef628933d3.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=dc2b8a75d10ef4c3842480c453bfb973914de9b3df6d5a486458c87808f1acb1",
            "html": "<span class=\"caption\">Figure 6: Merging buffers with relation paritions.</span>",
            "markdown": "Figure 6: Merging buffers with relation paritions.\n\n"
          },
          {
            "segment_id": "be590e35-22e0-4fcf-84a4-b73f29e01fcf",
            "bbox": {
              "left": 667.75,
              "top": 378.16666,
              "width": 422.8333,
              "height": 16.583332
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "1: procedure deserializeIntegerSSE (input,length)",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/be590e35-22e0-4fcf-84a4-b73f29e01fcf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0dc93345b17c65a176ce2ddfdce953d1d8dd5200d6f7358c249547e5cb38088c",
            "html": "<ul><li>1: procedure deserializeIntegerSSE (input,length)</li></ul>",
            "markdown": "- 1: procedure deserializeIntegerSSE (input,length)\n\n"
          },
          {
            "segment_id": "87f86476-e54b-4edb-a36c-a86552321690",
            "bbox": {
              "left": 667.75,
              "top": 396.91666,
              "width": 189.5,
              "height": 16.583332
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "2: if length < 4 then",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/87f86476-e54b-4edb-a36c-a86552321690.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a1b3a3d3f413dba3a05d069c4f7b98d3e185c9153e3c8d2e76a9a6b89f62cc30",
            "html": "<ul><li>2: if length < 4 then</li></ul>",
            "markdown": "- 2: if length < 4 then\n\n"
          },
          {
            "segment_id": "f5d4f0b8-f665-433b-bff3-2d68726a0d13",
            "bbox": {
              "left": 667.75,
              "top": 415.66666,
              "width": 385.3333,
              "height": 14.5
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "3: deserializeIntegerNoSSE(input,length)",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/f5d4f0b8-f665-433b-bff3-2d68726a0d13.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=943e9f8543b5741c73f8ceb934f8e50833310f3d25cb1dc6427baa66e40c2cc7",
            "html": "<ul><li>3: deserializeIntegerNoSSE(input,length)</li></ul>",
            "markdown": "- 3: deserializeIntegerNoSSE(input,length)\n\n"
          },
          {
            "segment_id": "01f3b971-a604-434d-9a1f-a5b23b8509da",
            "bbox": {
              "left": 667.75,
              "top": 432.3333,
              "width": 347.8333,
              "height": 16.583332
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "4:",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/01f3b971-a604-434d-9a1f-a5b23b8509da.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c596ac3d911d600388b2e98274333561f1bff314858c8bd31de7994a9c15c183",
            "html": "<ul><li>4:</li></ul>",
            "markdown": "- 4:\n\n"
          },
          {
            "segment_id": "77d9ea3b-9a9c-480c-a04f-dd782c346f5f",
            "bbox": {
              "left": 667.75,
              "top": 446.91666,
              "width": 279.0833,
              "height": 16.583332
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "range = mm set epi8(0,...,0,’9’,’0’) 5: data = mm loadu si128(input)",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/77d9ea3b-9a9c-480c-a04f-dd782c346f5f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=9c5fd794205dc9348f496abe16c5abaf7b580213929f7cb3d0f55b85e40c53a4",
            "html": "<ul><li>range = mm set epi8(0,...,0,’9’,’0’) 5: data = mm loadu si128(input)</li></ul>",
            "markdown": "- range = mm set epi8(0,...,0,’9’,’0’) 5: data = mm loadu si128(input)\n\n"
          },
          {
            "segment_id": "8bf8aab9-7621-483b-a779-d01e095f57e1",
            "bbox": {
              "left": 667.75,
              "top": 467.74997,
              "width": 491.5833,
              "height": 16.583332
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "6: mode = SIDD CMP RANGES| SIDD MASKED NEGATIVE POLARITY",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/8bf8aab9-7621-483b-a779-d01e095f57e1.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a4f267b66be365807bd7c9c2c253b8ff225d84ae828f080e91fa2b36351a50c1",
            "html": "<ul><li>6: mode = SIDD CMP RANGES| SIDD MASKED NEGATIVE POLARITY</li></ul>",
            "markdown": "- 6: mode = SIDD CMP RANGES| SIDD MASKED NEGATIVE POLARITY\n\n"
          },
          {
            "segment_id": "36d64e15-8a1a-43ca-b73c-044ddf65d19c",
            "bbox": {
              "left": 667.75,
              "top": 486.49997,
              "width": 429.0833,
              "height": 14.5
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "7: index = mm cmpestri(range,2,data,length,mode)",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/36d64e15-8a1a-43ca-b73c-044ddf65d19c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=51ad40a5d5a323d1717ec7235da66655968e23cc80b0a15bddc37de0587e7b3f",
            "html": "<ul><li>7: index = mm cmpestri(range,2,data,length,mode)</li></ul>",
            "markdown": "- 7: index = mm cmpestri(range,2,data,length,mode)\n\n"
          }
        ],
        "chunk_length": 509
      },
      {
        "segments": [
          {
            "segment_id": "1d2dde3d-cda4-4378-af3a-daa1bb62155a",
            "bbox": {
              "left": 667.75,
              "top": 503.16666,
              "width": 197.83333,
              "height": 14.5
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "8: if index != 16 then",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/1d2dde3d-cda4-4378-af3a-daa1bb62155a.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=84d969baa5e6da7c1476b38fe41d05301d5357d3ba4ece0895f36878de13e26d",
            "html": "<ul><li>8: if index != 16 then</li></ul>",
            "markdown": "- 8: if index != 16 then\n\n"
          },
          {
            "segment_id": "0f234135-5928-4d1b-999b-2201b3f9f873",
            "bbox": {
              "left": 669.8333,
              "top": 519.8333,
              "width": 437.41666,
              "height": 16.583332
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "9: throw RuntimeException(\"invalid character\")",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/0f234135-5928-4d1b-999b-2201b3f9f873.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=255a91c97bbce3ab9321a0501a82cdb2a132d70478459d390f28af902464e2b3",
            "html": "<ul><li>9: throw RuntimeException(\"invalid character\")</li></ul>",
            "markdown": "- 9: throw RuntimeException(\"invalid character\")\n\n"
          },
          {
            "segment_id": "2cbe125b-8214-46a9-aae7-4b59612b0598",
            "bbox": {
              "left": 657.3333,
              "top": 544.8333,
              "width": 501.99997,
              "height": 149.91666
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Experiments have shown that for string lengths of less than 4 byte, SSE optimized integer deserialization is slower than a standard non-SSE variant with current x86 CPUs. For integer deserialization we thus use a hybrid processing model where the SSE optimized variant is only used for strings longer than 3 characters. Deserialization methods for other data types were optimized analogously.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/2cbe125b-8214-46a9-aae7-4b59612b0598.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=83d4ec361f1240849ff8ead613fcaa1c06142d91533c8a8daa766f28fe41dad5",
            "html": "<p>Experiments have shown that for string lengths of less than 4 byte, SSE optimized integer deserialization is slower than a standard non-SSE variant with current x86 CPUs. For integer deserialization we thus use a hybrid processing model where the SSE optimized variant is only used for strings longer than 3 characters. Deserialization methods for other data types were optimized analogously.</p>",
            "markdown": "Experiments have shown that for string lengths of less than 4 byte, SSE optimized integer deserialization is slower than a standard non-SSE variant with current x86 CPUs. For integer deserialization we thus use a hybrid processing model where the SSE optimized variant is only used for strings longer than 3 characters. Deserialization methods for other data types were optimized analogously.\n\n"
          },
          {
            "segment_id": "295f489e-e795-40d8-9d9f-c8917b445667",
            "bbox": {
              "left": 657.3333,
              "top": 696.9166,
              "width": 501.99997,
              "height": 85.33333
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "The evaluation in Sect. 5 shows that our vectorized meth- ods reduce the number of branch misses significantly, im- prove energy efficiency, and increase performance by about 50% compared to non-vectorized methods.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/295f489e-e795-40d8-9d9f-c8917b445667.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=7014291add037c93d656aaa80471943acbfb1fb0085f70402991a543b2031534",
            "html": "<p>The evaluation in Sect. 5 shows that our vectorized meth- ods reduce the number of branch misses significantly, im- prove energy efficiency, and increase performance by about 50% compared to non-vectorized methods.</p>",
            "markdown": "The evaluation in Sect. 5 shows that our vectorized meth- ods reduce the number of branch misses significantly, im- prove energy efficiency, and increase performance by about 50% compared to non-vectorized methods.\n\n"
          }
        ],
        "chunk_length": 102
      },
      {
        "segments": [
          {
            "segment_id": "a1dfb439-ff73-4007-8690-e89c06fcc06b",
            "bbox": {
              "left": 657.3333,
              "top": 803.1666,
              "width": 239.49998,
              "height": 22.833332
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "3.5 Partition Buffers",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/a1dfb439-ff73-4007-8690-e89c06fcc06b.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=81a4aef49592379795fc323bd80926c1d562fad50feb3ed0e66ccd7379595f25",
            "html": "<h2>3.5 Partition Buffers</h2>",
            "markdown": "## 3.5 Partition Buffers\n\n"
          },
          {
            "segment_id": "4ae994f4-4a50-4360-8be3-1495a5ef48ed",
            "bbox": {
              "left": 657.3333,
              "top": 832.3333,
              "width": 501.99997,
              "height": 256.16666
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "CSV chunk-processing tasks store parsed and deserialized tuples as well as indexes on these tuples in partition buffers. These buffers have the same physical layout as the relation partitions in order to avoid further transformations of data during a merge step. In the following we discuss approaches to merge the tuples stored in a partition buffer with its cor- responding relation partition in the storage backend (see Fig. 6). Merging of indexes is discussed in the next sec- tion. The insert- and copy-based approaches are viable for contiguous memory-based as well as chunked storage back- ends. The chunk-based approach requires a chunked storage backend (see Sect. 2).",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/4ae994f4-4a50-4360-8be3-1495a5ef48ed.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e824f6322d74a0298d212599ee6eb0512263d6c19c3aa90e28b822c875bee05f",
            "html": "<p>CSV chunk-processing tasks store parsed and deserialized tuples as well as indexes on these tuples in partition buffers. These buffers have the same physical layout as the relation partitions in order to avoid further transformations of data during a merge step. In the following we discuss approaches to merge the tuples stored in a partition buffer with its cor- responding relation partition in the storage backend (see Fig. 6). Merging of indexes is discussed in the next sec- tion. The insert- and copy-based approaches are viable for contiguous memory-based as well as chunked storage back- ends. The chunk-based approach requires a chunked storage backend (see Sect. 2).</p>",
            "markdown": "CSV chunk-processing tasks store parsed and deserialized tuples as well as indexes on these tuples in partition buffers. These buffers have the same physical layout as the relation partitions in order to avoid further transformations of data during a merge step. In the following we discuss approaches to merge the tuples stored in a partition buffer with its cor- responding relation partition in the storage backend (see Fig. 6). Merging of indexes is discussed in the next sec- tion. The insert- and copy-based approaches are viable for contiguous memory-based as well as chunked storage back- ends. The chunk-based approach requires a chunked storage backend (see Sect. 2).\n\n"
          },
          {
            "segment_id": "9016a5cf-51d4-4e1c-af3b-8d0a865c0bf9",
            "bbox": {
              "left": 657.3333,
              "top": 1099,
              "width": 501.99997,
              "height": 126.99999
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "insert-based approach. The insert-based approach con- stitutes the simplest approach. It iterates over the tuples in the buffer and inserts the tuples one-by-one into the relation partition. This approach is obviously very simple to realize as insertion logic can be reused. However, its performance is bounded by the insertion speed of the storage backend.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/9016a5cf-51d4-4e1c-af3b-8d0a865c0bf9.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=025ce0add105ab46a86b2d5456ec4c357160459d6e94fc541e95cdc094aec8ea",
            "html": "<p>insert-based approach. The insert-based approach con- stitutes the simplest approach. It iterates over the tuples in the buffer and inserts the tuples one-by-one into the relation partition. This approach is obviously very simple to realize as insertion logic can be reused. However, its performance is bounded by the insertion speed of the storage backend.</p>",
            "markdown": "insert-based approach. The insert-based approach con- stitutes the simplest approach. It iterates over the tuples in the buffer and inserts the tuples one-by-one into the relation partition. This approach is obviously very simple to realize as insertion logic can be reused. However, its performance is bounded by the insertion speed of the storage backend.\n\n"
          },
          {
            "segment_id": "6b7d52b4-29b4-4105-aaf2-2eb4b6ba1bc7",
            "bbox": {
              "left": 657.3333,
              "top": 1232.3333,
              "width": 501.99997,
              "height": 193.66666
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "copy-based approach. In contrast to the insert-based approach, the copy-based approach copies all tuples from the buffer into the relation partition in one step. It is thereby faster than the insert-based approach as it largely only de- pends on the speed of the memcpy system call. We again task-parallelized memcpy ing for large buffers to fully lever- age the available memory bandwidth on modern hardware. No additional transformations are necessary as the buffer already uses the physical layout of the relation partition.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6b7d52b4-29b4-4105-aaf2-2eb4b6ba1bc7.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=91776d4f7c4a38988b1b51b4bf1bd2ce06255f16445a8881b958366cf82189b4",
            "html": "<p>copy-based approach. In contrast to the insert-based approach, the copy-based approach copies all tuples from the buffer into the relation partition in one step. It is thereby faster than the insert-based approach as it largely only de- pends on the speed of the memcpy system call. We again task-parallelized memcpy ing for large buffers to fully lever- age the available memory bandwidth on modern hardware. No additional transformations are necessary as the buffer already uses the physical layout of the relation partition.</p>",
            "markdown": "copy-based approach. In contrast to the insert-based approach, the copy-based approach copies all tuples from the buffer into the relation partition in one step. It is thereby faster than the insert-based approach as it largely only de- pends on the speed of the memcpy system call. We again task-parallelized memcpy ing for large buffers to fully lever- age the available memory bandwidth on modern hardware. No additional transformations are necessary as the buffer already uses the physical layout of the relation partition.\n\n"
          },
          {
            "segment_id": "001563a5-2ff7-48d9-b6c2-250141550571",
            "bbox": {
              "left": 657.3333,
              "top": 1434.4166,
              "width": 501.99997,
              "height": 62.416664
            },
            "page_number": 5,
            "page_width": 1275,
            "page_height": 1650,
            "content": "chunk-based approach. For chunked storage backends the memcpy system call can be avoided entirely. A merge step then only consists of the insertion of a buffer reference",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/001563a5-2ff7-48d9-b6c2-250141550571.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a54a210d5e30e9a7d043d79101344a668062c13185f0c6b283743962c36061d1",
            "html": "<p>chunk-based approach. For chunked storage backends the memcpy system call can be avoided entirely. A merge step then only consists of the insertion of a buffer reference</p>",
            "markdown": "chunk-based approach. For chunked storage backends the memcpy system call can be avoided entirely. A merge step then only consists of the insertion of a buffer reference\n\n"
          },
          {
            "segment_id": "84ed7bf0-58ff-4b63-a196-993a4b9e9ecf",
            "bbox": {
              "left": 109.416664,
              "top": 117.74999,
              "width": 499.91666,
              "height": 212.41666
            },
            "page_number": 6,
            "page_width": 1275,
            "page_height": 1650,
            "content": "into a list of chunk references in the backend. While merging time is minimal, too small and too many chunks negatively impact table scan and random access performance of the backend due to caching effects. In general, it is advanta- geous to have a small list of chunk references. Preferably, the list should fit in the CPU caches, so that it can be ac- cessed efficiently. For Instant Loading, we are faced with the tradeoff between using small CSV chunk sizes for a high de- gree of task-parallelization (cf., Sect. 3.3) and creating large storage backend chunks to keep the backend efficient.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/84ed7bf0-58ff-4b63-a196-993a4b9e9ecf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c0826037fd76e7295ac84b5b5ffc214ddfd6b00c8ae10380c8720ee1eacfebc9",
            "html": "<p>into a list of chunk references in the backend. While merging time is minimal, too small and too many chunks negatively impact table scan and random access performance of the backend due to caching effects. In general, it is advanta- geous to have a small list of chunk references. Preferably, the list should fit in the CPU caches, so that it can be ac- cessed efficiently. For Instant Loading, we are faced with the tradeoff between using small CSV chunk sizes for a high de- gree of task-parallelization (cf., Sect. 3.3) and creating large storage backend chunks to keep the backend efficient.</p>",
            "markdown": "into a list of chunk references in the backend. While merging time is minimal, too small and too many chunks negatively impact table scan and random access performance of the backend due to caching effects. In general, it is advanta- geous to have a small list of chunk references. Preferably, the list should fit in the CPU caches, so that it can be ac- cessed efficiently. For Instant Loading, we are faced with the tradeoff between using small CSV chunk sizes for a high de- gree of task-parallelization (cf., Sect. 3.3) and creating large storage backend chunks to keep the backend efficient.\n\n"
          },
          {
            "segment_id": "4674d276-9a60-4cc6-ad1e-dd67478a42d5",
            "bbox": {
              "left": 109.416664,
              "top": 336.5,
              "width": 501.99997,
              "height": 299.91666
            },
            "page_number": 6,
            "page_width": 1275,
            "page_height": 1650,
            "content": "One way to meet this challenge is to store the partition buffer references of CSV chunk processing tasks in thread- local storage. Partition buffers are then reused as threads are reused by the TBB library. Hence, the expected mean size of relation partition chunks is the CSV input size divided by the number of hardware threads used for loading. Nev- ertheless, this is no panacea. If partition buffers are reused, merging of partition buffers with the relation can no longer be interleaved with CSV chunk processing. Furthermore, this approach requires CSV input to be of a respective size. For chunked storage backends it can thus also make sense to use copy-based merging or a hybrid approach. We intend to investigate further merge algorithms for various types of chunked storage backends in future work.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/4674d276-9a60-4cc6-ad1e-dd67478a42d5.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=99fa8bda2969f7907713f296966fc2a4639b459e3ea76e254694d331f928ea04",
            "html": "<p>One way to meet this challenge is to store the partition buffer references of CSV chunk processing tasks in thread- local storage. Partition buffers are then reused as threads are reused by the TBB library. Hence, the expected mean size of relation partition chunks is the CSV input size divided by the number of hardware threads used for loading. Nev- ertheless, this is no panacea. If partition buffers are reused, merging of partition buffers with the relation can no longer be interleaved with CSV chunk processing. Furthermore, this approach requires CSV input to be of a respective size. For chunked storage backends it can thus also make sense to use copy-based merging or a hybrid approach. We intend to investigate further merge algorithms for various types of chunked storage backends in future work.</p>",
            "markdown": "One way to meet this challenge is to store the partition buffer references of CSV chunk processing tasks in thread- local storage. Partition buffers are then reused as threads are reused by the TBB library. Hence, the expected mean size of relation partition chunks is the CSV input size divided by the number of hardware threads used for loading. Nev- ertheless, this is no panacea. If partition buffers are reused, merging of partition buffers with the relation can no longer be interleaved with CSV chunk processing. Furthermore, this approach requires CSV input to be of a respective size. For chunked storage backends it can thus also make sense to use copy-based merging or a hybrid approach. We intend to investigate further merge algorithms for various types of chunked storage backends in future work.\n\n"
          }
        ],
        "chunk_length": 508
      },
      {
        "segments": [
          {
            "segment_id": "8c242a4e-c219-405c-bf30-7c64dfe7d0c1",
            "bbox": {
              "left": 109.416664,
              "top": 646.9166,
              "width": 499.91666,
              "height": 343.66666
            },
            "page_number": 6,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Buffer allocation. Allocation and reallocation of parti- tion buffers on the heap is costly as, in general, it needs to be synchronized. Using scalable allocators that provide per- thread heaps is not an option as these are usually too small for loading purposes where huge amounts of data are moved. While an initial allocation of a buffer is unavoidable, reallo- cations can be saved by initially allocating enough memory for the tuples in a CSV chunk. The difficulty lies in the estimation of the number of tuples in a CSV chunk of a cer- tain size. This is mainly due to nullable attributes and at- tributes of varying lengths. Our solution is to let CSV chunk processing tasks atomically update cardinality estimates for the partition buffers that serve as allocation hints for future tasks. For our implementation, at a multiprogramming level of 8, this allocation strategy increases performance by about 5% compared to dynamic allocation.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/8c242a4e-c219-405c-bf30-7c64dfe7d0c1.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=4b2f2297c0ba41bea6360e9337d1e2eb31eddebffa90b0b3a8c61a886825994a",
            "html": "<p>Buffer allocation. Allocation and reallocation of parti- tion buffers on the heap is costly as, in general, it needs to be synchronized. Using scalable allocators that provide per- thread heaps is not an option as these are usually too small for loading purposes where huge amounts of data are moved. While an initial allocation of a buffer is unavoidable, reallo- cations can be saved by initially allocating enough memory for the tuples in a CSV chunk. The difficulty lies in the estimation of the number of tuples in a CSV chunk of a cer- tain size. This is mainly due to nullable attributes and at- tributes of varying lengths. Our solution is to let CSV chunk processing tasks atomically update cardinality estimates for the partition buffers that serve as allocation hints for future tasks. For our implementation, at a multiprogramming level of 8, this allocation strategy increases performance by about 5% compared to dynamic allocation.</p>",
            "markdown": "Buffer allocation. Allocation and reallocation of parti- tion buffers on the heap is costly as, in general, it needs to be synchronized. Using scalable allocators that provide per- thread heaps is not an option as these are usually too small for loading purposes where huge amounts of data are moved. While an initial allocation of a buffer is unavoidable, reallo- cations can be saved by initially allocating enough memory for the tuples in a CSV chunk. The difficulty lies in the estimation of the number of tuples in a CSV chunk of a cer- tain size. This is mainly due to nullable attributes and at- tributes of varying lengths. Our solution is to let CSV chunk processing tasks atomically update cardinality estimates for the partition buffers that serve as allocation hints for future tasks. For our implementation, at a multiprogramming level of 8, this allocation strategy increases performance by about 5% compared to dynamic allocation.\n\n"
          },
          {
            "segment_id": "a23567de-adda-4713-b91f-fe0035a52025",
            "bbox": {
              "left": 109.416664,
              "top": 994.8333,
              "width": 499.91666,
              "height": 126.99999
            },
            "page_number": 6,
            "page_width": 1275,
            "page_height": 1650,
            "content": "For hybrid OLTP&OLAP databases like HyPer, it fur- ther makes sense to allocate partition buffers on huge virtual memory pages. Huge pages have the advantage they have a separate section in the memory management unit (MMU) on most platforms. Hence, loading and mission-critical OLTP compete less for the transaction lookaside buffer (TLB).",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/a23567de-adda-4713-b91f-fe0035a52025.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=873c4dd5468c2cc08ffc9e2556e469185ed5d72eb79882783ca72ef28249b5b4",
            "html": "<p>For hybrid OLTP&OLAP databases like HyPer, it fur- ther makes sense to allocate partition buffers on huge virtual memory pages. Huge pages have the advantage they have a separate section in the memory management unit (MMU) on most platforms. Hence, loading and mission-critical OLTP compete less for the transaction lookaside buffer (TLB).</p>",
            "markdown": "For hybrid OLTP&OLAP databases like HyPer, it fur- ther makes sense to allocate partition buffers on huge virtual memory pages. Huge pages have the advantage they have a separate section in the memory management unit (MMU) on most platforms. Hence, loading and mission-critical OLTP compete less for the transaction lookaside buffer (TLB).\n\n"
          }
        ],
        "chunk_length": 207
      },
      {
        "segments": [
          {
            "segment_id": "2db75994-d32f-4daf-b05a-148824a710b6",
            "bbox": {
              "left": 109.416664,
              "top": 1142.75,
              "width": 420.74997,
              "height": 24.916666
            },
            "page_number": 6,
            "page_width": 1275,
            "page_height": 1650,
            "content": "3.6 Bulk Creation of Index Structures",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/2db75994-d32f-4daf-b05a-148824a710b6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5a86f9280256a7a7349aa5507bfb6e622d1a88eca9a5332f632db1f8db6069ea",
            "html": "<h2>3.6 Bulk Creation of Index Structures</h2>",
            "markdown": "## 3.6 Bulk Creation of Index Structures\n\n"
          },
          {
            "segment_id": "d2a11701-50ca-4efd-8320-9137d6b9dcbf",
            "bbox": {
              "left": 109.416664,
              "top": 1174,
              "width": 499.91666,
              "height": 324.91666
            },
            "page_number": 6,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Indexes have a decisive impact on transaction and query execution performance. However, there is a tradeoff be- tween time spent on index creation and time saved dur- ing query and transaction processing. Using standard ap- proaches, creating indexes during bulk loading can signifi- cantly slow down the loading throughput. Alternatives to the creation of indexes at load time such as database crack- ing [13] and adaptive indexing [14] propose to create indexes as a by-product of query processing and thereby allow faster data loading and fast query performance over time. How- ever, if data is bulk loaded to a mission-critical OLTP or OLAP system that needs execution time guarantees imme- diately after loading, delayed index creation is not an option. This is especially true for our proposed data staging process- ing model where data is loaded, processed, and unloaded in",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/d2a11701-50ca-4efd-8320-9137d6b9dcbf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=05908560e922ef0a0e85ead0c292c8d76e6a518c290fdb015a310926f234a5e2",
            "html": "<p>Indexes have a decisive impact on transaction and query execution performance. However, there is a tradeoff be- tween time spent on index creation and time saved dur- ing query and transaction processing. Using standard ap- proaches, creating indexes during bulk loading can signifi- cantly slow down the loading throughput. Alternatives to the creation of indexes at load time such as database crack- ing [13] and adaptive indexing [14] propose to create indexes as a by-product of query processing and thereby allow faster data loading and fast query performance over time. How- ever, if data is bulk loaded to a mission-critical OLTP or OLAP system that needs execution time guarantees imme- diately after loading, delayed index creation is not an option. This is especially true for our proposed data staging process- ing model where data is loaded, processed, and unloaded in</p>",
            "markdown": "Indexes have a decisive impact on transaction and query execution performance. However, there is a tradeoff be- tween time spent on index creation and time saved dur- ing query and transaction processing. Using standard ap- proaches, creating indexes during bulk loading can signifi- cantly slow down the loading throughput. Alternatives to the creation of indexes at load time such as database crack- ing [13] and adaptive indexing [14] propose to create indexes as a by-product of query processing and thereby allow faster data loading and fast query performance over time. How- ever, if data is bulk loaded to a mission-critical OLTP or OLAP system that needs execution time guarantees imme- diately after loading, delayed index creation is not an option. This is especially true for our proposed data staging process- ing model where data is loaded, processed, and unloaded in\n\n"
          },
          {
            "segment_id": "6a908463-0dfe-46be-8e79-19af972c8881",
            "bbox": {
              "left": 657.3333,
              "top": 117.74999,
              "width": 501.99997,
              "height": 83.25
            },
            "page_number": 6,
            "page_width": 1275,
            "page_height": 1650,
            "content": "cycles. Furthermore, to assure consistency, loading should at least check for primary key violations. We thus advo- cate for the creation of primary indexes at load time. With Instant Loading, it is our goal to achieve this at wire speed.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6a908463-0dfe-46be-8e79-19af972c8881.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=917768d14cc89e9d76f7e9b70148bac6a74ecffe451b9e125aaec9693d23ce20",
            "html": "<p>cycles. Furthermore, to assure consistency, loading should at least check for primary key violations. We thus advo- cate for the creation of primary indexes at load time. With Instant Loading, it is our goal to achieve this at wire speed.</p>",
            "markdown": "cycles. Furthermore, to assure consistency, loading should at least check for primary key violations. We thus advo- cate for the creation of primary indexes at load time. With Instant Loading, it is our goal to achieve this at wire speed.\n\n"
          },
          {
            "segment_id": "f69d8167-97fb-4bcb-b98f-738e8cbc8def",
            "bbox": {
              "left": 657.3333,
              "top": 203.16666,
              "width": 501.99997,
              "height": 322.8333
            },
            "page_number": 6,
            "page_width": 1275,
            "page_height": 1650,
            "content": "We identified different options regarding how and when to create indexes during loading. The first option is to always have a single index for the whole relation that is incremen- tally updated by inserting keys of new tuples after they have been added to the relation. The second option is to com- pletely recreate a new index from scratch. The first option is limited by the insertion speed of the index structure. The second option could benefit from index structures that allow the efficient recreation of an index. However, depending on the size of the relation, this might impose a huge overhead. We thus propose a third way: each CSV chunk-processing task maintains indexes in its partition buffers. These indexes are then merged with the indexes in the relation partition during the merge step. We define indexes that allow our approach as merge-able index structures for bulk loading:",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/f69d8167-97fb-4bcb-b98f-738e8cbc8def.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=b5a45922ffc638ded7b1c2c7cc1e48943c3733b8136cd7869d2a941822b12d25",
            "html": "<p>We identified different options regarding how and when to create indexes during loading. The first option is to always have a single index for the whole relation that is incremen- tally updated by inserting keys of new tuples after they have been added to the relation. The second option is to com- pletely recreate a new index from scratch. The first option is limited by the insertion speed of the index structure. The second option could benefit from index structures that allow the efficient recreation of an index. However, depending on the size of the relation, this might impose a huge overhead. We thus propose a third way: each CSV chunk-processing task maintains indexes in its partition buffers. These indexes are then merged with the indexes in the relation partition during the merge step. We define indexes that allow our approach as merge-able index structures for bulk loading:</p>",
            "markdown": "We identified different options regarding how and when to create indexes during loading. The first option is to always have a single index for the whole relation that is incremen- tally updated by inserting keys of new tuples after they have been added to the relation. The second option is to com- pletely recreate a new index from scratch. The first option is limited by the insertion speed of the index structure. The second option could benefit from index structures that allow the efficient recreation of an index. However, depending on the size of the relation, this might impose a huge overhead. We thus propose a third way: each CSV chunk-processing task maintains indexes in its partition buffers. These indexes are then merged with the indexes in the relation partition during the merge step. We define indexes that allow our approach as merge-able index structures for bulk loading:\n\n"
          },
          {
            "segment_id": "52643eff-9469-4b0d-bbc6-8b4541abbc0e",
            "bbox": {
              "left": 657.3333,
              "top": 536.5,
              "width": 501.99997,
              "height": 279.0833
            },
            "page_number": 6,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Definition (Merge-able index structures for bulk loading). Merge-able index structures for bulk loading are index structures that allow the efficient and parallelized cre- ation of the set of indexes I = { I 1 , . . . , I n } over a set of keys K = { k 1 , . . . , k m } , where K is partitioned into n nonempty disjoint subsets K 1 , . . . , K n and I j is an index over K j for 1 ≤ j ≤ n . Further, there exists an efficient parallelized merge function that, given I , yields a single unified index over K . The unified index creation time t is the aggregate of time needed to create I and time needed to merge I . For merge-able index structures for bulk loading, t proportion- ally decreases with an increasing number n of key partitions assuming n available hardware threads.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/52643eff-9469-4b0d-bbc6-8b4541abbc0e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c3cbd7a6e5664941523ddd408b187fbb75117cde604c9c5c318a0475788817b7",
            "html": "<p>Definition (Merge-able index structures for bulk loading). Merge-able index structures for bulk loading are index structures that allow the efficient and parallelized cre- ation of the set of indexes I = { I 1 , . . . , I n } over a set of keys K = { k 1 , . . . , k m } , where K is partitioned into n nonempty disjoint subsets K 1 , . . . , K n and I j is an index over K j for 1 ≤ j ≤ n . Further, there exists an efficient parallelized merge function that, given I , yields a single unified index over K . The unified index creation time t is the aggregate of time needed to create I and time needed to merge I . For merge-able index structures for bulk loading, t proportion- ally decreases with an increasing number n of key partitions assuming n available hardware threads.</p>",
            "markdown": "Definition (Merge-able index structures for bulk loading). Merge-able index structures for bulk loading are index structures that allow the efficient and parallelized cre- ation of the set of indexes I = { I 1 , . . . , I n } over a set of keys K = { k 1 , . . . , k m } , where K is partitioned into n nonempty disjoint subsets K 1 , . . . , K n and I j is an index over K j for 1 ≤ j ≤ n . Further, there exists an efficient parallelized merge function that, given I , yields a single unified index over K . The unified index creation time t is the aggregate of time needed to create I and time needed to merge I . For merge-able index structures for bulk loading, t proportion- ally decreases with an increasing number n of key partitions assuming n available hardware threads.\n\n"
          }
        ],
        "chunk_length": 495
      },
      {
        "segments": [
          {
            "segment_id": "5851b846-90e3-47c5-af5e-b80d8a3b1e80",
            "bbox": {
              "left": 657.3333,
              "top": 823.99994,
              "width": 501.99997,
              "height": 126.99999
            },
            "page_number": 6,
            "page_width": 1275,
            "page_height": 1650,
            "content": "In the following we show that hash tables with chaining and the adaptive radix tree (ART) [20] are merge-able in- dex structures for bulk loading. Our evaluation (see Sect. 5) further demonstrates that parallelized forms of these indexes achieve a near-linear speedup with the number of key parti- tions and hardware threads used for bulk index creation.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/5851b846-90e3-47c5-af5e-b80d8a3b1e80.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=b2b55aabb25499f5c6aa5525c06c38377d8c1cabb52e9062585947a3eab8b9a8",
            "html": "<p>In the following we show that hash tables with chaining and the adaptive radix tree (ART) [20] are merge-able in- dex structures for bulk loading. Our evaluation (see Sect. 5) further demonstrates that parallelized forms of these indexes achieve a near-linear speedup with the number of key parti- tions and hardware threads used for bulk index creation.</p>",
            "markdown": "In the following we show that hash tables with chaining and the adaptive radix tree (ART) [20] are merge-able in- dex structures for bulk loading. Our evaluation (see Sect. 5) further demonstrates that parallelized forms of these indexes achieve a near-linear speedup with the number of key parti- tions and hardware threads used for bulk index creation.\n\n"
          }
        ],
        "chunk_length": 57
      },
      {
        "segments": [
          {
            "segment_id": "2f07abdb-e104-4bb9-ad5a-0c3fe5e14ddf",
            "bbox": {
              "left": 663.5833,
              "top": 971.9166,
              "width": 299.91666,
              "height": 20.75
            },
            "page_number": 6,
            "page_width": 1275,
            "page_height": 1650,
            "content": "3.6.1 Hash table with chaining",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/2f07abdb-e104-4bb9-ad5a-0c3fe5e14ddf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=48c72a743af328fbc5b2441ac893efc16df53b031fe45673afbfd47b34e85ddb",
            "html": "<h2>3.6.1 Hash table with chaining</h2>",
            "markdown": "## 3.6.1 Hash table with chaining\n\n"
          },
          {
            "segment_id": "e4e5dcd7-e495-4217-9cf7-022446255eef",
            "bbox": {
              "left": 657.3333,
              "top": 998.99994,
              "width": 501.99997,
              "height": 497.8333
            },
            "page_number": 6,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Hash tables are a popular in-memory data structure and are often used for indexes in main memory databases. In- dexes based on hash tables only allow point queries but are very fast due to their expected lookup time of O (1). Hash tables inevitably face the problem of hash collisions. Strategies for conflict resolution include open addressing and chaining. Hash tables that use chaining for conflict resolu- tion are particularly suitable as merge-able indexes for bulk loading. Our implementation of a merge-able hash table for bulk loading uses a fixed-sized hash table, where entries with the same hash value are chained in a linked list. For a given partitioned key range, equally-sized hash tables us- ing the same hash function are, in parallel, created for each partition. These hash tables are then repeatedly merged in pairs of two by scanning one of the tables and concatenat- ing each list entry for a specific hash value with the list for that hash value in the other hash table. The scan operation can thereby again be parallelized efficiently. It is of note that a space-time tradeoff is immanent in hash table-based index approaches. Our merge-able hash table with chaining allocates a fixed size hash table for each parallel task and is thus wasting space. In contrast to hash tables, the adaptive radix tree is highly space-efficient.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/e4e5dcd7-e495-4217-9cf7-022446255eef.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=622f9206bf71c94c5e5325876718b2e608d4741da39e58a3752d2c4089be3123",
            "html": "<p>Hash tables are a popular in-memory data structure and are often used for indexes in main memory databases. In- dexes based on hash tables only allow point queries but are very fast due to their expected lookup time of O (1). Hash tables inevitably face the problem of hash collisions. Strategies for conflict resolution include open addressing and chaining. Hash tables that use chaining for conflict resolu- tion are particularly suitable as merge-able indexes for bulk loading. Our implementation of a merge-able hash table for bulk loading uses a fixed-sized hash table, where entries with the same hash value are chained in a linked list. For a given partitioned key range, equally-sized hash tables us- ing the same hash function are, in parallel, created for each partition. These hash tables are then repeatedly merged in pairs of two by scanning one of the tables and concatenat- ing each list entry for a specific hash value with the list for that hash value in the other hash table. The scan operation can thereby again be parallelized efficiently. It is of note that a space-time tradeoff is immanent in hash table-based index approaches. Our merge-able hash table with chaining allocates a fixed size hash table for each parallel task and is thus wasting space. In contrast to hash tables, the adaptive radix tree is highly space-efficient.</p>",
            "markdown": "Hash tables are a popular in-memory data structure and are often used for indexes in main memory databases. In- dexes based on hash tables only allow point queries but are very fast due to their expected lookup time of O (1). Hash tables inevitably face the problem of hash collisions. Strategies for conflict resolution include open addressing and chaining. Hash tables that use chaining for conflict resolu- tion are particularly suitable as merge-able indexes for bulk loading. Our implementation of a merge-able hash table for bulk loading uses a fixed-sized hash table, where entries with the same hash value are chained in a linked list. For a given partitioned key range, equally-sized hash tables us- ing the same hash function are, in parallel, created for each partition. These hash tables are then repeatedly merged in pairs of two by scanning one of the tables and concatenat- ing each list entry for a specific hash value with the list for that hash value in the other hash table. The scan operation can thereby again be parallelized efficiently. It is of note that a space-time tradeoff is immanent in hash table-based index approaches. Our merge-able hash table with chaining allocates a fixed size hash table for each parallel task and is thus wasting space. In contrast to hash tables, the adaptive radix tree is highly space-efficient.\n\n"
          },
          {
            "segment_id": "40c6c89d-69db-407e-aa0e-69e2d55b730c",
            "bbox": {
              "left": 157.33333,
              "top": 99,
              "width": 408.24997,
              "height": 335.3333
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "ANT AND ANY ART A N R T Y D T (a) tree 1 ARE BED BEE B A R E E E D (b) tree 2 T E R A E E D digit 1 digit 2 digit 3 leaves BED BEE B N ANT AND ANY ART Y D T ARE updated reference new node (c) merged tree",
            "segment_type": "Picture",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/40c6c89d-69db-407e-aa0e-69e2d55b730c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=acd6496f9d975841f140052c1325e1fe20e7271c20a9c8d0e7ba385e680950e5",
            "html": "<img src=\"https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/40c6c89d-69db-407e-aa0e-69e2d55b730c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=acd6496f9d975841f140052c1325e1fe20e7271c20a9c8d0e7ba385e680950e5\" />",
            "markdown": "![Image](https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/40c6c89d-69db-407e-aa0e-69e2d55b730c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=acd6496f9d975841f140052c1325e1fe20e7271c20a9c8d0e7ba385e680950e5)"
          },
          {
            "segment_id": "3faae980-319c-44e5-a604-b6320150bc56",
            "bbox": {
              "left": 109.416664,
              "top": 451.0833,
              "width": 501.99997,
              "height": 37.416664
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Figure 7: Two adaptive radix trees (ART) (a) and (b) and the result of merging the two trees (c).",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/3faae980-319c-44e5-a604-b6320150bc56.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0d00b1cb4077edb59b2f24caee9734e47097592f3ec21e9d50a4e074f30bb8e9",
            "html": "<span class=\"caption\">Figure 7: Two adaptive radix trees (ART) (a) and (b) and the result of merging the two trees (c).</span>",
            "markdown": "Figure 7: Two adaptive radix trees (ART) (a) and (b) and the result of merging the two trees (c).\n\n"
          }
        ],
        "chunk_length": 308
      },
      {
        "segments": [
          {
            "segment_id": "21977fe3-3221-40fc-8dbd-b29c0fcc12ad",
            "bbox": {
              "left": 117.74999,
              "top": 536.5,
              "width": 316.5833,
              "height": 20.75
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "3.6.2 Adaptive Radix Tree (ART)",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/21977fe3-3221-40fc-8dbd-b29c0fcc12ad.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c1d8298d93aa27155096917d2830dfb1a2ab02d6e4a6e7f16594103d7d636377",
            "html": "<h2>3.6.2 Adaptive Radix Tree (ART)</h2>",
            "markdown": "## 3.6.2 Adaptive Radix Tree (ART)\n\n"
          },
          {
            "segment_id": "2ea5b6f6-77b9-4e48-a307-8f31e1da2040",
            "bbox": {
              "left": 109.416664,
              "top": 563.5833,
              "width": 501.99997,
              "height": 343.66666
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "The adaptive radix tree (ART) [20] is a high performance and space-efficient general purpose index structure for main memory databases that is tuned for modern hardware. Com- pared to hash tables, radix trees, also known as tries, di- rectly use the digital representation of keys for comparison. The idea of a radix tree is similar to that of a thumb index of dictionaries, which indexes its entries according to their first character prefix. Radix trees use this technique recursively until a specific entry is found. An example of an ART index is shown in Fig. 7(a). ART is a byte-wise radix tree that uses the individual bytes of a key for indexing. As a result, all operations have a complexity of O ( k ), where k is the byte length of the indexed keys. Compared to hash tables, which are not order-preserving, radix trees store keys in their lex- icographical order. This allows not only exact lookups but also range scans, prefix lookups, and top-k queries.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/2ea5b6f6-77b9-4e48-a307-8f31e1da2040.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a696179df8a55f4fe9a1a97424dfaae0788d425b9df45deff24ab7cb45284453",
            "html": "<p>The adaptive radix tree (ART) [20] is a high performance and space-efficient general purpose index structure for main memory databases that is tuned for modern hardware. Com- pared to hash tables, radix trees, also known as tries, di- rectly use the digital representation of keys for comparison. The idea of a radix tree is similar to that of a thumb index of dictionaries, which indexes its entries according to their first character prefix. Radix trees use this technique recursively until a specific entry is found. An example of an ART index is shown in Fig. 7(a). ART is a byte-wise radix tree that uses the individual bytes of a key for indexing. As a result, all operations have a complexity of O ( k ), where k is the byte length of the indexed keys. Compared to hash tables, which are not order-preserving, radix trees store keys in their lex- icographical order. This allows not only exact lookups but also range scans, prefix lookups, and top-k queries.</p>",
            "markdown": "The adaptive radix tree (ART) [20] is a high performance and space-efficient general purpose index structure for main memory databases that is tuned for modern hardware. Com- pared to hash tables, radix trees, also known as tries, di- rectly use the digital representation of keys for comparison. The idea of a radix tree is similar to that of a thumb index of dictionaries, which indexes its entries according to their first character prefix. Radix trees use this technique recursively until a specific entry is found. An example of an ART index is shown in Fig. 7(a). ART is a byte-wise radix tree that uses the individual bytes of a key for indexing. As a result, all operations have a complexity of O ( k ), where k is the byte length of the indexed keys. Compared to hash tables, which are not order-preserving, radix trees store keys in their lex- icographical order. This allows not only exact lookups but also range scans, prefix lookups, and top-k queries.\n\n"
          },
          {
            "segment_id": "0fcfc031-2b06-4267-87c9-0d744526cd53",
            "bbox": {
              "left": 109.416664,
              "top": 911.49994,
              "width": 501.99997,
              "height": 277
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "While other radix tree implementations rely on a glob- ally fixed fanout parameter and thus have to trade off tree height against space efficiency, ART distinguishes itself from these implementations by using adaptively sized nodes. In ART, nodes are represented using four types of efficient and compact data structures with different sizes of up to 256 en- tries. The type of a node is chosen dynamically depending on the number of child nodes, which optimizes space utiliza- tion and access efficiency at the same time. The evaluation in [20] shows that ART is the fastest general purpose index structure for main memory databases optimized for mod- ern hardware. Its performance is only met by hash tables, which, however, only support exact key lookups.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/0fcfc031-2b06-4267-87c9-0d744526cd53.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=ee2683f316a0b744ba6e1e04aa35c27f6966c1cb97de99386a3a8074a310f14a",
            "html": "<p>While other radix tree implementations rely on a glob- ally fixed fanout parameter and thus have to trade off tree height against space efficiency, ART distinguishes itself from these implementations by using adaptively sized nodes. In ART, nodes are represented using four types of efficient and compact data structures with different sizes of up to 256 en- tries. The type of a node is chosen dynamically depending on the number of child nodes, which optimizes space utiliza- tion and access efficiency at the same time. The evaluation in [20] shows that ART is the fastest general purpose index structure for main memory databases optimized for mod- ern hardware. Its performance is only met by hash tables, which, however, only support exact key lookups.</p>",
            "markdown": "While other radix tree implementations rely on a glob- ally fixed fanout parameter and thus have to trade off tree height against space efficiency, ART distinguishes itself from these implementations by using adaptively sized nodes. In ART, nodes are represented using four types of efficient and compact data structures with different sizes of up to 256 en- tries. The type of a node is chosen dynamically depending on the number of child nodes, which optimizes space utiliza- tion and access efficiency at the same time. The evaluation in [20] shows that ART is the fastest general purpose index structure for main memory databases optimized for mod- ern hardware. Its performance is only met by hash tables, which, however, only support exact key lookups.\n\n"
          },
          {
            "segment_id": "fca78461-2e7c-4de4-8b7c-2d5e5cb15046",
            "bbox": {
              "left": 109.416664,
              "top": 1196.9166,
              "width": 501.99997,
              "height": 299.91666
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "In this work we show that ART further belongs to the class of merge-able index structures for bulk loading by specifying an efficient parallelized merge algorithm. Fig. 7 illustrates the merging of two ART indexes. Radix trees in general are naturally suited for efficient parallelized merging: starting with the two root nodes, for each pair of nodes, children with common prefixes in the two trees are recursively merged in parallel. When all children with common prefixes have been merged, children of the smaller node that have no match in the bigger node are inserted into the bigger node. This bigger node is then used in the merged tree. Ideally, merging is thus reducible to a single insertion for non-empty trees. In the worst case, both trees contain only keys with common prefixes and nodes at maximum depth need to be merged.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/fca78461-2e7c-4de4-8b7c-2d5e5cb15046.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e86d3b9dce858f85fb82c9b001e4b9783982f5a2dac85c209b1465670e7d5f27",
            "html": "<p>In this work we show that ART further belongs to the class of merge-able index structures for bulk loading by specifying an efficient parallelized merge algorithm. Fig. 7 illustrates the merging of two ART indexes. Radix trees in general are naturally suited for efficient parallelized merging: starting with the two root nodes, for each pair of nodes, children with common prefixes in the two trees are recursively merged in parallel. When all children with common prefixes have been merged, children of the smaller node that have no match in the bigger node are inserted into the bigger node. This bigger node is then used in the merged tree. Ideally, merging is thus reducible to a single insertion for non-empty trees. In the worst case, both trees contain only keys with common prefixes and nodes at maximum depth need to be merged.</p>",
            "markdown": "In this work we show that ART further belongs to the class of merge-able index structures for bulk loading by specifying an efficient parallelized merge algorithm. Fig. 7 illustrates the merging of two ART indexes. Radix trees in general are naturally suited for efficient parallelized merging: starting with the two root nodes, for each pair of nodes, children with common prefixes in the two trees are recursively merged in parallel. When all children with common prefixes have been merged, children of the smaller node that have no match in the bigger node are inserted into the bigger node. This bigger node is then used in the merged tree. Ideally, merging is thus reducible to a single insertion for non-empty trees. In the worst case, both trees contain only keys with common prefixes and nodes at maximum depth need to be merged.\n\n"
          }
        ],
        "chunk_length": 436
      },
      {
        "segments": [
          {
            "segment_id": "2beef85a-41e9-438c-a006-a14ed1f4425c",
            "bbox": {
              "left": 657.3333,
              "top": 117.74999,
              "width": 501.99997,
              "height": 106.166664
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "In general, merging of two radix trees t 1 and t 2 needs O ( d ) copy operations, where d is the minimum of diff ( t 1 , t 2 ) and diff ( t 2 , t 1 ), where diff ( x, y ) is the number of inner nodes and leaves of y that are not present in x and are children of a node that does not already count towards this number.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/2beef85a-41e9-438c-a006-a14ed1f4425c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=38815cba8ec0a48f30f079471967326f16e3437ef29f29f32e37178f7181e001",
            "html": "<p>In general, merging of two radix trees t 1 and t 2 needs O ( d ) copy operations, where d is the minimum of diff ( t 1 , t 2 ) and diff ( t 2 , t 1 ), where diff ( x, y ) is the number of inner nodes and leaves of y that are not present in x and are children of a node that does not already count towards this number.</p>",
            "markdown": "In general, merging of two radix trees t 1 and t 2 needs O ( d ) copy operations, where d is the minimum of diff ( t 1 , t 2 ) and diff ( t 2 , t 1 ), where diff ( x, y ) is the number of inner nodes and leaves of y that are not present in x and are children of a node that does not already count towards this number.\n\n"
          },
          {
            "segment_id": "e92c493e-1853-44a1-9927-98ddd2f44c1f",
            "bbox": {
              "left": 676.0833,
              "top": 228.16666,
              "width": 422.8333,
              "height": 16.583332
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Our parallelized merge algorithm looks as follows:",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/e92c493e-1853-44a1-9927-98ddd2f44c1f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=1a65d2561838b6ad4f471409870a1c48010f723fb285b37435c636381bf39ec6",
            "html": "<p>Our parallelized merge algorithm looks as follows:</p>",
            "markdown": "Our parallelized merge algorithm looks as follows:\n\n"
          },
          {
            "segment_id": "30217149-bf89-4712-884d-a9b726148954",
            "bbox": {
              "left": 659.4166,
              "top": 248.99998,
              "width": 479.0833,
              "height": 297.8333
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "1: procedure merge ( t 1 , t 2 ,depth) 2: if isLeaf( t 1 ) then insert( t 2 , t 1 .keyByte, t 1 ,depth) 3: return t 2 4: if isLeaf( t 2 ) then insert( t 1 , t 2 .keyByte, t 2 ,depth) 5: return t 1 6: // ensure that t 1 is the bigger node 7: if t 1 .count > t 2 .count then swap( t 1 , t 2 ) 8: // descend trees in parallel for common key bytes 9: parallel for each entry e in t 2 do 10: c = findChildPtr( t 1 ,e.keyByte) 11: if c then c = merge ((c,e.child,depth +1 )) 12: // sequentially insert t 2 ’s unique entries in t 1 13: for each entry e in t 2 do 14: c = findChildPtr( t 1 ,e.keyByte) 15: if !c then insert( t 1 ,e.keyByte,e.child,depth) 16: return t 1",
            "segment_type": "Table",
            "ocr": [],
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/30217149-bf89-4712-884d-a9b726148954.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=01f91fed93971e1c211eed4b45d8dc98a3cb914c197bfe8639f333ae84ea166b",
            "html": "<span class=\"table\">1: procedure merge ( t 1 , t 2 ,depth) 2: if isLeaf( t 1 ) then insert( t 2 , t 1 .keyByte, t 1 ,depth) 3: return t 2 4: if isLeaf( t 2 ) then insert( t 1 , t 2 .keyByte, t 2 ,depth) 5: return t 1 6: // ensure that t 1 is the bigger node 7: if t 1 .count > t 2 .count then swap( t 1 , t 2 ) 8: // descend trees in parallel for common key bytes 9: parallel for each entry e in t 2 do 10: c = findChildPtr( t 1 ,e.keyByte) 11: if c then c = merge ((c,e.child,depth +1 )) 12: // sequentially insert t 2 ’s unique entries in t 1 13: for each entry e in t 2 do 14: c = findChildPtr( t 1 ,e.keyByte) 15: if !c then insert( t 1 ,e.keyByte,e.child,depth) 16: return t 1</span>",
            "markdown": "\n"
          },
          {
            "segment_id": "ba4c646e-304f-4179-8d29-41338e76595e",
            "bbox": {
              "left": 657.3333,
              "top": 557.3333,
              "width": 501.99997,
              "height": 279.0833
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "As mentioned before, we insert entries of key bytes of the smaller node that have no match in the bigger node se- quentially and after all children with common prefixes have been merged in parallel. In ART, this separation into par- allel and sequential phases is particularly due to the fact that nodes can grow when inserting new entries. For the biggest node type, which is essentially an array of size 256, insertions can further be parallelized using lock-free atomic operations. This kind of insertion parallelization is also ap- plicable to other radix trees that work with nodes of a fixed size. It is indeed also feasible to implement a completely lock-free version of ART, which is, however, out of scope for this work, as we focused on an efficient merge algorithm.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ba4c646e-304f-4179-8d29-41338e76595e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=6091c61c8ee74a11b97adc71e1779d5925be8550f792a93560c5095f25fa0483",
            "html": "<p>As mentioned before, we insert entries of key bytes of the smaller node that have no match in the bigger node se- quentially and after all children with common prefixes have been merged in parallel. In ART, this separation into par- allel and sequential phases is particularly due to the fact that nodes can grow when inserting new entries. For the biggest node type, which is essentially an array of size 256, insertions can further be parallelized using lock-free atomic operations. This kind of insertion parallelization is also ap- plicable to other radix trees that work with nodes of a fixed size. It is indeed also feasible to implement a completely lock-free version of ART, which is, however, out of scope for this work, as we focused on an efficient merge algorithm.</p>",
            "markdown": "As mentioned before, we insert entries of key bytes of the smaller node that have no match in the bigger node se- quentially and after all children with common prefixes have been merged in parallel. In ART, this separation into par- allel and sequential phases is particularly due to the fact that nodes can grow when inserting new entries. For the biggest node type, which is essentially an array of size 256, insertions can further be parallelized using lock-free atomic operations. This kind of insertion parallelization is also ap- plicable to other radix trees that work with nodes of a fixed size. It is indeed also feasible to implement a completely lock-free version of ART, which is, however, out of scope for this work, as we focused on an efficient merge algorithm.\n\n"
          }
        ],
        "chunk_length": 373
      },
      {
        "segments": [
          {
            "segment_id": "2e90f7a7-73f0-4a29-ad4b-4f5156979b18",
            "bbox": {
              "left": 657.3333,
              "top": 878.1666,
              "width": 406.16666,
              "height": 22.833332
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "4. INSTANT LOADING IN HYPER",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/2e90f7a7-73f0-4a29-ad4b-4f5156979b18.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5094efd2b7cbff08471966c1fcaf8bf6fd3b2a9cb0078903e3fcf24710658dbc",
            "html": "<h2>4. INSTANT LOADING IN HYPER</h2>",
            "markdown": "## 4. INSTANT LOADING IN HYPER\n\n"
          },
          {
            "segment_id": "fedd7fcc-b631-4a65-9f4a-11412c720bc9",
            "bbox": {
              "left": 657.3333,
              "top": 926.0833,
              "width": 437.41666,
              "height": 22.833332
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "4.1 The HyPer Main Memory Database",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/fedd7fcc-b631-4a65-9f4a-11412c720bc9.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=24014cfb29623f5c7507d2299057ea2c901ce027e278cc04f9804724d1519a1f",
            "html": "<h2>4.1 The HyPer Main Memory Database</h2>",
            "markdown": "## 4.1 The HyPer Main Memory Database\n\n"
          },
          {
            "segment_id": "1fc03f11-c28f-4e33-be0b-98e5f767d0fc",
            "bbox": {
              "left": 657.3333,
              "top": 955.24994,
              "width": 501.99997,
              "height": 191.58333
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "We integrated our generic Instant Loading approach in HyPer [19], our high-performance relational main memory database system. HyPer belongs to an emerging class of hybrid databases, which enable real-time business intelli- gence by evaluating OLAP queries directly in the trans- actional database. Using a novel snapshotting technique, HyPer achieves highest performance—compared to state of the art in-memory databases—for both, OLTP and OLAP workloads, operating simultaneously on the same database.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/1fc03f11-c28f-4e33-be0b-98e5f767d0fc.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=59bef57c4cb52e6af3f7996aa36cd0f0364da8c9a5eb0aa8648efa27da44efcc",
            "html": "<p>We integrated our generic Instant Loading approach in HyPer [19], our high-performance relational main memory database system. HyPer belongs to an emerging class of hybrid databases, which enable real-time business intelli- gence by evaluating OLAP queries directly in the trans- actional database. Using a novel snapshotting technique, HyPer achieves highest performance—compared to state of the art in-memory databases—for both, OLTP and OLAP workloads, operating simultaneously on the same database.</p>",
            "markdown": "We integrated our generic Instant Loading approach in HyPer [19], our high-performance relational main memory database system. HyPer belongs to an emerging class of hybrid databases, which enable real-time business intelli- gence by evaluating OLAP queries directly in the trans- actional database. Using a novel snapshotting technique, HyPer achieves highest performance—compared to state of the art in-memory databases—for both, OLTP and OLAP workloads, operating simultaneously on the same database.\n\n"
          },
          {
            "segment_id": "b3cdae02-45a3-4f1f-b7a4-1195f67bdebe",
            "bbox": {
              "left": 657.3333,
              "top": 1153.1666,
              "width": 501.99997,
              "height": 235.33333
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "OLAP is decoupled from mission-critical OLTP using a snapshot mechanism with (almost) no synchronization over- head. The mechanism is based on the POSIX system call fork() : OLAP queries are executed in a process that is fork ed from the OLTP process (see Fig. 8). This is very efficient as only the virtual page table of the OLTP process is copied. The operating system uses the processor’s mem- ory management unit to implement efficient copy-on-update semantics for snapshotted pages. Whenever the OLTP pro- cess modifies a snapshotted page for the first time, the page is replicated in the fork ed process (see Fig. 8).",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/b3cdae02-45a3-4f1f-b7a4-1195f67bdebe.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=ce99bebe9d3301cc8739ce538503274edc370a4838f45e7e62b759656fc18d8e",
            "html": "<p>OLAP is decoupled from mission-critical OLTP using a snapshot mechanism with (almost) no synchronization over- head. The mechanism is based on the POSIX system call fork() : OLAP queries are executed in a process that is fork ed from the OLTP process (see Fig. 8). This is very efficient as only the virtual page table of the OLTP process is copied. The operating system uses the processor’s mem- ory management unit to implement efficient copy-on-update semantics for snapshotted pages. Whenever the OLTP pro- cess modifies a snapshotted page for the first time, the page is replicated in the fork ed process (see Fig. 8).</p>",
            "markdown": "OLAP is decoupled from mission-critical OLTP using a snapshot mechanism with (almost) no synchronization over- head. The mechanism is based on the POSIX system call fork() : OLAP queries are executed in a process that is fork ed from the OLTP process (see Fig. 8). This is very efficient as only the virtual page table of the OLTP process is copied. The operating system uses the processor’s mem- ory management unit to implement efficient copy-on-update semantics for snapshotted pages. Whenever the OLTP pro- cess modifies a snapshotted page for the first time, the page is replicated in the fork ed process (see Fig. 8).\n\n"
          },
          {
            "segment_id": "fd51f8dc-b676-4b56-a511-921aaa83de05",
            "bbox": {
              "left": 657.3333,
              "top": 1390.6666,
              "width": 501.99997,
              "height": 106.166664
            },
            "page_number": 7,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Transactions are specified in SQL or in a PL/SQL style scripting language and are compiled into machine code us- ing the LLVM compiler framework [22]. Together with the elimination of ballast caused by buffer management, locking, and latching, HyPer can process more than 100,000 TPC-C",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/fd51f8dc-b676-4b56-a511-921aaa83de05.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=88f71ff8fdea003cc9e6de05feda903cc247229c34e45ff7d27f1d2aef7c594d",
            "html": "<p>Transactions are specified in SQL or in a PL/SQL style scripting language and are compiled into machine code us- ing the LLVM compiler framework [22]. Together with the elimination of ballast caused by buffer management, locking, and latching, HyPer can process more than 100,000 TPC-C</p>",
            "markdown": "Transactions are specified in SQL or in a PL/SQL style scripting language and are compiled into machine code us- ing the LLVM compiler framework [22]. Together with the elimination of ballast caused by buffer management, locking, and latching, HyPer can process more than 100,000 TPC-C\n\n"
          },
          {
            "segment_id": "34db4c74-514b-4ea3-ad12-7d3feee43f0e",
            "bbox": {
              "left": 151.08333,
              "top": 103.166664,
              "width": 410.3333,
              "height": 204.08333
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "fork（） OLAPsnapshot queries AB replicated page updates （due to update of A) A B updateAtoA' copy-on-update OLTPdata",
            "segment_type": "Picture",
            "ocr": [
              {
                "bbox": {
                  "left": 84,
                  "top": 6,
                  "width": 53,
                  "height": 19
                },
                "text": "fork（）",
                "confidence": 0.85866565
              },
              {
                "bbox": {
                  "left": 145,
                  "top": 12,
                  "width": 99,
                  "height": 20
                },
                "text": "OLAPsnapshot",
                "confidence": 0.9853072
              },
              {
                "bbox": {
                  "left": 266,
                  "top": 51,
                  "width": 48,
                  "height": 12
                },
                "text": "queries",
                "confidence": 0.9798664
              },
              {
                "bbox": {
                  "left": 232,
                  "top": 88,
                  "width": 10,
                  "height": 25
                },
                "text": "AB",
                "confidence": 0.9852688
              },
              {
                "bbox": {
                  "left": 274,
                  "top": 89,
                  "width": 101,
                  "height": 14
                },
                "text": "replicated page",
                "confidence": 0.9706675
              },
              {
                "bbox": {
                  "left": 33,
                  "top": 107,
                  "width": 54,
                  "height": 15
                },
                "text": "updates",
                "confidence": 0.99418193
              },
              {
                "bbox": {
                  "left": 276,
                  "top": 107,
                  "width": 129,
                  "height": 15
                },
                "text": "（due to update of A)",
                "confidence": 0.87624437
              },
              {
                "bbox": {
                  "left": 197,
                  "top": 134,
                  "width": 9,
                  "height": 10
                },
                "text": "A",
                "confidence": 0.99735874
              },
              {
                "bbox": {
                  "left": 197,
                  "top": 144,
                  "width": 9,
                  "height": 12
                },
                "text": "B",
                "confidence": 0.99210185
              },
              {
                "bbox": {
                  "left": 8,
                  "top": 155,
                  "width": 91,
                  "height": 15
                },
                "text": "updateAtoA'",
                "confidence": 0.9625173
              },
              {
                "bbox": {
                  "left": 225,
                  "top": 155,
                  "width": 103,
                  "height": 17
                },
                "text": "copy-on-update",
                "confidence": 0.9945574
              },
              {
                "bbox": {
                  "left": 127,
                  "top": 190,
                  "width": 64,
                  "height": 12
                },
                "text": "OLTPdata",
                "confidence": 0.9828026
              }
            ],
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/34db4c74-514b-4ea3-ad12-7d3feee43f0e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e6b6a365bdb5697e52709a914850fa379727ba46191ad10920320d8889fda208",
            "html": "<img src=\"https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/34db4c74-514b-4ea3-ad12-7d3feee43f0e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e6b6a365bdb5697e52709a914850fa379727ba46191ad10920320d8889fda208\" />",
            "markdown": "![Image](https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/34db4c74-514b-4ea3-ad12-7d3feee43f0e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e6b6a365bdb5697e52709a914850fa379727ba46191ad10920320d8889fda208)"
          },
          {
            "segment_id": "de03250d-9ba2-4d0d-8eb3-6d866ba3f038",
            "bbox": {
              "left": 146.91666,
              "top": 313.5833,
              "width": 426.99997,
              "height": 18.666666
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Figure 8: HyPer’s snapshotting mechanism.",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/de03250d-9ba2-4d0d-8eb3-6d866ba3f038.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f98e96da1f21298a5d09cb346edd2011f67fd915a6b5f0b6a0a0d73dbf202332",
            "html": "<span class=\"caption\">Figure 8: HyPer’s snapshotting mechanism.</span>",
            "markdown": "Figure 8: HyPer’s snapshotting mechanism.\n\n"
          },
          {
            "segment_id": "41245a65-2723-49c3-9dab-f21838008128",
            "bbox": {
              "left": 109.416664,
              "top": 359.41666,
              "width": 501.99997,
              "height": 168.66666
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "transactions per second in a single thread on modern hard- ware [19]. Similar to the design pioneered by H-Store [18] and VoltDB, HyPer also implements a partitioned execution model: The database is partitioned in a way that most trans- actions only need to access a single partition. Transactions that each exclusively work on a different partition can thus be processed in parallel without synchronization. Synchro- nization is only necessary for partition-crossing transactions.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/41245a65-2723-49c3-9dab-f21838008128.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2b7134d2914122b8bb73c3f0270e7cfb95800a9f317a37f754c2ed28d580ab05",
            "html": "<p>transactions per second in a single thread on modern hard- ware [19]. Similar to the design pioneered by H-Store [18] and VoltDB, HyPer also implements a partitioned execution model: The database is partitioned in a way that most trans- actions only need to access a single partition. Transactions that each exclusively work on a different partition can thus be processed in parallel without synchronization. Synchro- nization is only necessary for partition-crossing transactions.</p>",
            "markdown": "transactions per second in a single thread on modern hard- ware [19]. Similar to the design pioneered by H-Store [18] and VoltDB, HyPer also implements a partitioned execution model: The database is partitioned in a way that most trans- actions only need to access a single partition. Transactions that each exclusively work on a different partition can thus be processed in parallel without synchronization. Synchro- nization is only necessary for partition-crossing transactions.\n\n"
          },
          {
            "segment_id": "71892db0-f9de-4fac-bd5b-0ffc68f72f73",
            "bbox": {
              "left": 109.416664,
              "top": 534.4166,
              "width": 501.99997,
              "height": 149.91666
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Like transactions, SQL queries are compiled into LLVM code [22]. The data-centric compiler aims at good code and data locality and a predictable branch layout. LLVM code is then compiled into efficient machine code using LLVM’s just-in-time compiler. Together with its advanced query op- timizer, HyPer achieves superior query response times [19] comparable to those of MonetDB [4] or Vectorwise.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/71892db0-f9de-4fac-bd5b-0ffc68f72f73.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=aae5842c71f5da27d4d335b4b8e4d3884a7c5b0bde10c0297732911d9d007856",
            "html": "<p>Like transactions, SQL queries are compiled into LLVM code [22]. The data-centric compiler aims at good code and data locality and a predictable branch layout. LLVM code is then compiled into efficient machine code using LLVM’s just-in-time compiler. Together with its advanced query op- timizer, HyPer achieves superior query response times [19] comparable to those of MonetDB [4] or Vectorwise.</p>",
            "markdown": "Like transactions, SQL queries are compiled into LLVM code [22]. The data-centric compiler aims at good code and data locality and a predictable branch layout. LLVM code is then compiled into efficient machine code using LLVM’s just-in-time compiler. Together with its advanced query op- timizer, HyPer achieves superior query response times [19] comparable to those of MonetDB [4] or Vectorwise.\n\n"
          }
        ],
        "chunk_length": 389
      },
      {
        "segments": [
          {
            "segment_id": "61939fad-91bf-42ab-be37-2fb096af3e33",
            "bbox": {
              "left": 109.416664,
              "top": 703.1666,
              "width": 331.16666,
              "height": 22.833332
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "4.2 Instant Loading in HyPer",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/61939fad-91bf-42ab-be37-2fb096af3e33.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0f186187f6a632f86139beadbe2c52bd96ff6e65ab0e023969a640f3f134d72f",
            "html": "<h2>4.2 Instant Loading in HyPer</h2>",
            "markdown": "## 4.2 Instant Loading in HyPer\n\n"
          },
          {
            "segment_id": "f6e79da9-7186-42da-842e-133be72e0c00",
            "bbox": {
              "left": 109.416664,
              "top": 732.3333,
              "width": 499.91666,
              "height": 83.25
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Instant Loading in HyPer allows (lwu)* workflows but can indeed also be used for other use cases that require the load- ing of CSV data. This includes initial loads and incremental loads for continuous data integration.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/f6e79da9-7186-42da-842e-133be72e0c00.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e91c45b189328ca69c882e2e69a5e8d6f1e650cc5f00e9bbec54c1fb39bff6e9",
            "html": "<p>Instant Loading in HyPer allows (lwu)* workflows but can indeed also be used for other use cases that require the load- ing of CSV data. This includes initial loads and incremental loads for continuous data integration.</p>",
            "markdown": "Instant Loading in HyPer allows (lwu)* workflows but can indeed also be used for other use cases that require the load- ing of CSV data. This includes initial loads and incremental loads for continuous data integration.\n\n"
          },
          {
            "segment_id": "1298f168-8b7f-4129-ab6e-5b6326616c0c",
            "bbox": {
              "left": 109.416664,
              "top": 819.8333,
              "width": 501.99997,
              "height": 497.8333
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "The interface of Instant Loading in HyPer is designed in the style of the PostgreSQL COPY operator. Instant Loading takes CSV input, the schema it adheres to, and the CSV special characters as input. Except for \" \\ r \\ n\" , which we allow to be used as a record delimiter, we assume that spe- cial characters are single ASCII characters. For each rela- tion that is created or altered, we generate LLVM glue code functions for the processing of CSV chunks and for partition buffer merging (cf., the two steps in Fig. 4). Code genera- tion and compilation of these functions at runtime has the advantage that the resulting code has good locality and pre- dictable branching as the relation layout, e.g., the number of attributes and the attribute types, are known. Searching for delimiters and the deserialization methods are imple- mented as generic C++ functions that are not tailored to the design of HyPer. Just like the LLVM functions HyPer compiles for transactions and queries [22], the Instant Load- ing LLVM glue code calls these statically compiled C++ functions. Such LLVM glue code functions can further be created for other CSV-like formats using the C++ functions similar to a library. Code generation of the LLVM functions for CSV data is implemented for the four storage backend types in HyPer (cf. Sect. 2).",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/1298f168-8b7f-4129-ab6e-5b6326616c0c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c5df293f67ab00750cad7e14e489c7846df8cb2f00a98c17f34a53a859c0125c",
            "html": "<p>The interface of Instant Loading in HyPer is designed in the style of the PostgreSQL COPY operator. Instant Loading takes CSV input, the schema it adheres to, and the CSV special characters as input. Except for \" \\ r \\ n\" , which we allow to be used as a record delimiter, we assume that spe- cial characters are single ASCII characters. For each rela- tion that is created or altered, we generate LLVM glue code functions for the processing of CSV chunks and for partition buffer merging (cf., the two steps in Fig. 4). Code genera- tion and compilation of these functions at runtime has the advantage that the resulting code has good locality and pre- dictable branching as the relation layout, e.g., the number of attributes and the attribute types, are known. Searching for delimiters and the deserialization methods are imple- mented as generic C++ functions that are not tailored to the design of HyPer. Just like the LLVM functions HyPer compiles for transactions and queries [22], the Instant Load- ing LLVM glue code calls these statically compiled C++ functions. Such LLVM glue code functions can further be created for other CSV-like formats using the C++ functions similar to a library. Code generation of the LLVM functions for CSV data is implemented for the four storage backend types in HyPer (cf. Sect. 2).</p>",
            "markdown": "The interface of Instant Loading in HyPer is designed in the style of the PostgreSQL COPY operator. Instant Loading takes CSV input, the schema it adheres to, and the CSV special characters as input. Except for \" \\ r \\ n\" , which we allow to be used as a record delimiter, we assume that spe- cial characters are single ASCII characters. For each rela- tion that is created or altered, we generate LLVM glue code functions for the processing of CSV chunks and for partition buffer merging (cf., the two steps in Fig. 4). Code genera- tion and compilation of these functions at runtime has the advantage that the resulting code has good locality and pre- dictable branching as the relation layout, e.g., the number of attributes and the attribute types, are known. Searching for delimiters and the deserialization methods are imple- mented as generic C++ functions that are not tailored to the design of HyPer. Just like the LLVM functions HyPer compiles for transactions and queries [22], the Instant Load- ing LLVM glue code calls these statically compiled C++ functions. Such LLVM glue code functions can further be created for other CSV-like formats using the C++ functions similar to a library. Code generation of the LLVM functions for CSV data is implemented for the four storage backend types in HyPer (cf. Sect. 2).\n\n"
          },
          {
            "segment_id": "836c8447-df38-4464-8e4f-def26fdd9f0f",
            "bbox": {
              "left": 109.416664,
              "top": 1326.0833,
              "width": 499.91666,
              "height": 170.75
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Offline loading. In offline loading mode, loading has ex- clusive access to the relation, i.e., there are no concurrent transactions and queries; and loading is not logged. Pro- cessing of CSV chunks and merge steps are interleaved as much as possible to reduce overall loading time. If an er- ror occurs during the loading process, an exception is raised but the database might be left in a state where it is only partially loaded. For use cases such as (lwu)* workflows, in-",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/836c8447-df38-4464-8e4f-def26fdd9f0f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=bd455ff7b987e37f488cfdddab0728ab37d83c2a1e310d02f7623fd1796b19c3",
            "html": "<p>Offline loading. In offline loading mode, loading has ex- clusive access to the relation, i.e., there are no concurrent transactions and queries; and loading is not logged. Pro- cessing of CSV chunks and merge steps are interleaved as much as possible to reduce overall loading time. If an er- ror occurs during the loading process, an exception is raised but the database might be left in a state where it is only partially loaded. For use cases such as (lwu)* workflows, in-</p>",
            "markdown": "Offline loading. In offline loading mode, loading has ex- clusive access to the relation, i.e., there are no concurrent transactions and queries; and loading is not logged. Pro- cessing of CSV chunks and merge steps are interleaved as much as possible to reduce overall loading time. If an er- ror occurs during the loading process, an exception is raised but the database might be left in a state where it is only partially loaded. For use cases such as (lwu)* workflows, in-\n\n"
          },
          {
            "segment_id": "dbb4e95a-9cb0-405a-9510-ac09fd482eb5",
            "bbox": {
              "left": 657.3333,
              "top": 117.74999,
              "width": 501.99997,
              "height": 39.5
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "situ querying, and initial loading this is usually acceptable as the database can be recreated from scratch.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/dbb4e95a-9cb0-405a-9510-ac09fd482eb5.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8913b8cdfd8e8aa895523ac5600366c5415bc2bc9fe7ab5ef8b86cb2b62c4ddd",
            "html": "<p>situ querying, and initial loading this is usually acceptable as the database can be recreated from scratch.</p>",
            "markdown": "situ querying, and initial loading this is usually acceptable as the database can be recreated from scratch.\n\n"
          },
          {
            "segment_id": "6942b2fa-a34c-4c4c-86f7-e4606f21b964",
            "bbox": {
              "left": 657.3333,
              "top": 163.58333,
              "width": 501.99997,
              "height": 281.16666
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Online transactional loading. Online transactional loading supports loading with ACID semantics where only the merge steps need to be encapsulated in a single merge transaction. Processing of CSV chunks can happen in par- allel to transaction processing. There is a tradeoff between overall loading time and the duration of the merge transac- tion: To achieve online loading optimized for a short loading time, chunk processing is interleaved with merge steps. The duration of the merge transaction starts with the first and ends with last merge step. No other transactions can be pro- cessed in that time. To achieve a short merge transaction duration, first all chunks are processed and then all merge steps are processed at once.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6942b2fa-a34c-4c4c-86f7-e4606f21b964.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e208a7c9298ba3d56aa49b2edfb1932900e182d72b70e88480389348d2293dc3",
            "html": "<p>Online transactional loading. Online transactional loading supports loading with ACID semantics where only the merge steps need to be encapsulated in a single merge transaction. Processing of CSV chunks can happen in par- allel to transaction processing. There is a tradeoff between overall loading time and the duration of the merge transac- tion: To achieve online loading optimized for a short loading time, chunk processing is interleaved with merge steps. The duration of the merge transaction starts with the first and ends with last merge step. No other transactions can be pro- cessed in that time. To achieve a short merge transaction duration, first all chunks are processed and then all merge steps are processed at once.</p>",
            "markdown": "Online transactional loading. Online transactional loading supports loading with ACID semantics where only the merge steps need to be encapsulated in a single merge transaction. Processing of CSV chunks can happen in par- allel to transaction processing. There is a tradeoff between overall loading time and the duration of the merge transac- tion: To achieve online loading optimized for a short loading time, chunk processing is interleaved with merge steps. The duration of the merge transaction starts with the first and ends with last merge step. No other transactions can be pro- cessed in that time. To achieve a short merge transaction duration, first all chunks are processed and then all merge steps are processed at once.\n\n"
          }
        ],
        "chunk_length": 482
      },
      {
        "segments": [
          {
            "segment_id": "a160e904-e2b9-4d86-8f50-f1ae2c8c607f",
            "bbox": {
              "left": 657.3333,
              "top": 469.8333,
              "width": 206.16666,
              "height": 22.833332
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "5. EVALUATION",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/a160e904-e2b9-4d86-8f50-f1ae2c8c607f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=238f85f022c4b64e68dad4c02876388759f6063c605a782ee4c87c13809442d0",
            "html": "<h2>5. EVALUATION</h2>",
            "markdown": "## 5. EVALUATION\n\n"
          },
          {
            "segment_id": "f1032282-3a62-4afb-b734-457440e2a384",
            "bbox": {
              "left": 657.3333,
              "top": 498.99997,
              "width": 501.99997,
              "height": 281.16666
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "The evaluation of Instant Loading in HyPer was con- ducted on a commodity workstation with an Intel Core i7- 3770 CPU and 32 GB dual-channel DDR3-1600 DRAM. The CPU is based on the Ivy Bridge microarchitecture and sup- ports the SSE 4.2 string and text instructions, has 4 cores (8 hardware threads), a 3.4 GHz clock rate, and a 8 MB last- level shared L3 cache. As operating system we used Linux 3.5 in 64 bit mode. Sources were compiled using GCC 4.7 with -O3 -march=native optimizations. For lack of a high- speed network-attached storage or distributed file system in our lab, we used the in-memory file system ramfs as the CSV source to emulate a wire speed of multiple Gbit/s. Prior to each measurement we flushed the file system caches.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/f1032282-3a62-4afb-b734-457440e2a384.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e2857473e39480ed0fb51a311ccde85a5b1cd416e7a160f9ff4aa243a260f57a",
            "html": "<p>The evaluation of Instant Loading in HyPer was con- ducted on a commodity workstation with an Intel Core i7- 3770 CPU and 32 GB dual-channel DDR3-1600 DRAM. The CPU is based on the Ivy Bridge microarchitecture and sup- ports the SSE 4.2 string and text instructions, has 4 cores (8 hardware threads), a 3.4 GHz clock rate, and a 8 MB last- level shared L3 cache. As operating system we used Linux 3.5 in 64 bit mode. Sources were compiled using GCC 4.7 with -O3 -march=native optimizations. For lack of a high- speed network-attached storage or distributed file system in our lab, we used the in-memory file system ramfs as the CSV source to emulate a wire speed of multiple Gbit/s. Prior to each measurement we flushed the file system caches.</p>",
            "markdown": "The evaluation of Instant Loading in HyPer was con- ducted on a commodity workstation with an Intel Core i7- 3770 CPU and 32 GB dual-channel DDR3-1600 DRAM. The CPU is based on the Ivy Bridge microarchitecture and sup- ports the SSE 4.2 string and text instructions, has 4 cores (8 hardware threads), a 3.4 GHz clock rate, and a 8 MB last- level shared L3 cache. As operating system we used Linux 3.5 in 64 bit mode. Sources were compiled using GCC 4.7 with -O3 -march=native optimizations. For lack of a high- speed network-attached storage or distributed file system in our lab, we used the in-memory file system ramfs as the CSV source to emulate a wire speed of multiple Gbit/s. Prior to each measurement we flushed the file system caches.\n\n"
          }
        ],
        "chunk_length": 133
      },
      {
        "segments": [
          {
            "segment_id": "109d4dfa-7fb0-4cc1-9ee8-78ebeceac24d",
            "bbox": {
              "left": 657.3333,
              "top": 794.8333,
              "width": 352,
              "height": 22.833332
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "5.1 Parsing and Deserialization",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/109d4dfa-7fb0-4cc1-9ee8-78ebeceac24d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f6f0f289b84352f0328e18df9a1c03e6bc267b3f1dedf610649bc85e8b1c0311",
            "html": "<h2>5.1 Parsing and Deserialization</h2>",
            "markdown": "## 5.1 Parsing and Deserialization\n\n"
          },
          {
            "segment_id": "6ea428ff-da76-4c48-9a28-933edd0195a8",
            "bbox": {
              "left": 657.3333,
              "top": 823.99994,
              "width": 501.99997,
              "height": 322.8333
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "We first evaluated our task- and data-parallelized parsing and deserialization methods in isolation from the rest of the loading process. CSV data was read from ramfs , parsed, deserialized, and stored in heap-allocated result buffers. We implemented a variant that is SSE 4.2 optimized (SSE) as described in Sect. 3.4 and one that is not (non-SSE). As a contestant for these methods we used a parsing and dese- rialization implementation based on the Boost Spirit C++ library v2.5.2. In particular, we used Boost Spirit.Qi, which allows the generation of a recursive descent parser for a given grammar. We also experimented with an implementation based on Boost.Tokenizer and Boost.Lexical Cast but its performance trailed that of the Boost Spirit.Qi variant. Just like our SSE and non-SSE variants, we task-parallelized our Boost implementation as described in Sect. 3.3.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6ea428ff-da76-4c48-9a28-933edd0195a8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a00da090f192fe895cd79eab037050b55fc5fd2bd6327acfc7da2b150d9709e4",
            "html": "<p>We first evaluated our task- and data-parallelized parsing and deserialization methods in isolation from the rest of the loading process. CSV data was read from ramfs , parsed, deserialized, and stored in heap-allocated result buffers. We implemented a variant that is SSE 4.2 optimized (SSE) as described in Sect. 3.4 and one that is not (non-SSE). As a contestant for these methods we used a parsing and dese- rialization implementation based on the Boost Spirit C++ library v2.5.2. In particular, we used Boost Spirit.Qi, which allows the generation of a recursive descent parser for a given grammar. We also experimented with an implementation based on Boost.Tokenizer and Boost.Lexical Cast but its performance trailed that of the Boost Spirit.Qi variant. Just like our SSE and non-SSE variants, we task-parallelized our Boost implementation as described in Sect. 3.3.</p>",
            "markdown": "We first evaluated our task- and data-parallelized parsing and deserialization methods in isolation from the rest of the loading process. CSV data was read from ramfs , parsed, deserialized, and stored in heap-allocated result buffers. We implemented a variant that is SSE 4.2 optimized (SSE) as described in Sect. 3.4 and one that is not (non-SSE). As a contestant for these methods we used a parsing and dese- rialization implementation based on the Boost Spirit C++ library v2.5.2. In particular, we used Boost Spirit.Qi, which allows the generation of a recursive descent parser for a given grammar. We also experimented with an implementation based on Boost.Tokenizer and Boost.Lexical Cast but its performance trailed that of the Boost Spirit.Qi variant. Just like our SSE and non-SSE variants, we task-parallelized our Boost implementation as described in Sect. 3.3.\n\n"
          },
          {
            "segment_id": "250270e2-16b7-4777-b111-a5ce5cdd5b28",
            "bbox": {
              "left": 657.3333,
              "top": 1151.0833,
              "width": 501.99997,
              "height": 147.83333
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "As input for the experiment we chose TPC-H CSV data generated with a scale-factor of 10 ( ∼ 10 GB). While the SSE and non-SSE variants only require schema information at run-time, the Spirit.Qi parser generator is a set of templated C++ functions that require schema information at compile- time. For the Boost Spirit.Qi variant we thus hardcoded the TPC-H schema information into the source code.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/250270e2-16b7-4777-b111-a5ce5cdd5b28.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d889b8744ee0add93a5794f26e4c9e568f8deab6bc48515a149de31102e02a6b",
            "html": "<p>As input for the experiment we chose TPC-H CSV data generated with a scale-factor of 10 ( ∼ 10 GB). While the SSE and non-SSE variants only require schema information at run-time, the Spirit.Qi parser generator is a set of templated C++ functions that require schema information at compile- time. For the Boost Spirit.Qi variant we thus hardcoded the TPC-H schema information into the source code.</p>",
            "markdown": "As input for the experiment we chose TPC-H CSV data generated with a scale-factor of 10 ( ∼ 10 GB). While the SSE and non-SSE variants only require schema information at run-time, the Spirit.Qi parser generator is a set of templated C++ functions that require schema information at compile- time. For the Boost Spirit.Qi variant we thus hardcoded the TPC-H schema information into the source code.\n\n"
          },
          {
            "segment_id": "7542ebaa-5c2b-463d-b04d-199379210e43",
            "bbox": {
              "left": 657.3333,
              "top": 1305.25,
              "width": 499.91666,
              "height": 191.58333
            },
            "page_number": 8,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Fig. 9 shows that SSE and non-SSE perform better than Boost Spirit.Qi at all multiprogramming levels. SSE outper- forms non-SSE and shows a higher speedup: SSE achieves a parsing and deserialization throughput of over 1.6 GB/s with a multiprogramming level of 8 compared to about 1.0 GB/s with non-SSE, an improvement of 60%. The superior per- formance of SSE can be explained by (i) the exploitation of vector execution engines in addition to scalar execution units across all cores and (ii) by the reduced number of branch",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/7542ebaa-5c2b-463d-b04d-199379210e43.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=58521026e49b0a8aa74e6282659ffce4e77286f37b9ca9f99a253f21368eea62",
            "html": "<p>Fig. 9 shows that SSE and non-SSE perform better than Boost Spirit.Qi at all multiprogramming levels. SSE outper- forms non-SSE and shows a higher speedup: SSE achieves a parsing and deserialization throughput of over 1.6 GB/s with a multiprogramming level of 8 compared to about 1.0 GB/s with non-SSE, an improvement of 60%. The superior per- formance of SSE can be explained by (i) the exploitation of vector execution engines in addition to scalar execution units across all cores and (ii) by the reduced number of branch</p>",
            "markdown": "Fig. 9 shows that SSE and non-SSE perform better than Boost Spirit.Qi at all multiprogramming levels. SSE outper- forms non-SSE and shows a higher speedup: SSE achieves a parsing and deserialization throughput of over 1.6 GB/s with a multiprogramming level of 8 compared to about 1.0 GB/s with non-SSE, an improvement of 60%. The superior per- formance of SSE can be explained by (i) the exploitation of vector execution engines in addition to scalar execution units across all cores and (ii) by the reduced number of branch\n\n"
          },
          {
            "segment_id": "844e2e4e-f001-456d-80dd-0b37598799b8",
            "bbox": {
              "left": 111.49999,
              "top": 103.166664,
              "width": 1045.75,
              "height": 270.75
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "1 2 3 4 5 6 7 8 0 0 . 5 1 1 . 5 0 . 25 0 . 75 1 . 25 1 . 75 Hyper-Threading multiprogramming level [threads] throughput [GB/s] SSE Non-SSE Boost Spirit.Qi 1 2 3 4 5 6 7 8 0 M 50 M 100 M 150 M 25 M 75 M 125 M Hyper-Threading multiprogramming level [threads] creation [k eys/s] ART ordered dense HT ART unordered dense ART sparse HDD SSD DDR3-1600 0 % 50 % 100 % 25 % 75 % compute bound wire sp eed saturation w/ 8 ha rdw a re threads w/o I/O prefetching w/ I/O prefetching",
            "segment_type": "Picture",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/844e2e4e-f001-456d-80dd-0b37598799b8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2cb3b398db77a4c9235793f09c3c8e0a1bee1b330d779d4adb228168a57ad4e9",
            "html": "<img src=\"https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/844e2e4e-f001-456d-80dd-0b37598799b8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2cb3b398db77a4c9235793f09c3c8e0a1bee1b330d779d4adb228168a57ad4e9\" />",
            "markdown": "![Image](https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/844e2e4e-f001-456d-80dd-0b37598799b8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2cb3b398db77a4c9235793f09c3c8e0a1bee1b330d779d4adb228168a57ad4e9)"
          },
          {
            "segment_id": "a0d8f3bd-6f71-4f31-b1f3-7af8ced5f9e6",
            "bbox": {
              "left": 109.416664,
              "top": 378.16666,
              "width": 1049.9166,
              "height": 62.416664
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Figure 9: Speedup of parsing and deserialization methods with heap- allocated result buffers. Figure 10: Speedup of merge-able HT and ART parallelized index building and merging for 10 M 32 bit keys. Figure 11: Wire speed saturation of Instant Loading (cf., Fig. 1) and the impact of I/O prefetching.",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/a0d8f3bd-6f71-4f31-b1f3-7af8ced5f9e6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=cde36019464c7b84e093c340ce104aaeb99b849f2eface170b13ca8b0c6ec11b",
            "html": "<span class=\"caption\">Figure 9: Speedup of parsing and deserialization methods with heap- allocated result buffers. Figure 10: Speedup of merge-able HT and ART parallelized index building and merging for 10 M 32 bit keys. Figure 11: Wire speed saturation of Instant Loading (cf., Fig. 1) and the impact of I/O prefetching.</span>",
            "markdown": "Figure 9: Speedup of parsing and deserialization methods with heap- allocated result buffers. Figure 10: Speedup of merge-able HT and ART parallelized index building and merging for 10 M 32 bit keys. Figure 11: Wire speed saturation of Instant Loading (cf., Fig. 1) and the impact of I/O prefetching.\n\n"
          },
          {
            "segment_id": "0c207883-a5c1-47e7-82e2-c06754f3f25d",
            "bbox": {
              "left": 151.08333,
              "top": 469.8333,
              "width": 406.16666,
              "height": 66.58333
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "insert copy chunk column-store 7841 ms 6939 ms 6092 ms row-store 6609 ms 6608 ms 6049 ms",
            "segment_type": "Table",
            "ocr": [],
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/0c207883-a5c1-47e7-82e2-c06754f3f25d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5e0e86587a1d48a91f7a41b881e1a95738c4eb2a1b26407963de874a7d85b5dd",
            "html": "<table>\n  <thead>\n    <tr>\n      <th>insert</th>\n      <th>copy</th>\n      <th>chunk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>column-store</td>\n      <td>7841 ms</td>\n      <td>6939 ms</td>\n      <td>6092 ms</td>\n    </tr>\n    <tr>\n      <td>row-store</td>\n      <td>6609 ms</td>\n      <td>6608 ms</td>\n      <td>6049 ms</td>\n    </tr>\n  </tbody>\n</table>",
            "markdown": "insert copy chunk column-store 7841 ms 6939 ms 6092 ms row-store 6609 ms 6608 ms 6049 ms\n\n"
          },
          {
            "segment_id": "2f4854ea-3e86-4c5d-ae9e-7c52b6877ed6",
            "bbox": {
              "left": 109.416664,
              "top": 549,
              "width": 501.99997,
              "height": 60.333332
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Table 1: Loading of TPC-H CSV data (scale-factor 10) to a column- and row-store using insert-, copy-, and chunk-based partition buffer merging.",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/2f4854ea-3e86-4c5d-ae9e-7c52b6877ed6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2f62590c968d625a53944776c5fc873a91699f931b180d62cc080a0ee61def8a",
            "html": "<span class=\"caption\">Table 1: Loading of TPC-H CSV data (scale-factor 10) to a column- and row-store using insert-, copy-, and chunk-based partition buffer merging.</span>",
            "markdown": "Table 1: Loading of TPC-H CSV data (scale-factor 10) to a column- and row-store using insert-, copy-, and chunk-based partition buffer merging.\n\n"
          }
        ],
        "chunk_length": 489
      },
      {
        "segments": [
          {
            "segment_id": "61acef26-6d7e-4b50-b81f-5a6c3c8fc36b",
            "bbox": {
              "left": 109.416664,
              "top": 628.1666,
              "width": 501.99997,
              "height": 214.49998
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "misses compared to non-SSE. Performance counters show that the number of branch misses is reduced from 194/kB CSV with non-SSE to just 89/kB CSV with SSE, a decrease of over 50%. Using all execution units of the CPU cores also allows SSE to profit more from Hyper-Threading. This comes at no additional cost and improves energy efficiency: Measuring the Running Average Power Limit energy sensors available in recent Intel CPUs reveals that SSE used 388 J compared to 503 J (+23%) with non-SSE and 625 J (+38%) with Boost Spirit.Qi.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/61acef26-6d7e-4b50-b81f-5a6c3c8fc36b.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=4b72437a362e93660f0bdb3ce8f1354a660421404f776bbcdee4751e9cb60137",
            "html": "<p>misses compared to non-SSE. Performance counters show that the number of branch misses is reduced from 194/kB CSV with non-SSE to just 89/kB CSV with SSE, a decrease of over 50%. Using all execution units of the CPU cores also allows SSE to profit more from Hyper-Threading. This comes at no additional cost and improves energy efficiency: Measuring the Running Average Power Limit energy sensors available in recent Intel CPUs reveals that SSE used 388 J compared to 503 J (+23%) with non-SSE and 625 J (+38%) with Boost Spirit.Qi.</p>",
            "markdown": "misses compared to non-SSE. Performance counters show that the number of branch misses is reduced from 194/kB CSV with non-SSE to just 89/kB CSV with SSE, a decrease of over 50%. Using all execution units of the CPU cores also allows SSE to profit more from Hyper-Threading. This comes at no additional cost and improves energy efficiency: Measuring the Running Average Power Limit energy sensors available in recent Intel CPUs reveals that SSE used 388 J compared to 503 J (+23%) with non-SSE and 625 J (+38%) with Boost Spirit.Qi.\n\n"
          }
        ],
        "chunk_length": 90
      },
      {
        "segments": [
          {
            "segment_id": "e214e76a-accd-4ff9-b9d5-b15dba03fcc8",
            "bbox": {
              "left": 109.416664,
              "top": 859.4166,
              "width": 239.49998,
              "height": 22.833332
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "5.2 Partition Buffers",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/e214e76a-accd-4ff9-b9d5-b15dba03fcc8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=4b3b60b54e4cdaaa8f4ee99ceeba8e892094704f2f2ad8bead6dcf5a19e828bb",
            "html": "<h2>5.2 Partition Buffers</h2>",
            "markdown": "## 5.2 Partition Buffers\n\n"
          },
          {
            "segment_id": "54a0c31f-3a7b-4aed-b7fc-12bd1b0a5171",
            "bbox": {
              "left": 109.416664,
              "top": 890.6666,
              "width": 501.99997,
              "height": 279.0833
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "We evaluated Instant Loading for the column- and row- store storage backend implementations in HyPer (cf., Sect. 2) and the three partition buffer merging approaches we pro- posed in Sect. 3.5. For the insert- and copy-based merg- ing approaches we used storage backends based on contigu- ous memory, for the chunk-based approach we used chun- ked storage backends. Table 1 shows the benchmark results when loading a TPC-H CSV data set with a scale-factor of 10. For the column-store backends, copy was around 12% faster than insert. The chunk-based approach improved per- formance by another 12%. For the row-store backend, in- sert and copy performed similarly; chunk-based merging was 8.5% faster.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/54a0c31f-3a7b-4aed-b7fc-12bd1b0a5171.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e3a8df90c94b2be68186586ab4d36e3b3fa3a5ed599be909382624565ce6e38a",
            "html": "<p>We evaluated Instant Loading for the column- and row- store storage backend implementations in HyPer (cf., Sect. 2) and the three partition buffer merging approaches we pro- posed in Sect. 3.5. For the insert- and copy-based merg- ing approaches we used storage backends based on contigu- ous memory, for the chunk-based approach we used chun- ked storage backends. Table 1 shows the benchmark results when loading a TPC-H CSV data set with a scale-factor of 10. For the column-store backends, copy was around 12% faster than insert. The chunk-based approach improved per- formance by another 12%. For the row-store backend, in- sert and copy performed similarly; chunk-based merging was 8.5% faster.</p>",
            "markdown": "We evaluated Instant Loading for the column- and row- store storage backend implementations in HyPer (cf., Sect. 2) and the three partition buffer merging approaches we pro- posed in Sect. 3.5. For the insert- and copy-based merg- ing approaches we used storage backends based on contigu- ous memory, for the chunk-based approach we used chun- ked storage backends. Table 1 shows the benchmark results when loading a TPC-H CSV data set with a scale-factor of 10. For the column-store backends, copy was around 12% faster than insert. The chunk-based approach improved per- formance by another 12%. For the row-store backend, in- sert and copy performed similarly; chunk-based merging was 8.5% faster.\n\n"
          }
        ],
        "chunk_length": 114
      },
      {
        "segments": [
          {
            "segment_id": "58fe3deb-8325-460d-85f8-9edc1507147d",
            "bbox": {
              "left": 109.416664,
              "top": 1184.4166,
              "width": 277,
              "height": 27
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "5.3 Bulk Index Creation",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/58fe3deb-8325-460d-85f8-9edc1507147d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c8eae84d10cb0fe4c9782c5394cb6b3caa37a2b9cea469a9c01c4cf47985a947",
            "html": "<h2>5.3 Bulk Index Creation</h2>",
            "markdown": "## 5.3 Bulk Index Creation\n\n"
          },
          {
            "segment_id": "ba899e42-d4d1-4ce1-94a4-483d05845587",
            "bbox": {
              "left": 109.416664,
              "top": 1215.6666,
              "width": 501.99997,
              "height": 85.33333
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "We evaluated the parallelized creation of hash tables with chaining (HT) and adaptive radix trees (ART) on key range partitions and the parallelized merging of these indexes to create a unified index for the total key range.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ba899e42-d4d1-4ce1-94a4-483d05845587.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e5a2ca0571d077750345752c225e57709fcc5c96d397a05f9721691dd0546d86",
            "html": "<p>We evaluated the parallelized creation of hash tables with chaining (HT) and adaptive radix trees (ART) on key range partitions and the parallelized merging of these indexes to create a unified index for the total key range.</p>",
            "markdown": "We evaluated the parallelized creation of hash tables with chaining (HT) and adaptive radix trees (ART) on key range partitions and the parallelized merging of these indexes to create a unified index for the total key range.\n\n"
          },
          {
            "segment_id": "a241b924-d179-4a33-b048-99bd4419a19d",
            "bbox": {
              "left": 109.416664,
              "top": 1305.25,
              "width": 501.99997,
              "height": 191.58333
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Fig. 10 shows the speedup of index creation for a key range of 10M 32 bit keys. For ordered dense keys, i.e., ordered keys ranging from 1 to 10M, ART allows a faster creation of the index than the HT for all multiprogramming levels. Merg- ing of ART indexes is, in the case of an ordered dense key range, highly efficient and often only requires a few pointers to be copied such that the creation time of the unified in- dex largely only depends on the insertion speed of the ART indexes that are created in parallel. The lower speedup of",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/a241b924-d179-4a33-b048-99bd4419a19d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d2d555a182d74e45681848dc5d8532ebd613f44bb3c73bafd77260d76fa710fd",
            "html": "<p>Fig. 10 shows the speedup of index creation for a key range of 10M 32 bit keys. For ordered dense keys, i.e., ordered keys ranging from 1 to 10M, ART allows a faster creation of the index than the HT for all multiprogramming levels. Merg- ing of ART indexes is, in the case of an ordered dense key range, highly efficient and often only requires a few pointers to be copied such that the creation time of the unified in- dex largely only depends on the insertion speed of the ART indexes that are created in parallel. The lower speedup of</p>",
            "markdown": "Fig. 10 shows the speedup of index creation for a key range of 10M 32 bit keys. For ordered dense keys, i.e., ordered keys ranging from 1 to 10M, ART allows a faster creation of the index than the HT for all multiprogramming levels. Merg- ing of ART indexes is, in the case of an ordered dense key range, highly efficient and often only requires a few pointers to be copied such that the creation time of the unified in- dex largely only depends on the insertion speed of the ART indexes that are created in parallel. The lower speedup of\n\n"
          },
          {
            "segment_id": "54c35b01-b7a6-4229-9f11-366efd292e34",
            "bbox": {
              "left": 657.3333,
              "top": 476.0833,
              "width": 501.99997,
              "height": 368.66666
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "ART ( × 2 . 2) compared to HT ( × 2 . 6) with a multiprogram- ming level of 4 is due to caching effects. The performance of ART heavily depends on the size of the effectively usable CPU cache per index [20]. In absolute numbers, however, ART achieves an index creation speed of 130M keys per sec- ond compared to 27M keys per second with HT. While the performance of HT does not depend on the distribution of keys, an ordered dense key range is the best case for ART. For unordered dense, i.e., randomly permuted dense keys, and sparse keys, i.e., randomly generated keys for which each bit is 1 or 0 with equal probability, the performance of ART drops. The index creation speed is still slightly better than with HT. For unordered key ranges merging is more costly than for ordered key ranges because mostly leaf nodes need to be merged. For a multiprogramming level of 4, merging accounted for 1% of loading time for ordered dense, 16% for unordered dense, and 33% for sparse keys.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/54c35b01-b7a6-4229-9f11-366efd292e34.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e53fae7d3465e25c2c614cba10bce85eb4c914a5df9ed13618a839e26eb751f6",
            "html": "<p>ART ( × 2 . 2) compared to HT ( × 2 . 6) with a multiprogram- ming level of 4 is due to caching effects. The performance of ART heavily depends on the size of the effectively usable CPU cache per index [20]. In absolute numbers, however, ART achieves an index creation speed of 130M keys per sec- ond compared to 27M keys per second with HT. While the performance of HT does not depend on the distribution of keys, an ordered dense key range is the best case for ART. For unordered dense, i.e., randomly permuted dense keys, and sparse keys, i.e., randomly generated keys for which each bit is 1 or 0 with equal probability, the performance of ART drops. The index creation speed is still slightly better than with HT. For unordered key ranges merging is more costly than for ordered key ranges because mostly leaf nodes need to be merged. For a multiprogramming level of 4, merging accounted for 1% of loading time for ordered dense, 16% for unordered dense, and 33% for sparse keys.</p>",
            "markdown": "ART ( × 2 . 2) compared to HT ( × 2 . 6) with a multiprogram- ming level of 4 is due to caching effects. The performance of ART heavily depends on the size of the effectively usable CPU cache per index [20]. In absolute numbers, however, ART achieves an index creation speed of 130M keys per sec- ond compared to 27M keys per second with HT. While the performance of HT does not depend on the distribution of keys, an ordered dense key range is the best case for ART. For unordered dense, i.e., randomly permuted dense keys, and sparse keys, i.e., randomly generated keys for which each bit is 1 or 0 with equal probability, the performance of ART drops. The index creation speed is still slightly better than with HT. For unordered key ranges merging is more costly than for ordered key ranges because mostly leaf nodes need to be merged. For a multiprogramming level of 4, merging accounted for 1% of loading time for ordered dense, 16% for unordered dense, and 33% for sparse keys.\n\n"
          }
        ],
        "chunk_length": 322
      },
      {
        "segments": [
          {
            "segment_id": "11f189e0-4acf-4d81-9d68-dab3a49722f7",
            "bbox": {
              "left": 657.3333,
              "top": 859.4166,
              "width": 226.99998,
              "height": 24.916666
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "5.4 Offline Loading",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/11f189e0-4acf-4d81-9d68-dab3a49722f7.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=75f1d8f7a89e59afa3fdf6f880f94f43def4193b48f47f1c6214637da2788dbc",
            "html": "<h2>5.4 Offline Loading</h2>",
            "markdown": "## 5.4 Offline Loading\n\n"
          },
          {
            "segment_id": "f8c7f795-b33e-4c2e-8fd7-af9248b982b0",
            "bbox": {
              "left": 657.3333,
              "top": 890.6666,
              "width": 501.99997,
              "height": 299.91666
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "To evaluate the end-to-end application performance of offline loading we benchmarked a workload that consisted of (i) bulk loading TPC-H CSV data with a scale-factor of 10 ( ∼ 10 GB) from ramfs and (ii) then executing the 22 TPC-H queries in parallel query streams. We used an unpartitioned TPC-H database, i.e., only one merge task runs in parallel, and configure HyPer to use a column-store backend based on contiguous memory. Partition buffers were merged using the copy-based approach. We compared Instant Loading in HyPer to a Hadoop v1.1.1 Hive v0.10 [28] cluster con- sisting of 4 nodes of the kind described at the beginning of Sect. 5 (1 GbE interconnect), SQLite v3.7.15 compiled from source, MySQL v5.5.29, MonetDB [4] v11.13.7 com- piled from source, and Vectorwise v2.5.2.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/f8c7f795-b33e-4c2e-8fd7-af9248b982b0.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5814b4737f898b3028a0270d85e144e4a55f9d29bad19f6dd9058274f946a71d",
            "html": "<p>To evaluate the end-to-end application performance of offline loading we benchmarked a workload that consisted of (i) bulk loading TPC-H CSV data with a scale-factor of 10 ( ∼ 10 GB) from ramfs and (ii) then executing the 22 TPC-H queries in parallel query streams. We used an unpartitioned TPC-H database, i.e., only one merge task runs in parallel, and configure HyPer to use a column-store backend based on contiguous memory. Partition buffers were merged using the copy-based approach. We compared Instant Loading in HyPer to a Hadoop v1.1.1 Hive v0.10 [28] cluster con- sisting of 4 nodes of the kind described at the beginning of Sect. 5 (1 GbE interconnect), SQLite v3.7.15 compiled from source, MySQL v5.5.29, MonetDB [4] v11.13.7 com- piled from source, and Vectorwise v2.5.2.</p>",
            "markdown": "To evaluate the end-to-end application performance of offline loading we benchmarked a workload that consisted of (i) bulk loading TPC-H CSV data with a scale-factor of 10 ( ∼ 10 GB) from ramfs and (ii) then executing the 22 TPC-H queries in parallel query streams. We used an unpartitioned TPC-H database, i.e., only one merge task runs in parallel, and configure HyPer to use a column-store backend based on contiguous memory. Partition buffers were merged using the copy-based approach. We compared Instant Loading in HyPer to a Hadoop v1.1.1 Hive v0.10 [28] cluster con- sisting of 4 nodes of the kind described at the beginning of Sect. 5 (1 GbE interconnect), SQLite v3.7.15 compiled from source, MySQL v5.5.29, MonetDB [4] v11.13.7 com- piled from source, and Vectorwise v2.5.2.\n\n"
          },
          {
            "segment_id": "7f57731c-4229-495e-8c34-aafb4110bb7b",
            "bbox": {
              "left": 657.3333,
              "top": 1196.9166,
              "width": 501.99997,
              "height": 302
            },
            "page_number": 9,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Fig. 12 shows our benchmark results. Instant Loading achieves a superior combined bulk loading and query pro- cessing performance compared to the contestants. Load- ing took 6.9 s (HyPer), unloading the database as a LZ4- compressed binary to ramfs after loading took an additional 4.3 s (HyPer /w unload). The compressed binary has a size of 4.7 GB (50% the size of the CSV files) and can be loaded again in 2.6 s (3 × faster than loading the CSV files). In both cases, the queries were evaluated in just under 12 s. Our unloading and binary loading approaches in HyPer are again highly parallelized. We further evaluated the I/O sat- uration when loading from local I/O devices. Fig. 11 shows that Instant Loading fully saturates the wire speed of a tra- ditional HDD (160 MB/s) and a SSD (500 MB/s). When the",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/7f57731c-4229-495e-8c34-aafb4110bb7b.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=08d04bf408d1191d42953a2afc69cbfdf48b50ff8cd5948eba9b975de5680e67",
            "html": "<p>Fig. 12 shows our benchmark results. Instant Loading achieves a superior combined bulk loading and query pro- cessing performance compared to the contestants. Load- ing took 6.9 s (HyPer), unloading the database as a LZ4- compressed binary to ramfs after loading took an additional 4.3 s (HyPer /w unload). The compressed binary has a size of 4.7 GB (50% the size of the CSV files) and can be loaded again in 2.6 s (3 × faster than loading the CSV files). In both cases, the queries were evaluated in just under 12 s. Our unloading and binary loading approaches in HyPer are again highly parallelized. We further evaluated the I/O sat- uration when loading from local I/O devices. Fig. 11 shows that Instant Loading fully saturates the wire speed of a tra- ditional HDD (160 MB/s) and a SSD (500 MB/s). When the</p>",
            "markdown": "Fig. 12 shows our benchmark results. Instant Loading achieves a superior combined bulk loading and query pro- cessing performance compared to the contestants. Load- ing took 6.9 s (HyPer), unloading the database as a LZ4- compressed binary to ramfs after loading took an additional 4.3 s (HyPer /w unload). The compressed binary has a size of 4.7 GB (50% the size of the CSV files) and can be loaded again in 2.6 s (3 × faster than loading the CSV files). In both cases, the queries were evaluated in just under 12 s. Our unloading and binary loading approaches in HyPer are again highly parallelized. We further evaluated the I/O sat- uration when loading from local I/O devices. Fig. 11 shows that Instant Loading fully saturates the wire speed of a tra- ditional HDD (160 MB/s) and a SSD (500 MB/s). When the\n\n"
          },
          {
            "segment_id": "ee780175-77d7-4dfd-a790-8576ea444201",
            "bbox": {
              "left": 113.58333,
              "top": 111.49999,
              "width": 1018.6666,
              "height": 222.83333
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Hadoop Hive 4 nodes Hadoop Hive 4 nodes, RCFiles SQLite in-memory MySQL memory engine MySQL CSV engine MonetDB Vectorwise w/o Q5 HyPer HyPer w/ unload 0 50 100 150 50 minutes 48 minutes > 1 hour > 1 hour > 1 hour 133.7 s 110.0 s 109.9 s 101.6 s 18.8 s 6.9 s 23.1 s 11.2 s 0 s 173.5 s 302.0 s 119.9 s 0 s execution time [s] Loading TPC-H CSV (scale-factor 10) Processing the 22 TPC-H queries",
            "segment_type": "Picture",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ee780175-77d7-4dfd-a790-8576ea444201.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=68fef182a7fa9e72ba9780a378dfbb6d806e28d936ea2677d5243cf063465ea2",
            "html": "<img src=\"https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ee780175-77d7-4dfd-a790-8576ea444201.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=68fef182a7fa9e72ba9780a378dfbb6d806e28d936ea2677d5243cf063465ea2\" />",
            "markdown": "![Image](https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ee780175-77d7-4dfd-a790-8576ea444201.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=68fef182a7fa9e72ba9780a378dfbb6d806e28d936ea2677d5243cf063465ea2)"
          },
          {
            "segment_id": "42d25e2f-d1f4-4747-8f14-d03316b43b73",
            "bbox": {
              "left": 109.416664,
              "top": 349,
              "width": 1049.9166,
              "height": 41.583332
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Figure 12: Offline CSV bulk loading and query processing performance in HyPer with Instant Loading, other main memory databases, and a Hadoop Hive cluster with 4 nodes.",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/42d25e2f-d1f4-4747-8f14-d03316b43b73.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=199413b9a286b7b43774f239df7c831c316afc2a54a1c301e5e11a4306f8fc10",
            "html": "<span class=\"caption\">Figure 12: Offline CSV bulk loading and query processing performance in HyPer with Instant Loading, other main memory databases, and a Hadoop Hive cluster with 4 nodes.</span>",
            "markdown": "Figure 12: Offline CSV bulk loading and query processing performance in HyPer with Instant Loading, other main memory databases, and a Hadoop Hive cluster with 4 nodes.\n\n"
          },
          {
            "segment_id": "8b6aabd6-62a5-4df6-a7d0-75660393e95d",
            "bbox": {
              "left": 109.416664,
              "top": 417.74997,
              "width": 501.99997,
              "height": 106.166664
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "memory is used as the source and the sink, only 10% of the available wire speed are saturated (CPU bound). Fig. 11 further shows that advising the kernel to prefetch data from the local I/O device (using madvise ) is necessary to achieve a near-100% saturation of local devices.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/8b6aabd6-62a5-4df6-a7d0-75660393e95d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=ef8f7bf21dea47780d48b311481a59d6743a7ac0b296ddbec88b89faac976ac6",
            "html": "<p>memory is used as the source and the sink, only 10% of the available wire speed are saturated (CPU bound). Fig. 11 further shows that advising the kernel to prefetch data from the local I/O device (using madvise ) is necessary to achieve a near-100% saturation of local devices.</p>",
            "markdown": "memory is used as the source and the sink, only 10% of the available wire speed are saturated (CPU bound). Fig. 11 further shows that advising the kernel to prefetch data from the local I/O device (using madvise ) is necessary to achieve a near-100% saturation of local devices.\n\n"
          }
        ],
        "chunk_length": 431
      },
      {
        "segments": [
          {
            "segment_id": "05c3c133-ccb6-423c-a1d7-0eb32fa67070",
            "bbox": {
              "left": 109.416664,
              "top": 528.1666,
              "width": 501.99997,
              "height": 408.24997
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Hive is a data warehouse solution based on Hadoop. For our benchmark, we used 4 Hadoop nodes. Hadoop’s dis- tributed file system (HDFS) and Hive were configured to store data in ramfs . Other configuration settings were un- touched, including the default replication count of 3 for HDFS. This means that each node in the setup had a replica of the CSV files. We did not include the HDFS loading time (125.8 s) in our results as we assume that data is ideally already stored there. To evaluate the query performance, we used an official implementation of the TPC-H queries in HiveQL 3 , Hive’s SQL-like query language. Even though no explicit loading is required and 4 nodes instead of a sin- gle one are used, Hive needed 50 minutes to process the 22 queries. We also evaluated Hive with record columnar files (RCFiles). Loading the CSV files into RCFiles using the BinaryColumnarSerDe, a transformation pass that de- serializes strings to binary data type representations, took 173.5 s. Query processing on these RCFiles was, however, only 5 minutes faster than working on the raw CSV files.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/05c3c133-ccb6-423c-a1d7-0eb32fa67070.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=922047bd797a167cc7f9b572fb2dbece38e65377a1b551889a1fddee0bf6b1b9",
            "html": "<p>Hive is a data warehouse solution based on Hadoop. For our benchmark, we used 4 Hadoop nodes. Hadoop’s dis- tributed file system (HDFS) and Hive were configured to store data in ramfs . Other configuration settings were un- touched, including the default replication count of 3 for HDFS. This means that each node in the setup had a replica of the CSV files. We did not include the HDFS loading time (125.8 s) in our results as we assume that data is ideally already stored there. To evaluate the query performance, we used an official implementation of the TPC-H queries in HiveQL 3 , Hive’s SQL-like query language. Even though no explicit loading is required and 4 nodes instead of a sin- gle one are used, Hive needed 50 minutes to process the 22 queries. We also evaluated Hive with record columnar files (RCFiles). Loading the CSV files into RCFiles using the BinaryColumnarSerDe, a transformation pass that de- serializes strings to binary data type representations, took 173.5 s. Query processing on these RCFiles was, however, only 5 minutes faster than working on the raw CSV files.</p>",
            "markdown": "Hive is a data warehouse solution based on Hadoop. For our benchmark, we used 4 Hadoop nodes. Hadoop’s dis- tributed file system (HDFS) and Hive were configured to store data in ramfs . Other configuration settings were un- touched, including the default replication count of 3 for HDFS. This means that each node in the setup had a replica of the CSV files. We did not include the HDFS loading time (125.8 s) in our results as we assume that data is ideally already stored there. To evaluate the query performance, we used an official implementation of the TPC-H queries in HiveQL 3 , Hive’s SQL-like query language. Even though no explicit loading is required and 4 nodes instead of a sin- gle one are used, Hive needed 50 minutes to process the 22 queries. We also evaluated Hive with record columnar files (RCFiles). Loading the CSV files into RCFiles using the BinaryColumnarSerDe, a transformation pass that de- serializes strings to binary data type representations, took 173.5 s. Query processing on these RCFiles was, however, only 5 minutes faster than working on the raw CSV files.\n\n"
          },
          {
            "segment_id": "c71494e3-b619-4918-98b1-1a7c54f19a73",
            "bbox": {
              "left": 109.416664,
              "top": 942.74994,
              "width": 499.91666,
              "height": 106.166664
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "SQLite was started as an in-memory database using the special filename :memory: . For bulk loading, we locked the tables in exclusive mode and used the .import command. Query performance of SQLite is, however, not satisfactory. Processing of the 22 TPC-H queries took over 1 hour.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/c71494e3-b619-4918-98b1-1a7c54f19a73.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=aac3a3b4117ddb488a76fcdfbb8bcab82a93708c622298449f0780d1db018012",
            "html": "<p>SQLite was started as an in-memory database using the special filename :memory: . For bulk loading, we locked the tables in exclusive mode and used the .import command. Query performance of SQLite is, however, not satisfactory. Processing of the 22 TPC-H queries took over 1 hour.</p>",
            "markdown": "SQLite was started as an in-memory database using the special filename :memory: . For bulk loading, we locked the tables in exclusive mode and used the .import command. Query performance of SQLite is, however, not satisfactory. Processing of the 22 TPC-H queries took over 1 hour.\n\n"
          },
          {
            "segment_id": "a76ee768-0306-4b8f-8728-7415734203f8",
            "bbox": {
              "left": 109.416664,
              "top": 1053.1666,
              "width": 501.99997,
              "height": 145.75
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "For MySQL we ran two benchmarks: one with MySQL’s memory engine using the LOAD DATA INFILE command for bulk loading and one with MySQL’s CSV engine that al- lows query processing directly on external CSV files. Bulk loading using the memory engine took just under 2 minutes. Nevertheless, for both, the memory and CSV engine, pro- cessing of the 22 TPC-H queries took over 1 hour again.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/a76ee768-0306-4b8f-8728-7415734203f8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=bc673376997d2270bdb852da73adf0c8f807bc3743d321650fa807b3a9893313",
            "html": "<p>For MySQL we ran two benchmarks: one with MySQL’s memory engine using the LOAD DATA INFILE command for bulk loading and one with MySQL’s CSV engine that al- lows query processing directly on external CSV files. Bulk loading using the memory engine took just under 2 minutes. Nevertheless, for both, the memory and CSV engine, pro- cessing of the 22 TPC-H queries took over 1 hour again.</p>",
            "markdown": "For MySQL we ran two benchmarks: one with MySQL’s memory engine using the LOAD DATA INFILE command for bulk loading and one with MySQL’s CSV engine that al- lows query processing directly on external CSV files. Bulk loading using the memory engine took just under 2 minutes. Nevertheless, for both, the memory and CSV engine, pro- cessing of the 22 TPC-H queries took over 1 hour again.\n\n"
          },
          {
            "segment_id": "3ab328b9-22bd-4326-b448-0c16b41f8137",
            "bbox": {
              "left": 111.49999,
              "top": 1203.1666,
              "width": 499.91666,
              "height": 258.25
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "We compiled MonetDB with MonetDB5, MonetDB/SQL, and extra optimizations enabled. For bulk loading we used the COPY INTO command with the LOCKED qualifier that tells MonetDB to skip logging operations. As advised in the doc- umentation, primary key constraints were added to the ta- bles after loading. We created the MonetDB database inside ramfs so that BAT files written by MonetDB were again stored in memory. To the best of our knowledge MonetDB has no option to solely bulk load data to memory without writing the binary representation to BAT files. Bulk loading in MonetDB is thus best compared to Instant Loading with binary unloading (HyPer w/ unload). While loading time is",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/3ab328b9-22bd-4326-b448-0c16b41f8137.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d4d16b0186b6a2bca314a184e760684eda295351f808510c1dc0f3a9c443e607",
            "html": "<p>We compiled MonetDB with MonetDB5, MonetDB/SQL, and extra optimizations enabled. For bulk loading we used the COPY INTO command with the LOCKED qualifier that tells MonetDB to skip logging operations. As advised in the doc- umentation, primary key constraints were added to the ta- bles after loading. We created the MonetDB database inside ramfs so that BAT files written by MonetDB were again stored in memory. To the best of our knowledge MonetDB has no option to solely bulk load data to memory without writing the binary representation to BAT files. Bulk loading in MonetDB is thus best compared to Instant Loading with binary unloading (HyPer w/ unload). While loading time is</p>",
            "markdown": "We compiled MonetDB with MonetDB5, MonetDB/SQL, and extra optimizations enabled. For bulk loading we used the COPY INTO command with the LOCKED qualifier that tells MonetDB to skip logging operations. As advised in the doc- umentation, primary key constraints were added to the ta- bles after loading. We created the MonetDB database inside ramfs so that BAT files written by MonetDB were again stored in memory. To the best of our knowledge MonetDB has no option to solely bulk load data to memory without writing the binary representation to BAT files. Bulk loading in MonetDB is thus best compared to Instant Loading with binary unloading (HyPer w/ unload). While loading time is\n\n"
          },
          {
            "segment_id": "6c80ac91-b0b7-4d82-9efc-6fb903616809",
            "bbox": {
              "left": 680.25,
              "top": 411.49997,
              "width": 451.99997,
              "height": 118.666664
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[5/8] 1.6 1.4 1.2 1 0 1 2 3 4 5 6 CSVchunk size[MB]",
            "segment_type": "Picture",
            "ocr": [
              {
                "bbox": {
                  "left": 2,
                  "top": 13,
                  "width": 25,
                  "height": 51
                },
                "text": "[5/8]",
                "confidence": 0.81022966
              },
              {
                "bbox": {
                  "left": 35,
                  "top": 6,
                  "width": 27,
                  "height": 17
                },
                "text": "1.6",
                "confidence": 0.99296135
              },
              {
                "bbox": {
                  "left": 35,
                  "top": 26,
                  "width": 27,
                  "height": 16
                },
                "text": "1.4",
                "confidence": 0.98911244
              },
              {
                "bbox": {
                  "left": 35,
                  "top": 45,
                  "width": 27,
                  "height": 19
                },
                "text": "1.2",
                "confidence": 0.9868312
              },
              {
                "bbox": {
                  "left": 48,
                  "top": 65,
                  "width": 13,
                  "height": 16
                },
                "text": "1",
                "confidence": 0.9975491
              },
              {
                "bbox": {
                  "left": 64,
                  "top": 81,
                  "width": 14,
                  "height": 17
                },
                "text": "0",
                "confidence": 0.98794484
              },
              {
                "bbox": {
                  "left": 118,
                  "top": 80,
                  "width": 16,
                  "height": 19
                },
                "text": "1",
                "confidence": 0.9980489
              },
              {
                "bbox": {
                  "left": 173,
                  "top": 80,
                  "width": 17,
                  "height": 19
                },
                "text": "2",
                "confidence": 0.99785835
              },
              {
                "bbox": {
                  "left": 229,
                  "top": 80,
                  "width": 17,
                  "height": 19
                },
                "text": "3",
                "confidence": 0.99789447
              },
              {
                "bbox": {
                  "left": 286,
                  "top": 82,
                  "width": 14,
                  "height": 16
                },
                "text": "4",
                "confidence": 0.99897337
              },
              {
                "bbox": {
                  "left": 341,
                  "top": 81,
                  "width": 13,
                  "height": 17
                },
                "text": "5",
                "confidence": 0.99799323
              },
              {
                "bbox": {
                  "left": 398,
                  "top": 81,
                  "width": 13,
                  "height": 17
                },
                "text": "6",
                "confidence": 0.99851304
              },
              {
                "bbox": {
                  "left": 181,
                  "top": 104,
                  "width": 158,
                  "height": 13
                },
                "text": "CSVchunk size[MB]",
                "confidence": 0.9252324
              }
            ],
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6c80ac91-b0b7-4d82-9efc-6fb903616809.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=fcd7d5ede1b131613c5bf08ee282075bc13b48238f9b333e2aeee0764789d00f",
            "html": "<img src=\"https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6c80ac91-b0b7-4d82-9efc-6fb903616809.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=fcd7d5ede1b131613c5bf08ee282075bc13b48238f9b333e2aeee0764789d00f\" />",
            "markdown": "![Image](https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6c80ac91-b0b7-4d82-9efc-6fb903616809.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=fcd7d5ede1b131613c5bf08ee282075bc13b48238f9b333e2aeee0764789d00f)"
          },
          {
            "segment_id": "ecadb197-9139-47a4-85bf-ecc1eb8d1017",
            "bbox": {
              "left": 659.4166,
              "top": 542.75,
              "width": 495.74997,
              "height": 16.583332
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Figure 13: Throughput as a function of chunk size.",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ecadb197-9139-47a4-85bf-ecc1eb8d1017.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c2a4cf657dbe69ed07670d724799d159c5e72796168c67194f60448e5a229cdb",
            "html": "<span class=\"caption\">Figure 13: Throughput as a function of chunk size.</span>",
            "markdown": "Figure 13: Throughput as a function of chunk size.\n\n"
          },
          {
            "segment_id": "cc71969b-9edc-4a4c-9d64-9a1bed6731cf",
            "bbox": {
              "left": 655.25,
              "top": 584.4166,
              "width": 501.99997,
              "height": 95.75
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "scale-factor loading throughput query time 10 ( ∼ 10 GB) 1.14 GB/s ( ∼ 9 Gbit/s) 16.6 s 30 ( ∼ 30 GB) 1.29 GB/s ( ∼ 10 Gbit/s) 57.9 s 100 ( ∼ 100 GB) 1.36 GB/s ( ∼ 11 Gbit/s) 302.1 s",
            "segment_type": "Table",
            "ocr": [],
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/cc71969b-9edc-4a4c-9d64-9a1bed6731cf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e6b4916026ed2b5f74b153f893311e321ae914605e77f69b39b4f0298746d186",
            "html": "<table>\n  <thead>\n    <tr>\n      <th>scale-factor</th>\n      <th>loading throughput</th>\n      <th>query time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10 (~10GB)</td>\n      <td>1.14 GB/s (~9 Gbit/s)</td>\n      <td>16.6 s</td>\n    </tr>\n    <tr>\n      <td>30 (~30 GB)</td>\n      <td>1.29 GB/s (~10 Gbit/s)</td>\n      <td>57.9 s</td>\n    </tr>\n    <tr>\n      <td>100 (~100 GB)</td>\n      <td>1.36 GB/s (~11 Gbit/s)</td>\n      <td>302.1 s</td>\n    </tr>\n  </tbody>\n</table>",
            "markdown": "| scale-factor | loading throughput | query time |\n| --- | --- | --- |\n| 10 (~10GB) | 1.14 GB/s (~9 Gbit/s) | 16.6 s |\n| 30 (~30 GB) | 1.29 GB/s (~10 Gbit/s) | 57.9 s |\n| 100 (~100 GB) | 1.36 GB/s (~11 Gbit/s) | 302.1 s |\n"
          },
          {
            "segment_id": "bd40dc6f-e41d-4b06-a315-b8af0f177648",
            "bbox": {
              "left": 657.3333,
              "top": 694.8333,
              "width": 501.99997,
              "height": 39.5
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Table 2: Scaleup of Instant Loading of TPC-H data sets on a server with 256 GB main memory.",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/bd40dc6f-e41d-4b06-a315-b8af0f177648.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d435c750cc3bdf64428d5b39734469eab2d7f142a286171ccd5f0c230943563e",
            "html": "<span class=\"caption\">Table 2: Scaleup of Instant Loading of TPC-H data sets on a server with 256 GB main memory.</span>",
            "markdown": "Table 2: Scaleup of Instant Loading of TPC-H data sets on a server with 256 GB main memory.\n\n"
          }
        ],
        "chunk_length": 504
      },
      {
        "segments": [
          {
            "segment_id": "32fb96db-2806-42e2-9298-c74558c80fb8",
            "bbox": {
              "left": 657.3333,
              "top": 767.75,
              "width": 499.91666,
              "height": 62.416664
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "comparable to the MySQL memory engine, queries are pro- cessed much faster. The combined workload took 133.7 s to complete.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/32fb96db-2806-42e2-9298-c74558c80fb8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0acaca99f55928dd5cb97016b8448a92be871119923e78973726c646e6aa3558",
            "html": "<p>comparable to the MySQL memory engine, queries are pro- cessed much faster. The combined workload took 133.7 s to complete.</p>",
            "markdown": "comparable to the MySQL memory engine, queries are pro- cessed much faster. The combined workload took 133.7 s to complete.\n\n"
          },
          {
            "segment_id": "6938d363-094a-472a-ae06-fbac0dc759eb",
            "bbox": {
              "left": 657.3333,
              "top": 832.3333,
              "width": 501.99997,
              "height": 147.83333
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "For Vectorwise, we bulk loaded the files using the vwload utility with rollback on failure turned off. Loading time is comparable to MonetDB while queries are processed slightly faster. TPC-H query 5 could not be processed without the prior generation of statistics using optimizedb . We did not include the creation of statistics in our benchmark results as it took several minutes in our experiments.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/6938d363-094a-472a-ae06-fbac0dc759eb.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=6808aa4e93c9c3e9aa64bf1d328702d2eee5e669f2ab4eced027a68033da3c18",
            "html": "<p>For Vectorwise, we bulk loaded the files using the vwload utility with rollback on failure turned off. Loading time is comparable to MonetDB while queries are processed slightly faster. TPC-H query 5 could not be processed without the prior generation of statistics using optimizedb . We did not include the creation of statistics in our benchmark results as it took several minutes in our experiments.</p>",
            "markdown": "For Vectorwise, we bulk loaded the files using the vwload utility with rollback on failure turned off. Loading time is comparable to MonetDB while queries are processed slightly faster. TPC-H query 5 could not be processed without the prior generation of statistics using optimizedb . We did not include the creation of statistics in our benchmark results as it took several minutes in our experiments.\n\n"
          },
          {
            "segment_id": "121802f0-a0eb-46c1-8d83-d891379306c2",
            "bbox": {
              "left": 657.3333,
              "top": 984.4166,
              "width": 501.99997,
              "height": 126.99999
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "We would have liked to further compare Instant Loading to MonetDB’s CSV vault [16] but couldn’t get it running in the current version of MonetDB. We would have also liked to evaluate the NoDB implementation PostgresRaw [3] in the context of high-performance I/O devices and main memory databases, but its implementation is not (yet) available.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/121802f0-a0eb-46c1-8d83-d891379306c2.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=36874d0794a3fcaa7fe179bd468ef46da5e28752a86dbf387f9222f15c5c096a",
            "html": "<p>We would have liked to further compare Instant Loading to MonetDB’s CSV vault [16] but couldn’t get it running in the current version of MonetDB. We would have also liked to evaluate the NoDB implementation PostgresRaw [3] in the context of high-performance I/O devices and main memory databases, but its implementation is not (yet) available.</p>",
            "markdown": "We would have liked to further compare Instant Loading to MonetDB’s CSV vault [16] but couldn’t get it running in the current version of MonetDB. We would have also liked to evaluate the NoDB implementation PostgresRaw [3] in the context of high-performance I/O devices and main memory databases, but its implementation is not (yet) available.\n\n"
          },
          {
            "segment_id": "65bd377c-421a-4d6a-a027-ca78a363143b",
            "bbox": {
              "left": 657.3333,
              "top": 1119.8333,
              "width": 501.99997,
              "height": 106.166664
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Optimal chunk size. Fig. 13 shows Instant Loading throughput of a TPC-H data set as a function of chunk size. Highest throughputs were measured between 256 kB and 1 MB, which equals a range of 0 . 25–1 . 0 times the L3 cache size divided by the number of hardware threads used.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/65bd377c-421a-4d6a-a027-ca78a363143b.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f6a096107daa024b980acc36b09225942ad091961be8ebd59586a0a4bba3149d",
            "html": "<p>Optimal chunk size. Fig. 13 shows Instant Loading throughput of a TPC-H data set as a function of chunk size. Highest throughputs were measured between 256 kB and 1 MB, which equals a range of 0 . 25–1 . 0 times the L3 cache size divided by the number of hardware threads used.</p>",
            "markdown": "Optimal chunk size. Fig. 13 shows Instant Loading throughput of a TPC-H data set as a function of chunk size. Highest throughputs were measured between 256 kB and 1 MB, which equals a range of 0 . 25–1 . 0 times the L3 cache size divided by the number of hardware threads used.\n\n"
          },
          {
            "segment_id": "63e6b5c4-bda7-42c0-8f18-904dd305d31c",
            "bbox": {
              "left": 657.3333,
              "top": 1232.3333,
              "width": 501.99997,
              "height": 149.91666
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Scaleup of Instant Loading. We evaluated the scaleup of Instant Loading on a server machine with an 8 core In- tel Xeon X7560 CPU and 256 GB of DDR3-1066 DRAM and bulk loaded TPC-H CSV data with scale-factors of 10 ( ∼ 10 GB), 30 ( ∼ 30 GB), and 100 ( ∼ 100 GB). We then again executed the 22 TPC-H queries in parallel query streams. As shown in Table 2, Instant Loading achieves a linear scaleup.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/63e6b5c4-bda7-42c0-8f18-904dd305d31c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8126ac25d890f84e72750f7a130c67cb0654560d309d2246a1c8095ff0a3314a",
            "html": "<p>Scaleup of Instant Loading. We evaluated the scaleup of Instant Loading on a server machine with an 8 core In- tel Xeon X7560 CPU and 256 GB of DDR3-1066 DRAM and bulk loaded TPC-H CSV data with scale-factors of 10 ( ∼ 10 GB), 30 ( ∼ 30 GB), and 100 ( ∼ 100 GB). We then again executed the 22 TPC-H queries in parallel query streams. As shown in Table 2, Instant Loading achieves a linear scaleup.</p>",
            "markdown": "Scaleup of Instant Loading. We evaluated the scaleup of Instant Loading on a server machine with an 8 core In- tel Xeon X7560 CPU and 256 GB of DDR3-1066 DRAM and bulk loaded TPC-H CSV data with scale-factors of 10 ( ∼ 10 GB), 30 ( ∼ 30 GB), and 100 ( ∼ 100 GB). We then again executed the 22 TPC-H queries in parallel query streams. As shown in Table 2, Instant Loading achieves a linear scaleup.\n\n"
          },
          {
            "segment_id": "2cd58e6a-eab2-45cc-b111-ccefb98cab5c",
            "bbox": {
              "left": 657.3333,
              "top": 1390.6666,
              "width": 501.99997,
              "height": 106.166664
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "perf analysis of Instant Loading. A perf analysis of Instant Loading of a TPC-H scale-factor 10 lineitem CSV file shows that 37% of CPU cycles are used to find delim- iters, 11.2% to deserialize numerics, 9.1% to deserialize dates, 6.5% to deserialize integers, 5.5% in the LLVM glue",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/2cd58e6a-eab2-45cc-b111-ccefb98cab5c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d56681a95bcb0a02021b85f9061dca6db75ecdcb66ab07cc175ebbb1941922cf",
            "html": "<p>perf analysis of Instant Loading. A perf analysis of Instant Loading of a TPC-H scale-factor 10 lineitem CSV file shows that 37% of CPU cycles are used to find delim- iters, 11.2% to deserialize numerics, 9.1% to deserialize dates, 6.5% to deserialize integers, 5.5% in the LLVM glue</p>",
            "markdown": "perf analysis of Instant Loading. A perf analysis of Instant Loading of a TPC-H scale-factor 10 lineitem CSV file shows that 37% of CPU cycles are used to find delim- iters, 11.2% to deserialize numerics, 9.1% to deserialize dates, 6.5% to deserialize integers, 5.5% in the LLVM glue\n\n"
          },
          {
            "segment_id": "10bfad8e-6933-45e1-bfb5-592591217d65",
            "bbox": {
              "left": 113.58333,
              "top": 1480.25,
              "width": 404.0833,
              "height": 16.583332
            },
            "page_number": 10,
            "page_width": 1275,
            "page_height": 1650,
            "content": "3 http://issues.apache.org/jira/browse/HIVE-600",
            "segment_type": "Footnote",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/10bfad8e-6933-45e1-bfb5-592591217d65.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=ec9cdb56721571861b58902d54e685259ce24d25987915c3dfa6daa02f91d23d",
            "html": "<span class=\"footnote\">3 http://issues.apache.org/jira/browse/HIVE-600</span>",
            "markdown": "3 http://issues.apache.org/jira/browse/HIVE-600\n\n"
          },
          {
            "segment_id": "e19e65d3-ef08-4e76-9374-0ff2590deda4",
            "bbox": {
              "left": 115.666664,
              "top": 103.166664,
              "width": 466.5833,
              "height": 293.66666
            },
            "page_number": 11,
            "page_width": 1275,
            "page_height": 1650,
            "content": "0 1 2 3 4 5 6 7 8 9 100 , 000 200 , 000 300 , 000 400 , 000 500 , 000 600 , 000 merge beginning of loading execution time [s] throughput [TX/s] MT OLTP + chunk-parallel IL MT OLTP + ST IL ST OLTP + chunk-parallel IL ST OLTP + ST IL",
            "segment_type": "Picture",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/e19e65d3-ef08-4e76-9374-0ff2590deda4.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=720a760c12cd49d79407349b354199cb38b2c7df4f7eca480af60f051196678f",
            "html": "<img src=\"https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/e19e65d3-ef08-4e76-9374-0ff2590deda4.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=720a760c12cd49d79407349b354199cb38b2c7df4f7eca480af60f051196678f\" />",
            "markdown": "![Image](https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/e19e65d3-ef08-4e76-9374-0ff2590deda4.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=720a760c12cd49d79407349b354199cb38b2c7df4f7eca480af60f051196678f)"
          },
          {
            "segment_id": "5c87d884-7298-4a30-8256-7e6a9ca50508",
            "bbox": {
              "left": 109.416664,
              "top": 409.41666,
              "width": 499.91666,
              "height": 83.25
            },
            "page_number": 11,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Figure 14: Chunk-parallel and single-threaded (ST) online CSV Instant Loading (IL) of 1M item and 4M stock entries and single-threaded (ST) and multi- threaded (MT) TPC-C transaction processing.",
            "segment_type": "Caption",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/5c87d884-7298-4a30-8256-7e6a9ca50508.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=68769b8c8de06334b7a632642bed06e57a30b0a99c3fb2942d4dadd493c57a53",
            "html": "<span class=\"caption\">Figure 14: Chunk-parallel and single-threaded (ST) online CSV Instant Loading (IL) of 1M item and 4M stock entries and single-threaded (ST) and multi- threaded (MT) TPC-C transaction processing.</span>",
            "markdown": "Figure 14: Chunk-parallel and single-threaded (ST) online CSV Instant Loading (IL) of 1M item and 4M stock entries and single-threaded (ST) and multi- threaded (MT) TPC-C transaction processing.\n\n"
          },
          {
            "segment_id": "c393e5ab-1557-4167-abc5-851def5f734d",
            "bbox": {
              "left": 109.416664,
              "top": 519.8333,
              "width": 501.99997,
              "height": 126.99999
            },
            "page_number": 11,
            "page_width": 1275,
            "page_height": 1650,
            "content": "code that processes CSV chunks, and 5% in the LLVM glue code that merges partition buffers. The remaining cycles are mostly spent inside the kernel. In more detail, the costs of deserialization methods and the method to find delimiters are dominated by the instructions that load data to the SSE registers and the SSE comparison instructions.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/c393e5ab-1557-4167-abc5-851def5f734d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=7b6d892002c3c265b309c7fc730a9817d4589db2b7bccf284746a57921ee20d0",
            "html": "<p>code that processes CSV chunks, and 5% in the LLVM glue code that merges partition buffers. The remaining cycles are mostly spent inside the kernel. In more detail, the costs of deserialization methods and the method to find delimiters are dominated by the instructions that load data to the SSE registers and the SSE comparison instructions.</p>",
            "markdown": "code that processes CSV chunks, and 5% in the LLVM glue code that merges partition buffers. The remaining cycles are mostly spent inside the kernel. In more detail, the costs of deserialization methods and the method to find delimiters are dominated by the instructions that load data to the SSE registers and the SSE comparison instructions.\n\n"
          }
        ],
        "chunk_length": 462
      },
      {
        "segments": [
          {
            "segment_id": "174646ce-5ed4-4fd0-b222-4bdbb1333f90",
            "bbox": {
              "left": 109.416664,
              "top": 663.5833,
              "width": 379.0833,
              "height": 24.916666
            },
            "page_number": 11,
            "page_width": 1275,
            "page_height": 1650,
            "content": "5.5 Online Transactional Loading",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/174646ce-5ed4-4fd0-b222-4bdbb1333f90.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=45a1876059fdee451ff9e498908d0012f5a8f6f141b3a0d3aab4688976bb00b1",
            "html": "<h2>5.5 Online Transactional Loading</h2>",
            "markdown": "## 5.5 Online Transactional Loading\n\n"
          },
          {
            "segment_id": "e6996882-8fe4-4db3-9add-981f588fba14",
            "bbox": {
              "left": 109.416664,
              "top": 692.75,
              "width": 501.99997,
              "height": 654.0833
            },
            "page_number": 11,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Finally, we evaluated Instant Loading in the context of on- line transactional loading with ACID semantics. In partic- ular, we benchmarked the partitioned execution of TPC-C transactions in a TPC-C database partitioned by warehouse with 4 warehouses. In parallel to transaction processing, we bulk loaded a new product catalog with 1M new items into the item table. In addition to the 1M items, for each ware- house, 1M stock entries were inserted into the stock table. The storage backend was a chunked row-store and we used chunk-based partition buffer merging. Fig. 14 shows the TPC-C throughput with online bulk loading of the afore- mentioned data set ( ∼ 1.3 GB), which was stored as CSV files in ramfs . In our benchmark, loading started after 1 sec- ond. We measured transaction throughput in four scenarios: single- (ST) and multi-threaded (MT) transaction process- ing combined with single-threaded and CSV chunk-parallel Instant Loading. In case of ST transaction processing, a throughput of 200,000 transactions per second was sustained with ST Instant Loading; with chunk-parallel Instant Load- ing throughput shortly dropped to 100,000 transactions per second. Loading took around 3.5 s with ST Instant Load- ing and 1.2 s with chunk-parallel Instant Loading. Merge transactions took 250 ms. In case of MT transaction process- ing, transaction processing and Instant Loading compete for hardware resources and throughput decreased considerably from 600,000 to 250,000 transactions per second. With ST Instant Loading, the additional load on the system is lower and transaction throughput barely decreases. With chunk- parallel Instant Loading, loading took 4.6 s; with ST Instant Loading 7.0 s. Merge transactions took 250 ms again.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/e6996882-8fe4-4db3-9add-981f588fba14.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=924f5707225c0752cec0fd38c880886662d645a72b41921b030f3892e119c358",
            "html": "<p>Finally, we evaluated Instant Loading in the context of on- line transactional loading with ACID semantics. In partic- ular, we benchmarked the partitioned execution of TPC-C transactions in a TPC-C database partitioned by warehouse with 4 warehouses. In parallel to transaction processing, we bulk loaded a new product catalog with 1M new items into the item table. In addition to the 1M items, for each ware- house, 1M stock entries were inserted into the stock table. The storage backend was a chunked row-store and we used chunk-based partition buffer merging. Fig. 14 shows the TPC-C throughput with online bulk loading of the afore- mentioned data set ( ∼ 1.3 GB), which was stored as CSV files in ramfs . In our benchmark, loading started after 1 sec- ond. We measured transaction throughput in four scenarios: single- (ST) and multi-threaded (MT) transaction process- ing combined with single-threaded and CSV chunk-parallel Instant Loading. In case of ST transaction processing, a throughput of 200,000 transactions per second was sustained with ST Instant Loading; with chunk-parallel Instant Load- ing throughput shortly dropped to 100,000 transactions per second. Loading took around 3.5 s with ST Instant Load- ing and 1.2 s with chunk-parallel Instant Loading. Merge transactions took 250 ms. In case of MT transaction process- ing, transaction processing and Instant Loading compete for hardware resources and throughput decreased considerably from 600,000 to 250,000 transactions per second. With ST Instant Loading, the additional load on the system is lower and transaction throughput barely decreases. With chunk- parallel Instant Loading, loading took 4.6 s; with ST Instant Loading 7.0 s. Merge transactions took 250 ms again.</p>",
            "markdown": "Finally, we evaluated Instant Loading in the context of on- line transactional loading with ACID semantics. In partic- ular, we benchmarked the partitioned execution of TPC-C transactions in a TPC-C database partitioned by warehouse with 4 warehouses. In parallel to transaction processing, we bulk loaded a new product catalog with 1M new items into the item table. In addition to the 1M items, for each ware- house, 1M stock entries were inserted into the stock table. The storage backend was a chunked row-store and we used chunk-based partition buffer merging. Fig. 14 shows the TPC-C throughput with online bulk loading of the afore- mentioned data set ( ∼ 1.3 GB), which was stored as CSV files in ramfs . In our benchmark, loading started after 1 sec- ond. We measured transaction throughput in four scenarios: single- (ST) and multi-threaded (MT) transaction process- ing combined with single-threaded and CSV chunk-parallel Instant Loading. In case of ST transaction processing, a throughput of 200,000 transactions per second was sustained with ST Instant Loading; with chunk-parallel Instant Load- ing throughput shortly dropped to 100,000 transactions per second. Loading took around 3.5 s with ST Instant Load- ing and 1.2 s with chunk-parallel Instant Loading. Merge transactions took 250 ms. In case of MT transaction process- ing, transaction processing and Instant Loading compete for hardware resources and throughput decreased considerably from 600,000 to 250,000 transactions per second. With ST Instant Loading, the additional load on the system is lower and transaction throughput barely decreases. With chunk- parallel Instant Loading, loading took 4.6 s; with ST Instant Loading 7.0 s. Merge transactions took 250 ms again.\n\n"
          },
          {
            "segment_id": "4401ebba-98eb-468d-bf5c-ca196898c561",
            "bbox": {
              "left": 109.416664,
              "top": 1349,
              "width": 499.91666,
              "height": 147.83333
            },
            "page_number": 11,
            "page_width": 1275,
            "page_height": 1650,
            "content": "To the best of our knowledge, none of our contestants sup- ports online transactional loading yet. We still compared our approach to the MySQL memory engine, which, how- ever, has no support for transactions. We thus executed the TPC-C transactions sequentially. MySQL achieved a trans- action throughput of 36 transactions per second. Loading took 19.70 s; no transactions were processed during loading.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/4401ebba-98eb-468d-bf5c-ca196898c561.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=53f9404739bf1b3598723671c0973e7ae1507398cbe95a677762b1c082593ba5",
            "html": "<p>To the best of our knowledge, none of our contestants sup- ports online transactional loading yet. We still compared our approach to the MySQL memory engine, which, how- ever, has no support for transactions. We thus executed the TPC-C transactions sequentially. MySQL achieved a trans- action throughput of 36 transactions per second. Loading took 19.70 s; no transactions were processed during loading.</p>",
            "markdown": "To the best of our knowledge, none of our contestants sup- ports online transactional loading yet. We still compared our approach to the MySQL memory engine, which, how- ever, has no support for transactions. We thus executed the TPC-C transactions sequentially. MySQL achieved a trans- action throughput of 36 transactions per second. Loading took 19.70 s; no transactions were processed during loading.\n\n"
          }
        ],
        "chunk_length": 336
      },
      {
        "segments": [
          {
            "segment_id": "e89947a7-171a-4563-bbc8-3ccb5448703d",
            "bbox": {
              "left": 655.25,
              "top": 113.58333,
              "width": 254.08333,
              "height": 24.916666
            },
            "page_number": 11,
            "page_width": 1275,
            "page_height": 1650,
            "content": "6. RELATED WORK",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/e89947a7-171a-4563-bbc8-3ccb5448703d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=9f64d5d76df24e1354b6f2e2ade97284b581ad807f36f7376cfc7a18db353802",
            "html": "<h2>6. RELATED WORK</h2>",
            "markdown": "## 6. RELATED WORK\n\n"
          },
          {
            "segment_id": "4064595b-8373-4b96-ae93-dd0b63a3fa75",
            "bbox": {
              "left": 657.3333,
              "top": 142.75,
              "width": 501.99997,
              "height": 85.33333
            },
            "page_number": 11,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Due to Amdahl’s law, emerging multi-core CPUs can only be efficiently utilized by highly parallelized applications [17]. Instant Loading highly parallelizes CSV bulk loading and re- duces the proportion of sequential code to a minimum.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/4064595b-8373-4b96-ae93-dd0b63a3fa75.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=311373db113a2652c2fd197de42c49b8ee937c3722fca27e904797d0318dd9aa",
            "html": "<p>Due to Amdahl’s law, emerging multi-core CPUs can only be efficiently utilized by highly parallelized applications [17]. Instant Loading highly parallelizes CSV bulk loading and re- duces the proportion of sequential code to a minimum.</p>",
            "markdown": "Due to Amdahl’s law, emerging multi-core CPUs can only be efficiently utilized by highly parallelized applications [17]. Instant Loading highly parallelizes CSV bulk loading and re- duces the proportion of sequential code to a minimum.\n\n"
          },
          {
            "segment_id": "1d2ea811-4c50-493c-8949-97406caf616f",
            "bbox": {
              "left": 657.3333,
              "top": 232.33333,
              "width": 501.99997,
              "height": 212.41666
            },
            "page_number": 11,
            "page_width": 1275,
            "page_height": 1650,
            "content": "SIMD instructions have been used to accelerate a variety of database operators [31, 29]. Vectorized processing and the reduction of branching often enabled superlinear speedups. Compilers such as GCC and the LLVM JIT compiler [22] try to use SIMD instructions automatically. However, often sub- tle tricks, which can hardly be reproduced by compilers, are required to leverage SIMD instructions. To the best of our knowledge no compiler can yet automatically apply SSE 4.2 string and text instructions. To achieve highest speedups, algorithms need to be redesigned from scratch.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/1d2ea811-4c50-493c-8949-97406caf616f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f856e145e5ca125a0c30f5f927097a096864df3d7477970306d83e2b917e9edd",
            "html": "<p>SIMD instructions have been used to accelerate a variety of database operators [31, 29]. Vectorized processing and the reduction of branching often enabled superlinear speedups. Compilers such as GCC and the LLVM JIT compiler [22] try to use SIMD instructions automatically. However, often sub- tle tricks, which can hardly be reproduced by compilers, are required to leverage SIMD instructions. To the best of our knowledge no compiler can yet automatically apply SSE 4.2 string and text instructions. To achieve highest speedups, algorithms need to be redesigned from scratch.</p>",
            "markdown": "SIMD instructions have been used to accelerate a variety of database operators [31, 29]. Vectorized processing and the reduction of branching often enabled superlinear speedups. Compilers such as GCC and the LLVM JIT compiler [22] try to use SIMD instructions automatically. However, often sub- tle tricks, which can hardly be reproduced by compilers, are required to leverage SIMD instructions. To the best of our knowledge no compiler can yet automatically apply SSE 4.2 string and text instructions. To achieve highest speedups, algorithms need to be redesigned from scratch.\n\n"
          },
          {
            "segment_id": "c4443197-b984-4222-919e-3b5f801e38aa",
            "bbox": {
              "left": 657.3333,
              "top": 448.99997,
              "width": 501.99997,
              "height": 474.91666
            },
            "page_number": 11,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Already in 2005, Gray et al. [10] called for a synthesis of file systems and databases. Back then, scientists complained that loading structured text data to a database doesn’t seem worth it and that once it is loaded, it can no longer be manip- ulated using standard application programs. Recent works addressed these objections [12, 3, 16]. NoDB [3] describes systems that “do not require data loading while still main- taining the whole feature set of a modern database system”. NoDB directly works on files and populates positional maps, i.e., index structures on files, and caches as a by-product of query processing. Even though the NoDB reference imple- mentation PostgresRaw has shown that queries can be pro- cessed without loading and query processing profits from the positional maps and caches, major issues are not solved. These, in our opinion, mainly include the efficient support of transactions, the scalability and efficiency of query process- ing, and the adaptability of the paradigm for main memory databases. Instant Loading is a different and novel approach that does not face these issues: Instead of eliminating data loading and adding the overhead of an additional layer of indirection, our approach focusses on making loading and unloading as unobtrusive as possible.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/c4443197-b984-4222-919e-3b5f801e38aa.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8ba5271a4e010d2c98778ec70898f8997938dc9011820a35634f47e832e3646d",
            "html": "<p>Already in 2005, Gray et al. [10] called for a synthesis of file systems and databases. Back then, scientists complained that loading structured text data to a database doesn’t seem worth it and that once it is loaded, it can no longer be manip- ulated using standard application programs. Recent works addressed these objections [12, 3, 16]. NoDB [3] describes systems that “do not require data loading while still main- taining the whole feature set of a modern database system”. NoDB directly works on files and populates positional maps, i.e., index structures on files, and caches as a by-product of query processing. Even though the NoDB reference imple- mentation PostgresRaw has shown that queries can be pro- cessed without loading and query processing profits from the positional maps and caches, major issues are not solved. These, in our opinion, mainly include the efficient support of transactions, the scalability and efficiency of query process- ing, and the adaptability of the paradigm for main memory databases. Instant Loading is a different and novel approach that does not face these issues: Instead of eliminating data loading and adding the overhead of an additional layer of indirection, our approach focusses on making loading and unloading as unobtrusive as possible.</p>",
            "markdown": "Already in 2005, Gray et al. [10] called for a synthesis of file systems and databases. Back then, scientists complained that loading structured text data to a database doesn’t seem worth it and that once it is loaded, it can no longer be manip- ulated using standard application programs. Recent works addressed these objections [12, 3, 16]. NoDB [3] describes systems that “do not require data loading while still main- taining the whole feature set of a modern database system”. NoDB directly works on files and populates positional maps, i.e., index structures on files, and caches as a by-product of query processing. Even though the NoDB reference imple- mentation PostgresRaw has shown that queries can be pro- cessed without loading and query processing profits from the positional maps and caches, major issues are not solved. These, in our opinion, mainly include the efficient support of transactions, the scalability and efficiency of query process- ing, and the adaptability of the paradigm for main memory databases. Instant Loading is a different and novel approach that does not face these issues: Instead of eliminating data loading and adding the overhead of an additional layer of indirection, our approach focusses on making loading and unloading as unobtrusive as possible.\n\n"
          },
          {
            "segment_id": "1b0ffe48-750a-4f7a-b3f1-b09c74cfc619",
            "bbox": {
              "left": 657.3333,
              "top": 928.1666,
              "width": 501.99997,
              "height": 364.5
            },
            "page_number": 11,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Extensions of MapReduce, e.g., Hive [28], added support for declarative query languages to the paradigm. To im- prove query performance, some approaches, e.g., HAIL [7], propose using binary representations of text files for query processing. The conversion of text data into these binary representations is very similar to bulk loading in traditional databases. HadoopDB [1] is designed as a hybrid of tra- ditional databases and Hadoop-based approaches. It inter- connects relational single-node databases using a communi- cation layer based on Hadoop. Loading of the single-node databases has been identified as one of the obstacles of the approach. With Instant Loading, this obstacle can be re- moved. Polybase [6], a feature of the Microsoft SQL Server PDW, translates some SQL operators on HDFS-resident data into MapReduce jobs. The decision of when to push operators from the database to Hadoop largely depends on the text file loading performance of the database.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/1b0ffe48-750a-4f7a-b3f1-b09c74cfc619.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=556a7359f04bc2c3709c7b8a8264da08a08ea51e6297b20eae9673fb31e847e9",
            "html": "<p>Extensions of MapReduce, e.g., Hive [28], added support for declarative query languages to the paradigm. To im- prove query performance, some approaches, e.g., HAIL [7], propose using binary representations of text files for query processing. The conversion of text data into these binary representations is very similar to bulk loading in traditional databases. HadoopDB [1] is designed as a hybrid of tra- ditional databases and Hadoop-based approaches. It inter- connects relational single-node databases using a communi- cation layer based on Hadoop. Loading of the single-node databases has been identified as one of the obstacles of the approach. With Instant Loading, this obstacle can be re- moved. Polybase [6], a feature of the Microsoft SQL Server PDW, translates some SQL operators on HDFS-resident data into MapReduce jobs. The decision of when to push operators from the database to Hadoop largely depends on the text file loading performance of the database.</p>",
            "markdown": "Extensions of MapReduce, e.g., Hive [28], added support for declarative query languages to the paradigm. To im- prove query performance, some approaches, e.g., HAIL [7], propose using binary representations of text files for query processing. The conversion of text data into these binary representations is very similar to bulk loading in traditional databases. HadoopDB [1] is designed as a hybrid of tra- ditional databases and Hadoop-based approaches. It inter- connects relational single-node databases using a communi- cation layer based on Hadoop. Loading of the single-node databases has been identified as one of the obstacles of the approach. With Instant Loading, this obstacle can be re- moved. Polybase [6], a feature of the Microsoft SQL Server PDW, translates some SQL operators on HDFS-resident data into MapReduce jobs. The decision of when to push operators from the database to Hadoop largely depends on the text file loading performance of the database.\n\n"
          }
        ],
        "chunk_length": 480
      },
      {
        "segments": [
          {
            "segment_id": "5144071b-8202-454f-a66f-7021f715d9fe",
            "bbox": {
              "left": 657.3333,
              "top": 1301.0833,
              "width": 501.99997,
              "height": 189.5
            },
            "page_number": 11,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Bulk loading of index structures has, e.g., been discussed for B-trees [8, 9]. Database cracking [13] and adaptive in- dexing [14] propose an iterative creation of indexes as a by- product of query processing. These works argue that a high cost has to be paid up-front if indexes are created at load- time. While this is certainly true for disk-based systems, we have shown that for main memory databases at least the cre- ation of primary indexes—which enable the validation of pri- mary key constraints—as a side-effect of loading is feasible.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/5144071b-8202-454f-a66f-7021f715d9fe.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=636cab503d210dd87bc74a99037fa2b1723c028f741f3959dfddd8fde798eaca",
            "html": "<p>Bulk loading of index structures has, e.g., been discussed for B-trees [8, 9]. Database cracking [13] and adaptive in- dexing [14] propose an iterative creation of indexes as a by- product of query processing. These works argue that a high cost has to be paid up-front if indexes are created at load- time. While this is certainly true for disk-based systems, we have shown that for main memory databases at least the cre- ation of primary indexes—which enable the validation of pri- mary key constraints—as a side-effect of loading is feasible.</p>",
            "markdown": "Bulk loading of index structures has, e.g., been discussed for B-trees [8, 9]. Database cracking [13] and adaptive in- dexing [14] propose an iterative creation of indexes as a by- product of query processing. These works argue that a high cost has to be paid up-front if indexes are created at load- time. While this is certainly true for disk-based systems, we have shown that for main memory databases at least the cre- ation of primary indexes—which enable the validation of pri- mary key constraints—as a side-effect of loading is feasible.\n\n"
          }
        ],
        "chunk_length": 91
      },
      {
        "segments": [
          {
            "segment_id": "b728a5ff-40dd-437a-a9d1-6f28321bcecc",
            "bbox": {
              "left": 109.416664,
              "top": 113.58333,
              "width": 410.3333,
              "height": 24.916666
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "7. OUTLOOK AND CONCLUSION",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/b728a5ff-40dd-437a-a9d1-6f28321bcecc.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d3ea74eb5810fb0915323eb56eab3f942faadf12dca3c5a9fde2abe8d2fdd84a",
            "html": "<h2>7. OUTLOOK AND CONCLUSION</h2>",
            "markdown": "## 7. OUTLOOK AND CONCLUSION\n\n"
          },
          {
            "segment_id": "39da12f3-9fb5-477c-865a-d96649330d81",
            "bbox": {
              "left": 109.416664,
              "top": 142.75,
              "width": 501.99997,
              "height": 412.41666
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Ever increasing main memory capacities have fostered the development of in-memory database systems and very fast network infrastructures with wire speeds of tens of Gbit/s are becoming economical. Current bulk loading approaches for main memory databases, however, fail to leverage these wire speeds when loading structured text data. In this work we presented Instant Loading , a novel CSV loading approach that allows scalable bulk loading at wire speed . Task- and data-parallelization of every phase of loading allows us to fully leverage the performance of modern multi-core CPUs. We integrated the generic Instant Loading approach in our HyPer system and evaluated its end-to-end application per- formance. The performance results have shown that Instant Loading can indeed leverage the wire speed of emerging 10 GbE connectors. This paves the way for new (load-work- unload)* usage scenarios where the main memory database system serves as a flexible and high-performance compute engine for big data processing—instead of using resource- heavy MapReduce-style infrastructures.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/39da12f3-9fb5-477c-865a-d96649330d81.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=9f73ca17d458313ed2f812ead89439a32a323648cea6a9436f9a21aba12cd8ed",
            "html": "<p>Ever increasing main memory capacities have fostered the development of in-memory database systems and very fast network infrastructures with wire speeds of tens of Gbit/s are becoming economical. Current bulk loading approaches for main memory databases, however, fail to leverage these wire speeds when loading structured text data. In this work we presented Instant Loading , a novel CSV loading approach that allows scalable bulk loading at wire speed . Task- and data-parallelization of every phase of loading allows us to fully leverage the performance of modern multi-core CPUs. We integrated the generic Instant Loading approach in our HyPer system and evaluated its end-to-end application per- formance. The performance results have shown that Instant Loading can indeed leverage the wire speed of emerging 10 GbE connectors. This paves the way for new (load-work- unload)* usage scenarios where the main memory database system serves as a flexible and high-performance compute engine for big data processing—instead of using resource- heavy MapReduce-style infrastructures.</p>",
            "markdown": "Ever increasing main memory capacities have fostered the development of in-memory database systems and very fast network infrastructures with wire speeds of tens of Gbit/s are becoming economical. Current bulk loading approaches for main memory databases, however, fail to leverage these wire speeds when loading structured text data. In this work we presented Instant Loading , a novel CSV loading approach that allows scalable bulk loading at wire speed . Task- and data-parallelization of every phase of loading allows us to fully leverage the performance of modern multi-core CPUs. We integrated the generic Instant Loading approach in our HyPer system and evaluated its end-to-end application per- formance. The performance results have shown that Instant Loading can indeed leverage the wire speed of emerging 10 GbE connectors. This paves the way for new (load-work- unload)* usage scenarios where the main memory database system serves as a flexible and high-performance compute engine for big data processing—instead of using resource- heavy MapReduce-style infrastructures.\n\n"
          },
          {
            "segment_id": "154dd3da-0e48-44e5-ac8d-fdab4b53b989",
            "bbox": {
              "left": 109.416664,
              "top": 557.3333,
              "width": 501.99997,
              "height": 126.99999
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "In the future we intend to support other structured text formats and include more data preprocessing steps such as compression, clustering, and synopsis generation. E.g., small materialized aggregates [21] can efficiently be computed at load time. Another idea is to port our scalable loading ap- proach to coprocessor hardware and general-purpose GPUs.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/154dd3da-0e48-44e5-ac8d-fdab4b53b989.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=dffcd109fa42bdf7aab27794484c4b2d4a37b957e961ebedb19a1fc2399d6d01",
            "html": "<p>In the future we intend to support other structured text formats and include more data preprocessing steps such as compression, clustering, and synopsis generation. E.g., small materialized aggregates [21] can efficiently be computed at load time. Another idea is to port our scalable loading ap- proach to coprocessor hardware and general-purpose GPUs.</p>",
            "markdown": "In the future we intend to support other structured text formats and include more data preprocessing steps such as compression, clustering, and synopsis generation. E.g., small materialized aggregates [21] can efficiently be computed at load time. Another idea is to port our scalable loading ap- proach to coprocessor hardware and general-purpose GPUs.\n\n"
          }
        ],
        "chunk_length": 216
      },
      {
        "segments": [
          {
            "segment_id": "35b4dd88-afac-48bc-8e38-7690c7df9962",
            "bbox": {
              "left": 109.416664,
              "top": 709.4166,
              "width": 335.3333,
              "height": 22.833332
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "8. ACKNOWLEDGEMENTS",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/35b4dd88-afac-48bc-8e38-7690c7df9962.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=94b6b553623634dc5ee9e5af982716f924fab186c745aaf369fd1dbcb9f3fb0a",
            "html": "<h2>8. ACKNOWLEDGEMENTS</h2>",
            "markdown": "## 8. ACKNOWLEDGEMENTS\n\n"
          },
          {
            "segment_id": "01ad57f4-cf26-4dbe-8059-4aca0061c2d0",
            "bbox": {
              "left": 109.416664,
              "top": 738.5833,
              "width": 501.99997,
              "height": 126.99999
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "Tobias M¨ uhlbauer is a recipient of the Google Europe Fel- lowship in Structured Data Analysis, and this research is supported in part by this Google Fellowship. Wolf R¨ odiger is a recipient of the Oracle External Research Fellowship. This work is further sponsored by the German Federal Ministry of Education and Research (BMBF) grant HDBC 01IS12026.",
            "segment_type": "Text",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/01ad57f4-cf26-4dbe-8059-4aca0061c2d0.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=145e44d47c4b3329b8914289676a46f6a8efa6162f872d0215f63bc6ef3665f9",
            "html": "<p>Tobias M¨ uhlbauer is a recipient of the Google Europe Fel- lowship in Structured Data Analysis, and this research is supported in part by this Google Fellowship. Wolf R¨ odiger is a recipient of the Oracle External Research Fellowship. This work is further sponsored by the German Federal Ministry of Education and Research (BMBF) grant HDBC 01IS12026.</p>",
            "markdown": "Tobias M¨ uhlbauer is a recipient of the Google Europe Fel- lowship in Structured Data Analysis, and this research is supported in part by this Google Fellowship. Wolf R¨ odiger is a recipient of the Oracle External Research Fellowship. This work is further sponsored by the German Federal Ministry of Education and Research (BMBF) grant HDBC 01IS12026.\n\n"
          }
        ],
        "chunk_length": 59
      },
      {
        "segments": [
          {
            "segment_id": "edc869ad-fc04-4570-b104-f6dd5c7bbb94",
            "bbox": {
              "left": 109.416664,
              "top": 888.5833,
              "width": 212.41666,
              "height": 22.833332
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "9. REFERENCES",
            "segment_type": "Section header",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/edc869ad-fc04-4570-b104-f6dd5c7bbb94.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d5d534be8479fa483530f84b8d0198892215584487e919fe20a2d6b422b1dd80",
            "html": "<h2>9. REFERENCES</h2>",
            "markdown": "## 9. REFERENCES\n\n"
          },
          {
            "segment_id": "16f9dafd-dfa5-4c08-b762-f5f3a99f5190",
            "bbox": {
              "left": 119.83333,
              "top": 917.74994,
              "width": 447.8333,
              "height": 106.166664
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[1] A. Abouzeid, K. Bajda-Pawlikowski, D. J. Abadi, A. Rasin, and A. Silberschatz. HadoopDB: An Architectural Hybrid of MapReduce and DBMS Technologies for Analytical Workloads. PVLDB , 2(1):922–933, 2009.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/16f9dafd-dfa5-4c08-b762-f5f3a99f5190.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a6f2162229f2f91e1c376038f2e34738ccc24789056aa726e88eb80a0cbf7100",
            "html": "<ul><li>[1] A. Abouzeid, K. Bajda-Pawlikowski, D. J. Abadi, A. Rasin, and A. Silberschatz. HadoopDB: An Architectural Hybrid of MapReduce and DBMS Technologies for Analytical Workloads. PVLDB , 2(1):922–933, 2009.</li></ul>",
            "markdown": "- [1] A. Abouzeid, K. Bajda-Pawlikowski, D. J. Abadi, A. Rasin, and A. Silberschatz. HadoopDB: An Architectural Hybrid of MapReduce and DBMS Technologies for Analytical Workloads. PVLDB , 2(1):922–933, 2009.\n\n"
          },
          {
            "segment_id": "dc1e0282-ce25-4b09-a476-4d21c8610055",
            "bbox": {
              "left": 119.83333,
              "top": 1028.1666,
              "width": 466.5833,
              "height": 62.416664
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[2] A. Ailamaki, D. J. DeWitt, M. D. Hill, and D. A. Wood. DBMSs on a modern processor: Where does time go? VLDB , pages 266–277, 1999.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/dc1e0282-ce25-4b09-a476-4d21c8610055.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d636af4a91df99b6b9825717a62b259adfc63506b346447ec3e47e8add8e1398",
            "html": "<ul><li>[2] A. Ailamaki, D. J. DeWitt, M. D. Hill, and D. A. Wood. DBMSs on a modern processor: Where does time go? VLDB , pages 266–277, 1999.</li></ul>",
            "markdown": "- [2] A. Ailamaki, D. J. DeWitt, M. D. Hill, and D. A. Wood. DBMSs on a modern processor: Where does time go? VLDB , pages 266–277, 1999.\n\n"
          },
          {
            "segment_id": "69bfd867-4db6-42ac-a1c4-4541d91422d6",
            "bbox": {
              "left": 119.83333,
              "top": 1094.8333,
              "width": 474.91666,
              "height": 62.416664
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[3] I. Alagiannis, R. Borovica, M. Branco, S. Idreos, and A. Ailamaki. NoDB: Efficient Query Execution on Raw Data Files. In SIGMOD , pages 241–252, 2012.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/69bfd867-4db6-42ac-a1c4-4541d91422d6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=65d2012c8f9de31433bd7b566a965dc59c3ef5de45f1af678988d22923d1691b",
            "html": "<ul><li>[3] I. Alagiannis, R. Borovica, M. Branco, S. Idreos, and A. Ailamaki. NoDB: Efficient Query Execution on Raw Data Files. In SIGMOD , pages 241–252, 2012.</li></ul>",
            "markdown": "- [3] I. Alagiannis, R. Borovica, M. Branco, S. Idreos, and A. Ailamaki. NoDB: Efficient Query Execution on Raw Data Files. In SIGMOD , pages 241–252, 2012.\n\n"
          },
          {
            "segment_id": "b7520d11-0b77-4d30-a67b-2db857d0c429",
            "bbox": {
              "left": 119.83333,
              "top": 1163.5833,
              "width": 481.16666,
              "height": 62.416664
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[4] P. Boncz, M. Zukowski, and N. Nes. MonetDB/X100: Hyper-pipelining query execution. In CIDR , pages 225–237, 2005.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/b7520d11-0b77-4d30-a67b-2db857d0c429.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=3f1fc677718326ce697cdf31310d35b51271cc58ad9b108c80f79ef62fd877e7",
            "html": "<ul><li>[4] P. Boncz, M. Zukowski, and N. Nes. MonetDB/X100: Hyper-pipelining query execution. In CIDR , pages 225–237, 2005.</li></ul>",
            "markdown": "- [4] P. Boncz, M. Zukowski, and N. Nes. MonetDB/X100: Hyper-pipelining query execution. In CIDR , pages 225–237, 2005.\n\n"
          },
          {
            "segment_id": "ccc281b0-7d11-47d9-8ccb-63654dfe396b",
            "bbox": {
              "left": 119.83333,
              "top": 1232.3333,
              "width": 464.49997,
              "height": 37.416664
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[5] J. Dean. MapReduce: simplified data processing on large clusters. CACM , 51(1):107–113, 2008.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/ccc281b0-7d11-47d9-8ccb-63654dfe396b.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=aa14587a2e3188c58b7e00083309f7ef85cc2f62421a8ad21c8277b76e47ada4",
            "html": "<ul><li>[5] J. Dean. MapReduce: simplified data processing on large clusters. CACM , 51(1):107–113, 2008.</li></ul>",
            "markdown": "- [5] J. Dean. MapReduce: simplified data processing on large clusters. CACM , 51(1):107–113, 2008.\n\n"
          },
          {
            "segment_id": "e9c1767c-a7c4-4150-8dfc-367a49c3dba8",
            "bbox": {
              "left": 119.83333,
              "top": 1278.1666,
              "width": 466.5833,
              "height": 62.416664
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[6] D. J. DeWitt, A. Halverson, R. Nehme, S. Shankar, J. Aguilar-Saborit, et al. Split Query Processing in Polybase. In SIGMOD , pages 1255–1266, 2013.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/e9c1767c-a7c4-4150-8dfc-367a49c3dba8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=863fb465528034ce1d944ba493573a1d9f6d0e275228a9e2b367a77d46b6c606",
            "html": "<ul><li>[6] D. J. DeWitt, A. Halverson, R. Nehme, S. Shankar, J. Aguilar-Saborit, et al. Split Query Processing in Polybase. In SIGMOD , pages 1255–1266, 2013.</li></ul>",
            "markdown": "- [6] D. J. DeWitt, A. Halverson, R. Nehme, S. Shankar, J. Aguilar-Saborit, et al. Split Query Processing in Polybase. In SIGMOD , pages 1255–1266, 2013.\n\n"
          },
          {
            "segment_id": "7a8f9c7c-df15-471b-8d84-cac70bf27f20",
            "bbox": {
              "left": 119.83333,
              "top": 1344.8333,
              "width": 470.74997,
              "height": 62.416664
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[7] J. Dittrich, J.-A. Quian´ e-Ruiz, S. Richter, S. Schuh, A. Jindal, and J. Schad. Only Aggressive Elephants are Fast Elephants. PVLDB , 5(11):1591–1602, 2012.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/7a8f9c7c-df15-471b-8d84-cac70bf27f20.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=71196dc3d2cd47f34e9c25e8963d2392c7cfb94a5525d52e25c18a3cf953154d",
            "html": "<ul><li>[7] J. Dittrich, J.-A. Quian´ e-Ruiz, S. Richter, S. Schuh, A. Jindal, and J. Schad. Only Aggressive Elephants are Fast Elephants. PVLDB , 5(11):1591–1602, 2012.</li></ul>",
            "markdown": "- [7] J. Dittrich, J.-A. Quian´ e-Ruiz, S. Richter, S. Schuh, A. Jindal, and J. Schad. Only Aggressive Elephants are Fast Elephants. PVLDB , 5(11):1591–1602, 2012.\n\n"
          },
          {
            "segment_id": "10fc6e44-1eab-47ad-aef0-d94fee7429d1",
            "bbox": {
              "left": 117.74999,
              "top": 1411.5,
              "width": 439.49997,
              "height": 39.5
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[8] G. Graefe. B-tree indexes for high update rates. SIGMOD Rec. , 35(1):39–44, 2006.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/10fc6e44-1eab-47ad-aef0-d94fee7429d1.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0d48955c39bf6204a50a6d86a9aab4a012b0f54e9e257392f4ff8050e425ea69",
            "html": "<ul><li>[8] G. Graefe. B-tree indexes for high update rates. SIGMOD Rec. , 35(1):39–44, 2006.</li></ul>",
            "markdown": "- [8] G. Graefe. B-tree indexes for high update rates. SIGMOD Rec. , 35(1):39–44, 2006.\n\n"
          },
          {
            "segment_id": "4f1e97ac-86a9-446b-8f59-566c43dfa118",
            "bbox": {
              "left": 119.83333,
              "top": 1457.3333,
              "width": 487.41666,
              "height": 39.5
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[9] G. Graefe and H. Kuno. Fast Loads and Queries. In TLDKS II , number 6380 in LNCS, pages 31–72, 2010.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/4f1e97ac-86a9-446b-8f59-566c43dfa118.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c82fe9568205e7e2ba3f852b32fed385f60cb6a7e1e6c1727b434aff516a0d60",
            "html": "<ul><li>[9] G. Graefe and H. Kuno. Fast Loads and Queries. In TLDKS II , number 6380 in LNCS, pages 31–72, 2010.</li></ul>",
            "markdown": "- [9] G. Graefe and H. Kuno. Fast Loads and Queries. In TLDKS II , number 6380 in LNCS, pages 31–72, 2010.\n\n"
          },
          {
            "segment_id": "3ea93fef-5bc5-415c-95df-33b07c5749b7",
            "bbox": {
              "left": 659.4166,
              "top": 117.74999,
              "width": 483.24997,
              "height": 83.25
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[10] J. Gray, D. Liu, M. Nieto-Santisteban, A. Szalay, D. DeWitt, and G. Heber. Scientific Data Management in the Coming Decade. SIGMOD Rec. , 34(4):34–41, 2005.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/3ea93fef-5bc5-415c-95df-33b07c5749b7.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=7c3abb70c6432b2c6a8d134ac345fe38d83aab0d73d70e961fea437f18e3faa0",
            "html": "<ul><li>[10] J. Gray, D. Liu, M. Nieto-Santisteban, A. Szalay, D. DeWitt, and G. Heber. Scientific Data Management in the Coming Decade. SIGMOD Rec. , 34(4):34–41, 2005.</li></ul>",
            "markdown": "- [10] J. Gray, D. Liu, M. Nieto-Santisteban, A. Szalay, D. DeWitt, and G. Heber. Scientific Data Management in the Coming Decade. SIGMOD Rec. , 34(4):34–41, 2005.\n\n"
          },
          {
            "segment_id": "beaa0020-5655-42f5-9625-ed49b3b7e96f",
            "bbox": {
              "left": 657.3333,
              "top": 207.33333,
              "width": 487.41666,
              "height": 41.583332
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[11] Hive user group presentation from Netflix. http://slideshare.net/slideshow/embed_code/3483386 .",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/beaa0020-5655-42f5-9625-ed49b3b7e96f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=6baa54b9889377b97d69ad638bbe8d2bbd973333f63e8d8148aeb072553b42f9",
            "html": "<ul><li>[11] Hive user group presentation from Netflix. http://slideshare.net/slideshow/embed_code/3483386 .</li></ul>",
            "markdown": "- [11] Hive user group presentation from Netflix. http://slideshare.net/slideshow/embed_code/3483386 .\n\n"
          },
          {
            "segment_id": "405b047a-9c9d-47d7-9ce9-bb0c12ae9013",
            "bbox": {
              "left": 657.3333,
              "top": 251.08333,
              "width": 495.74997,
              "height": 62.416664
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[12] S. Idreos, I. Alagiannis, R. Johnson, and A. Ailamaki. Here are my Data Files. Here are my Queries. Where are my Results? In CIDR , pages 57–68, 2011.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/405b047a-9c9d-47d7-9ce9-bb0c12ae9013.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=01d3ba6aaeaf17a0e6a9565279094f08ab1a139fbd417cfe2e860d317a1f1521",
            "html": "<ul><li>[12] S. Idreos, I. Alagiannis, R. Johnson, and A. Ailamaki. Here are my Data Files. Here are my Queries. Where are my Results? In CIDR , pages 57–68, 2011.</li></ul>",
            "markdown": "- [12] S. Idreos, I. Alagiannis, R. Johnson, and A. Ailamaki. Here are my Data Files. Here are my Queries. Where are my Results? In CIDR , pages 57–68, 2011.\n\n"
          },
          {
            "segment_id": "7bbaab16-2985-41b4-814f-d4a1f102e544",
            "bbox": {
              "left": 657.3333,
              "top": 319.8333,
              "width": 489.49997,
              "height": 39.5
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[13] S. Idreos, M. L. Kersten, and S. Manegold. Database Cracking. In CIDR , pages 68–78, 2007.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/7bbaab16-2985-41b4-814f-d4a1f102e544.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8aa271409eb7879dbbff48ca3f476a885fa3f1504abce673523ce22cd563d82d",
            "html": "<ul><li>[13] S. Idreos, M. L. Kersten, and S. Manegold. Database Cracking. In CIDR , pages 68–78, 2007.</li></ul>",
            "markdown": "- [13] S. Idreos, M. L. Kersten, and S. Manegold. Database Cracking. In CIDR , pages 68–78, 2007.\n\n"
          },
          {
            "segment_id": "3f58b818-113c-4d87-b91b-bb72cf403170",
            "bbox": {
              "left": 659.4166,
              "top": 365.66666,
              "width": 458.24997,
              "height": 83.25
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[14] S. Idreos, S. Manegold, H. Kuno, and G. Graefe. Merging what’s cracked, cracking what’s merged: adaptive indexing in main-memory column-stores. PVLDB , 4(9):586–597, 2011.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/3f58b818-113c-4d87-b91b-bb72cf403170.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a74b95f8f1c4f4882cbb013c16f95c5b70509601d55c1fcc47d046c46d3deb9a",
            "html": "<ul><li>[14] S. Idreos, S. Manegold, H. Kuno, and G. Graefe. Merging what’s cracked, cracking what’s merged: adaptive indexing in main-memory column-stores. PVLDB , 4(9):586–597, 2011.</li></ul>",
            "markdown": "- [14] S. Idreos, S. Manegold, H. Kuno, and G. Graefe. Merging what’s cracked, cracking what’s merged: adaptive indexing in main-memory column-stores. PVLDB , 4(9):586–597, 2011.\n\n"
          },
          {
            "segment_id": "2a546ea0-9193-4c61-b454-bd863eec4717",
            "bbox": {
              "left": 657.3333,
              "top": 455.24997,
              "width": 424.91666,
              "height": 39.5
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[15] Extending the worlds most popular processor architecture. Intel Whitepaper , 2006.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/2a546ea0-9193-4c61-b454-bd863eec4717.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=906ed3d560e1dca19217796c3a9d90328bd91c9af2de769cd4e304f9e9ee32a4",
            "html": "<ul><li>[15] Extending the worlds most popular processor architecture. Intel Whitepaper , 2006.</li></ul>",
            "markdown": "- [15] Extending the worlds most popular processor architecture. Intel Whitepaper , 2006.\n\n"
          },
          {
            "segment_id": "fca4d71d-ea00-444f-bc16-475766def4aa",
            "bbox": {
              "left": 659.4166,
              "top": 498.99997,
              "width": 470.74997,
              "height": 83.25
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[16] M. Ivanova, M. Kersten, and S. Manegold. Data Vaults: A Symbiosis between Database Technology and Scientific File Repositories. In SSDM , volume 7338 of LNCS , pages 485–494, 2012.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/fca4d71d-ea00-444f-bc16-475766def4aa.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d077beb65ab7599b22823b74eb04afb229584dfeac95729a11fbb1e55cfbf4b1",
            "html": "<ul><li>[16] M. Ivanova, M. Kersten, and S. Manegold. Data Vaults: A Symbiosis between Database Technology and Scientific File Repositories. In SSDM , volume 7338 of LNCS , pages 485–494, 2012.</li></ul>",
            "markdown": "- [16] M. Ivanova, M. Kersten, and S. Manegold. Data Vaults: A Symbiosis between Database Technology and Scientific File Repositories. In SSDM , volume 7338 of LNCS , pages 485–494, 2012.\n\n"
          },
          {
            "segment_id": "f676a530-a089-4598-8f55-652d75b97004",
            "bbox": {
              "left": 657.3333,
              "top": 588.5833,
              "width": 468.66666,
              "height": 39.5
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[17] R. Johnson and I. Pandis. The bionic DBMS is coming, but what will it look like? In CIDR , 2013.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/f676a530-a089-4598-8f55-652d75b97004.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a1fa76c37a4466d1ac22fab34b5d180ec11d1d6fc2e1f614062f6e9ba981c7a2",
            "html": "<ul><li>[17] R. Johnson and I. Pandis. The bionic DBMS is coming, but what will it look like? In CIDR , 2013.</li></ul>",
            "markdown": "- [17] R. Johnson and I. Pandis. The bionic DBMS is coming, but what will it look like? In CIDR , 2013.\n\n"
          },
          {
            "segment_id": "dc3c7151-db96-4748-a2f4-4e3887ae23b2",
            "bbox": {
              "left": 657.3333,
              "top": 634.4166,
              "width": 447.8333,
              "height": 83.25
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[18] R. Kallman, H. Kimura, J. Natkins, A. Pavlo, A. Rasin, et al. H-store: a high-performance, distributed main memory transaction processing system. PVLDB , 1(2):1496–1499, 2008.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/dc3c7151-db96-4748-a2f4-4e3887ae23b2.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=fded81cf11e6e98a3302370cafb5a31774399050744614033ea8a239342deb70",
            "html": "<ul><li>[18] R. Kallman, H. Kimura, J. Natkins, A. Pavlo, A. Rasin, et al. H-store: a high-performance, distributed main memory transaction processing system. PVLDB , 1(2):1496–1499, 2008.</li></ul>",
            "markdown": "- [18] R. Kallman, H. Kimura, J. Natkins, A. Pavlo, A. Rasin, et al. H-store: a high-performance, distributed main memory transaction processing system. PVLDB , 1(2):1496–1499, 2008.\n\n"
          },
          {
            "segment_id": "03acb5fb-d2fb-4138-b75a-a0d0ca1b84ae",
            "bbox": {
              "left": 657.3333,
              "top": 724,
              "width": 485.3333,
              "height": 83.25
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[19] A. Kemper and T. Neumann. HyPer: A hybrid OLTP&OLAP main memory database system based on virtual memory snapshots. In ICDE , pages 195–206, 2011.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/03acb5fb-d2fb-4138-b75a-a0d0ca1b84ae.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=675040b3237bb60886e72ec62466e57ce274bed8bc6c216591851edbc4a7d82c",
            "html": "<ul><li>[19] A. Kemper and T. Neumann. HyPer: A hybrid OLTP&OLAP main memory database system based on virtual memory snapshots. In ICDE , pages 195–206, 2011.</li></ul>",
            "markdown": "- [19] A. Kemper and T. Neumann. HyPer: A hybrid OLTP&OLAP main memory database system based on virtual memory snapshots. In ICDE , pages 195–206, 2011.\n\n"
          },
          {
            "segment_id": "2ed18bb1-13db-493d-a09b-4baf824b267b",
            "bbox": {
              "left": 657.3333,
              "top": 813.5833,
              "width": 489.49997,
              "height": 62.416664
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[20] V. Leis, A. Kemper, and T. Neumann. The Adaptive Radix Tree: ARTful Indexing for Main-Memory Databases. In ICDE , pages 38–49, 2013.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/2ed18bb1-13db-493d-a09b-4baf824b267b.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5ec5c24a606bf37778d0d95b2190ee4f9ab93b3da000d0a682125c6e9b96fc57",
            "html": "<ul><li>[20] V. Leis, A. Kemper, and T. Neumann. The Adaptive Radix Tree: ARTful Indexing for Main-Memory Databases. In ICDE , pages 38–49, 2013.</li></ul>",
            "markdown": "- [20] V. Leis, A. Kemper, and T. Neumann. The Adaptive Radix Tree: ARTful Indexing for Main-Memory Databases. In ICDE , pages 38–49, 2013.\n\n"
          },
          {
            "segment_id": "d318e6c3-213c-4f97-b47c-fe02f3f2190a",
            "bbox": {
              "left": 659.4166,
              "top": 880.24994,
              "width": 501.99997,
              "height": 62.416664
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[21] G. Moerkotte. Small Materialized Aggregates: A Light Weight Index Structure for Data Warehousing. VLDB , pages 476–487, 1998.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/d318e6c3-213c-4f97-b47c-fe02f3f2190a.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=bdc30452ad07b87048462cfca0466a956636ac3c121ba97e513374dc1da33d2c",
            "html": "<ul><li>[21] G. Moerkotte. Small Materialized Aggregates: A Light Weight Index Structure for Data Warehousing. VLDB , pages 476–487, 1998.</li></ul>",
            "markdown": "- [21] G. Moerkotte. Small Materialized Aggregates: A Light Weight Index Structure for Data Warehousing. VLDB , pages 476–487, 1998.\n\n"
          },
          {
            "segment_id": "688c47a5-9a0d-40ad-8632-58db50e358e7",
            "bbox": {
              "left": 659.4166,
              "top": 948.99994,
              "width": 470.74997,
              "height": 60.333332
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[22] T. Neumann. Efficiently compiling efficient query plans for modern hardware. PVLDB , 4(9):539–550, 2011.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/688c47a5-9a0d-40ad-8632-58db50e358e7.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=4f82dfe46eb2dd684bf1a903acd8f9c3e3b074a3cc5db252937a69958db79418",
            "html": "<ul><li>[22] T. Neumann. Efficiently compiling efficient query plans for modern hardware. PVLDB , 4(9):539–550, 2011.</li></ul>",
            "markdown": "- [22] T. Neumann. Efficiently compiling efficient query plans for modern hardware. PVLDB , 4(9):539–550, 2011.\n\n"
          },
          {
            "segment_id": "d4f764a7-f04a-47eb-b9c6-5434e3afb1a7",
            "bbox": {
              "left": 657.3333,
              "top": 1015.6666,
              "width": 468.66666,
              "height": 83.25
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[23] A. Pavlo, E. Paulson, A. Rasin, D. J. Abadi, D. J. DeWitt, et al. A Comparison of Approaches to Large-Scale Data Analysis. In SIGMOD , pages 165–178, 2009.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/d4f764a7-f04a-47eb-b9c6-5434e3afb1a7.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=407f5e0cba910265c8c72792f6673b05f84d6473826e00e8dc7f7a279648912c",
            "html": "<ul><li>[23] A. Pavlo, E. Paulson, A. Rasin, D. J. Abadi, D. J. DeWitt, et al. A Comparison of Approaches to Large-Scale Data Analysis. In SIGMOD , pages 165–178, 2009.</li></ul>",
            "markdown": "- [23] A. Pavlo, E. Paulson, A. Rasin, D. J. Abadi, D. J. DeWitt, et al. A Comparison of Approaches to Large-Scale Data Analysis. In SIGMOD , pages 165–178, 2009.\n\n"
          }
        ],
        "chunk_length": 507
      },
      {
        "segments": [
          {
            "segment_id": "e0ee31bd-f14e-49e1-a6c6-f7ccd614f21b",
            "bbox": {
              "left": 657.3333,
              "top": 1105.25,
              "width": 489.49997,
              "height": 41.583332
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[24] J. Reinders. Intel threading building blocks: outfitting C++ for multi-core processor parallelism . 2007.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/e0ee31bd-f14e-49e1-a6c6-f7ccd614f21b.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a63415996ffdf8e4ceadc57d8a70e9de37389cfa240353a16607d3e107238811",
            "html": "<ul><li>[24] J. Reinders. Intel threading building blocks: outfitting C++ for multi-core processor parallelism . 2007.</li></ul>",
            "markdown": "- [24] J. Reinders. Intel threading building blocks: outfitting C++ for multi-core processor parallelism . 2007.\n\n"
          },
          {
            "segment_id": "192205eb-2e6d-4440-8ed1-c9efe24148a0",
            "bbox": {
              "left": 657.3333,
              "top": 1151.0833,
              "width": 501.99997,
              "height": 18.666666
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[25] E. Sedlar. Oracle Labs. Personal comm. May 29, 2013.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/192205eb-2e6d-4440-8ed1-c9efe24148a0.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=afdd6b307d5fd4ace93570e86dce986dc105b44cd3e297c098c6c102f255fd4b",
            "html": "<ul><li>[25] E. Sedlar. Oracle Labs. Personal comm. May 29, 2013.</li></ul>",
            "markdown": "- [25] E. Sedlar. Oracle Labs. Personal comm. May 29, 2013.\n\n"
          },
          {
            "segment_id": "4cfa3b78-2c56-4c34-9457-a8ef15b0a053",
            "bbox": {
              "left": 657.3333,
              "top": 1176.0833,
              "width": 437.41666,
              "height": 16.583332
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[26] A. Szalay. JHU. Personal comm. May 16, 2013.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/4cfa3b78-2c56-4c34-9457-a8ef15b0a053.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0f5340ace4220fc028d8e71e08dddfec316d37912e1d58b814cb5a5e671148d6",
            "html": "<ul><li>[26] A. Szalay. JHU. Personal comm. May 16, 2013.</li></ul>",
            "markdown": "- [26] A. Szalay. JHU. Personal comm. May 16, 2013.\n\n"
          },
          {
            "segment_id": "0f91b8c4-93c0-4a7b-ba9d-b5ccb6972f14",
            "bbox": {
              "left": 657.3333,
              "top": 1199,
              "width": 485.3333,
              "height": 41.583332
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[27] A. Szalay, A. R. Thakar, and J. Gray. The sqlLoader Data-Loading Pipeline. JCSE , 10:38–48, 2008.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/0f91b8c4-93c0-4a7b-ba9d-b5ccb6972f14.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=59ecbd9e862ee15f84773a5f674954f53ca0ad10c47bd7f4b66f82be788133e0",
            "html": "<ul><li>[27] A. Szalay, A. R. Thakar, and J. Gray. The sqlLoader Data-Loading Pipeline. JCSE , 10:38–48, 2008.</li></ul>",
            "markdown": "- [27] A. Szalay, A. R. Thakar, and J. Gray. The sqlLoader Data-Loading Pipeline. JCSE , 10:38–48, 2008.\n\n"
          },
          {
            "segment_id": "0da45a47-3d76-48f1-aec8-1c3f72a6da29",
            "bbox": {
              "left": 657.3333,
              "top": 1244.8333,
              "width": 499.91666,
              "height": 62.416664
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[28] A. Thusoo, J. S. Sarma, N. Jain, Z. Shao, P. Chakka, et al. Hive: A warehousing solution over a map-reduce framework. PVLDB , 2(2):1626–1629, 2009.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/0da45a47-3d76-48f1-aec8-1c3f72a6da29.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=42052b7b7a907357add9034e8f7b72eafef25e3793feab37af5c8a6787b346cb",
            "html": "<ul><li>[28] A. Thusoo, J. S. Sarma, N. Jain, Z. Shao, P. Chakka, et al. Hive: A warehousing solution over a map-reduce framework. PVLDB , 2(2):1626–1629, 2009.</li></ul>",
            "markdown": "- [28] A. Thusoo, J. S. Sarma, N. Jain, Z. Shao, P. Chakka, et al. Hive: A warehousing solution over a map-reduce framework. PVLDB , 2(2):1626–1629, 2009.\n\n"
          },
          {
            "segment_id": "5292ee31-58d7-4298-a212-df531fcd49c5",
            "bbox": {
              "left": 659.4166,
              "top": 1311.5,
              "width": 472.8333,
              "height": 83.25
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[29] T. Willhalm, N. Popovici, Y. Boshmaf, H. Plattner, A. Zeier, et al. SIMD-Scan: Ultra Fast in-Memory Table Scan using on-Chip Vector Processing Units. PVLDB , 2(1):385–394, 2009.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/5292ee31-58d7-4298-a212-df531fcd49c5.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=1c6859b7fd03f79dfe0bcde0873f2234a2d4ba8cc6dc0bda0a59f1bb60baedf4",
            "html": "<ul><li>[29] T. Willhalm, N. Popovici, Y. Boshmaf, H. Plattner, A. Zeier, et al. SIMD-Scan: Ultra Fast in-Memory Table Scan using on-Chip Vector Processing Units. PVLDB , 2(1):385–394, 2009.</li></ul>",
            "markdown": "- [29] T. Willhalm, N. Popovici, Y. Boshmaf, H. Plattner, A. Zeier, et al. SIMD-Scan: Ultra Fast in-Memory Table Scan using on-Chip Vector Processing Units. PVLDB , 2(1):385–394, 2009.\n\n"
          },
          {
            "segment_id": "becc6af1-8a00-4091-a24d-ead2b5224b13",
            "bbox": {
              "left": 657.3333,
              "top": 1401.0833,
              "width": 379.0833,
              "height": 18.666666
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[30] Y. Shafranovich. IETF RFC 4180, 2005.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/becc6af1-8a00-4091-a24d-ead2b5224b13.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=ce14683b7d6e0f60685d8dd720728665a6c251cb7640c101413f8de93bd1839e",
            "html": "<ul><li>[30] Y. Shafranovich. IETF RFC 4180, 2005.</li></ul>",
            "markdown": "- [30] Y. Shafranovich. IETF RFC 4180, 2005.\n\n"
          },
          {
            "segment_id": "f4e8fa91-d5e7-4a59-9140-ca5bd20430ad",
            "bbox": {
              "left": 657.3333,
              "top": 1424,
              "width": 458.24997,
              "height": 62.416664
            },
            "page_number": 12,
            "page_width": 1275,
            "page_height": 1650,
            "content": "[31] J. Zhou and K. A. Ross. Implementing database operations using SIMD instructions. In SIGMOD , pages 145–156, 2002.",
            "segment_type": "List item",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/1f24fd9e-4896-4b1e-bb60-da91b8518cb8/images/f4e8fa91-d5e7-4a59-9140-ca5bd20430ad.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T035051Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=7c2fc20b82375c9d5ffa386bb6863e83c1d99f1498f127a48b4f0a9bc12d968b",
            "html": "<ul><li>[31] J. Zhou and K. A. Ross. Implementing database operations using SIMD instructions. In SIGMOD , pages 145–156, 2002.</li></ul>",
            "markdown": "- [31] J. Zhou and K. A. Ross. Implementing database operations using SIMD instructions. In SIGMOD , pages 145–156, 2002.\n\n"
          }
        ],
        "chunk_length": 131
      }
    ],
    "extracted_json": {
      "title": "Document Metadata",
      "schema_type": "object",
      "extracted_fields": [
        {
          "name": "title",
          "field_type": "string",
          "value": "Instant Loading for Main Memory Databases\n"
        },
        {
          "name": "author",
          "field_type": "string",
          "value": "Tilmann Rabl, Volker Markl\n"
        },
        {
          "name": "date_published",
          "field_type": "string",
          "value": "2013\n"
        },
        {
          "name": "location",
          "field_type": "string",
          "value": "Riva del Garda, Trento, Italy\nMunich, Germany\n"
        }
      ]
    }
  }
}