{
  "file_name": "Lightweight Contention Management for Efficient Compare-and-Swap Operations.pdf",
  "task_id": "187a3f88-57ca-45ce-9b5a-ee349f9dff13",
  "output": {
    "chunks": [
      {
        "segments": [
          {
            "segment_id": "795e7646-0ecf-4f1c-b2ab-5231ea45b63e",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 1,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "Lightweight Contention Management for\r\nEfficient Compare-and-Swap Operations\r\nDave Dice\r\n1\r\n, Danny Hendler\r\n2 and Ilya Mirsky2\r\n1 Sun Labs at Oracle\r\n2 Ben-Gurion University of the Negev\r\nAbstract. Many concurrent data-structure implementations – both\r\nblocking and non-blocking – use the well-known compare-and-swap\r\n(CAS) operation, supported in hardware by most modern multiprocessor\r\narchitectures for inter-thread synchronization.\r\nA key weakness of the CAS operation is its performance in the pres\u0002ence of memory contention. When multiple threads concurrently attempt\r\nto apply CAS operations to the same shared variable, at most a single\r\nthread will succeed in changing the shared variable’s value and the CAS\r\noperations of all other threads will fail. Moreover, significant degrada\u0002tion in performance occurs when variables manipulated by CAS become\r\ncontention “hot spots”, since failed CAS operations congest the inter\u0002connect and memory devices and slow down successful CAS operations.\r\nIn this work we study the following question: can software-based\r\ncontention management improve the efficiency of hardware-provided CAS\r\noperations? In other words, can a software contention management layer,\r\nencapsulating invocations of hardware CAS instructions, improve the\r\nperformance of CAS-based concurrent data-structures?\r\nTo address this question, we conduct what is, to the best of our\r\nknowledge, the first study on the impact of contention management algo\u0002rithms on the efficiency of the CAS operation.\r\nWe implemented several Java classes, which extend Java’s Atomic\u0002Reference class, that encapsulate calls to native CAS with simple conten\u0002tion management mechanisms tuned for different hardwares. A key prop\u0002erty of our algorithms is the support for an almost-transparent inter\u0002change with Java’s AtomicReference objects, used in implementations of\r\nconcurrent data structures. We then evaluate the impact of these algo\u0002rithms on both a synthetic micro-benchmark and on CAS-based concur\u0002rent implementations of widely-used data-structures such as stacks and\r\nqueues.\r\nOur performance evaluation establishes that lightweight contention\r\nmanagement support can greatly improve performance under medium\r\nand high contention levels while typically incurring only small over\u0002head when contention is low. In some cases, applying efficient conten\u0002tion management for CAS operations used by a simpler data-structure\r\nimplementation yields better performance than highly optimized imple\u0002mentations of that data-structure that use native CAS operations di\u0002rectly.\r\nKeywords: Compare-and-swap, contention management, concurrent\r\nalgorithms.\r\narXiv:1305.5800v1 [cs.DC] 24 May 2013",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/795e7646-0ecf-4f1c-b2ab-5231ea45b63e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2d08f472d161967cd09ecb5e1f0c8b7e9ff2f966be20581261ed81ac099a7c62",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 359
      },
      {
        "segments": [
          {
            "segment_id": "9176fa4b-8766-449c-adfe-33ba26b80ec8",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 2,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "1 Introduction\r\nMany key problems in shared-memory multiprocessors revolve around the coor\u0002dination of access to shared resources and can be captured as concurrent data\r\nstructures [3,17]: abstract data structures that are concurrently accessed by asyn\u0002chronous threads. Efficient concurrent data structure algorithms are key to the\r\nscalability of applications on multiprocessor machines. Devising efficient and\r\nscalable concurrent algorithms for widely-used data structures such as counters\r\n(e.g., [15,19]), queues (e.g.,[1,7,8,11,12,22,23,25,28], stacks (e.g.,[7,11,13]), pools\r\n(e.g.,[2,4,9]) and hash tables (e.g., [10,18,31,32]), to name a few, is the focus of\r\nintense research.\r\nModern multiprocessors provide hardware support of atomic read-modify\u0002write operations in order to facilitate inter-thread coordination and synchroni\u0002zation. The compare-and-swap (CAS) operation has become the synchronization\r\nprimitive of choice for implementing concurrent data structures - both lock-based\r\nand nonblocking [20] - and is supported by hardware in most contemporary mul\u0002tiprocessor architectures [6,27,29]. The CAS operation takes three arguments: a\r\nmemory address3\r\n, an old value, and a new value. If the address stores the old\r\nvalue, it is replaced with the new value; otherwise it is unchanged. The success\r\nor failure of the operation is then reported back to the calling thread. CAS is\r\nwidely available and used since its atomic semantics allow threads to read a\r\nshared variable, compute a new value which is a function of the value read, and\r\nwrite the new value back only if the shared variable was not changed in the\r\ninterim by other, concurrent, threads. As proven in Herlihy’s seminal paper [20],\r\nCAS can implement, together with reads and writes, any object in a wait-free\r\nmanner.\r\nA key weakness of the CAS operation, known to both researchers and practi\u0002tioners of concurrent programming, is its performance in the presence of memory\r\ncontention. When multiple threads concurrently attempt to apply CAS opera\u0002tions to the same shared variable, typically at most a single thread will succeed in\r\nchanging the shared variable’s value and the CAS operations of all other threads\r\nwill fail. Moreover, significant degradation in performance occurs when variables\r\nmanipulated by CAS become contention “hot spots”, since failed CAS opera\u0002tions congest the interconnect and memory devices and slow down successful\r\nCAS operations.\r\n1E+6\r\n0\r\n10\r\n20\r\n30\r\n40\r\n50\r\n60\r\n70\r\n80\r\n90\r\n10 20 30 40 50 60 70\r\nFig. 1: SPARC: Java’s CAS\r\nTo illustrate this weakness of the CAS op\u0002eration, Figure 1 shows the results of a simple\r\ntest, conducted on an UltraSPARC T2+ (Ni\u0002agara II) chip, comprising 8 cores, each multi\u0002plexing 8 hardware threads, in which a varying\r\nnumber of Java threads run for 5 seconds, re\u0002peatedly reading the same variable and then\r\n3\r\nIn managed programming languages such as Java, the memory address is encap\u0002sulated by the object on which the CAS operation is invoked and is therefore not\r\nexplicitly passed to the CAS operation.\r\n2",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/9176fa4b-8766-449c-adfe-33ba26b80ec8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=7a582480cb535d7ee04e0457eab7b236e075993a0fc18069eb17225cb4550bbc",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 462
      },
      {
        "segments": [
          {
            "segment_id": "632ffb15-c87b-46f2-9ed7-5de918febe0e",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 3,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "applying CAS operations attempting to change its value.4 The number of suc\u0002cessful CAS operations scales from 1 to 4 threads but then quickly deteriorates,\r\neventually falling to about 16% of the single thread performance, less than 9%\r\nof the performance of 4 threads. As we show in Section 3, similar performance\r\ndegradation occurs on Intel’s Xeon and i7 platforms.\r\nIn this work we study the following question: can software-based contention\r\nmanagement improve the efficiency of hardware-provided CAS operations? In\r\nother words, can a software contention management layer, encapsulating invoc\u0002ations of hardware CAS instructions, significantly improve the performance of\r\nCAS-based concurrent data-structures?\r\nTo address this question, we conduct what is, to the best of our knowledge,\r\nthe first study on the impact of contention management algorithms on the effi\u0002ciency of the CAS operation. We implemented several Java classes that extend\r\nJava’s AtomicReference class, and encapsulate calls to direct CAS by contention\r\nmanagement layer. This design allows for an almost transparent plugging of our\r\nclasses into existing data structures which make use of Java’s AtomicReference.\r\nWe then evaluated the impact of these algorithms on the Xeon, SPARC and i7\r\nplatforms by using both a synthetic micro-benchmark and CAS-based concurrent\r\ndata-structure implementations of stacks and queues.\r\nWe note that the lock-freedom and wait-freedom progress properties aren’t\r\naffected by our contention management algorithms since in all of them a thread\r\nonly waits for a bounded period of time.\r\nThe idea of employing contention management and backoff techniques to im\u0002prove performance was widely studied in the context of software transactional\r\nmemory (see, e.g., [16,30]) and lock implementations (see, e.g., [5,24]). Backoff\r\ntechniques are also used at the higher abstraction level of specific data struc\u0002ture implementations [13,14,26]. However, this approach adds complexity to the\r\ndesign of the data-structure and requires careful per-data structure tuning. Our\r\napproach, of adding contention management (and, specifically, backoff) mecha\u0002nisms at the CAS instruction level, provides a simple and generic solution, in\r\nwhich tuning can be done per architecture rather than per implementation.\r\nOur performance evaluation establishes that lightweight contention manage\u0002ment support can significantly improve the performance of concurrent data\u0002structure implementations as compared with direct use of Java’s Atomic\u0002Reference class. Our CAS contention management algorithms improve the\r\nthroughput of the concurrent data-structure implementations we experimented\r\nwith by a factor of up to 12 for medium and high contention levels, typically\r\nincurring only small overhead in low contention levels.\r\nWe also compared relatively simple data-structure implementations that use\r\nour CAS contention management classes with more complex implementations\r\nthat employ data-structure specific optimizations. We have found that, in some\r\ncases, applying efficient contention management at the level of CAS operations,\r\nused by simpler and non-optimized data-structure implementations, yields better\r\n4 We provide more details on this test in Section 3.\r\n3",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/632ffb15-c87b-46f2-9ed7-5de918febe0e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=554f2336087d734fe7ca99d8413d20278ff1ffcbe671c6aab69c73f12c82b906",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 457
      },
      {
        "segments": [
          {
            "segment_id": "5216fd16-772d-4e6f-b418-e14d8b9b1866",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 4,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "performance than that of highly optimized implementations of the same data\u0002structure that uses Java’s AtomicReference objects directly.\r\nOur results imply that encapsulating invocations of CAS by lightweight\r\ncontention management algorithms is a simple and generic way of significantly\r\nimproving the performance of concurrent objects.\r\nThe rest of this paper is organized as follows. We describe the contention\r\nmanagement algorithms we implemented in Section 2. We report on our experi\u0002mental evaluation in Section 3. We conclude the paper in Section 4 with a short\r\ndiscussion of our results.\r\n2 Contention Management Algorithms\r\nIn this section, we describe the Java CAS contention management algorithms\r\nthat we implemented and evaluated. These algorithms are implemented as classes\r\nthat extend the AtomicReference class of the java.util.concurrent.atomic pack\u0002age. Each instance of these classes operates on a specific location in memory and\r\nimplements the read and CAS methods.5\r\nIn some of our algorithms, threads need to access per-thread state associated\r\nwith the object. For example, a thread may keep record of the number of CAS\r\nfailures it incurred on the object in the past in order to determine how to proceed\r\nif it fails again. Such information is stored as an array of per-thread structures.\r\nTo access this information, threads call a registerThread method on the object\r\nto obtain an index of an array entry. This thread index is referred to as TInd in\r\nthe pseudo-code. After registering, a thread may call a deregisterThread method\r\non the object to indicate that it is no longer interested in accessing this object\r\nand that its entry in this object array may be allocated to another thread.6\r\nTechnically, a thread’s TInd index is stored as a thread local variable, using\r\nthe services of Java’s ThreadLocal class. The TInd index may be retrieved within\r\nthe CAS contention management method implementation. However, in some\r\ncases it might be more efficient to retrieve this index at a higher level (for\r\ninstance, when CAS is called in a loop until it is successful) and to pass it as an\r\nargument to the methods of the CAS contention management object.\r\n2.1 The ConstantBackoffCAS Algorithm\r\nAlgorithm 1 presents the ConstantBackoffCAS class, which employs the sim\u0002plest contention management algorithm that we implemented. No per-thread\r\nstate is required for this algorithm. The read operation simply delegates to the\r\nget method of the AtomicReference object to return the current value of the\r\nreference (line 2). The CAS operation invokes the compareAndSet method on the\r\nAtomicReference superclass, passing to it the old and new operands (line 4). The\r\n5 None of the methods of AtomicReference are overridden.\r\n6 An alternative design is to have a global registration/deregistration mechanism so\r\nthat the TInd index may be used by a thread for accessing several CAS contention\u0002management objects.\r\n4",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/5216fd16-772d-4e6f-b418-e14d8b9b1866.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e09050d51801b04bee5fc37883cf18ec91a684f2c6f63955c67ce533373e2e39",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 456
      },
      {
        "segments": [
          {
            "segment_id": "04002b53-cf36-44ca-a0da-abb6fefa88d6",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 5,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "Algorithm 1: ConstBackoffCAS\r\n1 public class ConstBackoffCAS<V> extends AtomicReference<V>\r\n2 public V read() { return get() }\r\n3 public boolean CAS(V old, V new)\r\n4 if ¬compareAndSet( old,new) then\r\n5 wait(WAITING TIME)\r\n6 return false\r\n7 else return true\r\nCAS operation returns true in line 7 if the native CAS succeeded. If the native\r\nCAS failed, then the thread busy-waits for a platform-dependent period of time,\r\nafter which the CAS operation returns (lines 5–6).\r\n2.2 The TimeSliceCAS Algorithm\r\nAlgorithm 2 presents the TimeSliceCAS class, which implements a time-division\r\ncontention-management algorithm that, under high contention, assigns different\r\ntime-slices to different threads. Each instance of the class has access to a field\r\nregN which stores the number of threads that are currently registered at the\r\nobject.\r\nThe read operation simply delegates to the get method of the Atomic\u0002Reference class (line 9). The CAS operation invokes the compareAndSet method\r\non the AtomicReference superclass (line 11). If the CAS is successful, the method\r\nreturns true (line 12).\r\nIf the CAS fails and the number of registered threads exceeds a platform\u0002dependent level CONC (line 13), then the algorithm attempts to limit the level\r\nof concurrency (that is, the number of threads concurrently attempting CAS on\r\nthe object) at any given time to at most CONC. This is done as follows. The\r\nthread picks a random integer slice number in {1, . . . , dregN/CONCe} (line 14).\r\nThe length of each time-slice is set to 2SLICE nanoseconds, where SLICE is a\r\nplatform-dependent integer. The thread waits until its next time-slice starts and\r\nthen returns false (lines 15–18).\r\n2.3 The ExpBackoffCAS Algorithm\r\nAlgorithm 3 presents the ExpBackoffCAS class, which implements an exponen\u0002tial backoff contention management algorithm. Each instance of this class has a\r\nfailures array, each entry of which – initialized to 0 – stores simple per-registered\r\nthread statistics about the history of successes and failures of past CAS oper\u0002ations to this object (line 20). The read operation simply delegates to the get\r\nmethod of the AtomicReference class (line 21).\r\nThe CAS operation invokes the compareAndSet method on the Atomic\u0002Reference superclass (line 23). If the CAS is successful, then the CAS operation\r\nreturns true (line 26).\r\nIf the CAS fails, then the thread’s entry in the failures array is incremented\r\nand if its value f is larger than a platform-dependent threshold, the thread waits\r\n5",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/04002b53-cf36-44ca-a0da-abb6fefa88d6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f92bbf0b33d363482b799af9dd92ac18d9238e16c0761e807861a4db04df432c",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 389
      },
      {
        "segments": [
          {
            "segment_id": "090890e3-b2e7-4f9b-86dd-98c61700acd4",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 6,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "Algorithm 2: TimeSliceCAS\r\n8 public class TimeSliceCAS<V>\r\nextends AtomicReference<V>\r\n9 public V read() { return get() }\r\n10 public boolean CAS(V old, V new)\r\n11 if compareAndSet(old,new) then\r\n12 return true\r\n13 if regN > CONC then\r\n14 int sliceNum =\r\nRandom.nextInt(dregN/CONCe)\r\n15 repeat\r\n16 currentSlice =\r\n(System.nanoTime() >>\r\nSLICE) % dregN/CONCe\r\n17 until sliceNum = currentSlice\r\n18 return false\r\nAlgorithm 3: ExpBackoffCAS\r\n19 public class ExpBackoffCAS<V>\r\nextends AtomicReference<V>\r\n20 private int[] failures = new int\r\n[MAX THREADS]\r\n21 public V read() { return get() }\r\n22 public boolean CAS(V old, V new)\r\n23 if compareAndSet(old,new) then\r\n24 if failures[TInd] > 0 then\r\n25 failures[TInd]−−\r\n26 return true\r\n27 else\r\n28 int f = failures[TInd]++\r\n29 if f > EXP THRESHOLD then\r\n30 wait(2min(c·f,m))\r\n31 return false\r\nfor a period of time proportional to 2min(c·f,m) where c and m are platform\u0002dependent integer algorithm parameters (lines 28–29).\r\n2.4 The MCS-CAS Algorithm\r\nWith the MCS-CAS algorithm, threads may apply their operations in either\r\nlow-contention mode or high-contention mode. Initially, a thread starts oper\u0002ating in low-contention mode, in which it essentially delegates read and CAS\r\noperations to the respective methods of the AtomicReference class. When a\r\nthread incurs CONTENTION THRESHOLD (a platform-dependent constant)\r\nconsecutive CAS failures on a specific memory location, it reverts to operating\r\nin high-contention mode when accessing this location.\r\nIn high-contention mode, threads that apply CAS operations to the same\r\nmemory location attempt to serialize their operations by forming a queue deter\u0002mining the order in which their read and CAS operations-pairs will be performed.\r\nThreads wait for a bounded period of time within their read operation and pro\u0002ceed to perform the read (and later on the CAS) once the thread that precedes\r\nthem in the queue (if any) completes its CAS operation.\r\nMCS-CAS implements a variation of the Mellor-Crummey and Scott (MCS)\r\nlock algorithm [24]. Since we would like to maintain the nonblocking semantics of\r\nthe CAS operation, a thread t awaits its queue predecessor (if any) for at most\r\na platform-dependent period of time. If this waiting time expires, t proceeds\r\nwith the read operation without further waiting. If all threads operate in high\u0002contention mode w.r.t. memory location m (and assuming the waiting-time is\r\nsufficiently long), then all CAS operations to m will succeed, since each thread\r\nmay read m and later apply its CAS to m without interruption. In practice,\r\nhowever, threads may apply operations to m concurrently in both low- and\r\nhigh-contention modes and failures may result. After successfully performing\r\na platform-dependent number of CAS operations in high-contention mode, a\r\nthread reverts to operating in low-contention mode.\r\n6",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/090890e3-b2e7-4f9b-86dd-98c61700acd4.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=6efa6971f3c0e49c078a733c57c1bf696701bd7164ca0f45125521e6392b3da3",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 431
      },
      {
        "segments": [
          {
            "segment_id": "c5c95506-2697-48c7-8d59-e160bb07ab91",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 7,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "If a thread needs to apply a read that is not followed by a CAS, then it\r\nmay directly apply the get method of the AtomicReference super-class as this\r\nmethod is not overridden by the MCS-CAS class. There may be situations,\r\nhowever, in which it is not known in advance whether a read will be followed\r\nby a CAS and this depends on the value returned by the read. Such scenarios\r\nwill not compromise the correctness and non-blocking progress of MCS-CAS,\r\nbut may have adverse effect on performance. This comment applies also to the\r\nArrayBased algorithm described in Section 2.5. The full pseudo-code of the MCS\r\nalgorithm and its description is provided in appendix A.\r\n2.5 The ArrayBasedCAS Algorithm\r\nThe ArrayBased algorithm uses an array-based signalling mechanism, in which a\r\nlock owner searches for the next entry in the array on which a thread is waiting\r\nfor permission to proceed with its load-CAS operations in order to signal it. Also\r\nin this algorithm, waiting-times are bounded.\r\nThere are two key differences between how MCS-CAS and ArrayBasedCAS\r\nattempt to serialize read and CAS operations-pairs to a memory location under\r\nhigh contention. First, whereas in MCS-CAS a thread signals its successor after\r\ncompleting a single read/CAS operations-pair, with array based a thread per\u0002forms a multiple, platform-dependent, number of such operations-pairs before\r\nsignaling other waiting threads.\r\nA second difference is that whereas MCS-CAS forms a dynamic queue in\r\nwhich a thread signals its successor, with array based a thread t that completes\r\nits CAS scans the threads records array starting from t’s entry for finding a wait\u0002ing thread to be signaled. This implies that every waiting thread will eventually\r\nreceive the opportunity to attempt its read/CAS operations-pair.\r\nSince array based does not use a dynamic waiting queue, threads may enter\r\nwaiting mode and be signaled without having to perform a successful CAS on\r\nany of the ArrayBasedCAS data-structures. This is in contrast to MCS-CAS,\r\nwhere a thread must apply a successful CAS to the tail variable for joining the\r\nwaiting queue.\r\nSimilarly to MCS-CAS, a thread t waits to be signaled for at most a platform\u0002dependent period of time. If this waiting time expires, t proceeds with its read\r\noperation without further waiting. This ensures that array based is nonblocking.\r\nThe full pseudo-code of the array-based algorithm and its description appears\r\nin Appendix B.\r\n3 Evaluation\r\nWe conducted our performance evaluation on the SPARC and on Intel’s Xeon\r\nand i7 multi-core CPUs. The SPARC machine comprises an UltraSPARC T2+\r\n(Niagara II) chip containing 8 cores, each core multiplexing 8 hardware threads,\r\nfor a total of 64 hardware threads. It runs the 64-bit Solaris 10 operating system\r\nwith Java SE 1.6.0 update 23. The Xeon machine comprises a Xeon E7-4870 chip,\r\n7",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/c5c95506-2697-48c7-8d59-e160bb07ab91.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=3a7b73cd10edd50d2b38f44269f10e06589380d80be4f32f308c01d315fbf4c9",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 458
      },
      {
        "segments": [
          {
            "segment_id": "fcd167cc-35a9-4b43-a2a4-11445492f879",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 8,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "containing 10 cores and hyper-threaded to 20 hardware threads. The i7 machine\r\nhas an i7-920 CPU comprising 4 cores each supporting 2 hardware threads, for\r\na total of 8 hardware threads. Both Intel machines run the 64-bit Linux 3.2.1\r\nkernel with Java SE 1.6.0 update 25. All tests were conducted with HotSpot in\r\n64-bit server mode.\r\nInitially we evaluated our CAS contention management algorithms using\r\na synthetic micro-benchmark and used the results to optimize the platform\u0002dependent parameters used by the algorithms. We then evaluated the impact\r\nof our algorithms on implementations of widely-used data structures such as\r\nqueues and stacks. No explicit threads placement was used.\r\n3.1 The CAS micro-benchmark\r\nTo tune and compare our CAS contention management algorithms, we used the\r\nfollowing synthetic CAS benchmark. For every concurrency level k, varying from\r\n1 to the maximum number of supported hardware threads, k threads repeatedly\r\nread the same atomic reference and attempt to CAS its value, for a period of 5\r\nseconds. Before the test begins, each thread generates an array of 128 objects and\r\nduring the test it attempts to CAS the value of the shared object to a reference\r\nto one of these objects, in a round-robin manner. In the course of the test, each\r\nthread counts the number of successful CAS operations and these local counters\r\nare summed up at the end of the test.\r\nUsing the CAS benchmark, we’ve tuned the parameters used by the algo\u0002rithms described in Section 2. The values that were chosen as optimal were\r\nthose that produced the highest average throughput of all concurrency levels.\r\nThese values appear in Table 1.\r\n7 Figures 2a-3b show the results of the CAS syn\u0002thetic benchmarks on the three platforms on which we conducted our tests using\r\nthese optimal parameter values. Each data point is the average of 10 independent\r\nexecutions.\r\nXeon results :\r\nFigure 2a shows the throughput (the number of successful CAS operations)\r\non the Xeon machine as a function of the concurrency level. It can be seen\r\nthat the throughput of Java CAS falls steeply for concurrency levels of 2 or\r\nmore. Whereas a single thread performs approximately 413M successful CAS\r\noperations in the course of the test, the number of successful CAS operations\r\nis only approximately 89M for 2 threads and 62M for 4 threads. For higher\r\nconcurrency levels, the number of successes remains in the range of 50M-59M\r\noperations.\r\nIn sharp contrast, both the constant wait and exponential backoff CAS algo\u0002rithms are able to maintain high throughput across the concurrency range. Ex\u0002ponential backoff is slightly better up until 16 threads, but then its throughput\r\n7 The values of the WAITING TIME and MAX WAIT parameters are expressed in\r\nmilliseconds. Waiting is done by performing a corresponding number of loop itera\u0002tions.\r\n8",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/fcd167cc-35a9-4b43-a2a4-11445492f879.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0d7675db9169ead9d7626ec8b4919cc83804ed1d66402641044517428af4cf33",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 460
      },
      {
        "segments": [
          {
            "segment_id": "05690f0f-cdbb-44a1-add9-3ad0345b9dea",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 9,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "Table 1: Summary of tuned algorithm parameters.\r\nXeon i7 Sparc\r\nCB-CAS WAITING TIME=0.13ms WAITING TIME=0.8ms WAITING TIME=0.2ms\r\nEXP THRESHOLD=2 EXP THRESHOLD=2 EXP THRESHOLD=1\r\nEXP-CAS c = 8 c = 9 c = 1\r\nm = 24 m = 27 m = 15\r\nCONTENTION THRESHOLD=8 CONTENTION THRESHOLD=8 CONTENTION THRESHOLD=14\r\nMCS-CAS NUM OPS = 10,000 NUM OPS = 10,000 NUM OPS = 10\r\nMAX WAIT = 0.9ms MAX WAIT = 7.5ms MAX WAIT = 1ms\r\nCONTENTION THRESHOLD=2 CONTENTION THRESHOLD=2 CONTENTION THRESHOLD=14\r\nAB-CAS NUM OPS = 10,000 NUM OPS = 100,000 NUM OPS = 100\r\nMAX WAIT = 0.9ms MAX WAIT = 7.5ms MAX WAIT = 1ms\r\nCONC = 1 CONC = 1 CONC = 10\r\nTS-CAS SLICE = 20 SLICE = 25 SLICE = 6\r\n1E+6\r\n0\r\n50\r\n100\r\n150\r\n200\r\n250\r\n300\r\n350\r\n400\r\n450\r\n2 4 6 8 10 12 14 16 18 20\r\n(a) Xeon: Successes\r\n1E+6\r\n0\r\n10\r\n20\r\n30\r\n40\r\n50\r\n60\r\n70\r\n80\r\n2 4 6 8 10 12 14 16 18 20\r\n(b) Xeon: Failures\r\n1E+6\r\n50\r\n100\r\n150\r\n200\r\n250\r\n300\r\n350\r\n400\r\n450\r\n500\r\n1 2 3 4 5 6 7 8\r\n(c) i7: Successes\r\nJava\r\nConstBackoff\r\nExpBackoff\r\nMCS\r\nArrayBased\r\nTimeSlice\r\nFig. 2: Xeon & i7 CAS: Number of successful and failed CAS operations as a function\r\nof concurrency level.\r\ndeclines to below 350M and falls below constant backoff. The throughput of\r\nboth these algorithms exceeds that of Java CAS by a factor of more than 4 for 2\r\nthreads and their performance boost grows to a factor of between 6-7 for higher\r\nconcurrency levels.\r\nThe time slice algorithm is the 3’rd performer in this test, outperforming\r\nJava CAS by a factor of between 3-5.6 but providing only between 65%-87% the\r\nthroughput of constant and exponential backoff.\r\n9",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/05690f0f-cdbb-44a1-add9-3ad0345b9dea.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=cfac0cd3fe4518bb992af9b110a2b270dea75609ce53b6932617db1a10ca9346",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 295
      },
      {
        "segments": [
          {
            "segment_id": "eb392840-b76a-4d0e-985a-68488bb01db8",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 10,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "The array based algorithm incurs some overhead and performs only approxi\u0002mately 390M successful operations in the single thread tests. In higher conc\u0002urrency levels, its throughput exceeds that of Java CAS by a factor of between\r\n2.5-3 but it is consistently outperformed by the simpler backoff algorithms by\r\na wide margin. MCS-CAS is the worst performer on the Xeon CAS benchmark\r\nand is outperformed by all other algorithms across the concurrency range.\r\nMore insights into these results are provided by Figure 2b, which shows the\r\nnumbers of CAS failures incurred by the algorithms. All algorithms except for\r\nMCS-CAS incur orders-of-magnitude less failures than Java CAS. Specifically,\r\nfor concurrency level 20, Java CAS incurs almost 80M CAS failures, three orders\r\nof magnitude more than constant backoff which incurs approximately 569K fail\u0002ures. Exponential backoff incurs approximately 184K failures. Array based incurs\r\napproximately 104K failures. MCS-CAS incurs a high number of failures since\r\nthe tuning of its parameters sets the contention threshold to 8, implying that it\r\nis much less likely to enter high contention mode than array based. This high\r\nthreshold indicates that MCS-CAS is not a good CAS contention management\r\nalgorithm for Xeon.\r\ni7 results :\r\nFigure 2c shows the CAS throughput on the i7 machine as a function of the\r\nconcurrency level. It can be seen that both the absolute and relative performance\r\nof the evaluated algorithms are very similar to the behavior on the Xeon machine.\r\nThe numbers of CAS failures are also very similar to Xeon (for corresponding\r\nconcurrency levels) and therefore a figure showing these numbers is not provided.\r\nSPARC results :\r\nFigure 3a shows the throughput of the evaluated algorithms in the CAS\r\nbenchmark on the SPARC machine. Unlike Xeon where Java CAS does not scale\r\nat all, on SPARC the performance of Java CAS scales from 1 to 4 threads but\r\nthen quickly deteriorates, eventually falling to about 16% of the single thread\r\nperformance, less than 9% of the performance of 4 threads. More specifically,\r\nin the single thread test, Java CAS performs slightly more than 48M successful\r\nCAS operations and its performance reaches a peak of almost 90M operations at\r\n4 threads. Java CAS is the worst performer for concurrency levels 12 or higher\r\nand its throughput drops to about 8M for 64 threads.\r\nThe exponential backoff CAS is the clear winner on the SPARC CAS bench\u0002mark. Its throughput is slightly lower than that of Java CAS for concurrency\r\nlevels 1 and 2, but for higher concurrency levels it outperforms Java CAS by a\r\nwide margin that grows with concurrency. For concurrency levels 28 or more,\r\nexponential backoff completes more than 7 times successful CAS operations and\r\nthe gap peaks for 54 thread where Java CAS is outperformed by a factor of\r\nalmost 12.\r\nThe constant wait CAS is second best. Since it has smaller overhead than\r\nexponential backoff CAS, it slightly outperforms it in the single thread test,\r\n10",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/eb392840-b76a-4d0e-985a-68488bb01db8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5ad623428bb2a004dbaccb97e7a40baa8b0d65067dcc7544f58f272679b16fb4",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 485
      },
      {
        "segments": [
          {
            "segment_id": "37ebf3d7-7c6c-4412-8acd-cdc00fc6e664",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 11,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "Java ConstBackoff ExpBackoff MCS ArrayBased TimeSlice\r\n1E+6\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\n120\r\n10 20 30 40 50 60 70\r\n(a) Successes\r\n1E+6\r\n0\r\n50\r\n100\r\n150\r\n200\r\n250\r\n10 20 30 40 50 60 70\r\n(b) Failures\r\nFig. 3: SPARC CAS: Number of successful and failed CAS operations as a function of\r\nconcurrency level.\r\nbut for higher concurrency levels it is outperformed by exponential backoff by a\r\nmargin of up to 56%.\r\nThe high overhead of MCS-CAS and array based manifests itself in the single\r\nthread test, where both provide significantly less throughput than all other algo\u0002rithms. For higher concurrency levels, both MCS-CAS and array based perform\r\nbetween 20M-60M successful CAS operations, significantly more than Java CAS\r\nbut much less than the constant and exponential backoff algorithms.\r\nFigure 3b shows the numbers of CAS failures incurred by the algorithms.\r\nConstant backoff and exponential bakcoff incur the smallest number of failures,\r\nan order of magnitude less failures than Java CAS. Array based, time slice and\r\nMCS-CAS incur more failures than the two backoffs, but significantly less than\r\nJava CAS in almost all concurrency levels.\r\nZooming into the numbers of successes and failures incurred by MCS-CAS\r\nin low- and high-contention modes, we find that for high concurrency levels,\r\nMCS-CAS obtains approximately 10% of its successes in high-contention mode\r\nbut also incurs about 10 times more failures in low-contention mode than in\r\nhigh-contention mode.\r\nAnalysis :\r\nAs shown by Figures 2a, 2c and 3a, whereas on the SPARC the number\r\nof successes in the CAS benchmark scales up to 4 or 8 threads (depending on\r\nthe contention management algorithm being used), no such scalability occurs on\r\nthe Xeon or the i7 platforms. We now explain the architectural reasons for this\r\ndifference. This requires some background which we now provide.\r\nThe SPARC T2+ processor chip contains 8 cores where each core has a\r\nprivate 8KB L1 data cache and 2 pipelines with 4 hardware thread contexts per\r\npipeline, for a total of 64 hardware thread contexts per chip. The L1 data caches,\r\nwhich are physically indexed and physically tagged, use a write-through policy\r\n11",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/37ebf3d7-7c6c-4412-8acd-cdc00fc6e664.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=01ff107310f5117152dd5b1f650993bf1214a741130bd125c51bdc4a86f606ef",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 352
      },
      {
        "segments": [
          {
            "segment_id": "81d1e343-d08f-4d7b-b02e-bc218f01440f",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 12,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "where stores do not allocate. The 8 cores are connected via an intra-chip cross\u0002bar to 8 L2 banks. Based on a hash of the physical address, the cross-bar directs\r\nrequests to one of the 8 L2 cache banks. The L2 banks are 16-way set associative\r\nand have a total capacity of 4MB. Pairs of banks share DRAM channels. All\r\nstore instructions, including CAS, pass over the cross-bar to the L2 cache. For\r\ncoherence, the L2, which is inclusive of all L1s, maintains a reverse directory of\r\nwhich L1 instances hold a given line. L1 lines are either valid or invalid; there\r\nare no cache-to-cache transfers between L1 caches. T2+ processors enjoy very\r\nshort cache-coherent communication latencies relative to other processors. On\r\nan otherwise unloaded system, a coherence miss can be satisfied from the L2 in\r\nunder 20 cycles.\r\nCAS instructions are implemented at the interface between the cores and the\r\ncross-bar. For ease of implementation, CAS instructions, whether successful or\r\nnot, invalidate the line from the issuer’s L1. A subsequent load from that same\r\naddress will miss in the L1 and revert to the L2. The cross-bar and L2 have\r\nsufficient bandwidth and latency, relative to the speed of the cores, to allow\r\nload-CAS benchmarks to scale beyond just one thread, as we see in Figure 3a.\r\nWe now describe why such scalability is not observed on the XEON and i7\r\nplatforms, as seen by Figures 2a and 2c. Modern x86 processors tend to have\r\ndeeper cache hierarchies, often adding core-local MESI L2 caches connected via\r\nan on-chip coherent interconnect fabric and backed by a chip-level L3. Intra-chip\r\ninter-core communication is accomplished by L2 cache-to-cache transfers. With\r\nrespect to coherence, a store instruction is no different than a CAS – both need\r\nto issue request-to-own bus operations, if necessary, to make sure the underlying\r\nline can be modified. That is, CAS is performed ”locally” in the L1 or L2.\r\nIn addition to the cost of obtaining ownership, load-CAS benchmarks may\r\nalso be subject to a number of confounding factors on x86. As contention in\u0002creases and the CAS starts to fail more frequently, branch predictors can be\r\ntrained to expect the failure path, so when the CAS is ultimately successful the\r\nthread will incur a branch misprediction penalty. In contrast, T2+ does not have\r\na branch predictor.\r\nFurthermore, some x86 processors have an optimization that allows specul\u0002ative coherence probes. If a load is followed in close succession, in program order,\r\nby a store or CAS to the same address, the processor may need to send coherence\r\nrequest messages to upgrade the line to writable state in its local cache at the\r\ntime of the load. This avoids the situation where the load induces a read-to-share\r\nbus transaction followed in short order by a transaction to upgrade the line to\r\nwritable state. While useful, under intense communication traffic this facility\r\ncan cause excessive invalidation. Finally, we note that coherence arbitration for\r\nlines is not necessarily fair over the short term, and in turn this can impact\r\nperformance.\r\n12",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/81d1e343-d08f-4d7b-b02e-bc218f01440f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=72fe61805a2a726812b699ebdd71aba96332551a1bac60b7e49520d4400a1c48",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 506
      },
      {
        "segments": [
          {
            "segment_id": "ed7c92a4-edf0-49e6-bd9d-1384b56f5fc6",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 13,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "Fairness :\r\nTable 2: Fairness measures.\r\nNormal stdev Jain’s Index\r\nXeon SPARC Xeon SPARC\r\nJava 0.291 0.164 0.900 0.961\r\nCB-CAS 0.077 0.196 0.992 0.957\r\nEXP-CAS 0.536 0.936 0.761 0.588\r\nMCS-CAS 0.975 0.596 0.563 0.727\r\nAB-CAS 0.001 0.822 1.000 0.638\r\nTS-CAS 0.829 0.211 0.605 0.946\r\nTable 2 summarizes the fairness measures of the synthetic CAS benchmarks.\r\nWe used normalized standard deviation and Jain’s fairness index to quantify the\r\nfairness of individual threads’ throughput for each concurrency level, and then\r\ntook the average over all concurrency levels. The widely used Jain’s index for\r\na set of n samples is the quotient of the square of the sum and the product\r\nof the sum of squares by n. Its value ranges between 1/n (lowest fairness) and\r\n1 (highest fairness). It equals k/n when k threads have the same throughput,\r\nand the other n − k threads are starved. We see that CB-CAS and TS-CAS\r\nprovide comparable and even superior fairness to Java CAS while the rest of the\r\nalgorithms provide less fairness.\r\n3.2 FIFO queue\r\nTo further investigate the impact of our CAS contention management algorithms,\r\nwe experimented with the FIFO queue algorithm of Michael and Scott [25] (MS\u0002queue). We used the Java code provided in Herlihy and Shavit’s book [17] without\r\nany optimizations. The queue is represented by a list of nodes and by head and\r\ntail atomic references to the first and last entries in the list, which become hot\r\nspots under high contention.\r\nWe evaluated four versions of the MS-queue: one using Java’s Atomic\u0002Reference objects (called J-MSQ), and the other three replacing them by\r\nConstantBackoffCAS, ExpBackoffCAS and TimeSliceCAS objects (respectively\r\ncalled CB-MSQ, Exp-MSQ and TS-MSQ). MCS and array based were consisten\u0002tly outperformed and are therefore omitted from the following comparison. We\r\ncompared these algorithms with the Java 6 ConcurrentLinkedQueue class from\r\nthe java.util.concurrent package,8 and the flat-combining queue algorithm [11].9\r\n8 We used a slightly modified version in which direct usage of Java’s Unsafe class was\r\nreplaced by an AtomicReference mediator.\r\n9 We used the Java implementation provided by Tel-Aviv University’s Multicore Com\u0002puting Group.\r\n13",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/ed7c92a4-edf0-49e6-bd9d-1384b56f5fc6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=48f8be082ae1826ee88894f58faa7c7bba1f636981999d2bcc6f7a5e69582317",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 345
      },
      {
        "segments": [
          {
            "segment_id": "a1212735-d872-442a-8988-24605c5b2a28",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 14,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "1E+6\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\n120\r\n140\r\n160\r\n2 4 6 8 10 12 14 16 18 20\r\n(a) Xeon\r\n1E+6\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\n120\r\n140\r\n160\r\n180\r\n1 2 3 4 5 6 7 8\r\n(b) i7\r\n1E+6\r\n0\r\n10\r\n20\r\n30\r\n40\r\n50\r\n60\r\n10 20 30 40 50 60 70\r\n(c) SPARC\r\nJ-MSQ\r\nCB-MSQ\r\nEXP-MSQ\r\nTS-MSQ\r\nJava6 Queue\r\nFC Queue\r\nFig. 4: Queue: Number of completed ops as a function concurrency level.\r\nThe ConcurrentLinkedQueue class, written by Doug Lea, implements an algo\u0002rithm (henceforth simply called Java 6 queue) that is also based on Michael and\r\nScott’s algorithm. However, the Java 6 queue algorithm incorporates several sig\u0002nificant optimizations such as performing lagged updates of the head and tail\r\nreferences and using lazySets instead of normal writes.\r\nWe conducted the following test. For varying number of threads, each thread\r\nrepeatedly performed either an enqueue or a dequeue operation on the data\r\nstructure for a period of 5 seconds. The queue is pre-populated by 1000 items.\r\nA pseudo-random sequence of 128 integers is generated by each thread indepen\u0002dently before the test starts where the i’th operation of thread t is an enqueue\r\noperation if integer (i mod 128) is even and is a dequeue operation otherwise.\r\nEach thread counts the number of operations it completes on the queue. These\r\nlocal counters are summed up at the end of the test. Each data point is the aver\u0002age of 10 independent runs. In order to make the results comparable between the\r\ndifferent platforms, the same set of 10 pre-generated seeds was used to initialize\r\nthe random generator.\r\nFigures 4a-4c show the results of the queue tests on the platforms on which\r\nwe ran our experiments, using the optimal parameter values of Table 1.\r\n14",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/a1212735-d872-442a-8988-24605c5b2a28.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c87f8d1f8d441c0e533251739903c608dbb20a24b459c7cf5c621c04a7f51715",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 297
      },
      {
        "segments": [
          {
            "segment_id": "09bacf26-7df7-4fda-b22f-a68f80cd7bb5",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 15,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "Xeon results :\r\nAs shown by Figure 4a, CB-MSQ is the best queue implementation, outper\u0002forming the Java-CAS based queue in all concurrency levels by a factor of up to\r\n6 (for 16 threads).\r\nSurprisingly, CB-MSQ also outperforms the Java 6 queue by a wide margin in\r\nall concurrency levels except 1, in spite of the optimizations incorporated to the\r\nlatter. More specifically, in the single thread test, the performance of the Java\r\n6 queue exceeds that of CB-MSQ by approximately 15%. In higher concurrency\r\nlevels, however, CB-MSQ outperforms Java 6 queue by a factor of up to 3.5. Java\r\n6 queue is outperformed in all concurrency levels higher than 1 also by EXP\u0002MSQ and TS-MSQ. The FC queue hardly scales on this test and is outperformed\r\nby almost all algorithms in most concurrency levels.\r\nHowever, whereas in the Xeon CAS benchmark the constant backoff and\r\nexponential backoff provided nearly the same throughput, in the queue test CB\u0002MSQ outperforms EXP-MSQ by a wide margin in most concurrency levels.\r\nJ-MSQ has the worst performance in all concurrency levels higher than 1. It\r\nis outperformed by CB-MSQ by a factor of between 2-6 in all concurrency levels\r\nhigher than 1.\r\ni7 results :\r\nFigure 4b shows the results of the queue test on the i7 machine. The differ\u0002ences between the algorithms in this test are less significant than on the Xeon.\r\nCB-MSQ and TS-MSQ provide the highest throughput for all concurrency lev\u0002els except for 1. CB-MSQ peaks at 2 threads providing 124.5M operations, after\r\nwhich it starts to decline until reaching 81M for 8 threads. TS-MSQ maintains a\r\nconsistent throughput of 90M-100M for concurrency levels higher than 1 and is\r\nthe best performer for concurrency levels 6 or more. EXP-MSQ, which was sig\u0002nificantly better than the Java 6 queue on Xeon, outperforms it only by roughly\r\n5% in this test for concurrency levels of 2-6, and by 9% for 8 threads.\r\nJ-MSQ falls from 96.7M for 1 thread to about 40M-44M for higher conc\u0002urrency levels, exhibiting similar behavior to the Xeon test. FC queue hardly\r\nscales in this test as well, providing the lowest throughput in all concurrency\r\nlevels. TS-MSQ outperforms J-MSQ by factor of between 2.1-2.4 for all conc\u0002urrency levels except for 1.\r\nSPARC results :\r\nFigure 4c shows the results of the queue test on the SPARC machine. Here,\r\nunlike on Xeon and i7, the Java 6 queue has the best throughput in all conc\u0002urrency levels, outperforming TS-MSQ - which is second best in most conc\u0002urrency levels - by a factor of up to 2. It seems that the optimizations of the\r\nJava 6 algorithm are more effective on the SPARC architecture. CB-MSQ starts\r\nlow but its performance scales up to 30 threads where it slightly exceeds that of\r\nEXP-MSQ.\r\nJ-MSQ scales up to 14 threads where it performs approximately 36M queue\r\noperations, but quickly deteriorates in higher concurrency levels and its through\u000215",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/09bacf26-7df7-4fda-b22f-a68f80cd7bb5.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=aa614f57fa785c0b987e06337746b5834445ca07b48e13095576db4173e17e76",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 482
      },
      {
        "segments": [
          {
            "segment_id": "6319947f-2222-45d3-bd80-c24987bee858",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 16,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "put falls to less than 10M operations with 64 threads. This is similar to the\r\ndecline exhibited by Java CAS in the CAS benchmark, except that the graph\r\nis “stretched” and the decline is slightly milder. The reason for this change is\r\nthat the effective levels of CAS contention on the data-structure’s variables are\r\nreduced in the queue implementations, since the code of the MS-queue algorithm\r\ncontains operations other than CAS. For concurrency levels 40 or higher, J-MSQ\r\nis outperformed by EXP-MSQ by a factor of up to 2.4 (for 54 threads). Unlike\r\non Xeon, the FC queue scales on SPARC up to 20 threads, when its performance\r\nalmost equals that of the simple backoff schemes.\r\n3.3 Stack\r\nWe also experimented with the lock-free stack algorithm of Treiber.10 The stack\r\nis represented by a list of nodes and a reference to the top-most node is stored\r\nby an AtomicReference object.\r\nWe evaluated five versions of the Treiber algorithm: one using Java’s Atomic\u0002Reference objects (called J-Treiber), and the other three replacing them by the\r\nConstantBackoffCAS, ExpBackoffCAS and TimeSliceCAS (respectively called\r\nCB-Treiber, Exp-Treiber and TS-Treiber). We also compared with a Java imple\u0002mentation of the elimination-backoff stack (EB stack) of Hendler et al. [13].11\r\nThe elimination-backoff stack copes with high-contention by attempting to pair\u0002up concurrent push and pop operations that “collide” on entries of a so-called\r\nelimination array. In addition, it employs an exponential-backoff scheme after a\r\nCAS failure.\r\nThe structure of the Stack test is identical to that of the Queue test: each\r\nthread repeatedly performs either a push or a pop operation on the stack for a\r\nperiod of 5 seconds. The stack is pre-populated by 1000 items. A pseudo-random\r\nsequence of 128 bits is generated by each thread independently before the test\r\nstarts where the i’th operation of thread t is an push operation if bit (i mod 128)\r\nis true and is a pop operation otherwise. Each data point is the average of 10\r\nindependent runs.\r\nFigures 5a-5c show the results of the stack tests on the three platforms, using\r\nthe optimal parameter values of Table 1.\r\nXeon results :\r\nFigure 5a shows the results of the stack test on Xeon. As with all Xeon test\r\nresults, also in the stack test, the implementation using Java’s AtomicReference\r\nsuffers from a steep performance decrease as concurrency levels increase, falling\r\n10 The first non-blocking implementation of a concurrent list-based stack appeared\r\nin the IBM System 370 principles of operation manual in 1983 [21] and used the\r\ndouble-width compare-and-swap (CAS) primitive. Treiber’s algorithm is a variant\r\nof IBM’s algorithm, in which push operations use a single-word-width CAS instead\r\nof double-width compare-and-swap.\r\n11 We used IBM’s implementation available from the Amino Concurrent Building\r\nBlocks project at http://amino-cbbs.wiki.sourceforge.net/\r\n16",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/6319947f-2222-45d3-bd80-c24987bee858.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=19f17c8387fb7fd0b14c7502ca5f949fa9568b03ad7b2377626eac791f12f5da",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 455
      },
      {
        "segments": [
          {
            "segment_id": "bcad12c3-3401-4248-8e89-72e0eee84a67",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 17,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "1E+6\r\n0\r\n50\r\n100\r\n150\r\n200\r\n250\r\n2 4 6 8 10 12 14 16 18 20\r\n(a) Xeon\r\n1E+6\r\n0\r\n50\r\n100\r\n150\r\n200\r\n250\r\n1 2 3 4 5 6 7 8\r\n(b) i7\r\n1E+6\r\n5\r\n10\r\n15\r\n20\r\n25\r\n30\r\n35\r\n40\r\n10 20 30 40 50 60 70\r\n(c) SPARC\r\nJ-Treiber\r\nCB-Treiber\r\nEXP-Treiber\r\nTS-Treiber\r\nEB Stack\r\nFig. 5: Stack: Number of completed ops as a function concurrency level.\r\nfrom throughput of approximately 126M stack operations in the single thread\r\ntest to about 17M operations for 20 threads, approximately 13% of the single\r\nthread performance.\r\nThe EB stack is the winner of the Xeon stack test and CB-Treiber is second\u0002best lagging behind only slightly. CB-Treiber maintains and even exceeds its high\r\nsingle-thread throughput across the concurrency range, scaling up from 144M\r\noperations for a single thread to 195M operations for 18 threads, outperforming\r\nJ-Treiber by a factor of 11.5 for 18 threads. EXP-Treiber and TS-Treiber are\r\nsecond best, with performance lagging behind CB-Treiber in all concurrency\r\nlevels by between 20%-40%.\r\ni7 results :\r\nFigure 5b shows the results of our evaluation on the i7. The EB stack and\r\nCB-Treiber algorithms are the best performers. CB-Treiber has the upper hand\r\nin low concurrency levels, providing between 5%-10% more throughput than EB\r\nstack for 1-4 threads. It scales up to 4 threads, then starts to deteriorate and\r\nlevels up with EB stack at 6 threads, where the throughput of both algorithms\r\nis approximately 186M. EB Stack maintains a consistent throughput of about\r\n17",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/bcad12c3-3401-4248-8e89-72e0eee84a67.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=4ae552428766335c18da3006ff8d3f1380d9736dac3ec1ceb445065aadb56408",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 254
      },
      {
        "segments": [
          {
            "segment_id": "9c98b422-6c33-4e8f-846f-9fc98c2a135a",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 18,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "185M through all concurrency levels, outperforming CB-Treiber at 8 threads by\r\n15%.\r\nEXP-Treiber is significantly outperformed by both EB stack and CB-Treiber.\r\nIts throughput declines from about 168M in the single-thread test to approxi\u0002mately 110M for 8 threads. TS-Treiber starts high at 206M for 1 thread, but\r\ndeteriorates to 107M, in high correlation with Exp-Treiber. J-Treiber exhibits\r\na curve similar to the corresponding Java CAS in the CAS benchmark; it falls\r\nfrom more than 212M for a single thread to only 37M for 8 threads, and is out\u0002performed by CB-Treiber in all concurrency levels except for 1 by a wide margin\r\nof up to 6.2.\r\nSPARC results :\r\nFigure 5c shows the results of the stack tests on SPARC. J-Treiber scales\r\nup to 6 threads where it reaches its peak performance of 39.5M stack oper\u0002ations. Then its performance deteriorates with concurrency and reaches less\r\nthan 10M operations for 64 threads. From concurrency level 18 and higher, J\u0002Treiber has the lowest throughput. TS-Treiber has the highest throughput in\r\nmost medium and high concurrency levels, with EXP-Treiber mostly second\r\nbest. Unlike on XEON, EB stack is almost consistently and significantly outper\u0002formed on SPARC by all simple backoff algorithms.\r\nTS-Treiber has the highest throughput for 30 threads or more (with the\r\nexception of concurrency levels 62-64) and outperforms J-Treiber in high conc\u0002urrency levels by a factor of up to 3. CB-Treiber starts low but scales up to\r\n18 where it levels up at about 27M until it starts to deteriorate at 34 threads\r\nand higher, matching and even slightly exceeding TS-Treiber and EXP-Treiber\r\nabove 62 threads.\r\n4 Discussion\r\nWe conduct what is, to the best of our knowledge, the first study on the impact\r\nof contention management algorithms on the efficiency of the CAS operation.\r\nWe implemented several Java classes that encapsulate calls to Java’s Atomic\u0002Reference class by CAS contention management algorithms. We then evaluated\r\nthe benefits gained by these algorithms on the Xeon, SPARC and i7 platforms\r\nby using both a synthetic benchmark and CAS-based concurrent data-structure\r\nimplementations of stacks and queues.\r\nOut of the contention management approaches we have experimented with,\r\nthe three simplest algorithms - constant backoff, exponential backoff and time\u0002slice - yielded the best results, primarily because they have very small overheads.\r\nThe more complicated approaches - the MCS-CAS and array-based algorithms\r\n- provided better results than direct calls to AtomicReference in most tests, but\r\nwere significantly outperformed by the simpler algorithms.\r\nOur evaluation demonstrates that encapsulating Java’s AtomicReference by\r\nclasses that implement lightweight contention management support can improve\r\n18",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/9c98b422-6c33-4e8f-846f-9fc98c2a135a.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2a7cf8c76812dc55bcdb59f612ddab8899f727d05ec98a1ca09d0c7ef20c8919",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 421
      },
      {
        "segments": [
          {
            "segment_id": "fe953910-28c2-4027-a60b-5cb9edc3fd2c",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 19,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "the performance of CAS-based algorithms considerably. We also compared rel\u0002atively simple data-structure implementations that use our CAS contention\r\nmanagement classes with more complex implementations that employ data\u0002structure specific optimizations and use AtomicReference objects.\r\nWe have found that, in some cases, simpler and non-optimized data-structure\r\nimplementations that apply efficient contention management for CAS operations\r\nyield better performance than that of highly optimized implementations of the\r\nsame data-structure that use Java’s AtomicReference directly.\r\nOur results imply that encapsulating invocations of CAS by lightweight\r\ncontention management classes is a simple and generic way of improving the\r\nperformance of concurrent objects.\r\nThis work may be extended in several directions. First, we may have over\u0002looked CAS contention management algorithms that yield better results. Sec\u0002ond, our methodology tuned the platform-dependent parameters of contention\r\nmanagement algorithms by using the CAS benchmark. Although the generality\r\nof this approach is appealing, tuning these parameters per data-structure may\r\nyield better results. Moreover, a dynamic tuning may provide a general, cross\r\ndata-structure, cross CPU, solution.\r\nIt would also be interesting to investigate if and how similar approaches\r\ncan be used for other atomic-operation related classes in both Java and other\r\nprogramming languages such as C++.\r\nFinally, combining contention management algorithms at the atomic opera\u0002tion level with optimizations at the data-structure algorithmic level may yield\r\nmore performance gains than applying only one of these approaches separately.\r\nWe leave these research directions for future work.\r\nReferences\r\n1. Yehuda Afek, Michael Hakimi, and Adam Morrison. Fast and scalable rendezvous\u0002ing. In DISC, pages 16–31, 2011.\r\n2. Yehuda Afek, Guy Korland, Maria Natanzon, and Nir Shavit. Scalable producer\u0002consumer pools based on elimination-diffraction trees. In Euro-Par (2), pages\r\n151–162, 2010.\r\n3. Hagit Attiya and Jennifer Welch. Distributed Computing: Fundamentals, Simula\u0002tions and Advanced Topics (2nd edition). John Wiley Interscience, March 2004.\r\n4. Dmitry Basin, Rui Fan, Idit Keidar, Ofer Kiselov, and Dmitri Perelman. Caf´e:\r\nScalable task pools with adjustable fairness and contention. In DISC, pages 475–\r\n488, 2011.\r\n5. Silas Boyd-Wickizer, M. Frans Kaashoek, Robert Morris, and Nickolai Zeldovich.\r\nNon-scalable locks are dangerous. In Proceedings of the Linux Symposium, pages\r\n119–130, 2012.\r\n6. Intel Corporation. Intel Itanium Architecture Software Developer’s Manual. 2006.\r\n7. Panagiota Fatourou and Nikolaos D. Kallimanis. Revisiting the combining syn\u0002chronization technique. In PPOPP, pages 257–266, 2012.\r\n8. Anders Gidenstam, H˚akan Sundell, and Philippas Tsigas. Cache-aware lock\u0002free queues for multiple producers/consumers and weak memory consistency. In\r\nOPODIS, pages 302–317, 2010.\r\n19",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/fe953910-28c2-4027-a60b-5cb9edc3fd2c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a880d851f3ed54655c866be7503b062dd9ff1997c19799cd3d2f4444f5fb5a2a",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 395
      },
      {
        "segments": [
          {
            "segment_id": "7cc58540-7808-4c1b-8280-59b8d345cdd9",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 20,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "9. Elad Gidron, Idit Keidar, Dmitri Perelman, and Yonathan Perez. Salsa: scalable\r\nand low synchronization numa-aware algorithm for producer-consumer pools. In\r\nSPAA, pages 151–160, 2012.\r\n10. Eric L. Goodman, M. Nicole Lemaster, and Edward Jimenez. Scalable hashing for\r\nshared memory supercomputers. In SC, page 41, 2011.\r\n11. Danny Hendler, Itai Incze, Nir Shavit, and Moran Tzafrir. Flat combining and the\r\nsynchronization-parallelism tradeoff. In SPAA, pages 355–364, 2010.\r\n12. Danny Hendler, Itai Incze, Nir Shavit, and Moran Tzafrir. Scalable flat-combining\r\nbased synchronous queues. In DISC, pages 79–93, 2010.\r\n13. Danny Hendler, Nir Shavit, and Lena Yerushalmi. A scalable lock-free stack algo\u0002rithm. J. Parallel Distrib. Comput., 70(1):1–12, 2010.\r\n14. Maurice Herlihy. A methodology for implementing highly concurrent data objects.\r\nACM Trans. Program. Lang. Syst., 15(5):745–770, November 1993.\r\n15. Maurice Herlihy, Beng-Hong Lim, and Nir Shavit. Scalable concurrent counting.\r\nACM Trans. Comput. Syst., 13(4):343–364, 1995.\r\n16. Maurice Herlihy and J. Eliot B. Moss. Transactional memory: architectural sup\u0002port for lock-free data structures. In Proceedings of the 20th annual international\r\nsymposium on computer architecture, ISCA ’93, pages 289–300, New York, NY,\r\nUSA, 1993. ACM.\r\n17. Maurice Herlihy and Nir Shavit. The Art of Multiprocessor Programming. Morgan\r\nKaufmann Publishers Inc., San Francisco, CA, USA, 2008.\r\n18. Maurice Herlihy, Nir Shavit, and Moran Tzafrir. Hopscotch hashing. In DISC,\r\npages 350–364, 2008.\r\n19. Maurice Herlihy, Nir Shavit, and Orli Waarts. Linearizable counting networks.\r\nDistributed Computing, 9(4):193–203, 1996.\r\n20. M.P. Herlihy. Wait-free synchronization. ACM Transactions On Programming\r\nLanguages and Systems, 13(1):123–149, January 1991.\r\n21. IBM. IBM System/370 Extended Architecture, Principles of Operation, publication\r\nno. SA22-7085. 1983.\r\n22. William N. Scherer III, Doug Lea, and Michael L. Scott. Scalable synchronous\r\nqueues. Commun. ACM, 52(5):100–111, 2009.\r\n23. Edya Ladan-Mozes and Nir Shavit. An optimistic approach to lock-free fifo queues.\r\nDistributed Computing, 20(5):323–341, 2008.\r\n24. J. M. Mellor-Crummey and M. L. Scott. Algorithms for scalable synchroniza\u0002tion on shared-memory multiprocessors. ACM Transactions on Computer Systems\r\n(TOCS), 9(1):21–65, 1991.\r\n25. Maged M. Michael and Michael L. Scott. Simple, fast, and practical non-blocking\r\nand blocking concurrent queue algorithms. In PODC, pages 267–275, 1996.\r\n26. Maged M. Michael and Michael L. Scott. Simple, fast, and practical non-blocking\r\nand blocking concurrent queue algorithms. In Proceedings of the fifteenth annual\r\nACM symposium on Principles of distributed computing, PODC ’96, pages 267–\r\n275, New York, NY, USA, 1996. ACM.\r\n27. Sun Microsystems. UltraSPARC Architecture 2005, Draft D0.9.2. 2008.\r\n28. Mark Moir, Daniel Nussbaum, Ori Shalev, and Nir Shavit. Using elimination to\r\nimplement scalable and lock-free fifo queues. In SPAA, pages 253–262, 2005.\r\n29. Motorola. MC68000 Programmer’s Reference Manual. 1992.\r\n30. William N. Scherer, III and Michael L. Scott. Advanced contention management\r\nfor dynamic software transactional memory. In Proceedings of the twenty-fourth\r\nannual ACM symposium on Principles of distributed computing, PODC ’05, pages\r\n240–248, New York, NY, USA, 2005. ACM.\r\n20",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/7cc58540-7808-4c1b-8280-59b8d345cdd9.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8140a130b2cf75801bbc3963a6eb33c5468b57e9fa09b67d4ac8ac6d8e48f50a",
            "html": null,
            "markdown": null
          },
          {
            "segment_id": "4ae12b00-3876-4d90-9a64-e5c2ff5e51bf",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 21,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "31. Ori Shalev and Nir Shavit. Split-ordered lists: Lock-free extensible hash tables. J.\r\nACM, 53(3):379–405, 2006.\r\n32. Josh Triplett, Paul E. McKenney, and Jonathan Walpole. Scalable concurrent\r\nhash tables via relativistic programming. Operating Systems Review, 44(3):102–\r\n109, 2010.\r\n21",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/4ae12b00-3876-4d90-9a64-e5c2ff5e51bf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0af76ee4eaf3086b1b8d647f22a6cca8741598019030f712a381a8b7b65ffa6c",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 500
      },
      {
        "segments": [
          {
            "segment_id": "3f65f3e0-439d-433f-add6-81880aa34cab",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 22,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "5 Appendix A: the MSC-CAS algorithm\r\nAlgorithm 4: The MCS-CAS class.\r\n32 public class MCS-CAS<V> extends AtomicReference<V>\r\n33 private class ThreadRecord\r\n34 long modeCount\r\n35 boolean contentionMode\r\n36 int next = NONE\r\n37 volatile boolean notify\r\n38 private ThreadRecord[] tRecords = new ThreadRecord[MAX THREADS]\r\n39 private AtmicInteger tail = new AtomicInteger(NONE)\r\n40 public V read()\r\n41 ThreadRecord r = tRecords[TInd]\r\n42 if r.contentionMode then\r\n43 r.next = NONE\r\n44 int pred = tail.getAndSet(TInd)\r\n45 if pred != NONE then\r\n46 tRecords[pred].next.set(TInd)\r\n47 r.notify.set(false)\r\n48 long wait = MAX WAIT\r\n49 while ¬r.notify[TInd] ∧ (wait > 0) do wait=wait-1\r\n50 return get()\r\n51 public boolean CAS(V old, V new)\r\n52 boolean ret = compareAndSet(old,new)\r\n53 ThreadRecord r = tRecords[TInd]\r\n54 if r.contentionMode then\r\n55 if r.next == NONE then\r\n56 if ¬tail.compareAndSet( TInd, NONE) then\r\n57 long wait = MAX WAIT\r\n58 while r.next == NONE ∧ (wait > 0) do wait=wait-1\r\n59 int successor = r.next\r\n60 if successor 6= NONE then tRecords[successor].notify =true\r\n61 else\r\n62 int successor = r.next[TInd]\r\n63 tRecords[successor].notify =true\r\n64 r.modeCount = r.modeCount + 1\r\n65 if r.modeCount=NUM OPS then\r\n66 r.modeCount = 0, r.contentionMode = false\r\n67 else if ret then\r\n68 r.modeCount = 0\r\n69 else\r\n70 r.modeCount = r.modeCount + 1\r\n71 if r.modeCount == CONTENTION THRESHOLD then\r\n72 r.contentionMode = true\r\n73 r.modeCount = 0\r\n74 return ret\r\n22",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/3f65f3e0-439d-433f-add6-81880aa34cab.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=bb29fd8db26e3be5fd48b760a7d6c53a667a2989679e7a5fb9ef84b30f74eb11",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 228
      },
      {
        "segments": [
          {
            "segment_id": "40e58950-5852-46f8-a4b9-2cc645071b08",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 23,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "Algorithm 4 presents the MCS-CAS class, which implements this algorithm.\r\nEach class instance contains the following two fields. The tail field is an atomic\r\ninteger storing the TInd of the thread that is at the tail of the queue of threads\r\nthat are currently in high-contention mode. The tRecords field is an array of\r\nper-thread data records, storing the following fields.12 The contentionMode field\r\nis a boolean, indicating whether the respective thread is in high-contention mode\r\n(if true) or in low-contention mode (if false). The next field of the record cor\u0002responding to t is an atomic integer, used by t’s successor in the queue for\r\ncommunicating its TInd to t. The notify field of the record corresponding to t\r\nis an atomic integer array used by t’s predecessor to signal t when it is allowed\r\nto proceed with its read operation. The modeCount field is used by a thread\r\nto determine when it should shift from high-contention mode to low-contention\r\nmode or vice versa as we soon explain.\r\nWe start by describing the read operation. If thread t is in low-contention\r\nmode, then it simply delegates to the get method of the AtomicReference object\r\nto return the current reference value in line 50.\r\nIf t is in high-contention mode, then it initializes its next entry (line 43) and\r\nswaps the value of tail to its TInd (line 44). After the swap t checks if it has a\r\npredecessor (line 45). If it does, t writes its TInd to the next field of the pred\r\nentry of its predecessor in the tRecords array, and initializes its notify field\r\n(lines 46–47).\r\nThread t then waits until it is either notified by its predecessor that it can\r\ngo ahead or until a platform-dependent waiting time elapses (lines 48–49) and\r\nthen returns the current reference value.\r\nRegardless of whether t is in high- or low-contention mode it always leaves the\r\nfunction by returning the CAS success/failure indication in line 74. We now\r\ndescribe the CAS operation.\r\nFirst, the compareAndSet method on the AtomicReference superclass is\r\ncalled, passing to it the old and new operands (line 52). If t is in high-contention\r\nmode then it checks whether a successor has written its TInd to t’s next field\r\n(line 55) and if so signals that successor that it may stop waiting for t (lines 62–\r\n63).\r\nIf no successor wrote its TInd, then t attempts to swap the field tail back\r\nfrom its TInd to NONE in line 56. If it fails, then it has a successor, in which\r\ncase t waits for it to write its TInd for at most a platform-dependent period of\r\ntime (lines 57–58) and then re-checks its next field; if it’s non-empty, t signals\r\nthe successor (lines 59–60).\r\nBefore exiting the CAS method, t increments its modeCount field and shifts\r\nto low-contention mode if the number of CAS operations it applied in high\u0002contention mode reached a platform-dependent threshold value (lines 64–66).\r\nWhen t is in low-contention mode its modeCount field is used for counting the\r\nnumber of consecutive CAS failures. If the current CAS operation was successful,\r\nthen t resets modeCount field (line 68). If the CAS failed then the field is incre\u000212 To cope with false sharing the records are padded with dummy fields (which we\r\nensure that are not optimized-out).\r\n23",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/40e58950-5852-46f8-a4b9-2cc645071b08.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f82c82f4e887bc324d128044d1c41a616a856569e3f0d6219eb70df40240533b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 552
      },
      {
        "segments": [
          {
            "segment_id": "40e58950-5852-46f8-a4b9-2cc645071b08",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 23,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "Algorithm 4 presents the MCS-CAS class, which implements this algorithm.\r\nEach class instance contains the following two fields. The tail field is an atomic\r\ninteger storing the TInd of the thread that is at the tail of the queue of threads\r\nthat are currently in high-contention mode. The tRecords field is an array of\r\nper-thread data records, storing the following fields.12 The contentionMode field\r\nis a boolean, indicating whether the respective thread is in high-contention mode\r\n(if true) or in low-contention mode (if false). The next field of the record cor\u0002responding to t is an atomic integer, used by t’s successor in the queue for\r\ncommunicating its TInd to t. The notify field of the record corresponding to t\r\nis an atomic integer array used by t’s predecessor to signal t when it is allowed\r\nto proceed with its read operation. The modeCount field is used by a thread\r\nto determine when it should shift from high-contention mode to low-contention\r\nmode or vice versa as we soon explain.\r\nWe start by describing the read operation. If thread t is in low-contention\r\nmode, then it simply delegates to the get method of the AtomicReference object\r\nto return the current reference value in line 50.\r\nIf t is in high-contention mode, then it initializes its next entry (line 43) and\r\nswaps the value of tail to its TInd (line 44). After the swap t checks if it has a\r\npredecessor (line 45). If it does, t writes its TInd to the next field of the pred\r\nentry of its predecessor in the tRecords array, and initializes its notify field\r\n(lines 46–47).\r\nThread t then waits until it is either notified by its predecessor that it can\r\ngo ahead or until a platform-dependent waiting time elapses (lines 48–49) and\r\nthen returns the current reference value.\r\nRegardless of whether t is in high- or low-contention mode it always leaves the\r\nfunction by returning the CAS success/failure indication in line 74. We now\r\ndescribe the CAS operation.\r\nFirst, the compareAndSet method on the AtomicReference superclass is\r\ncalled, passing to it the old and new operands (line 52). If t is in high-contention\r\nmode then it checks whether a successor has written its TInd to t’s next field\r\n(line 55) and if so signals that successor that it may stop waiting for t (lines 62–\r\n63).\r\nIf no successor wrote its TInd, then t attempts to swap the field tail back\r\nfrom its TInd to NONE in line 56. If it fails, then it has a successor, in which\r\ncase t waits for it to write its TInd for at most a platform-dependent period of\r\ntime (lines 57–58) and then re-checks its next field; if it’s non-empty, t signals\r\nthe successor (lines 59–60).\r\nBefore exiting the CAS method, t increments its modeCount field and shifts\r\nto low-contention mode if the number of CAS operations it applied in high\u0002contention mode reached a platform-dependent threshold value (lines 64–66).\r\nWhen t is in low-contention mode its modeCount field is used for counting the\r\nnumber of consecutive CAS failures. If the current CAS operation was successful,\r\nthen t resets modeCount field (line 68). If the CAS failed then the field is incre\u000212 To cope with false sharing the records are padded with dummy fields (which we\r\nensure that are not optimized-out).\r\n23",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/40e58950-5852-46f8-a4b9-2cc645071b08.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f82c82f4e887bc324d128044d1c41a616a856569e3f0d6219eb70df40240533b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 552
      },
      {
        "segments": [
          {
            "segment_id": "9a1e4fd1-a599-476b-ae90-00e6a3c872ae",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 24,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "mented. If the number of consecutive failures now reaches a platform-dependent\r\nthreshold value, t shifts to high-contention mode (lines 69–73).\r\n6 Appendix B: the Array-Based CAS algorithm\r\nAlgorithm 5: The ArrayBasedCAS class.\r\n75 public class AB-CAS<V> extends AtomicReference<V>\r\n76 private class ThreadRecord\r\n77 long modeCount\r\n78 boolean contentionMode\r\n79 volatile boolean request\r\n80 private ThreadRecord[] tRecords = new ThreadRecord[MAX THREADS]\r\n81 private AtomicInteger owner = new AtomicInteger(NONE)\r\n82 public V read()\r\n83 ThreadRecord r = tRecords[TInd]\r\n84 if r.contentionMode ∧ (owner.get() 6= TInd) then\r\n85 r.request = true\r\n86 for i=0; (i<MAX WAIT) ∧ r.request; i++ do\r\n87 if owner.get() == NONE ∧ owner.compareAndSet(NONE, TInd) then\r\n88 r.request = false , break\r\n89 if r.request then r.request = false\r\n90 return get()\r\n91 boolean CAS(V old, V new)\r\n92 boolean ret = compareAndSet(old,new)\r\n93 ThreadRecord r = tRecords[TInd]\r\n94 if r.contentionMode then\r\n95 if ++r.modeCount ≥ NUM OPS then\r\n96 r.modeCount\r\n97 r.contentionMode = false\r\n98 for i = (TInd+1)%MAX THREADS; i 6= TInd; i = (i+1)%MAX THREADS\r\ndo\r\n99 if tRecords[i].request then\r\n100 owner.set(i)\r\n101 r.request = false\r\n102 return ret\r\n103 owner.set(NONE)\r\n104 else if ret then\r\n105 r.modeCount = 0\r\n106 else if ++r.modeCount ≥ CONTENTION THRESHOLD then\r\n107 r.modeCount = 0 , r.contentionMode = true\r\n108 return ret\r\n24",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/9a1e4fd1-a599-476b-ae90-00e6a3c872ae.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=16975a13308a83e142354e67bc58af1849328b5fe68450a7fe3489d5364208e7",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 213
      },
      {
        "segments": [
          {
            "segment_id": "086e208b-9797-4b93-8fb5-6c68c1c1f62e",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 25,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "Algorithm 5 presents the ArrayBasedCAS class, which implements a CAS\r\ncontention management algorithm that we call array-based CAS. Similarly to\r\nthe MCS-CAS algorithm, with the array based CAS threads may apply their\r\noperations in either low-contention or high-contention mode.\r\nEach class instance contains the following fields. The tRecords array stores\r\nfor each thread the following fields; contentionMode, request and modeCount,\r\nwhich are used by the array based algorithm similarly to the way they are used\r\nby MSC-CAS. The owner atomic integer stores the TInd of the current “owner”\r\nof the memory location or NONE if there is no such owner. At any point in time,\r\nthe owner thread is the single high-contention mode thread that is permitted to\r\nperform read or CAS operations on the memory location encapsulated by the\r\nArrayBasedCAS object without waiting.\r\nWe now describe the read operation. If thread t is in low-contention mode or\r\nis the current owner (line 84), then it simply delegates to the get method of the\r\nAtomicReference object to return the current reference value (line 90). If t is in\r\nhigh-contention mode and is not the owner, then it initializes its request entry\r\nto true (line 101) and executes the loop of lines 86–88, until it is either signaled,\r\nmanages to become the owner, or performs a platform-dependent number of loop\r\niterations. If t is signaled or becomes the owner in the course of the loop then it\r\nimmediately exits it, ensuring that its request entry is reset in line 88 or line 89.\r\nAfter exiting the loop, t returns the current reference value in line 90.\r\nWe now describe the CAS operation. First, the compareAndSet method on\r\nthe AtomicReference superclass is called, passing to it the old and new operands\r\n(line 92). If t is in high-contention mode (line 94), then it is the current owner.\r\nAn owner performs NUM OP (a platform-dependent value) number of CAS\r\noperations before releasing ownership. Thread t increments its modeCount field\r\n(line 95). If it has to release ownership, then it resets its modeCount field and exits\r\nhigh-contention mode (lines 96–97). It then scans the tRcords array and notifies\r\nthe next waiting thread (if any) that it now becomes the owner (lines 98–102). If\r\nno waiting thread is found, t sets the value of the owner field to NONE (line 103).\r\nIf t is not in high-contention mode, then it proceeds to update its statistics.\r\nIf the current CAS was successful (line 104), then t resets its modeCount field\r\nline 105. If the current CAS failed (line 106), thread t increments its modeCount\r\nfield which counts the number of consecutive failures in low-contention mode.\r\nIf this number now reaches a platform-dependent threshold value (line 106), t\r\nresets its modeCount entry and shifts to high-contention mode (lines 107–107).\r\nRegardless of whether t is in high- or low-contention mode it always leaves\r\nthe method by returning the CAS success/failure indication in line 108.\r\n25",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/187a3f88-57ca-45ce-9b5a-ee349f9dff13/images/086e208b-9797-4b93-8fb5-6c68c1c1f62e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041947Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=7aca131b28a2bf306b80e476950a98d342ac9f2a13b47f95ffcfe8ca2ae3cd72",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 487
      }
    ],
    "extracted_json": {
      "title": "Document Metadata",
      "schema_type": "object",
      "extracted_fields": [
        {
          "name": "title",
          "field_type": "string",
          "value": "\"MCS-CAS\"\n"
        },
        {
          "name": "author",
          "field_type": "string",
          "value": "\"Dave Dice, Danny Hendler, and Ilya Mirsky\"\n"
        },
        {
          "name": "date_published",
          "field_type": "string",
          "value": "2013-05-24\n"
        },
        {
          "name": "location",
          "field_type": "string",
          "value": "```json\n{\"location\": \"line 50\", \"location\": \"line 43\", \"location\": \"line 44\", \"location\": \"lines 46–47\", \"location\": \"lines 48–49\", \"location\": \"line 74\", \"location\": \"line 52\", \"location\": \"line 55\", \"location\": \"lines 62–63\", \"location\": \"line 56\", \"location\": \"lines 57–58\", \"location\": \"lines 59–60\", \"location\": \"lines 64–66\", \"location\": \"line 68\", \"location\": \"lines 69–73\", \"location\": \"line 2\", \"location\": \"line 9\", \"location\": \"line 11\", \"location\": \"line 12\", \"location\": \"line 13\", \"location\": \"line 14\", \"location\": \"lines 15–18\", \"location\": \"line 21\", \"location\": \"line 23\", \"location\": \"line 26\", \"location\": \"lines 28–29\", \"location\": \"line 4\", \"location\": \"lines 5–6\", \"location\": \"line 7\", \"location\": \"line 84\", \"location\": \"line 90\", \"location\": \"line 101\", \"location\": \"lines 86–88\", \"location\": \"line 88\", \"location\": \"line 89\", \"location\": \"line 92\", \"location\": \"line 94\", \"location\": \"line 95\", \"location\": \"lines 96–97\", \"location\": \"lines 98–102\", \"location\": \"line 103\", \"location\": \"line 104\", \"location\": \"line 105\", \"location\": \"line 106\", \"location\": \"lines 107–107\", \"location\": \"line 108\"}\n```"
        }
      ]
    }
  }
}