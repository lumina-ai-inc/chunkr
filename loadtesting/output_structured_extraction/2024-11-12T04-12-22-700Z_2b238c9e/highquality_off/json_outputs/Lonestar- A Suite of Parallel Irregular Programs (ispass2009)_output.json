{
  "file_name": "Lonestar- A Suite of Parallel Irregular Programs (ispass2009).pdf",
  "task_id": "b8e0e52c-e94c-4791-b663-5104d75b4866",
  "output": {
    "chunks": [
      {
        "segments": [
          {
            "segment_id": "7aeacb6e-6cb5-487a-8375-a911102f2d03",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 1,
            "page_width": 612,
            "page_height": 792,
            "content": "Lonestar: A Suite of Parallel Irregular Programs ∗\r\nMilind Kulkarnia, Martin Burtschera, Calin Cas¸caval ˘ b, and Keshav Pingalia\r\naThe University of Texas at Austin\r\nb\r\nIBM T.J. Watson Research Center\r\nAbstract\r\nUntil recently, parallel programming has largely focused on the\r\nexploitation of data-parallelism in dense matrix programs. How\u0002ever, many important application domains, including meshing,\r\nclustering, simulation, and machine learning, have very different\r\nalgorithmic foundations: they require building, computing with,\r\nand modifying large sparse graphs. In the parallel programming\r\nliterature, these types of applications are usually classified as ir\u0002regular applications, and relatively little attention has been paid\r\nto them. To study and understand the patterns of parallelism and\r\nlocality in sparse graph computations better, we are in the pro\u0002cess of building the Lonestar benchmark suite. In this paper, we\r\ncharacterize the first five programs from this suite, which target\r\ndomains like data mining, survey propagation, and design au\u0002tomation. We show that even such irregular applications often\r\nexpose large amounts of parallelism in the form of amorphous\r\ndata-parallelism. Our speedup numbers demonstrate that this\r\nnew type of parallelism can successfully be exploited on modern\r\nmulti-core machines.\r\n1 Introduction\r\nWith the increasing importance of parallel programming, there\r\nis a need to broaden the scope of parallelization research. While\r\nsignificant research effort has been expended over the past few\r\ndecades investigating parallelism in domains such as dense linear\r\nalgebra and stencil codes, less effort has been spent in finding\r\nand exploiting parallelism in irregular algorithms, i.e., those that\r\nmanipulate pointer-based data structures such as trees and lists.\r\nMany irregular programs in important application domains,\r\nsuch as data mining, machine learning, computational geome\u0002try and SAT solving, implement iterative, worklist-based algo\u0002rithms that manipulate large, sparse graphs. Recent case studies\r\nby the Galois project have shown that many such programs have\r\na generalized form of data-parallelism called amorphous data\u0002parallelism [13]. To understand this pattern of parallelism, it\r\nhelps to consider Figure 1, which shows an abstract represen\u0002tation of an irregular algorithm. Typically, these algorithms are\r\norganized around a graph that has some number of nodes and\r\nedges; in some applications, the edges are undirected while in\r\n∗This work is supported in part by NSF grants 0833162, 0719966, 0702353,\r\n0724966, 0739601, and 0615240, as well as grants and equipment donations\r\nfrom IBM, SUN, and Intel Corporation.\r\nFigure 1: Active elements and neighborhoods\r\nothers they are directed. At each point during the execution of an\r\nirregular algorithm, there are certain nodes or edges in the graph\r\nwhere computation might be performed. Performing a compu\u0002tation may require reading or writing other nodes and edges in\r\nthe graph. The node or edge on which a computation is cen\u0002tered is called an active element. To simplify the discussion, we\r\nassume henceforth that active elements are nodes. Borrowing\r\nterminology from the cellular automata literature, we refer to the\r\nset of nodes and edges that are read or written in performing the\r\ncomputation at an active node as the neighborhood of that active\r\nnode. Figure 1 shows an undirected graph in which the filled\r\nnodes represent active nodes, and shaded regions represent the\r\nneighborhoods of those active nodes. In general, the neighbor\u0002hood of an active node is distinct from the set of its neighbors in\r\nthe graph. In some algorithms, such as Delaunay mesh refine\u0002ment [8] and the preflow-push algorithm for maxflow computa\u0002tion [10], there is no a priori ordering on the active nodes, and\r\na sequential implementation is free to choose any active node\r\nat each step of the computation. In other algorithms, such as\r\nevent-driven simulation [17] and agglomerative clustering [19],\r\nthe algorithm imposes an order on active elements that must be\r\nrespected by the sequential implementation. Both kinds of al\u0002gorithms can be written using worklists to keep track of active\r\nnodes.\r\nLet us illustrate these notions on the example of Delaunay\r\nMesh Refinement [8]. The input to this algorithm is a trian\u0002gulation of a set of points in a plane (Figure 2(a)), with some\r\ntriangles designated as “bad” according to some quality criterion\r\n(colored in black in Figure 2(a)). The bad triangles are placed\r\non a worklist, and, for each bad triangle, the algorithm collects a\r\nnumber of triangles around the bad triangle, called a cavity (col-",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/7aeacb6e-6cb5-487a-8375-a911102f2d03.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f2c4c01e803f865ceb72f8e0d18cf628d93c0d3eddad150c8324a5c6c72ebd2f",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 697
      },
      {
        "segments": [
          {
            "segment_id": "7aeacb6e-6cb5-487a-8375-a911102f2d03",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 1,
            "page_width": 612,
            "page_height": 792,
            "content": "Lonestar: A Suite of Parallel Irregular Programs ∗\r\nMilind Kulkarnia, Martin Burtschera, Calin Cas¸caval ˘ b, and Keshav Pingalia\r\naThe University of Texas at Austin\r\nb\r\nIBM T.J. Watson Research Center\r\nAbstract\r\nUntil recently, parallel programming has largely focused on the\r\nexploitation of data-parallelism in dense matrix programs. How\u0002ever, many important application domains, including meshing,\r\nclustering, simulation, and machine learning, have very different\r\nalgorithmic foundations: they require building, computing with,\r\nand modifying large sparse graphs. In the parallel programming\r\nliterature, these types of applications are usually classified as ir\u0002regular applications, and relatively little attention has been paid\r\nto them. To study and understand the patterns of parallelism and\r\nlocality in sparse graph computations better, we are in the pro\u0002cess of building the Lonestar benchmark suite. In this paper, we\r\ncharacterize the first five programs from this suite, which target\r\ndomains like data mining, survey propagation, and design au\u0002tomation. We show that even such irregular applications often\r\nexpose large amounts of parallelism in the form of amorphous\r\ndata-parallelism. Our speedup numbers demonstrate that this\r\nnew type of parallelism can successfully be exploited on modern\r\nmulti-core machines.\r\n1 Introduction\r\nWith the increasing importance of parallel programming, there\r\nis a need to broaden the scope of parallelization research. While\r\nsignificant research effort has been expended over the past few\r\ndecades investigating parallelism in domains such as dense linear\r\nalgebra and stencil codes, less effort has been spent in finding\r\nand exploiting parallelism in irregular algorithms, i.e., those that\r\nmanipulate pointer-based data structures such as trees and lists.\r\nMany irregular programs in important application domains,\r\nsuch as data mining, machine learning, computational geome\u0002try and SAT solving, implement iterative, worklist-based algo\u0002rithms that manipulate large, sparse graphs. Recent case studies\r\nby the Galois project have shown that many such programs have\r\na generalized form of data-parallelism called amorphous data\u0002parallelism [13]. To understand this pattern of parallelism, it\r\nhelps to consider Figure 1, which shows an abstract represen\u0002tation of an irregular algorithm. Typically, these algorithms are\r\norganized around a graph that has some number of nodes and\r\nedges; in some applications, the edges are undirected while in\r\n∗This work is supported in part by NSF grants 0833162, 0719966, 0702353,\r\n0724966, 0739601, and 0615240, as well as grants and equipment donations\r\nfrom IBM, SUN, and Intel Corporation.\r\nFigure 1: Active elements and neighborhoods\r\nothers they are directed. At each point during the execution of an\r\nirregular algorithm, there are certain nodes or edges in the graph\r\nwhere computation might be performed. Performing a compu\u0002tation may require reading or writing other nodes and edges in\r\nthe graph. The node or edge on which a computation is cen\u0002tered is called an active element. To simplify the discussion, we\r\nassume henceforth that active elements are nodes. Borrowing\r\nterminology from the cellular automata literature, we refer to the\r\nset of nodes and edges that are read or written in performing the\r\ncomputation at an active node as the neighborhood of that active\r\nnode. Figure 1 shows an undirected graph in which the filled\r\nnodes represent active nodes, and shaded regions represent the\r\nneighborhoods of those active nodes. In general, the neighbor\u0002hood of an active node is distinct from the set of its neighbors in\r\nthe graph. In some algorithms, such as Delaunay mesh refine\u0002ment [8] and the preflow-push algorithm for maxflow computa\u0002tion [10], there is no a priori ordering on the active nodes, and\r\na sequential implementation is free to choose any active node\r\nat each step of the computation. In other algorithms, such as\r\nevent-driven simulation [17] and agglomerative clustering [19],\r\nthe algorithm imposes an order on active elements that must be\r\nrespected by the sequential implementation. Both kinds of al\u0002gorithms can be written using worklists to keep track of active\r\nnodes.\r\nLet us illustrate these notions on the example of Delaunay\r\nMesh Refinement [8]. The input to this algorithm is a trian\u0002gulation of a set of points in a plane (Figure 2(a)), with some\r\ntriangles designated as “bad” according to some quality criterion\r\n(colored in black in Figure 2(a)). The bad triangles are placed\r\non a worklist, and, for each bad triangle, the algorithm collects a\r\nnumber of triangles around the bad triangle, called a cavity (col-",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/7aeacb6e-6cb5-487a-8375-a911102f2d03.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f2c4c01e803f865ceb72f8e0d18cf628d93c0d3eddad150c8324a5c6c72ebd2f",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 697
      },
      {
        "segments": [
          {
            "segment_id": "d90da515-92c7-4a24-bd90-4c745e082c96",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 2,
            "page_width": 612,
            "page_height": 792,
            "content": "(a) Unrefined Mesh (b) Refined Mesh\r\nFigure 2: Delaunay Mesh Refinement\r\nored in grey in Figure 2(a)), removes the cavity from the graph,\r\nand retriangulates the region (colored in grey in Figure 2(b)). If\r\nthe retriangulation creates new bad triangles, these are placed on\r\nthe worklist and processed in turn. To relate this algorithm to\r\nFigure 1, we note that the mesh is usually represented by a graph\r\nin which nodes represent triangles and edges represent triangle\r\nadjacencies. At any stage in the computation, the active nodes\r\nare the nodes representing badly shaped triangles and the neigh\u0002borhoods are the cavities of these triangles. In this problem, the\r\nactive nodes are not ordered.\r\nIt should be apparent that this algorithm can be parallelized\r\nby processing bad triangles in parallel as long as their cavities\r\ndo not overlap. In general, the parallelism in an algorithm with\r\namorphous data-parallelism is exploited by processing multiple\r\nelements from the worklist concurrently. Because the depen\u0002dences between elements on the worklist are very complex (e.g.,\r\nwhether or not two cavities overlap is dependent on the size\r\nand shape of the mesh), it appears as though there may be lit\u0002tle parallelism in these applications. However, we have found\r\nthat these applications do, indeed, exhibit significant parallelism\r\n[12], which we expand on in Section 4.1.\r\nKulkarni et al. [13] propose set iterators as an abstraction\r\nto express the parallelism in amorphous data-parallel programs.\r\nTwo types of iterators are used, un-ordered iterators that allow\r\nloop iterations to be executed in any order (as in Delaunay Mesh\r\nRefinement), and ordered iterators that impose a partial order on\r\nthe loop iterations. These iterators take the form of foreach\r\nstatements, where additional work can be added to the worklist\r\nbeing iterated over. Delaunay Mesh Refinement can be easily\r\nexpressed using these constructs, as seen in Figure 3. The exe\u0002cution model is straightforward: an application executes sequen\u0002tially until encountering a set iterator, at which point multiple\r\nthreads begin to execute iterations from the worklist in parallel.\r\nA runtime system manages the execution of the threads to ensure\r\nthat sequential semantics are preserved.\r\nGiven this execution model, we implemented five amorphous\r\ndata-parallel algorithms that span data mining, meshing, simu\u0002lation, and SAT solving in the Lonestar benchmark suite. We\r\ncharacterize these applications with respect to:\r\n• the amount of available parallelism in the algorithm; we use\r\ntwo metrics, the parallelism profile and the parallelism in\u0002tensity, that provide insight into the dynamic availability of\r\n1: Mesh m = /* read input mesh */\r\n2: Worklist wl = new Worklist(m.getBad());\r\n3: foreach Triangle t in wl {\r\n4: Cavity c = new Cavity(t);\r\n5: c.expand();\r\n6: c.retriangulate();\r\n7: m.updateMesh(c);\r\n8: wl.add(c.getBad());\r\n9: }\r\nFigure 3: Pseudocode for Delaunay Mesh Refinement\r\nparallel work in these algorithms for different inputs;\r\n• parallel execution (scaling) on three hardware platforms,\r\ndemonstrating that the parallelism can, indeed, be ex\u0002ploited; and\r\n• program characteristics, such as cache behavior, memory\r\naccesses, and working set sizes to provide an overview of\r\nhow the algorithmic implementation maps to architectural\r\nfeatures.\r\nThis paper makes the following contributions.\r\n• It introduces the Lonestar benchmark suite, whose focus is\r\non pointer-based (irregular) data structures and amorphous\r\ndata-parallelism. The suite covers important emerging and\r\nwell-known applications, all of which process large datasets\r\nand are long running, making it important to parallelize\r\nthem.\r\n• It reveals that these algorithms have a lot of parallelism, and\r\nthat this parallelism grows with the input size.\r\n• It demonstrate that this algorithmic parallelism can, indeed,\r\nbe exploited in parallelized implementations thereof.\r\n• It presents important workload characteristics of these pro\u0002grams. One key finding is that the transactions can be quite\r\nlarge, making them less suitable for hardware-based ap\u0002proaches.\r\nThe C++ and Java source code of the benchmark programs,\r\nsample inputs, and some documentation are available on-line at\r\nhttp://iss.ices.utexas.edu/lonestar/.\r\nThe rest of this paper is organized as follows. Section 2 ex\u0002plains the key algorithms, the data structures, and the parallelism\r\nstrategy in each of the five benchmarks. Section 3 presents our\r\nevaluation methodology. Section 4 shows the workloads’ theo\u0002retical and delivered parallelism as well as other characteristics.\r\nSection 5 discusses related work and Section 6 summarizes the\r\npaper.\r\n2 Applications\r\nThe following is a detailed description of our benchmarks, their\r\ndata structures, algorithms and parallel decomposition.\r\n2.1 Agglomerative Clustering\r\nThis benchmark is an implementation of a well-known data\u0002mining algorithm, Agglomerative Clustering [19], as used in",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/d90da515-92c7-4a24-bd90-4c745e082c96.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d5a9fcd10deb04d8c42b6322826c3ace89e9b319b0b152af51c378ccd649c7c4",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 729
      },
      {
        "segments": [
          {
            "segment_id": "d90da515-92c7-4a24-bd90-4c745e082c96",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 2,
            "page_width": 612,
            "page_height": 792,
            "content": "(a) Unrefined Mesh (b) Refined Mesh\r\nFigure 2: Delaunay Mesh Refinement\r\nored in grey in Figure 2(a)), removes the cavity from the graph,\r\nand retriangulates the region (colored in grey in Figure 2(b)). If\r\nthe retriangulation creates new bad triangles, these are placed on\r\nthe worklist and processed in turn. To relate this algorithm to\r\nFigure 1, we note that the mesh is usually represented by a graph\r\nin which nodes represent triangles and edges represent triangle\r\nadjacencies. At any stage in the computation, the active nodes\r\nare the nodes representing badly shaped triangles and the neigh\u0002borhoods are the cavities of these triangles. In this problem, the\r\nactive nodes are not ordered.\r\nIt should be apparent that this algorithm can be parallelized\r\nby processing bad triangles in parallel as long as their cavities\r\ndo not overlap. In general, the parallelism in an algorithm with\r\namorphous data-parallelism is exploited by processing multiple\r\nelements from the worklist concurrently. Because the depen\u0002dences between elements on the worklist are very complex (e.g.,\r\nwhether or not two cavities overlap is dependent on the size\r\nand shape of the mesh), it appears as though there may be lit\u0002tle parallelism in these applications. However, we have found\r\nthat these applications do, indeed, exhibit significant parallelism\r\n[12], which we expand on in Section 4.1.\r\nKulkarni et al. [13] propose set iterators as an abstraction\r\nto express the parallelism in amorphous data-parallel programs.\r\nTwo types of iterators are used, un-ordered iterators that allow\r\nloop iterations to be executed in any order (as in Delaunay Mesh\r\nRefinement), and ordered iterators that impose a partial order on\r\nthe loop iterations. These iterators take the form of foreach\r\nstatements, where additional work can be added to the worklist\r\nbeing iterated over. Delaunay Mesh Refinement can be easily\r\nexpressed using these constructs, as seen in Figure 3. The exe\u0002cution model is straightforward: an application executes sequen\u0002tially until encountering a set iterator, at which point multiple\r\nthreads begin to execute iterations from the worklist in parallel.\r\nA runtime system manages the execution of the threads to ensure\r\nthat sequential semantics are preserved.\r\nGiven this execution model, we implemented five amorphous\r\ndata-parallel algorithms that span data mining, meshing, simu\u0002lation, and SAT solving in the Lonestar benchmark suite. We\r\ncharacterize these applications with respect to:\r\n• the amount of available parallelism in the algorithm; we use\r\ntwo metrics, the parallelism profile and the parallelism in\u0002tensity, that provide insight into the dynamic availability of\r\n1: Mesh m = /* read input mesh */\r\n2: Worklist wl = new Worklist(m.getBad());\r\n3: foreach Triangle t in wl {\r\n4: Cavity c = new Cavity(t);\r\n5: c.expand();\r\n6: c.retriangulate();\r\n7: m.updateMesh(c);\r\n8: wl.add(c.getBad());\r\n9: }\r\nFigure 3: Pseudocode for Delaunay Mesh Refinement\r\nparallel work in these algorithms for different inputs;\r\n• parallel execution (scaling) on three hardware platforms,\r\ndemonstrating that the parallelism can, indeed, be ex\u0002ploited; and\r\n• program characteristics, such as cache behavior, memory\r\naccesses, and working set sizes to provide an overview of\r\nhow the algorithmic implementation maps to architectural\r\nfeatures.\r\nThis paper makes the following contributions.\r\n• It introduces the Lonestar benchmark suite, whose focus is\r\non pointer-based (irregular) data structures and amorphous\r\ndata-parallelism. The suite covers important emerging and\r\nwell-known applications, all of which process large datasets\r\nand are long running, making it important to parallelize\r\nthem.\r\n• It reveals that these algorithms have a lot of parallelism, and\r\nthat this parallelism grows with the input size.\r\n• It demonstrate that this algorithmic parallelism can, indeed,\r\nbe exploited in parallelized implementations thereof.\r\n• It presents important workload characteristics of these pro\u0002grams. One key finding is that the transactions can be quite\r\nlarge, making them less suitable for hardware-based ap\u0002proaches.\r\nThe C++ and Java source code of the benchmark programs,\r\nsample inputs, and some documentation are available on-line at\r\nhttp://iss.ices.utexas.edu/lonestar/.\r\nThe rest of this paper is organized as follows. Section 2 ex\u0002plains the key algorithms, the data structures, and the parallelism\r\nstrategy in each of the five benchmarks. Section 3 presents our\r\nevaluation methodology. Section 4 shows the workloads’ theo\u0002retical and delivered parallelism as well as other characteristics.\r\nSection 5 discusses related work and Section 6 summarizes the\r\npaper.\r\n2 Applications\r\nThe following is a detailed description of our benchmarks, their\r\ndata structures, algorithms and parallel decomposition.\r\n2.1 Agglomerative Clustering\r\nThis benchmark is an implementation of a well-known data\u0002mining algorithm, Agglomerative Clustering [19], as used in",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/d90da515-92c7-4a24-bd90-4c745e082c96.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d5a9fcd10deb04d8c42b6322826c3ace89e9b319b0b152af51c378ccd649c7c4",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 729
      },
      {
        "segments": [
          {
            "segment_id": "32a20915-5ae1-4af8-a94d-20f9f6b31958",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 3,
            "page_width": 612,
            "page_height": 792,
            "content": "1: worklist = new Set(input_points);\r\n2: kdtree = new KDTree(input_points);\r\n3: for each Element p in worklist do {\r\n4: if (/* p already clustered */) continue;\r\n5: q = kdtree.findNearest(p);\r\n6: if (q == null) break; //stop if p is last element\r\n7: r = kdtree.findNearest(q);\r\n8: if (p == r) {\r\n//create new cluster e that contains a and b\r\n9: Element e = cluster(p,q);\r\n10: kdtree.remove(p);\r\n11: kdtree.remove(q);\r\n11: kdtree.add(e);\r\n13: worklist.add(e);\r\n14: } else { //can’t cluster yet, try again later\r\n15: worklist.add(p); //add back to worklist\r\n16: }\r\n17: }\r\nFigure 4: Psuedocode for Agglomerative Clustering\r\na\r\nb\r\nc\r\nd\r\ne\r\na\r\nb\r\nc\r\nd\r\ne\r\na b c d e\r\n(a) Data points (b) Hierarchical clusters (c) Dendrogram\r\nFigure 5: Example of Agglomerative Clustering\r\nthe graphics application Lightcuts [21]. The input to the clus\u0002tering algorithm is (1) a data-set consisting of points in an N\u0002dimensional space and (2) a measure of the similarity between\r\nitems in the data-set. We refer to this measure of similarity as a\r\ndistance metric; the more dissimilar items are, the farther apart\r\nthey are according to the distance metric. The output of the algo\u0002rithm is a binary tree (called a dendrogram) representing a hier\u0002archical, pair-wise clustering of the items in the data set. Figure\r\n5(a) shows a data-set containing points in the plane, with a dis\u0002tance metric corresponding to Euclidean distance. The clustering\r\nfor the data-set is in Figure 5(b), and the resulting dendrogram is\r\nin Figure 5(c).\r\nWe implement an Agglomerative Clustering algorithm first\r\ndescribed by Walter et al. [20], which is based on the follow\u0002ing observation: if at any time two points agree that they are one\r\nanother’s nearest neighbor, they will be clustered together in the\r\nfinal dendrogram1. Pseudocode for the algorithm is in Figure\r\n4. Initially, all data points are placed onto a worklist (line 1).\r\nWe then build a kd-tree, an acceleration structure that allows the\r\nquick determination of a point’s nearest neighbor (line 2). The\r\nalgorithm proceeds as follows. For each point p in the worklist,\r\nfind its nearest neighbor q (line 5) and determine if q’s nearest\r\nneighbor is p (lines 6-8). If so, cluster p and q and insert a new\r\npoint into the worklist representing the cluster (lines 9-13). Oth\u0002erwise, place p back onto the worklist (line 15). The algorithm\r\nterminates when there is only one point left in the worklist.\r\nThere are two key data structures in Agglomerative Cluster\u0002ing:\r\n1Subject to certain conditions on the distance metric\r\n• Unordered Set: The points left to be clustered can be pro\u0002cessed in any order, so the worklist holding those points is\r\nrepresented as an unordered set.\r\n• KD-Tree: The kd-tree represents a hierarchical decompo\u0002sition of the point space in a manner similar to an octree.\r\nIt is built prior to performing clustering as a means of ac\u0002celerating nearest-neighbor queries. Rather than requiring\r\nO(n) time to find a point’s nearest neighbor, the kd-tree\r\nallows the search to occur in O(logn) time. It is kept up\u0002to-date throughout execution by removing clustered points\r\nand adding newly created clusters. The kd-tree interface is\r\nessentially that of a set (supporting addition and removal)\r\naugmented with a nearest-neighbor method.\r\nParallelism The active nodes in agglomerative clustering are\r\nthe points to be clustered; they can be processed in any order.\r\nIntuitively, two points can be processed simultaneously if their\r\nclustering decisions are independent. This means that the follow\u0002ing conditions must hold: (i) the formed clusters must involve\r\ndifferent points (otherwise, both iterations would attempt to re\u0002move the same point from the kd-tree) and (ii) the newly added\r\npoints must not interfere with the nearest neighbor computations\r\nperformed by other iterations.\r\n2.2 Barnes-Hut\r\nThis benchmark simulates the gravitational forces acting on a\r\ngalactic cluster using the Barnes-Hut n-body algorithm [3]. The\r\npositions and velocities of the n galaxies are initialized according\r\nto the empirical Plummer model. The program calculates the\r\nmotion of each galaxy through space for a number of time steps.\r\nThe Barnes-Hut force-calculation algorithm employs a hier\u0002archical data Structure, called an octree, to approximately com\u0002pute the force that the n bodies in the system induce upon each\r\nother. With n bodies, O(n2) interactions need to be considered,\r\ni.e., the precise calculation is quadratic in the number of bodies.\r\nThe Barnes-Hut algorithm hierarchically partitions the volume\r\naround the n bodies into successively smaller cells. Each cell\r\nforms an internal node of the octree and summarizes information\r\nabout the bodies it contains, in particular their combined mass\r\nand center of gravity. The leaves of the octree are the individual\r\nbodies. This hierarchy reduces the time to calculate the force on\r\nthe n bodies to O(nlogn) because, for cells that are sufficiently\r\nfar away, it suffices to perform only one force calculation with\r\nthe cell instead of performing one calculation with every body\r\ninside the cell.\r\nStep by step, the algorithm works as follows (pseudocode is in\r\nFigure 6). First, the list of bodies is initialized with the starting\r\nlocation and velocity of each body (line 1). Then the code iterates\r\nover the time steps (line 2). In each iteration, a new octree (i.e.,\r\nspatial hierarchy) is generated by inserting all bodies (lines 3 -\r\n6). Then the cumulative mass and center of mass of each cell\r\nis recursively computed (line 7). Next, the force acting on each\r\nbody is computed (lines 8 - 10) by traversing the octree. The\r\ntraversal along any path is terminated as soon as a leaf node (i.e.,",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/32a20915-5ae1-4af8-a94d-20f9f6b31958.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=9561a1ec10925bd38ddca4d688d64686b7ce250f2a5e6a9738b8cea14efd3b80",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 913
      },
      {
        "segments": [
          {
            "segment_id": "32a20915-5ae1-4af8-a94d-20f9f6b31958",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 3,
            "page_width": 612,
            "page_height": 792,
            "content": "1: worklist = new Set(input_points);\r\n2: kdtree = new KDTree(input_points);\r\n3: for each Element p in worklist do {\r\n4: if (/* p already clustered */) continue;\r\n5: q = kdtree.findNearest(p);\r\n6: if (q == null) break; //stop if p is last element\r\n7: r = kdtree.findNearest(q);\r\n8: if (p == r) {\r\n//create new cluster e that contains a and b\r\n9: Element e = cluster(p,q);\r\n10: kdtree.remove(p);\r\n11: kdtree.remove(q);\r\n11: kdtree.add(e);\r\n13: worklist.add(e);\r\n14: } else { //can’t cluster yet, try again later\r\n15: worklist.add(p); //add back to worklist\r\n16: }\r\n17: }\r\nFigure 4: Psuedocode for Agglomerative Clustering\r\na\r\nb\r\nc\r\nd\r\ne\r\na\r\nb\r\nc\r\nd\r\ne\r\na b c d e\r\n(a) Data points (b) Hierarchical clusters (c) Dendrogram\r\nFigure 5: Example of Agglomerative Clustering\r\nthe graphics application Lightcuts [21]. The input to the clus\u0002tering algorithm is (1) a data-set consisting of points in an N\u0002dimensional space and (2) a measure of the similarity between\r\nitems in the data-set. We refer to this measure of similarity as a\r\ndistance metric; the more dissimilar items are, the farther apart\r\nthey are according to the distance metric. The output of the algo\u0002rithm is a binary tree (called a dendrogram) representing a hier\u0002archical, pair-wise clustering of the items in the data set. Figure\r\n5(a) shows a data-set containing points in the plane, with a dis\u0002tance metric corresponding to Euclidean distance. The clustering\r\nfor the data-set is in Figure 5(b), and the resulting dendrogram is\r\nin Figure 5(c).\r\nWe implement an Agglomerative Clustering algorithm first\r\ndescribed by Walter et al. [20], which is based on the follow\u0002ing observation: if at any time two points agree that they are one\r\nanother’s nearest neighbor, they will be clustered together in the\r\nfinal dendrogram1. Pseudocode for the algorithm is in Figure\r\n4. Initially, all data points are placed onto a worklist (line 1).\r\nWe then build a kd-tree, an acceleration structure that allows the\r\nquick determination of a point’s nearest neighbor (line 2). The\r\nalgorithm proceeds as follows. For each point p in the worklist,\r\nfind its nearest neighbor q (line 5) and determine if q’s nearest\r\nneighbor is p (lines 6-8). If so, cluster p and q and insert a new\r\npoint into the worklist representing the cluster (lines 9-13). Oth\u0002erwise, place p back onto the worklist (line 15). The algorithm\r\nterminates when there is only one point left in the worklist.\r\nThere are two key data structures in Agglomerative Cluster\u0002ing:\r\n1Subject to certain conditions on the distance metric\r\n• Unordered Set: The points left to be clustered can be pro\u0002cessed in any order, so the worklist holding those points is\r\nrepresented as an unordered set.\r\n• KD-Tree: The kd-tree represents a hierarchical decompo\u0002sition of the point space in a manner similar to an octree.\r\nIt is built prior to performing clustering as a means of ac\u0002celerating nearest-neighbor queries. Rather than requiring\r\nO(n) time to find a point’s nearest neighbor, the kd-tree\r\nallows the search to occur in O(logn) time. It is kept up\u0002to-date throughout execution by removing clustered points\r\nand adding newly created clusters. The kd-tree interface is\r\nessentially that of a set (supporting addition and removal)\r\naugmented with a nearest-neighbor method.\r\nParallelism The active nodes in agglomerative clustering are\r\nthe points to be clustered; they can be processed in any order.\r\nIntuitively, two points can be processed simultaneously if their\r\nclustering decisions are independent. This means that the follow\u0002ing conditions must hold: (i) the formed clusters must involve\r\ndifferent points (otherwise, both iterations would attempt to re\u0002move the same point from the kd-tree) and (ii) the newly added\r\npoints must not interfere with the nearest neighbor computations\r\nperformed by other iterations.\r\n2.2 Barnes-Hut\r\nThis benchmark simulates the gravitational forces acting on a\r\ngalactic cluster using the Barnes-Hut n-body algorithm [3]. The\r\npositions and velocities of the n galaxies are initialized according\r\nto the empirical Plummer model. The program calculates the\r\nmotion of each galaxy through space for a number of time steps.\r\nThe Barnes-Hut force-calculation algorithm employs a hier\u0002archical data Structure, called an octree, to approximately com\u0002pute the force that the n bodies in the system induce upon each\r\nother. With n bodies, O(n2) interactions need to be considered,\r\ni.e., the precise calculation is quadratic in the number of bodies.\r\nThe Barnes-Hut algorithm hierarchically partitions the volume\r\naround the n bodies into successively smaller cells. Each cell\r\nforms an internal node of the octree and summarizes information\r\nabout the bodies it contains, in particular their combined mass\r\nand center of gravity. The leaves of the octree are the individual\r\nbodies. This hierarchy reduces the time to calculate the force on\r\nthe n bodies to O(nlogn) because, for cells that are sufficiently\r\nfar away, it suffices to perform only one force calculation with\r\nthe cell instead of performing one calculation with every body\r\ninside the cell.\r\nStep by step, the algorithm works as follows (pseudocode is in\r\nFigure 6). First, the list of bodies is initialized with the starting\r\nlocation and velocity of each body (line 1). Then the code iterates\r\nover the time steps (line 2). In each iteration, a new octree (i.e.,\r\nspatial hierarchy) is generated by inserting all bodies (lines 3 -\r\n6). Then the cumulative mass and center of mass of each cell\r\nis recursively computed (line 7). Next, the force acting on each\r\nbody is computed (lines 8 - 10) by traversing the octree. The\r\ntraversal along any path is terminated as soon as a leaf node (i.e.,",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/32a20915-5ae1-4af8-a94d-20f9f6b31958.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=9561a1ec10925bd38ddca4d688d64686b7ce250f2a5e6a9738b8cea14efd3b80",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 913
      },
      {
        "segments": [
          {
            "segment_id": "29d6f7ba-36a9-4b44-9d58-7ed6dcde03ee",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 4,
            "page_width": 612,
            "page_height": 792,
            "content": "1: List bodylist = ...\r\n2: foreach timestep do {\r\n3: Octree octree;\r\n4: foreach Body b in bodylist {\r\n5: octree.Insert(b);\r\n6: }\r\n7: octree.SummarizeSubtrees();\r\n8: foreach Body b in bodylist {\r\n9: b.ComputeForce(octree);\r\n10: }\r\n11: foreach Body b in bodylist {\r\n12: b.Advance();\r\n13: }\r\n14: }\r\nFigure 6: Pseudocode for Barnes-Hut\r\na body) or an internal node (i.e., a cell) that is far enough away\r\nis encountered. Finally, each body’s position and velocity are\r\nupdated based on the computed force (lines 11 - 13).\r\nThere are two key data structures in Barnes-Hut:\r\n• Unordered list: The bodies are stored in an unordered list,\r\nas they can be processed in any order.\r\n• Octree: The spatial hierarchy is represented by an octree\r\n(the 3-dimensional equivalent of a binary tree), where each\r\nnode has up to eight children. The leaves of the octree corre\u0002spond to individual bodies whereas the internal nodes repre\u0002sent cells that contain multiple spatially nearby bodies. This\r\ndata structure supports the insertion of bodies and recursive\r\ntraversal.\r\nParallelism While many phases of Barnes-Hut can be par\u0002allelized (including building the octree and calculating the\r\nsummary information), we focus on parallelizing the force\u0002computation step, which consumes the vast majority of the run\u0002time. The active nodes in this step are the bodies. Calculating the\r\nforce on each body requires reading some portion of the octree,\r\nso the accessed nodes and edges form the body’s neighborhood.\r\nHowever, because these accesses are read-only, the bodies can be\r\nprocessed in any order, and in parallel, provided that a body does\r\nnot update its position and velocity until all force computations\r\nare complete.\r\n2.3 Delaunay Mesh Refinement\r\nThis benchmark is an implementation of the algorithm described\r\nby Kulkarni et al. [13]. It is the algorithm discussed in Sec\u0002tion 1. The application produces a guaranteed quality Delaunay\r\nmesh, which is a Delaunay triangulation with the additional qual\u0002ity constraint that no angle in the mesh be less than 30 degrees.\r\nThe benchmark takes as input an unrefined Delaunay triangula\u0002tion and produces a new mesh that satisfies the quality constraint.\r\nThe algorithm is initialized with a worklist of all the triangles\r\nin the input mesh that do not meet the quality constraints, called\r\n“bad” triangles. In each step, the refinement procedure (i) picks a\r\nbad triangle from the worklist, (ii) collects the affected triangles\r\nin the neighborhood of that bad triangle (called the cavity, shown\r\nin grey in Figure 2(a)), and (iii) re-triangulates the cavity (creat\u0002ing the new grey triangles in Figure 2(b)). If this re-triangulation\r\ncreates new badly-shaped triangles in the cavity, these are pro\u0002cessed as well until all bad triangles have been eliminated from\r\nthe mesh. The order in which the bad triangles are processed is\r\nirrelevant—all orders lead to a valid refined mesh.\r\nIn more detail, the algorithm proceeds as follows (pseudocode\r\nis provided in Figure 3). After reading in the input mesh (line 1),\r\na worklist is initialized with the bad triangles in the mesh (line 2).\r\nFor each bad triangle, a cavity is created (line 4) and expanded\r\nto encompass the neighboring triangles (line 5). The algorithm\r\nthen determines the new triangles that should be created (line\r\n6) and updates the original mesh by removing the old triangles\r\nand adding the new triangles (line 7). Recall that the order of\r\nprocessing is irrelevant in this algorithm, so the foreach in line 3\r\niterates over an unordered set.\r\nThere are two key data structures used in Delaunay Mesh Re\u0002finement:\r\n• Unordered Set: The worklist used to hold the bad triangles\r\nis represented as an unordered set as the triangles can be\r\nprocessed in any order.\r\n• Graph: The mesh is represented as a graph. Triangles in\r\nthe mesh are represented as nodes in the graph, and triangle\r\nadjacency is represented by edges between nodes. The data\r\nstructure supports the addition and removal of nodes and\r\nedges, membership tests for nodes and edges, and a method\r\nthat returns the neighbors of a given node (this is used dur\u0002ing cavity expansion).\r\nParallelism As discussed in Section 1, the active nodes in De\u0002launay Mesh Refinement are the bad triangles; the algorithm can\r\nbe parallelized by processing multiple bad triangles simultane\u0002ously. Because the neighborhood of a bad triangle is its cavity,\r\nthis may result in significant parallelism if the triangles are far\r\nenough apart so that their cavities do not overlap (as in Figure 2,\r\nwhere all of the bad triangles can be processed in parallel).\r\n2.4 Delaunay Triangulation\r\nThis benchmark produces a Delaunay Triangulation given a set\r\nof points. It implements the algorithm proposed by Guibas et\r\nal. [11]. The algorithm produces a 2D Delaunay mesh given a\r\nset of points in a plane. It can be used to generate inputs for\r\nDelaunay mesh refinement.\r\nThe algorithm proceeds as follows. A worklist is initialized\r\nwith the points to be inserted, and the mesh is initialized with a\r\nsingle, large triangle encompassing all the points. In each step,\r\nthe triangulation procedure (i) picks a new point from the work\u0002list; (ii) determines which triangle contains the point; (iii) splits\r\nthis triangle into three new triangles that share the point; and (iv)\r\nre-triangulates the neighborhood. The order in which the points\r\nare processed is irrelevant—all orders lead to the same valid De\u0002launay mesh.\r\nIn more detail, the algorithm proceeds as follows (pseudocode\r\nis provided in Figure 7). After initializing the mesh with one sur-",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/29d6f7ba-36a9-4b44-9d58-7ed6dcde03ee.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=88cd039322c6f2e6e9ce7fb5d78b9553867dff57960036033a10c3052a9c6546",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 897
      },
      {
        "segments": [
          {
            "segment_id": "29d6f7ba-36a9-4b44-9d58-7ed6dcde03ee",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 4,
            "page_width": 612,
            "page_height": 792,
            "content": "1: List bodylist = ...\r\n2: foreach timestep do {\r\n3: Octree octree;\r\n4: foreach Body b in bodylist {\r\n5: octree.Insert(b);\r\n6: }\r\n7: octree.SummarizeSubtrees();\r\n8: foreach Body b in bodylist {\r\n9: b.ComputeForce(octree);\r\n10: }\r\n11: foreach Body b in bodylist {\r\n12: b.Advance();\r\n13: }\r\n14: }\r\nFigure 6: Pseudocode for Barnes-Hut\r\na body) or an internal node (i.e., a cell) that is far enough away\r\nis encountered. Finally, each body’s position and velocity are\r\nupdated based on the computed force (lines 11 - 13).\r\nThere are two key data structures in Barnes-Hut:\r\n• Unordered list: The bodies are stored in an unordered list,\r\nas they can be processed in any order.\r\n• Octree: The spatial hierarchy is represented by an octree\r\n(the 3-dimensional equivalent of a binary tree), where each\r\nnode has up to eight children. The leaves of the octree corre\u0002spond to individual bodies whereas the internal nodes repre\u0002sent cells that contain multiple spatially nearby bodies. This\r\ndata structure supports the insertion of bodies and recursive\r\ntraversal.\r\nParallelism While many phases of Barnes-Hut can be par\u0002allelized (including building the octree and calculating the\r\nsummary information), we focus on parallelizing the force\u0002computation step, which consumes the vast majority of the run\u0002time. The active nodes in this step are the bodies. Calculating the\r\nforce on each body requires reading some portion of the octree,\r\nso the accessed nodes and edges form the body’s neighborhood.\r\nHowever, because these accesses are read-only, the bodies can be\r\nprocessed in any order, and in parallel, provided that a body does\r\nnot update its position and velocity until all force computations\r\nare complete.\r\n2.3 Delaunay Mesh Refinement\r\nThis benchmark is an implementation of the algorithm described\r\nby Kulkarni et al. [13]. It is the algorithm discussed in Sec\u0002tion 1. The application produces a guaranteed quality Delaunay\r\nmesh, which is a Delaunay triangulation with the additional qual\u0002ity constraint that no angle in the mesh be less than 30 degrees.\r\nThe benchmark takes as input an unrefined Delaunay triangula\u0002tion and produces a new mesh that satisfies the quality constraint.\r\nThe algorithm is initialized with a worklist of all the triangles\r\nin the input mesh that do not meet the quality constraints, called\r\n“bad” triangles. In each step, the refinement procedure (i) picks a\r\nbad triangle from the worklist, (ii) collects the affected triangles\r\nin the neighborhood of that bad triangle (called the cavity, shown\r\nin grey in Figure 2(a)), and (iii) re-triangulates the cavity (creat\u0002ing the new grey triangles in Figure 2(b)). If this re-triangulation\r\ncreates new badly-shaped triangles in the cavity, these are pro\u0002cessed as well until all bad triangles have been eliminated from\r\nthe mesh. The order in which the bad triangles are processed is\r\nirrelevant—all orders lead to a valid refined mesh.\r\nIn more detail, the algorithm proceeds as follows (pseudocode\r\nis provided in Figure 3). After reading in the input mesh (line 1),\r\na worklist is initialized with the bad triangles in the mesh (line 2).\r\nFor each bad triangle, a cavity is created (line 4) and expanded\r\nto encompass the neighboring triangles (line 5). The algorithm\r\nthen determines the new triangles that should be created (line\r\n6) and updates the original mesh by removing the old triangles\r\nand adding the new triangles (line 7). Recall that the order of\r\nprocessing is irrelevant in this algorithm, so the foreach in line 3\r\niterates over an unordered set.\r\nThere are two key data structures used in Delaunay Mesh Re\u0002finement:\r\n• Unordered Set: The worklist used to hold the bad triangles\r\nis represented as an unordered set as the triangles can be\r\nprocessed in any order.\r\n• Graph: The mesh is represented as a graph. Triangles in\r\nthe mesh are represented as nodes in the graph, and triangle\r\nadjacency is represented by edges between nodes. The data\r\nstructure supports the addition and removal of nodes and\r\nedges, membership tests for nodes and edges, and a method\r\nthat returns the neighbors of a given node (this is used dur\u0002ing cavity expansion).\r\nParallelism As discussed in Section 1, the active nodes in De\u0002launay Mesh Refinement are the bad triangles; the algorithm can\r\nbe parallelized by processing multiple bad triangles simultane\u0002ously. Because the neighborhood of a bad triangle is its cavity,\r\nthis may result in significant parallelism if the triangles are far\r\nenough apart so that their cavities do not overlap (as in Figure 2,\r\nwhere all of the bad triangles can be processed in parallel).\r\n2.4 Delaunay Triangulation\r\nThis benchmark produces a Delaunay Triangulation given a set\r\nof points. It implements the algorithm proposed by Guibas et\r\nal. [11]. The algorithm produces a 2D Delaunay mesh given a\r\nset of points in a plane. It can be used to generate inputs for\r\nDelaunay mesh refinement.\r\nThe algorithm proceeds as follows. A worklist is initialized\r\nwith the points to be inserted, and the mesh is initialized with a\r\nsingle, large triangle encompassing all the points. In each step,\r\nthe triangulation procedure (i) picks a new point from the work\u0002list; (ii) determines which triangle contains the point; (iii) splits\r\nthis triangle into three new triangles that share the point; and (iv)\r\nre-triangulates the neighborhood. The order in which the points\r\nare processed is irrelevant—all orders lead to the same valid De\u0002launay mesh.\r\nIn more detail, the algorithm proceeds as follows (pseudocode\r\nis provided in Figure 7). After initializing the mesh with one sur-",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/29d6f7ba-36a9-4b44-9d58-7ed6dcde03ee.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=88cd039322c6f2e6e9ce7fb5d78b9553867dff57960036033a10c3052a9c6546",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 897
      },
      {
        "segments": [
          {
            "segment_id": "ceed0939-6b61-4171-86f4-dd5363da0ab1",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 5,
            "page_width": 612,
            "page_height": 792,
            "content": "1: Mesh m = /* initialize with one\r\nsurrounding triangle */\r\n2: Set<Point> points = /* read\r\npoints to insert */\r\n3: Worklist wl;\r\n4: wl.add(points);\r\n5: foreach Point p in wl {\r\n6: Triangle t = m.surrounding(p);\r\n7: Triangle newSplit[3] =\r\nm.splitTriangle(t, p);\r\n8: Worklist wl2;\r\n9: wl2.add(edges(newSplit));\r\n10: for each Edge e in wl2 {\r\n11: if (!isDelaunay(e)) {\r\n12: Triangle newFlipped[2] =\r\nm.flipEdge(e);\r\n13: wl2.add(edges(newFlipped))\r\n14: }\r\n15: }\r\n16: }\r\nFigure 7: Pseudocode for Delaunay Triangulation\r\nrounding triangle (line 1), a worklist is initialized with the set of\r\ninput points (lines 2-4). For each point p in the worklist (line 5),\r\nthe triangle t that contains p is retrieved (line 6). Then t is split\r\ninto three new triangles such that they share the point p (line 7).\r\nBecause these new triangles may not satisfy the Delaunay prop\u0002erty, a procedure called edge flipping is applied to restore the\r\nDelaunay property (lines 9-15); If any edge of the newly created\r\ntriangles is non-Delaunay, the edge is flipped, removing the two\r\nnon-Delaunay triangles and replacing them with two new trian\u0002gles (line 12). The edges of these newly created triangles are\r\nexamined in turn (line 13). Thus, at the end of each iteration of\r\nthe outer loop, the resulting mesh is once again a Delaunay mesh.\r\nRecall that the order of processing is irrelevant in this algorithm,\r\nso the foreach in line 5 iterates over an unordered set.\r\nThere are three key data structures used in Delaunay Triangu\u0002lation:\r\n• Unordered Set: The worklist used to hold the 2D points\r\nis represented as an unordered set, as the points can be in\u0002serted in any order.\r\n• Graph: The mesh is represented as a graph, as in Delaunay\r\nrefinement.\r\n• History DAG: To efficiently locate the triangle containing\r\na given point, a data structure called history DAG is used,\r\nwhich behaves like a ternary search tree. After each step of\r\nthe algorithm, the leaves represent the triangles in the cur\u0002rent mesh. Splitting a triangle (line 9) adds three children\r\nto the data structure corresponding to the three newly cre\u0002ated triangles. When an edge is flipped (line 12), the two\r\nnew triangles are children of both old triangles, so the data\r\nstructure is a DAG in general, rather than a tree. With this\r\nstructure finding the triangle containing a point is equiva\u0002lent to traversing the history DAG from the root to the cor\u0002responding leaf. The data structure supports the addition\r\nand removal of nodes and membership tests for nodes.\r\nParallelism The active nodes in Delaunay Triangulation are\r\nthe points to be inserted into the mesh, which can be processed\r\nin any order. Processing a point requires splitting a triangle and\r\n1: FactorGraph f = /* read initial formula */\r\n2: wl.put(f.clausesAndVariables());\r\n3: foreach Node n in wl {\r\n4: if (/*time out or number of variables is small*/) {\r\n5: break;\r\n6: }\r\n7: if (n.isVariable()) {\r\n8: n.updateVariable();\r\n9: if (/* n is frozen */) {\r\n10: /* remove n from graph */\r\n11: continue;\r\n12: } else {\r\n13: n.updateClause();\r\n14: }\r\n15: wl.add(n);\r\n16: }\r\nFigure 8: Pseudocode for Survey Propagation\r\nthen flipping some set of edges; the affected triangles are in the\r\npoint’s neighborhood. Because these neighborhoods are typi\u0002cally small, connected regions of the mesh, significant paral\u0002lelism can be achieved by inserting multiple points in parallel,\r\nprovided the points affect triangles that are far apart in the mesh.\r\n2.5 Survey Propagation\r\nSurvey Propagation is a heuristic SAT-solver based on Bayesian\r\ninference [6]. The algorithm represents the Boolean formula as\r\na factor graph, a bipartite graph with variables on one side and\r\nclauses on the other. An edge connects a variable to a clause if\r\nthe variable participates in the clause. The edge is given a value\r\nof -1 if the literal in the clause is negated, and +1 otherwise. The\r\ngeneral strategy of SP is to iteratively update each variable with\r\nthe likelihood that it should be assigned a truth value of true or\r\nfalse.\r\nPseudocode is given in Figure 8. The worklist for Survey\r\nPropagation consists of all nodes (both variables and clauses)\r\nin the graph. At each step, Survey Propagation chooses a node\r\nat random and processes it. To process a node, the algorithm\r\nupdates the value of the node based on the values of its neigh\u0002bors. After a number of updates, the value for a variable may\r\nbecome “frozen” (i.e., set to true or false). At that point, the\r\nvariable is removed from the graph. If a node is not frozen, it\r\nis returned to the worklist to be processed again. As the algo\u0002rithm progresses and variables become frozen, the graph begins\r\nto shrink. Note that although the algorithm chooses variables\r\nto update at random, the algorithm is nonetheless highly order\r\ndependent: different orders of processing will lead to variables\r\nbecoming frozen at different times.\r\nThe termination condition for Survey Propagation is fairly\r\ncomplex: when the number of variables is small enough, the\r\nSurvey Propagation iterations are terminated, and the remaining\r\nproblem is solved using a local heuristic such as WalkSAT. Alter\u0002natively, if there is no progress after some number of iterations,\r\nthe algorithm may just give up.\r\nThere are two key data structures in Survey Propagation:\r\n• Unordered Set: Because the algorithm is based on itera\u0002tively updating the values of variables chosen at random, the\r\nworklist can be represented as an unordered set. There are\r\nno ordering constraints on the processing the elements of",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/ceed0939-6b61-4171-86f4-dd5363da0ab1.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=73a875f34b4584c71103ff0f79f92cb564034540ece56d6affe76cfdfadd0a30",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 910
      },
      {
        "segments": [
          {
            "segment_id": "ceed0939-6b61-4171-86f4-dd5363da0ab1",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 5,
            "page_width": 612,
            "page_height": 792,
            "content": "1: Mesh m = /* initialize with one\r\nsurrounding triangle */\r\n2: Set<Point> points = /* read\r\npoints to insert */\r\n3: Worklist wl;\r\n4: wl.add(points);\r\n5: foreach Point p in wl {\r\n6: Triangle t = m.surrounding(p);\r\n7: Triangle newSplit[3] =\r\nm.splitTriangle(t, p);\r\n8: Worklist wl2;\r\n9: wl2.add(edges(newSplit));\r\n10: for each Edge e in wl2 {\r\n11: if (!isDelaunay(e)) {\r\n12: Triangle newFlipped[2] =\r\nm.flipEdge(e);\r\n13: wl2.add(edges(newFlipped))\r\n14: }\r\n15: }\r\n16: }\r\nFigure 7: Pseudocode for Delaunay Triangulation\r\nrounding triangle (line 1), a worklist is initialized with the set of\r\ninput points (lines 2-4). For each point p in the worklist (line 5),\r\nthe triangle t that contains p is retrieved (line 6). Then t is split\r\ninto three new triangles such that they share the point p (line 7).\r\nBecause these new triangles may not satisfy the Delaunay prop\u0002erty, a procedure called edge flipping is applied to restore the\r\nDelaunay property (lines 9-15); If any edge of the newly created\r\ntriangles is non-Delaunay, the edge is flipped, removing the two\r\nnon-Delaunay triangles and replacing them with two new trian\u0002gles (line 12). The edges of these newly created triangles are\r\nexamined in turn (line 13). Thus, at the end of each iteration of\r\nthe outer loop, the resulting mesh is once again a Delaunay mesh.\r\nRecall that the order of processing is irrelevant in this algorithm,\r\nso the foreach in line 5 iterates over an unordered set.\r\nThere are three key data structures used in Delaunay Triangu\u0002lation:\r\n• Unordered Set: The worklist used to hold the 2D points\r\nis represented as an unordered set, as the points can be in\u0002serted in any order.\r\n• Graph: The mesh is represented as a graph, as in Delaunay\r\nrefinement.\r\n• History DAG: To efficiently locate the triangle containing\r\na given point, a data structure called history DAG is used,\r\nwhich behaves like a ternary search tree. After each step of\r\nthe algorithm, the leaves represent the triangles in the cur\u0002rent mesh. Splitting a triangle (line 9) adds three children\r\nto the data structure corresponding to the three newly cre\u0002ated triangles. When an edge is flipped (line 12), the two\r\nnew triangles are children of both old triangles, so the data\r\nstructure is a DAG in general, rather than a tree. With this\r\nstructure finding the triangle containing a point is equiva\u0002lent to traversing the history DAG from the root to the cor\u0002responding leaf. The data structure supports the addition\r\nand removal of nodes and membership tests for nodes.\r\nParallelism The active nodes in Delaunay Triangulation are\r\nthe points to be inserted into the mesh, which can be processed\r\nin any order. Processing a point requires splitting a triangle and\r\n1: FactorGraph f = /* read initial formula */\r\n2: wl.put(f.clausesAndVariables());\r\n3: foreach Node n in wl {\r\n4: if (/*time out or number of variables is small*/) {\r\n5: break;\r\n6: }\r\n7: if (n.isVariable()) {\r\n8: n.updateVariable();\r\n9: if (/* n is frozen */) {\r\n10: /* remove n from graph */\r\n11: continue;\r\n12: } else {\r\n13: n.updateClause();\r\n14: }\r\n15: wl.add(n);\r\n16: }\r\nFigure 8: Pseudocode for Survey Propagation\r\nthen flipping some set of edges; the affected triangles are in the\r\npoint’s neighborhood. Because these neighborhoods are typi\u0002cally small, connected regions of the mesh, significant paral\u0002lelism can be achieved by inserting multiple points in parallel,\r\nprovided the points affect triangles that are far apart in the mesh.\r\n2.5 Survey Propagation\r\nSurvey Propagation is a heuristic SAT-solver based on Bayesian\r\ninference [6]. The algorithm represents the Boolean formula as\r\na factor graph, a bipartite graph with variables on one side and\r\nclauses on the other. An edge connects a variable to a clause if\r\nthe variable participates in the clause. The edge is given a value\r\nof -1 if the literal in the clause is negated, and +1 otherwise. The\r\ngeneral strategy of SP is to iteratively update each variable with\r\nthe likelihood that it should be assigned a truth value of true or\r\nfalse.\r\nPseudocode is given in Figure 8. The worklist for Survey\r\nPropagation consists of all nodes (both variables and clauses)\r\nin the graph. At each step, Survey Propagation chooses a node\r\nat random and processes it. To process a node, the algorithm\r\nupdates the value of the node based on the values of its neigh\u0002bors. After a number of updates, the value for a variable may\r\nbecome “frozen” (i.e., set to true or false). At that point, the\r\nvariable is removed from the graph. If a node is not frozen, it\r\nis returned to the worklist to be processed again. As the algo\u0002rithm progresses and variables become frozen, the graph begins\r\nto shrink. Note that although the algorithm chooses variables\r\nto update at random, the algorithm is nonetheless highly order\r\ndependent: different orders of processing will lead to variables\r\nbecoming frozen at different times.\r\nThe termination condition for Survey Propagation is fairly\r\ncomplex: when the number of variables is small enough, the\r\nSurvey Propagation iterations are terminated, and the remaining\r\nproblem is solved using a local heuristic such as WalkSAT. Alter\u0002natively, if there is no progress after some number of iterations,\r\nthe algorithm may just give up.\r\nThere are two key data structures in Survey Propagation:\r\n• Unordered Set: Because the algorithm is based on itera\u0002tively updating the values of variables chosen at random, the\r\nworklist can be represented as an unordered set. There are\r\nno ordering constraints on the processing the elements of",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/ceed0939-6b61-4171-86f4-dd5363da0ab1.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=73a875f34b4584c71103ff0f79f92cb564034540ece56d6affe76cfdfadd0a30",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 910
      },
      {
        "segments": [
          {
            "segment_id": "2a15df0b-a0a2-4a04-8ba8-e2c4abbeaf11",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 6,
            "page_width": 612,
            "page_height": 792,
            "content": "the worklist (although, as discussed above, different orders\r\nof processing may lead to different algorithmic behavior).\r\n• Factor Graph: The bipartite graph representing the\r\nboolean formula.\r\nParallelism The active nodes in Survey Propagation are the\r\nclauses and variables of the factor graph; in other words, every\r\nnode in the graph is an active node, and they can be processed in\r\nany order. Because processing a node requires reading its neigh\u0002bors, two nodes can be processed in parallel as long as they are\r\nnot neighbors. If a variable node needs to be removed from the\r\ngraph because it is frozen, this restriction becomes a little tighter.\r\nBecause removing a variable from the factor graph requires up\u0002dating the edge information at the neighboring clause nodes, an\r\niteration that removes a variable cannot occur concurrently with\r\nan iteration that reads or writes one of the neighboring clauses.\r\n3 Evaluation Methodology\r\nFirst, we studied each algorithm to determine how much poten\u0002tial for parallelism it has. To do this, we used a profiling tool\r\ncalled ParaMeter [12], which estimates the amount of available\r\nparallelism in an algorithm with amorphous data-parallelism.\r\nDetails on ParaMeter and the results from profiling our appli\u0002cations are presented in Section 4.1.\r\nTo determine whether amorphous data-parallelism can be ex\u0002ploited to speed up program execution, we used the Galois sys\u0002tem [13] to produce a parallel version of each application. We\r\nmeasured the performance with various numbers of threads on\r\nthe following three systems.\r\n• The UltraSPARC IV system is a Sun E25K server running\r\nSunOS 5.9. It contains sixteen CPU boards with four dual\u0002core 1.05 GHz UltraSPARC IV processors. The 128 CPUs\r\nshare 512 GB of main memory. Each core has a 64 kB\r\nfour-way set-associative L1 data cache and a unified 8 MB\r\nL2 cache.\r\n• The Xeon X7350 system is a SuperMicro SuperServer\u00028045C-3R running Linux 2.6.22. It contains four CPU\r\nmodules with four-core 2.93 GHz Intel Xeon X7350 x86 64\r\nprocessors. The 16 CPUs share 48 GB of main memory.\r\nEach core has a 32 kB L1 data cache and shares a unified 4\r\nMB L2 cache with one other core.\r\n• The UltraSPARC T1 system is a Sun-Fire-T200 server\r\nrunning SunOS 5.10. It contains an eight-core 1.2 GHz Ul\u0002traSPARC T1 “Niagara” processor. The cores are four-way\r\nmultithreaded. The 32 virtual CPUs share 16 GB of main\r\nmemory. Each core has an 8 kB four-way set-associative L1\r\ndata cache and all cores share a unified 3 MB L2 cache.\r\nWe compiled the parallel code with Sun’s Java compiler ver\u0002sion 1.6.0 and ran it on the HotSpot 64-bit server virtual machine\r\non each platform. Because HotSpot dynamically compiles fre\u0002quently executed bytecode into native machine code, we repeat\r\neach experiment nine times in the same VM and report results\r\nfor the fastest run. We use a 400 GB heap on the UltraSPARC\r\nIV, a 40 GB heap on the Xeon X7350, and a 15 GB heap on the\r\nUltraSPARC T1. To minimize the interference by the garbage\r\ncollector, we force a full-heap garbage collection before execut\u0002ing the measured code section.\r\nAll measurements, other than memory footprints, are obtained\r\nthrough source-code instrumentation; that is, we read the timer\r\n(and the CPU performance counters where applicable) before\r\nand after the measured code section, compute the difference, and\r\nwrite the result to the standard output. We use the Java Native\r\nInterface and C code we wrote to access the performance coun\u0002ters on the UltraSPARC IV system. Note that the performance\r\ncounters only capture events in user mode.\r\nTo approximate the memory footprints of our applications, we\r\ndetermined the minimum heap size for which the program would\r\ncomplete when run using the HotSpot 64-bit virtual machine.\r\nBecause each program uses its maximum amount of memory\r\nduring the parallelized section, this approach suffices to find the\r\nmemory footprint of the parallel code.\r\nWe ran each benchmark with three random inputs. Note that\r\nwe only measure the core of each application and omit, for ex\u0002ample, initialization (reading in or generating the input) and fi\u0002nalization code. In all cases, the omitted code represents no more\r\nthan a few percent of the total sequential runtime.\r\n• Agglomerative Clustering The small input contains\r\n500,000, the middle input 1,000,000, and the large input\r\n2,000,000 numbers. We measure the clustering code but\r\nexclude building the kd-tree.\r\n• Barnes-Hut The small input contains 65,000, the middle\r\ninput 110,000, and the large input 220,000 bodies. The\r\nbodies’ positions and velocities are initialized according to\r\nthe empirical Plummer model. We only measure the force\r\ncalculation code. Building the octree is excluded from our\r\nmeasurements.\r\n• Delaunay Mesh Refinement The small input contains\r\n100,770 triangles of which 47,768 are initially bad, the mid\u0002dle input has 219,998 triangles of which 104,229 are ini\u0002tially bad, and the large input consists of 549,998 triangles\r\nof which 261,100 are initially bad. We only measure the\r\nrefinement algorithm. Building the initial graph and parti\u0002tioning it are excluded from our measurements.\r\n• Delaunay Triangulation The small input contains 20,000,\r\nthe middle input 40,000, and the large input 80,000 points.\r\n• Survey Propagation The small input is a Boolean formula\r\nin conjunctive normal form with three literals per clause and\r\na total of 250 variables and 1050 clauses, the medium input\r\ncontains 350 variables and 1470 clauses, and the large input\r\ncontains 500 variables and 2100 clauses.\r\n4 Workload Characterization\r\n4.1 Available Parallelism\r\nA commonality among several of the worklist algorithms we\r\nhave described is that, while the potential for parallelism exists,\r\nthe pattern of dependences between individual iterations of the",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/2a15df0b-a0a2-4a04-8ba8-e2c4abbeaf11.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=75fd11956122d330628c4381df94fe7dc27c63b290b64b242b63c6c65d03f490",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 917
      },
      {
        "segments": [
          {
            "segment_id": "2a15df0b-a0a2-4a04-8ba8-e2c4abbeaf11",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 6,
            "page_width": 612,
            "page_height": 792,
            "content": "the worklist (although, as discussed above, different orders\r\nof processing may lead to different algorithmic behavior).\r\n• Factor Graph: The bipartite graph representing the\r\nboolean formula.\r\nParallelism The active nodes in Survey Propagation are the\r\nclauses and variables of the factor graph; in other words, every\r\nnode in the graph is an active node, and they can be processed in\r\nany order. Because processing a node requires reading its neigh\u0002bors, two nodes can be processed in parallel as long as they are\r\nnot neighbors. If a variable node needs to be removed from the\r\ngraph because it is frozen, this restriction becomes a little tighter.\r\nBecause removing a variable from the factor graph requires up\u0002dating the edge information at the neighboring clause nodes, an\r\niteration that removes a variable cannot occur concurrently with\r\nan iteration that reads or writes one of the neighboring clauses.\r\n3 Evaluation Methodology\r\nFirst, we studied each algorithm to determine how much poten\u0002tial for parallelism it has. To do this, we used a profiling tool\r\ncalled ParaMeter [12], which estimates the amount of available\r\nparallelism in an algorithm with amorphous data-parallelism.\r\nDetails on ParaMeter and the results from profiling our appli\u0002cations are presented in Section 4.1.\r\nTo determine whether amorphous data-parallelism can be ex\u0002ploited to speed up program execution, we used the Galois sys\u0002tem [13] to produce a parallel version of each application. We\r\nmeasured the performance with various numbers of threads on\r\nthe following three systems.\r\n• The UltraSPARC IV system is a Sun E25K server running\r\nSunOS 5.9. It contains sixteen CPU boards with four dual\u0002core 1.05 GHz UltraSPARC IV processors. The 128 CPUs\r\nshare 512 GB of main memory. Each core has a 64 kB\r\nfour-way set-associative L1 data cache and a unified 8 MB\r\nL2 cache.\r\n• The Xeon X7350 system is a SuperMicro SuperServer\u00028045C-3R running Linux 2.6.22. It contains four CPU\r\nmodules with four-core 2.93 GHz Intel Xeon X7350 x86 64\r\nprocessors. The 16 CPUs share 48 GB of main memory.\r\nEach core has a 32 kB L1 data cache and shares a unified 4\r\nMB L2 cache with one other core.\r\n• The UltraSPARC T1 system is a Sun-Fire-T200 server\r\nrunning SunOS 5.10. It contains an eight-core 1.2 GHz Ul\u0002traSPARC T1 “Niagara” processor. The cores are four-way\r\nmultithreaded. The 32 virtual CPUs share 16 GB of main\r\nmemory. Each core has an 8 kB four-way set-associative L1\r\ndata cache and all cores share a unified 3 MB L2 cache.\r\nWe compiled the parallel code with Sun’s Java compiler ver\u0002sion 1.6.0 and ran it on the HotSpot 64-bit server virtual machine\r\non each platform. Because HotSpot dynamically compiles fre\u0002quently executed bytecode into native machine code, we repeat\r\neach experiment nine times in the same VM and report results\r\nfor the fastest run. We use a 400 GB heap on the UltraSPARC\r\nIV, a 40 GB heap on the Xeon X7350, and a 15 GB heap on the\r\nUltraSPARC T1. To minimize the interference by the garbage\r\ncollector, we force a full-heap garbage collection before execut\u0002ing the measured code section.\r\nAll measurements, other than memory footprints, are obtained\r\nthrough source-code instrumentation; that is, we read the timer\r\n(and the CPU performance counters where applicable) before\r\nand after the measured code section, compute the difference, and\r\nwrite the result to the standard output. We use the Java Native\r\nInterface and C code we wrote to access the performance coun\u0002ters on the UltraSPARC IV system. Note that the performance\r\ncounters only capture events in user mode.\r\nTo approximate the memory footprints of our applications, we\r\ndetermined the minimum heap size for which the program would\r\ncomplete when run using the HotSpot 64-bit virtual machine.\r\nBecause each program uses its maximum amount of memory\r\nduring the parallelized section, this approach suffices to find the\r\nmemory footprint of the parallel code.\r\nWe ran each benchmark with three random inputs. Note that\r\nwe only measure the core of each application and omit, for ex\u0002ample, initialization (reading in or generating the input) and fi\u0002nalization code. In all cases, the omitted code represents no more\r\nthan a few percent of the total sequential runtime.\r\n• Agglomerative Clustering The small input contains\r\n500,000, the middle input 1,000,000, and the large input\r\n2,000,000 numbers. We measure the clustering code but\r\nexclude building the kd-tree.\r\n• Barnes-Hut The small input contains 65,000, the middle\r\ninput 110,000, and the large input 220,000 bodies. The\r\nbodies’ positions and velocities are initialized according to\r\nthe empirical Plummer model. We only measure the force\r\ncalculation code. Building the octree is excluded from our\r\nmeasurements.\r\n• Delaunay Mesh Refinement The small input contains\r\n100,770 triangles of which 47,768 are initially bad, the mid\u0002dle input has 219,998 triangles of which 104,229 are ini\u0002tially bad, and the large input consists of 549,998 triangles\r\nof which 261,100 are initially bad. We only measure the\r\nrefinement algorithm. Building the initial graph and parti\u0002tioning it are excluded from our measurements.\r\n• Delaunay Triangulation The small input contains 20,000,\r\nthe middle input 40,000, and the large input 80,000 points.\r\n• Survey Propagation The small input is a Boolean formula\r\nin conjunctive normal form with three literals per clause and\r\na total of 250 variables and 1050 clauses, the medium input\r\ncontains 350 variables and 1470 clauses, and the large input\r\ncontains 500 variables and 2100 clauses.\r\n4 Workload Characterization\r\n4.1 Available Parallelism\r\nA commonality among several of the worklist algorithms we\r\nhave described is that, while the potential for parallelism exists,\r\nthe pattern of dependences between individual iterations of the",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/2a15df0b-a0a2-4a04-8ba8-e2c4abbeaf11.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=75fd11956122d330628c4381df94fe7dc27c63b290b64b242b63c6c65d03f490",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 917
      },
      {
        "segments": [
          {
            "segment_id": "f30a4f05-9533-48ac-95e6-7f305b425549",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 7,
            "page_width": 612,
            "page_height": 792,
            "content": "algorithm are quite complex. For example, in Delaunay Trian\u0002gulation, it is apparent that it should be possible to insert mul\u0002tiple points into the mesh simultaneously, provided they affect\r\ndifferent regions of the mesh. However, determining whether\r\ntwo points are, indeed, independent is non-trivial and dependent\r\non the current state of the computation as well as the two points\r\nin question.\r\nDue to the nature of these complex dependencies, it is not al\u0002ways clear that there is, in fact, any parallelism to be exploited\r\nin irregular applications such as the ones we have presented. To\r\ndetermine how much parallelism actually exists in our applica\u0002tions, we applied a profiling tool called ParaMeter [12] to our\r\nbenchmark applications.\r\nThe goal of ParaMeter is to estimate an upper bound on the\r\namount of exploitable parallelism in algorithms exhibiting amor\u0002phous data-parallelism. It does so by simulating execution of the\r\napplication on a system with an infinite number of processors.\r\nThe tool divides the execution of the algorithm into a series of\r\ndiscrete computation steps. In each step, the worklist is exam\u0002ined and a maximally independent set of iterations is executed.\r\nThat is, in each step, a set of iterations that can safely be executed\r\nin parallel is chosen and executed. Iterations are deemed inde\u0002pendent if they do not conflict algorithmically, regardless of any\r\ndependences due to specific data structure implementations or\r\nconflicts due to parallelization run-time systems such as the Ga\u0002lois system [13] or Transactional Memory [14]. In other words,\r\nthe parallelism found by ParaMeter is an intrinsic property of the\r\nalgorithm.\r\nParaMeter generates parallelism profiles and parallelism in\u0002tensity plots. A parallelism profile shows the amount of par\u0002allel work available in each computation step of an algorithm;\r\nit makes clear how the amount of available parallelism changes\r\nthroughout the execution of an application. Parallelism profiles\r\nshow the absolute amount of parallelism available at any point in\r\ntime. However, while low available parallelism may be a result\r\nof too many conflicts between iterations, it may also be a prod\u0002uct of too little work to do. Parallelism intensity addresses this\r\nby expressing the amount of parallel work as a percentage of the\r\ntotal amount of work available to be executed. Thus, a low par\u0002allel intensity means that most of the work in the worklist cannot\r\nsafely be executed in parallel, while a high intensity means that\r\nmost of the work in the worklist is independent.\r\nWe applied ParaMeter to our suite of applications, examining\r\nboth the available parallelism and the parallelism intensity across\r\nthe three input sizes for each application. The results of these\r\nprofiling runs can be seen in Figures 9(a) through 9(d).\r\nAgglomerative Clustering Agglomerative Clustering is, at its\r\nheart, a bottom-up tree-building algorithm. We note that the tree\r\ncan be built level-by-level in parallel: all the leaves can be clus\u0002tered simultaneously, then the second-to-last level, and so forth.\r\nThe amount of parallelism is thus proportional to the number of\r\nnodes at each level of the tree. Intuitively, building a bushy tree\r\nwill allow more parallelism than building a skinny tree.\r\nBecause the points in our Agglomerative Clustering inputs are\r\nrandomly generated, we expect relatively bushy trees, and hence\r\na pattern of parallelism that begins high and rapidly decreases as\r\ncomputation progresses. This is precisely the behavior we see in\r\nthe parallelism profiles of Figure 9(a). Further, as the computa\u0002tion progresses, we see that the parallelism intensity (shown in\r\nFigure 9(b)) decreases as well, until the end of the computation,\r\nwhen there is little work in the worklist. If we were building a\r\ncomplete, balanced binary tree, we would expect the intensity\r\nto remain constant: at each step, all of the points in the work\u0002list could be clustered. This would result in an intensity of 50%,\r\nas for each pair of points, only one could complete successfully.\r\nOur results are lower than that as the inputs do not lead to such\r\na tree. Finally, we note that, as we increase the input size, the\r\namount of parallelism scales roughly linearly.\r\nBarnes-Hut The parallelized portion of Barnes-Hut, the force\r\ncalculation code, is embarrassingly parallel; there are no con\u0002flicts between any of the iterations in the worklist. As a result,\r\nthe parallelism profile and parallelism intensity plot for the appli\u0002cation are uninteresting. All the iterations can be safely executed\r\nin parallel in a single computation step, and the parallelism in\u0002tensity is 100% for that step. This is true for all input sizes.\r\nDelaunay Mesh Refinement In the abstract, Delaunay Mesh\r\nRefinement is a graph refinement code. The current mesh is rep\u0002resented as a graph, with nodes of the graph representing trian\u0002gles in the mesh and edges between nodes representing triangle\r\nadjacency. When processing a bad triangle, the cavity formed is a\r\nsmall, connected set of triangles, which is a subgraph of the over\u0002all graph. The retriangulated cavity is another subgraph, contain\u0002ing more nodes than the subgraph it is replacing, and hence the\r\ngraph becomes larger. As the graph becomes bigger, the likeli\u0002hood of two cavities overlapping decreases, so we would expect\r\nthe available parallelism and parallelism intensity to increase.\r\nWe see that the parallelism profiles for Delaunay Mesh Re\u0002finement (the top graphs in Figure 9(b)) behave largely as ex\u0002pected: we start out with a significant amount of parallelism; as\r\nthe graph becomes larger, the amount of parallelism increases,\r\nuntil it begins to drop as the algorithm runs out of work to do.\r\nThe parallelism intensity plots (the bottom graphs in Figure 9(b))\r\nshow the expected increase in intensity. However, even though\r\nthe graph continues to get bigger throughout execution, by the\r\nmiddle portion of the computation, the intensity stops increas\u0002ing. This runs contrary to our expectation of increasing paral\u0002lelism as the graph grows. This is because parallelism intensity\r\nincreases as the graph grows larger only if the work is uniformly\r\ndistributed through the graph. Initially, bad triangles are uni\u0002formly distributed through the mesh, so the intensity increases\r\nas the mesh becomes larger and more computations become in\u0002dependent. Eventually, however, the majority of the work in\r\nthe worklist is from bad triangles created by retriangulation—in\r\nother words, newly created work. This work, rather than being\r\nuniformly distributed, is created at the site of retriangulations.\r\nSuppose retriangulating a cavity produces, on average, two new\r\nbad triangles. No matter how large the graph is, those two bad",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/f30a4f05-9533-48ac-95e6-7f305b425549.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c6931beb180d331a6514bef7051f0a4f5532ed24bfe36d2b0b0faecfbe403949",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 1047
      },
      {
        "segments": [
          {
            "segment_id": "f30a4f05-9533-48ac-95e6-7f305b425549",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 7,
            "page_width": 612,
            "page_height": 792,
            "content": "algorithm are quite complex. For example, in Delaunay Trian\u0002gulation, it is apparent that it should be possible to insert mul\u0002tiple points into the mesh simultaneously, provided they affect\r\ndifferent regions of the mesh. However, determining whether\r\ntwo points are, indeed, independent is non-trivial and dependent\r\non the current state of the computation as well as the two points\r\nin question.\r\nDue to the nature of these complex dependencies, it is not al\u0002ways clear that there is, in fact, any parallelism to be exploited\r\nin irregular applications such as the ones we have presented. To\r\ndetermine how much parallelism actually exists in our applica\u0002tions, we applied a profiling tool called ParaMeter [12] to our\r\nbenchmark applications.\r\nThe goal of ParaMeter is to estimate an upper bound on the\r\namount of exploitable parallelism in algorithms exhibiting amor\u0002phous data-parallelism. It does so by simulating execution of the\r\napplication on a system with an infinite number of processors.\r\nThe tool divides the execution of the algorithm into a series of\r\ndiscrete computation steps. In each step, the worklist is exam\u0002ined and a maximally independent set of iterations is executed.\r\nThat is, in each step, a set of iterations that can safely be executed\r\nin parallel is chosen and executed. Iterations are deemed inde\u0002pendent if they do not conflict algorithmically, regardless of any\r\ndependences due to specific data structure implementations or\r\nconflicts due to parallelization run-time systems such as the Ga\u0002lois system [13] or Transactional Memory [14]. In other words,\r\nthe parallelism found by ParaMeter is an intrinsic property of the\r\nalgorithm.\r\nParaMeter generates parallelism profiles and parallelism in\u0002tensity plots. A parallelism profile shows the amount of par\u0002allel work available in each computation step of an algorithm;\r\nit makes clear how the amount of available parallelism changes\r\nthroughout the execution of an application. Parallelism profiles\r\nshow the absolute amount of parallelism available at any point in\r\ntime. However, while low available parallelism may be a result\r\nof too many conflicts between iterations, it may also be a prod\u0002uct of too little work to do. Parallelism intensity addresses this\r\nby expressing the amount of parallel work as a percentage of the\r\ntotal amount of work available to be executed. Thus, a low par\u0002allel intensity means that most of the work in the worklist cannot\r\nsafely be executed in parallel, while a high intensity means that\r\nmost of the work in the worklist is independent.\r\nWe applied ParaMeter to our suite of applications, examining\r\nboth the available parallelism and the parallelism intensity across\r\nthe three input sizes for each application. The results of these\r\nprofiling runs can be seen in Figures 9(a) through 9(d).\r\nAgglomerative Clustering Agglomerative Clustering is, at its\r\nheart, a bottom-up tree-building algorithm. We note that the tree\r\ncan be built level-by-level in parallel: all the leaves can be clus\u0002tered simultaneously, then the second-to-last level, and so forth.\r\nThe amount of parallelism is thus proportional to the number of\r\nnodes at each level of the tree. Intuitively, building a bushy tree\r\nwill allow more parallelism than building a skinny tree.\r\nBecause the points in our Agglomerative Clustering inputs are\r\nrandomly generated, we expect relatively bushy trees, and hence\r\na pattern of parallelism that begins high and rapidly decreases as\r\ncomputation progresses. This is precisely the behavior we see in\r\nthe parallelism profiles of Figure 9(a). Further, as the computa\u0002tion progresses, we see that the parallelism intensity (shown in\r\nFigure 9(b)) decreases as well, until the end of the computation,\r\nwhen there is little work in the worklist. If we were building a\r\ncomplete, balanced binary tree, we would expect the intensity\r\nto remain constant: at each step, all of the points in the work\u0002list could be clustered. This would result in an intensity of 50%,\r\nas for each pair of points, only one could complete successfully.\r\nOur results are lower than that as the inputs do not lead to such\r\na tree. Finally, we note that, as we increase the input size, the\r\namount of parallelism scales roughly linearly.\r\nBarnes-Hut The parallelized portion of Barnes-Hut, the force\r\ncalculation code, is embarrassingly parallel; there are no con\u0002flicts between any of the iterations in the worklist. As a result,\r\nthe parallelism profile and parallelism intensity plot for the appli\u0002cation are uninteresting. All the iterations can be safely executed\r\nin parallel in a single computation step, and the parallelism in\u0002tensity is 100% for that step. This is true for all input sizes.\r\nDelaunay Mesh Refinement In the abstract, Delaunay Mesh\r\nRefinement is a graph refinement code. The current mesh is rep\u0002resented as a graph, with nodes of the graph representing trian\u0002gles in the mesh and edges between nodes representing triangle\r\nadjacency. When processing a bad triangle, the cavity formed is a\r\nsmall, connected set of triangles, which is a subgraph of the over\u0002all graph. The retriangulated cavity is another subgraph, contain\u0002ing more nodes than the subgraph it is replacing, and hence the\r\ngraph becomes larger. As the graph becomes bigger, the likeli\u0002hood of two cavities overlapping decreases, so we would expect\r\nthe available parallelism and parallelism intensity to increase.\r\nWe see that the parallelism profiles for Delaunay Mesh Re\u0002finement (the top graphs in Figure 9(b)) behave largely as ex\u0002pected: we start out with a significant amount of parallelism; as\r\nthe graph becomes larger, the amount of parallelism increases,\r\nuntil it begins to drop as the algorithm runs out of work to do.\r\nThe parallelism intensity plots (the bottom graphs in Figure 9(b))\r\nshow the expected increase in intensity. However, even though\r\nthe graph continues to get bigger throughout execution, by the\r\nmiddle portion of the computation, the intensity stops increas\u0002ing. This runs contrary to our expectation of increasing paral\u0002lelism as the graph grows. This is because parallelism intensity\r\nincreases as the graph grows larger only if the work is uniformly\r\ndistributed through the graph. Initially, bad triangles are uni\u0002formly distributed through the mesh, so the intensity increases\r\nas the mesh becomes larger and more computations become in\u0002dependent. Eventually, however, the majority of the work in\r\nthe worklist is from bad triangles created by retriangulation—in\r\nother words, newly created work. This work, rather than being\r\nuniformly distributed, is created at the site of retriangulations.\r\nSuppose retriangulating a cavity produces, on average, two new\r\nbad triangles. No matter how large the graph is, those two bad",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/f30a4f05-9533-48ac-95e6-7f305b425549.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c6931beb180d331a6514bef7051f0a4f5532ed24bfe36d2b0b0faecfbe403949",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 1047
      },
      {
        "segments": [
          {
            "segment_id": "f20d864c-2458-4350-ab64-6ae2e42a763b",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 8,
            "page_width": 612,
            "page_height": 792,
            "content": "0 20 40 60 80\r\nComputation Step\r\n0\r\n20000\r\n40000\r\n60000\r\n80000\r\n100000\r\n120000\r\n140000\r\n160000\r\nAvailable Parallelism\r\n0 20 40 60 80\r\nComputation Step\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nParallelism Intensity\r\n0 20 40 60 80 100\r\nComputation Step\r\n0\r\n50000\r\n100000\r\n150000\r\n200000\r\n250000\r\n300000\r\nAvailable Parallelism\r\n0 20 40 60 80 100\r\nComputation Step\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nParallelism Intensity\r\n0 20 40 60 80 100\r\nComputation Step\r\n0\r\n100000\r\n200000\r\n300000\r\n400000\r\n500000\r\n600000\r\nAvailable Parallelism\r\n0 20 40 60 80 100\r\nComputation Step\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nParallelism Intensity\r\nSmall Medium Large\r\n(a) Agglomerative Clustering\r\n0 10 20 30 40 50 60\r\nComputation Step\r\n0\r\n1000\r\n2000\r\n3000\r\n4000\r\n5000\r\n6000\r\n7000\r\nAvailable Parallelism\r\n0 10 20 30 40 50 60\r\nComputation Step\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nParallelism Intensity\r\n0 10 20 30 40 50 60\r\nComputation Step\r\n0\r\n2000\r\n4000\r\n6000\r\n8000\r\n10000\r\n12000\r\n14000\r\n16000\r\nAvailable Parallelism\r\n0 10 20 30 40 50 60\r\nComputation Step\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nParallelism Intensity\r\n0 20 40 60\r\nComputation Step\r\n0\r\n10000\r\n20000\r\n30000\r\n40000\r\nAvailable Parallelism\r\n0 20 40 60\r\nComputation Step\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nParallelism Intensity\r\nSmall Medium Large\r\n(b) Delaunay Mesh Refinement\r\n0 20 40 60 80 100\r\nComputation Step\r\n0\r\n100\r\n200\r\n300\r\n400\r\n500\r\nAvailable Parallelism\r\n0 20 40 60 80 100\r\nComputation Step\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nParallelism Intensity\r\n0 20 40 60 80 100\r\nComputation Step\r\n0\r\n200\r\n400\r\n600\r\n800\r\n1000\r\n1200\r\nAvailable Parallelism\r\n0 20 40 60 80 100\r\nComputation Step\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nParallelism Intensity\r\n0 20 40 60 80 100 120 140\r\nComputation Step\r\n0\r\n500\r\n1000\r\n1500\r\n2000\r\nAvailable Parallelism\r\n0 20 40 60 80 100 120 140\r\nComputation Step\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nParallelism Intensity\r\nSmall Medium Large\r\n(c) Delaunay Triangulation\r\n0 5000 10000 15000 20000 25000\r\nComputation Step\r\n0\r\n50\r\n100\r\n150\r\n200\r\n250\r\nAvailable Parallelism\r\n0 5000 10000 15000 20000 25000\r\nComputation Step\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nParallelism Intensity\r\n0 5000 10000 15000 20000 25000 30000\r\nComputation Step\r\n0\r\n50\r\n100\r\n150\r\n200\r\n250\r\n300\r\n350\r\nAvailable Parallelism\r\n0 5000 10000 15000 20000 25000 30000\r\nComputation Step\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nParallelism Intensity\r\n0 5000 10000 15000 20000 25000\r\nComputation Step\r\n0\r\n100\r\n200\r\n300\r\n400\r\n500\r\nAvailable Parallelism\r\n0 5000 10000 15000 20000 25000\r\nComputation Step\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nParallelism Intensity\r\nSmall Medium Large\r\n(d) Survey Propagation\r\nFigure 9: Parallelism profiles and parallelism intensity for three input sizes",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/f20d864c-2458-4350-ab64-6ae2e42a763b.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=3eb3d0b53710f97baf9a0762f61ee0474bd90c381860e09b110ec514b843cd9a",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 435
      },
      {
        "segments": [
          {
            "segment_id": "284c2ec0-5ae8-4190-9d56-5efef7ba888d",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 9,
            "page_width": 612,
            "page_height": 792,
            "content": "triangles are necessarily near each other, and are therefore likely\r\nto conflict with one another. Thus, in the steady state, where\r\nall work is newly created work, we would expect a parallelism\r\nintensity of roughly 50%, which happens to be close to what\r\nwe observe. Finally, we see that as the input size increases, the\r\npattern of parallelism is identical, but the amount of parallelism\r\nscales with the input.\r\nDelaunay Triangulation Delaunay Triangulation is also a\r\ngraph refinement code. Point insertion removes a subgraph from\r\nthe graph (representing the triangle that will be split, as well as\r\nany triangles affected by edge-flipping actions) and replaces it\r\nwith a larger subgraph (the three triangles formed as the result of\r\nthe splitting, as well as the triangles created after edge-flipping).\r\nWe thus expect a behavior similar to that of Delaunay Mesh Re\u0002finement. This is borne out by the parallelism profile seen in the\r\ntop set of graphs in Figure 9(c), which exhibits the same bell\r\nshape as the profiles of Delaunay Mesh Refinement. Unlike in\r\nmesh refinement, at the beginning of the computation, there is ef\u0002fectively no parallelism. This is because the initial mesh is very\r\nsmall, consisting of a single triangle. The parallelism intensity\r\nplots also look similar to those of mesh refinement. However,\r\nbecause the work for triangulation is uniformly distributed, we\r\nsee that the parallelism intensity increases throughout execution.\r\nAs in the case of mesh refinement, the amount of parallelism\r\nincreases as the input size increases.\r\nSurvey Propagation Each iteration of Survey Propagation\r\ntouches a single node in the factor graph, and a small neigh\u0002borhood around that node; iterations conflict with one another\r\nif those neighborhoods overlap. The structure of the graph is\r\nlargely constant, except for occasionally removing a node. Thus,\r\nwe would expect the available parallelism to reflect the connec\u0002tivity of the graph, and remain roughly constant, dropping as\r\nnodes are removed from the graph. This is what we observe in\r\nthe parallelism profiles shown in Figure 9(d). Note that unlike\r\nthe other applications we have examined, Survey Propagation\r\nterminates before the worklist is empty.\r\nParallelism intensity, interestingly, increases slightly as nodes\r\nare removed from the graph, as seen in Figure 9(d). This is be\u0002cause removing nodes from the factor graph serves to reduce the\r\nconnectivity of the graph, making it less likely that two itera\u0002tions will conflict. Unsurprisingly, the amount of parallelism is\r\ncorrelated with the input size, increasing roughly linearly.\r\n4.2 Exploiting Amorphous Data-Parallelism\r\nTo ascertain that the amorphous data-parallelism identified in the\r\nprevious subsection can, in fact, be exploited, we wrote Galois\r\nversions of our applications and measured their performance on\r\nthree platforms. Figure 10 shows the results. The five rows of\r\npanels correspond to the five applications and the three columns\r\ncorrespond to the three platforms. Each panel contains three\r\ngraphs representing the three inputs. The x-axis in each panel\r\nlists the number of threads and the y-axis shows the speedup\r\nof the Galoised code over our sequential implementation of the\r\nsame algorithm. The sequential codes do not include any lock\u0002ing, threading, conflict detection, or undo-information-recording\r\noverhead. The absolute runtimes of the sequential programs are\r\npresented in the next subsection.\r\nWe observe that all five applications achieve at least a 15x\r\nspeedup on one of their inputs. Survey Propagation scales the\r\nleast but also has the smallest amount of available parallelism. It\r\nis the only application that does not achieve a speedup over se\u0002quential with two threads. The remaining four applications scale\r\nwell and achieve over 50% parallel efficiency up to 16 threads on\r\nthe UltraSPARC IV system.\r\nAlmost all program and input combinations result in worse\r\nperformance with 128 threads than with 64 threads. We per\u0002formed a detailed investigation of the causes for this behavior\r\non Delaunay Refinement [7] and identified two main culprits.\r\nThe first is inter-board communication, which is high for large\r\nnumbers of threads. Recall that this machine comprises sixteen\r\nboards with eight processors each. Hence, threads that execute\r\non different boards have to communicate via much slower chan\u0002nels than threads that are collocated on the same CPU board.\r\nThe second culprit is load imbalance. Above eight threads, the\r\nimbalance starts to become significant, and for 128 threads on\r\naverage over half of the time the threads are idling with all three\r\ninputs. The load imbalance grows with the number of threads\r\nbecause more threads result in less work per thread, increasing\r\nthe likelihood of imbalance problems. Clearly, the Galois system\r\nshould be augmented with a load balancer and should attempt to\r\nallocate worker threads that communicate to nearby CPUs.\r\nIn most instances, especially Barnes-Hut and Delaunay Trian\u0002gulation but also Agglomerative Clustering and Survey Propaga\u0002tion, larger inputs result in higher speedups. This observation is\r\nin line with the results from the previous subsection and prob\u0002ably means that even larger inputs would result in even higher\r\nparallel speedups. Only Delaunay Refinement does not follow\r\nthis trend. We surmise that this is because better load balancing\r\nand increased parallelism are the “low-hanging fruit” that allow\r\nlarger problem sizes to exhibit improved scalability. The for\u0002mer factor aids Barnes-Hut, while the latter factor aids Delaunay\r\nTriangulation. In contrast, Delaunay Refinement already has sig\u0002nificant parallelism with the small input, and load balancing may\r\nnot improve as the input size increases.\r\nComparing the speedup with 16 threads on the different sys\u0002tems, we find that Agglomerative Clustering scales much bet\u0002ter on the UltraSPARC IV than on the other platforms. Barnes\r\nHut scales similarly well on each platform. It is trivially paral\u0002lelizable and reaches a speedup of about 14x with 16 threads.\r\nDelaunay Refinement does much better on the two UltraSPARC\r\nmachines than on the Xeon system. Similarly, Delaunay Tri\u0002angulation scales best on the UltraSPARC T1 and worst on the\r\nXeon. We believe the reason for this behavior is the large num\u0002ber of stores and data-cache write misses of the two Delaunay\r\ncodes (see next section), which cause a lot of coherence traffic\r\nthat affects the Xeon system more than the other two systems.\r\nNevertheless, in absolute terms, the Xeon system is typically the",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/284c2ec0-5ae8-4190-9d56-5efef7ba888d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=6baf0b9ffffb738686e73491ca45ad2decc78d4edc190afaf40ffefa58b55298",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 1007
      },
      {
        "segments": [
          {
            "segment_id": "284c2ec0-5ae8-4190-9d56-5efef7ba888d",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 9,
            "page_width": 612,
            "page_height": 792,
            "content": "triangles are necessarily near each other, and are therefore likely\r\nto conflict with one another. Thus, in the steady state, where\r\nall work is newly created work, we would expect a parallelism\r\nintensity of roughly 50%, which happens to be close to what\r\nwe observe. Finally, we see that as the input size increases, the\r\npattern of parallelism is identical, but the amount of parallelism\r\nscales with the input.\r\nDelaunay Triangulation Delaunay Triangulation is also a\r\ngraph refinement code. Point insertion removes a subgraph from\r\nthe graph (representing the triangle that will be split, as well as\r\nany triangles affected by edge-flipping actions) and replaces it\r\nwith a larger subgraph (the three triangles formed as the result of\r\nthe splitting, as well as the triangles created after edge-flipping).\r\nWe thus expect a behavior similar to that of Delaunay Mesh Re\u0002finement. This is borne out by the parallelism profile seen in the\r\ntop set of graphs in Figure 9(c), which exhibits the same bell\r\nshape as the profiles of Delaunay Mesh Refinement. Unlike in\r\nmesh refinement, at the beginning of the computation, there is ef\u0002fectively no parallelism. This is because the initial mesh is very\r\nsmall, consisting of a single triangle. The parallelism intensity\r\nplots also look similar to those of mesh refinement. However,\r\nbecause the work for triangulation is uniformly distributed, we\r\nsee that the parallelism intensity increases throughout execution.\r\nAs in the case of mesh refinement, the amount of parallelism\r\nincreases as the input size increases.\r\nSurvey Propagation Each iteration of Survey Propagation\r\ntouches a single node in the factor graph, and a small neigh\u0002borhood around that node; iterations conflict with one another\r\nif those neighborhoods overlap. The structure of the graph is\r\nlargely constant, except for occasionally removing a node. Thus,\r\nwe would expect the available parallelism to reflect the connec\u0002tivity of the graph, and remain roughly constant, dropping as\r\nnodes are removed from the graph. This is what we observe in\r\nthe parallelism profiles shown in Figure 9(d). Note that unlike\r\nthe other applications we have examined, Survey Propagation\r\nterminates before the worklist is empty.\r\nParallelism intensity, interestingly, increases slightly as nodes\r\nare removed from the graph, as seen in Figure 9(d). This is be\u0002cause removing nodes from the factor graph serves to reduce the\r\nconnectivity of the graph, making it less likely that two itera\u0002tions will conflict. Unsurprisingly, the amount of parallelism is\r\ncorrelated with the input size, increasing roughly linearly.\r\n4.2 Exploiting Amorphous Data-Parallelism\r\nTo ascertain that the amorphous data-parallelism identified in the\r\nprevious subsection can, in fact, be exploited, we wrote Galois\r\nversions of our applications and measured their performance on\r\nthree platforms. Figure 10 shows the results. The five rows of\r\npanels correspond to the five applications and the three columns\r\ncorrespond to the three platforms. Each panel contains three\r\ngraphs representing the three inputs. The x-axis in each panel\r\nlists the number of threads and the y-axis shows the speedup\r\nof the Galoised code over our sequential implementation of the\r\nsame algorithm. The sequential codes do not include any lock\u0002ing, threading, conflict detection, or undo-information-recording\r\noverhead. The absolute runtimes of the sequential programs are\r\npresented in the next subsection.\r\nWe observe that all five applications achieve at least a 15x\r\nspeedup on one of their inputs. Survey Propagation scales the\r\nleast but also has the smallest amount of available parallelism. It\r\nis the only application that does not achieve a speedup over se\u0002quential with two threads. The remaining four applications scale\r\nwell and achieve over 50% parallel efficiency up to 16 threads on\r\nthe UltraSPARC IV system.\r\nAlmost all program and input combinations result in worse\r\nperformance with 128 threads than with 64 threads. We per\u0002formed a detailed investigation of the causes for this behavior\r\non Delaunay Refinement [7] and identified two main culprits.\r\nThe first is inter-board communication, which is high for large\r\nnumbers of threads. Recall that this machine comprises sixteen\r\nboards with eight processors each. Hence, threads that execute\r\non different boards have to communicate via much slower chan\u0002nels than threads that are collocated on the same CPU board.\r\nThe second culprit is load imbalance. Above eight threads, the\r\nimbalance starts to become significant, and for 128 threads on\r\naverage over half of the time the threads are idling with all three\r\ninputs. The load imbalance grows with the number of threads\r\nbecause more threads result in less work per thread, increasing\r\nthe likelihood of imbalance problems. Clearly, the Galois system\r\nshould be augmented with a load balancer and should attempt to\r\nallocate worker threads that communicate to nearby CPUs.\r\nIn most instances, especially Barnes-Hut and Delaunay Trian\u0002gulation but also Agglomerative Clustering and Survey Propaga\u0002tion, larger inputs result in higher speedups. This observation is\r\nin line with the results from the previous subsection and prob\u0002ably means that even larger inputs would result in even higher\r\nparallel speedups. Only Delaunay Refinement does not follow\r\nthis trend. We surmise that this is because better load balancing\r\nand increased parallelism are the “low-hanging fruit” that allow\r\nlarger problem sizes to exhibit improved scalability. The for\u0002mer factor aids Barnes-Hut, while the latter factor aids Delaunay\r\nTriangulation. In contrast, Delaunay Refinement already has sig\u0002nificant parallelism with the small input, and load balancing may\r\nnot improve as the input size increases.\r\nComparing the speedup with 16 threads on the different sys\u0002tems, we find that Agglomerative Clustering scales much bet\u0002ter on the UltraSPARC IV than on the other platforms. Barnes\r\nHut scales similarly well on each platform. It is trivially paral\u0002lelizable and reaches a speedup of about 14x with 16 threads.\r\nDelaunay Refinement does much better on the two UltraSPARC\r\nmachines than on the Xeon system. Similarly, Delaunay Tri\u0002angulation scales best on the UltraSPARC T1 and worst on the\r\nXeon. We believe the reason for this behavior is the large num\u0002ber of stores and data-cache write misses of the two Delaunay\r\ncodes (see next section), which cause a lot of coherence traffic\r\nthat affects the Xeon system more than the other two systems.\r\nNevertheless, in absolute terms, the Xeon system is typically the",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/284c2ec0-5ae8-4190-9d56-5efef7ba888d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=6baf0b9ffffb738686e73491ca45ad2decc78d4edc190afaf40ffefa58b55298",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 1007
      },
      {
        "segments": [
          {
            "segment_id": "a90a0a66-a962-4893-b0ea-b911b0e68509",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 10,
            "page_width": 612,
            "page_height": 792,
            "content": "!\"\"#$%&\r\n'#()*+,-.\"\r\n/0,.+)\r\n1(*\r\n2+#0(.03\r\n4+5-.+%+.*\r\n6#*,078!4'9:; <+$.9<=>?@ 6#*,078!4'9AB\r\n!\"!\r\n#\"!\r\n$!\"!\r\n$#\"!\r\n%!\"!\r\n%#\"!\r\n$ % & ' $( )% (& $%'\r\n#!!*!!!\r\n$*!!!*!!!\r\n%*!!!*!!!\r\n!\"!\r\n$!\"!\r\n%!\"!\r\n)!\"!\r\n&!\"!\r\n#!\"!\r\n$ % & ' $( )% (& $%'\r\n(#*!!!\r\n$$!*!!!\r\n%%!*!!!\r\n$#\"!\r\n%!\"!\r\n%#\"!\r\n)!\"!\r\n$!!*++!\r\n%$, ,,'\r\n!\"!\r\n$\"!\r\n%\"!\r\n)\"!\r\n&\"!\r\n#\"!\r\n(\"!\r\n$ % & ' $(\r\n#!!*!!!\r\n$*!!!*!!!\r\n%*!!!*!!!\r\n!\"!\r\n%\"!\r\n&\"!\r\n(\"!\r\n'\"!\r\n$!\"!\r\n$%\"!\r\n$&\"!\r\n$(\"!\r\n$ % & ' $(\r\n(#*!!!\r\n$$!*!!!\r\n%%!*!!!\r\n% !\r\n)\"!\r\n&\"!\r\n#\"!\r\n$!!*++!\r\n%$, ,,'\r\n!\"!\r\n$\"!\r\n%\"!\r\n)\"!\r\n&\"!\r\n#\"!\r\n(\"!\r\n+\"!\r\n'\"!\r\n$ % & ' $( )%\r\n#!!*!!!\r\n$*!!!*!!!\r\n%*!!!*!!!\r\n!\"!\r\n#\"!\r\n$!\"!\r\n$#\"!\r\n%!\"!\r\n$ % & ' $( )%\r\n(#*!!!\r\n$$!*!!!\r\n%%!*!!!\r\n$!\"!\r\n$#\"!\r\n%!\"!\r\n$!!*++!\r\n%$, ,,'\r\n2+#0(.03\r\nA,-0.\"(#&\r\n7(,C+3\r\n8,$D0\"&\r\n!\"!\r\n#\"!\r\n$!\"!\r\n$ % & ' $( )% (& $%'\r\n%$,*,,'\r\n#&,*,,'\r\n!\"!\r\n&\"!\r\n'\"!\r\n$%\"!\r\n$(\"!\r\n$ % & ' $( )% (& $%'\r\n%!*!!!\r\n&!*!!!\r\n'!*!!!\r\n!\"!\r\n$\"!\r\n%\"!\r\n$ % & ' $(\r\n%$,*,,'\r\n#&,*,,'\r\n!\"!\r\n!\"#\r\n$\"!\r\n$\"#\r\n%\"!\r\n%\"#\r\n)\"!\r\n)\"#\r\n&\"!\r\n$ % & ' $(\r\n%!*!!!\r\n&!*!!!\r\n'!*!!!\r\n!\"!\r\n$\"!\r\n%\"!\r\n)\"!\r\n&\"!\r\n#\"!\r\n$ % & ' $(\r\n%#!\r\n)#!\r\n#!!\r\n!\"!\r\n#\"!\r\n$ % & ' $( )%\r\n%$,*,,'\r\n#&,*,,'\r\n!\"!\r\n&\"!\r\n'\"!\r\n$%\"!\r\n$(\"!\r\n$ % & ' $( )%\r\n%!*!!!\r\n&!*!!!\r\n'!*!!!\r\n!\"!\r\n)\"!\r\n(\"!\r\n,\"!\r\n$%\"!\r\n$#\"!\r\n$'\"!\r\n$ % & ' $( )% (& $%'\r\n%#!\r\n)#!\r\n#!!\r\n!\"!\r\n%\"!\r\n&\"!\r\n(\"!\r\n'\"!\r\n$!\"!\r\n$%\"!\r\n$ % & ' $( )%\r\n%#!\r\n)#!\r\n#!!\r\nFigure 10: Speedup over sequential code (y-axis) of the 5 benchmarks on the 3 architectures for different numbers of threads (x-axis)\r\n!\"#$%\"!&'( )!'*+,#%- ./0 !'(\"$12\"!&'( )#)*+%22* 3&%4(+-#$ (\"&$#(+-#$ 564+)!(( 3&%4+)!(( (\"&$#+)!((\r\n7/89.+0: ;#&' 7/89.+<6 (!=#+>?@A -#$+!\"#$%\"!&' -#$+!\"#$%\"!&' !\"#$%\"!&' !\"#$%\"!&' $%\"#+BCD $%\"#+BCD $%\"#+BCD )#)*+%22* 3&%4( (\"&$#(\r\n!\"\"#\"\"\" $!%& '%( !)*%& )&+ +%') &(#')$%' +(#*)'%) ++#\"$'%( +#*&\"%\" ,%* +%$ &'%, )*%! +'%, +%,\r\n\"\"\"#\"\"\" ++!%' +,%) '$,%) $+\" +%'+ &&#)!'%) +(#!!,%) +)#($*%$ +#*\"&%, ,%* +%$ &\"%) )*%( +'%& +%,\r\n+#\"\"\"#\"\"\" )($%! ((%\" +#,!'%+ +#*(\" +%'\" &,#\")*%! +(#'(+%) +)#,*'%) +#+)(%* ,%+ +%$ &\"%& )*%! +'%, +%,\r\n&$#*** ))%$ ,%+ )#'+*%* +( )%+$ +&,#'$)%, !+#''!%( (!#$)'%& ,#($$%, +(%( +*%( ),%( )$%* )*%& !%!\r\n++*#*** !+%' +)%\" $#+$,%, )+ )%)* +')#+\"!%' !$#(,*%+ (,#(,&%! ,#\"\"(%, +!%! ++%, ),%) )!%\" )*%$ !%!\r\n))*#*** \")%* )'%( ++#((*%& !+ )%+\" +\"\"#+&&%, !\"#,'\"%* !*#\"')%\" '#'*&%+ +!%+ ++%( ),%+ )$%* )*%& !%!\r\n)*&#,(' ()%* &%+ )(+%, !$$ )%+& ,$#)'+%! )(#!&!%( +!#!*'%\" \"#*$$%! (+%' &%( ,)%$ (+%) +\"%+ +)%*\r\n$*(#\")* ,&%) +$%! $!$%& +#*)) )%+' ,)#$*$%* ))#,)\"%! +(#\"'$%* '#,!!%! (+%' &%( ,)%$ (+%( +\"%( +)%+\r\n+#)\",#('* +\"$%+ !(%+ +#(\"*%' )#$!$ )%)! ,)#,!,%+ ))#&'!%* +(#\"$'%' '#,)$%) (+%, &%( ,)%! (+%) +\"%) +)%*\r\n)*#*** +(%) (%( &(%! )(' )%,( )!*#\"$(%+ '*#&&(%) !$#&'\"%* (!#\",!%) !*%* ++%' ,&%, ((%$ +\"%* +!%$\r\n!*#*** )\"%) ,%) +(*%& !'( )%') )&,#&\"*%$ ',#**\"%$ !'#$,+%! ('#!('%+ !+%) +)%) ,,%' ()%$ +'%+ +!%!\r\n'*#*** &*%* +$%$ )&(%\" \"), )%\"\" )&)#\"$)%! \"+#$!,%+ $+#,,+%' (\"#,,$%! !+%+ +)%$ ,'%( (!%' +\"%, +$%+\r\n\"&&#)*! $,%, +(%! +*(%' ' +%)+ $+#,,*%& +!#)&(%( +)#\")$%, +#((,%& !%& )%) ),%' ),%& )$%* )%&\r\n+#',$#&,* +(\"%$ )$%& )!$%$ ' +%)! &)#,'(%+ +*#*!'%, '#,!+%) +#(*,%$ ,%) (%, (*%) +&%* +(%\" )%+\r\n!#!\")#!*( &,(%! +(+%* +#(&!%& ' *%', +,,#''$%+ !)#*+&%, !*#&+*%' +#!*$%' )%+ +%+ )\"%( )(%& ))%' *%'\r\n71$E#F+\r\n/$&-%G*\r\n(#H1#'\"!%3+$1'\"!)#+>(A+&' C+&I+!'(\"$12\"!&'(+\",%\"+%$#\r\n8GG3&)*+\r\n.31(\"#$!'G\r\n@%$'#(+J1\"\r\nK#3%1'%F+\r\n9#I!'#)#'\"\r\nK#3%1'%F+\r\n<$!%'G13*\r\nTable 1: Information about the five benchmarks for the three inputs",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/a90a0a66-a962-4893-b0ea-b911b0e68509.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c878ae854a836e97533379efedd748bccd52cc9d2b35d8738d960be188c33906",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 567
      },
      {
        "segments": [
          {
            "segment_id": "a90a0a66-a962-4893-b0ea-b911b0e68509",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 10,
            "page_width": 612,
            "page_height": 792,
            "content": "!\"\"#$%&\r\n'#()*+,-.\"\r\n/0,.+)\r\n1(*\r\n2+#0(.03\r\n4+5-.+%+.*\r\n6#*,078!4'9:; <+$.9<=>?@ 6#*,078!4'9AB\r\n!\"!\r\n#\"!\r\n$!\"!\r\n$#\"!\r\n%!\"!\r\n%#\"!\r\n$ % & ' $( )% (& $%'\r\n#!!*!!!\r\n$*!!!*!!!\r\n%*!!!*!!!\r\n!\"!\r\n$!\"!\r\n%!\"!\r\n)!\"!\r\n&!\"!\r\n#!\"!\r\n$ % & ' $( )% (& $%'\r\n(#*!!!\r\n$$!*!!!\r\n%%!*!!!\r\n$#\"!\r\n%!\"!\r\n%#\"!\r\n)!\"!\r\n$!!*++!\r\n%$, ,,'\r\n!\"!\r\n$\"!\r\n%\"!\r\n)\"!\r\n&\"!\r\n#\"!\r\n(\"!\r\n$ % & ' $(\r\n#!!*!!!\r\n$*!!!*!!!\r\n%*!!!*!!!\r\n!\"!\r\n%\"!\r\n&\"!\r\n(\"!\r\n'\"!\r\n$!\"!\r\n$%\"!\r\n$&\"!\r\n$(\"!\r\n$ % & ' $(\r\n(#*!!!\r\n$$!*!!!\r\n%%!*!!!\r\n% !\r\n)\"!\r\n&\"!\r\n#\"!\r\n$!!*++!\r\n%$, ,,'\r\n!\"!\r\n$\"!\r\n%\"!\r\n)\"!\r\n&\"!\r\n#\"!\r\n(\"!\r\n+\"!\r\n'\"!\r\n$ % & ' $( )%\r\n#!!*!!!\r\n$*!!!*!!!\r\n%*!!!*!!!\r\n!\"!\r\n#\"!\r\n$!\"!\r\n$#\"!\r\n%!\"!\r\n$ % & ' $( )%\r\n(#*!!!\r\n$$!*!!!\r\n%%!*!!!\r\n$!\"!\r\n$#\"!\r\n%!\"!\r\n$!!*++!\r\n%$, ,,'\r\n2+#0(.03\r\nA,-0.\"(#&\r\n7(,C+3\r\n8,$D0\"&\r\n!\"!\r\n#\"!\r\n$!\"!\r\n$ % & ' $( )% (& $%'\r\n%$,*,,'\r\n#&,*,,'\r\n!\"!\r\n&\"!\r\n'\"!\r\n$%\"!\r\n$(\"!\r\n$ % & ' $( )% (& $%'\r\n%!*!!!\r\n&!*!!!\r\n'!*!!!\r\n!\"!\r\n$\"!\r\n%\"!\r\n$ % & ' $(\r\n%$,*,,'\r\n#&,*,,'\r\n!\"!\r\n!\"#\r\n$\"!\r\n$\"#\r\n%\"!\r\n%\"#\r\n)\"!\r\n)\"#\r\n&\"!\r\n$ % & ' $(\r\n%!*!!!\r\n&!*!!!\r\n'!*!!!\r\n!\"!\r\n$\"!\r\n%\"!\r\n)\"!\r\n&\"!\r\n#\"!\r\n$ % & ' $(\r\n%#!\r\n)#!\r\n#!!\r\n!\"!\r\n#\"!\r\n$ % & ' $( )%\r\n%$,*,,'\r\n#&,*,,'\r\n!\"!\r\n&\"!\r\n'\"!\r\n$%\"!\r\n$(\"!\r\n$ % & ' $( )%\r\n%!*!!!\r\n&!*!!!\r\n'!*!!!\r\n!\"!\r\n)\"!\r\n(\"!\r\n,\"!\r\n$%\"!\r\n$#\"!\r\n$'\"!\r\n$ % & ' $( )% (& $%'\r\n%#!\r\n)#!\r\n#!!\r\n!\"!\r\n%\"!\r\n&\"!\r\n(\"!\r\n'\"!\r\n$!\"!\r\n$%\"!\r\n$ % & ' $( )%\r\n%#!\r\n)#!\r\n#!!\r\nFigure 10: Speedup over sequential code (y-axis) of the 5 benchmarks on the 3 architectures for different numbers of threads (x-axis)\r\n!\"#$%\"!&'( )!'*+,#%- ./0 !'(\"$12\"!&'( )#)*+%22* 3&%4(+-#$ (\"&$#(+-#$ 564+)!(( 3&%4+)!(( (\"&$#+)!((\r\n7/89.+0: ;#&' 7/89.+<6 (!=#+>?@A -#$+!\"#$%\"!&' -#$+!\"#$%\"!&' !\"#$%\"!&' !\"#$%\"!&' $%\"#+BCD $%\"#+BCD $%\"#+BCD )#)*+%22* 3&%4( (\"&$#(\r\n!\"\"#\"\"\" $!%& '%( !)*%& )&+ +%') &(#')$%' +(#*)'%) ++#\"$'%( +#*&\"%\" ,%* +%$ &'%, )*%! +'%, +%,\r\n\"\"\"#\"\"\" ++!%' +,%) '$,%) $+\" +%'+ &&#)!'%) +(#!!,%) +)#($*%$ +#*\"&%, ,%* +%$ &\"%) )*%( +'%& +%,\r\n+#\"\"\"#\"\"\" )($%! ((%\" +#,!'%+ +#*(\" +%'\" &,#\")*%! +(#'(+%) +)#,*'%) +#+)(%* ,%+ +%$ &\"%& )*%! +'%, +%,\r\n&$#*** ))%$ ,%+ )#'+*%* +( )%+$ +&,#'$)%, !+#''!%( (!#$)'%& ,#($$%, +(%( +*%( ),%( )$%* )*%& !%!\r\n++*#*** !+%' +)%\" $#+$,%, )+ )%)* +')#+\"!%' !$#(,*%+ (,#(,&%! ,#\"\"(%, +!%! ++%, ),%) )!%\" )*%$ !%!\r\n))*#*** \")%* )'%( ++#((*%& !+ )%+\" +\"\"#+&&%, !\"#,'\"%* !*#\"')%\" '#'*&%+ +!%+ ++%( ),%+ )$%* )*%& !%!\r\n)*&#,(' ()%* &%+ )(+%, !$$ )%+& ,$#)'+%! )(#!&!%( +!#!*'%\" \"#*$$%! (+%' &%( ,)%$ (+%) +\"%+ +)%*\r\n$*(#\")* ,&%) +$%! $!$%& +#*)) )%+' ,)#$*$%* ))#,)\"%! +(#\"'$%* '#,!!%! (+%' &%( ,)%$ (+%( +\"%( +)%+\r\n+#)\",#('* +\"$%+ !(%+ +#(\"*%' )#$!$ )%)! ,)#,!,%+ ))#&'!%* +(#\"$'%' '#,)$%) (+%, &%( ,)%! (+%) +\"%) +)%*\r\n)*#*** +(%) (%( &(%! )(' )%,( )!*#\"$(%+ '*#&&(%) !$#&'\"%* (!#\",!%) !*%* ++%' ,&%, ((%$ +\"%* +!%$\r\n!*#*** )\"%) ,%) +(*%& !'( )%') )&,#&\"*%$ ',#**\"%$ !'#$,+%! ('#!('%+ !+%) +)%) ,,%' ()%$ +'%+ +!%!\r\n'*#*** &*%* +$%$ )&(%\" \"), )%\"\" )&)#\"$)%! \"+#$!,%+ $+#,,+%' (\"#,,$%! !+%+ +)%$ ,'%( (!%' +\"%, +$%+\r\n\"&&#)*! $,%, +(%! +*(%' ' +%)+ $+#,,*%& +!#)&(%( +)#\")$%, +#((,%& !%& )%) ),%' ),%& )$%* )%&\r\n+#',$#&,* +(\"%$ )$%& )!$%$ ' +%)! &)#,'(%+ +*#*!'%, '#,!+%) +#(*,%$ ,%) (%, (*%) +&%* +(%\" )%+\r\n!#!\")#!*( &,(%! +(+%* +#(&!%& ' *%', +,,#''$%+ !)#*+&%, !*#&+*%' +#!*$%' )%+ +%+ )\"%( )(%& ))%' *%'\r\n71$E#F+\r\n/$&-%G*\r\n(#H1#'\"!%3+$1'\"!)#+>(A+&' C+&I+!'(\"$12\"!&'(+\",%\"+%$#\r\n8GG3&)*+\r\n.31(\"#$!'G\r\n@%$'#(+J1\"\r\nK#3%1'%F+\r\n9#I!'#)#'\"\r\nK#3%1'%F+\r\n<$!%'G13*\r\nTable 1: Information about the five benchmarks for the three inputs",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/a90a0a66-a962-4893-b0ea-b911b0e68509.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c878ae854a836e97533379efedd748bccd52cc9d2b35d8738d960be188c33906",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 567
      },
      {
        "segments": [
          {
            "segment_id": "47e9ae1d-95a8-4c0d-bf36-bf4609bc2303",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 11,
            "page_width": 612,
            "page_height": 792,
            "content": "fastest.\r\nThe performance anomaly in Delaunay Refinement with 64\r\nthreads is due to a very high CPI, which we believe is caused by\r\nunfortunate partitioning that results in an unusually large amount\r\nof communication.\r\n4.3 Program Characteristics\r\nTable 1 provides information about the sequential versions of our\r\nbenchmarks as it pertains to the UltraSPARC IV system (unless\r\notherwise noted). For each program, it lists results for the small,\r\nmiddle, and large inputs from top to bottom. From left to right,\r\nthe table presents information on the number of iterations in the\r\nloop that is the parallelization target, the runtimes on the three\r\nevaluation platforms, the smallest heap size necessary to run the\r\napplications, the average cycles per executed instruction (CPI),\r\nthe average number of executed instructions, memory accesses\r\n(mem. acc.), loads, and stores per iteration, the L1 data-cache\r\n(L1d) miss rate, the load and store miss rates, and the fraction of\r\nexecuted instructions that access, read from, and write to mem\u0002ory.\r\nThe main observations are that, in all five applications, the av\u0002erage iteration executes several tens of thousands of instructions,\r\nincluding thousands of memory accesses. A substantial fraction\r\nof the memory accesses misses in the 64 kB four-way associative\r\ncache. These results indicate that L1-cache-based concurrency\r\nmechanisms such as TM may not be ideal for these programs.\r\nThe instruction mix contains between 20% and 35% memory\r\naccesses. Each application executes, on average, close to 20%\r\nloads. However, only the two Delaunay codes execute many\r\nstores (over 12% compared to under 4.5% for the other appli\u0002cations). For all programs except Barnes-Hut, most of the stores\r\nmiss in the L1 cache. Part of the reason for the poor L1 d-cache\r\nperformance on stores is the UltraSPARC IV’s no-write-allocate\r\npolicy. The load miss rates are much lower but still high for\r\nBarnes-Hut, Delaunay Triangulation, and, to a lesser degree, De\u0002launay Refinement. These three programs also suffer from high\r\noverall L1 miss rates, especially the two Delaunay codes. This\r\nis expected as they jump back and forth between processing dif\u0002ferent parts of the mesh. Because of the high cache miss rates,\r\nthese three programs also have the highest CPIs. Nevertheless,\r\nthe CPIs are not low for the remaining programs, either. In other\r\nwords, the superscalar CPU is only able to execute one instruc\u0002tion per two to three cycles on average.\r\nThe total data size of these programs varies between 8 MB and\r\n2.5 GB. Except for Survey Propagation, the heap sizes exceed\r\ncommon last-level cache sizes. Of the three systems, the Xeon is\r\nthe fastest (probably because of its much higher clock frequency)\r\nand the UltraSPARC T1 the slowest (presumably because of its\r\nsmall caches).\r\n5 Related Work\r\nA number of recent papers have explored the characterization of\r\nparallel program behavior for emerging workloads. PARSEC [5]\r\nis a suite of multithreaded applications targeted to shared mem\u0002ory multiprocessors. The suite focuses on a set of diverse emerg\u0002ing workloads that spans a number of domains (financial, data\r\nmining, data processing, computer vision, etc.) and parallelism\r\nmodels (data-parallel, pipeline parallel, and unstructured). The\r\nsuite contains one unstructured parallel benchmark, canneal, that\r\nperforms a simulated annealing search used in circuit placement.\r\nAll presented results are simulated using a PIN [15] plugin that\r\nprovides a cache model. A subset of these benchmarks is ported\r\nto the Thread Building Blocks library [9] and characterized on\r\nreal hardware up to four cores and simulated up to 32. This\r\ncharacterization addresses mainly TBB overheads for dynamic\r\nmanagement of parallelism.\r\nThe STAMP benchmark suite [16] is a set of codes intended\r\nto characterize transactional memory behavior. The codes in the\r\nsuite are also intended to capture the parallel behavior of new\r\nemerging algorithms in domains such as data mining, search and\r\nclassification. They use a variety of dynamic data structures such\r\nas lists, trees and graphs. The published characterization of these\r\nbenchmarks is mainly focused on simulated transactional mem\u0002ory behavior and does not address the parallelization potential.\r\nIn contrast, our study is a theoretical and practical characteri\u0002zation of irregular applications, quantifying the available paral\u0002lelism, the memory behavior, and the scalability on different ar\u0002chitectures.\r\nSeveral other studies have characterized older parallel bench\u0002mark suites, including Perfect Club [4], SPLASH-2 [22], NAS\r\nParallel Benchmarks [2], and SPEComp [1]. The codes in these\r\nbenchmarks are almost exclusively characteristic of the scien\u0002tific, high-performance computing domain of regular dense lin\u0002ear algebra. Many of these codes are no longer considered rep\u0002resentative of the behavior of workloads on current machines.\r\nThe Olden benchmarks [18] are small, hand-parallelized kernels\r\nthat operate over irregular data structures. They are intended for\r\nprogram analysis research for finding structural invariants rather\r\nthan for studying parallelism.\r\n6 Conclusions\r\nWe have identified a type of parallelism, called amorphous data\u0002parallelism, that arises naturally in iterative algorithms that op\u0002erate over sparse-graph data structures. To study this style of\r\nparallelism better, we have begun to collect the Lonestar suite of\r\nreal-world applications that exhibit amorphous data-parallelism,\r\nthe first five of which are Agglomerative Clustering, Barnes\u0002Hut, Delaunay Triangulation, Delaunay Refinement, and Survey\r\nPropagation. These applications span a range of domains, from\r\nsimulation to data-mining to graphics.\r\nWe have studied these algorithms and determined that, despite\r\nthe complex nature of their execution, there is significant paral\u0002lelism available to be exploited, and this parallelism scales with\r\nthe problem size. We have further shown that this potential par\u0002allelism can, indeed, be realized by a software parallelization\r\nsystem, achieving high speedups over sequential execution on a\r\nrange of architectures. Finally, we examined the low-level char-",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/47e9ae1d-95a8-4c0d-bf36-bf4609bc2303.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=972ed49ab62c3e8e7d24441428724c98d49c8ca5cc9c74ce3fcbc31a7770f60b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 909
      },
      {
        "segments": [
          {
            "segment_id": "47e9ae1d-95a8-4c0d-bf36-bf4609bc2303",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 11,
            "page_width": 612,
            "page_height": 792,
            "content": "fastest.\r\nThe performance anomaly in Delaunay Refinement with 64\r\nthreads is due to a very high CPI, which we believe is caused by\r\nunfortunate partitioning that results in an unusually large amount\r\nof communication.\r\n4.3 Program Characteristics\r\nTable 1 provides information about the sequential versions of our\r\nbenchmarks as it pertains to the UltraSPARC IV system (unless\r\notherwise noted). For each program, it lists results for the small,\r\nmiddle, and large inputs from top to bottom. From left to right,\r\nthe table presents information on the number of iterations in the\r\nloop that is the parallelization target, the runtimes on the three\r\nevaluation platforms, the smallest heap size necessary to run the\r\napplications, the average cycles per executed instruction (CPI),\r\nthe average number of executed instructions, memory accesses\r\n(mem. acc.), loads, and stores per iteration, the L1 data-cache\r\n(L1d) miss rate, the load and store miss rates, and the fraction of\r\nexecuted instructions that access, read from, and write to mem\u0002ory.\r\nThe main observations are that, in all five applications, the av\u0002erage iteration executes several tens of thousands of instructions,\r\nincluding thousands of memory accesses. A substantial fraction\r\nof the memory accesses misses in the 64 kB four-way associative\r\ncache. These results indicate that L1-cache-based concurrency\r\nmechanisms such as TM may not be ideal for these programs.\r\nThe instruction mix contains between 20% and 35% memory\r\naccesses. Each application executes, on average, close to 20%\r\nloads. However, only the two Delaunay codes execute many\r\nstores (over 12% compared to under 4.5% for the other appli\u0002cations). For all programs except Barnes-Hut, most of the stores\r\nmiss in the L1 cache. Part of the reason for the poor L1 d-cache\r\nperformance on stores is the UltraSPARC IV’s no-write-allocate\r\npolicy. The load miss rates are much lower but still high for\r\nBarnes-Hut, Delaunay Triangulation, and, to a lesser degree, De\u0002launay Refinement. These three programs also suffer from high\r\noverall L1 miss rates, especially the two Delaunay codes. This\r\nis expected as they jump back and forth between processing dif\u0002ferent parts of the mesh. Because of the high cache miss rates,\r\nthese three programs also have the highest CPIs. Nevertheless,\r\nthe CPIs are not low for the remaining programs, either. In other\r\nwords, the superscalar CPU is only able to execute one instruc\u0002tion per two to three cycles on average.\r\nThe total data size of these programs varies between 8 MB and\r\n2.5 GB. Except for Survey Propagation, the heap sizes exceed\r\ncommon last-level cache sizes. Of the three systems, the Xeon is\r\nthe fastest (probably because of its much higher clock frequency)\r\nand the UltraSPARC T1 the slowest (presumably because of its\r\nsmall caches).\r\n5 Related Work\r\nA number of recent papers have explored the characterization of\r\nparallel program behavior for emerging workloads. PARSEC [5]\r\nis a suite of multithreaded applications targeted to shared mem\u0002ory multiprocessors. The suite focuses on a set of diverse emerg\u0002ing workloads that spans a number of domains (financial, data\r\nmining, data processing, computer vision, etc.) and parallelism\r\nmodels (data-parallel, pipeline parallel, and unstructured). The\r\nsuite contains one unstructured parallel benchmark, canneal, that\r\nperforms a simulated annealing search used in circuit placement.\r\nAll presented results are simulated using a PIN [15] plugin that\r\nprovides a cache model. A subset of these benchmarks is ported\r\nto the Thread Building Blocks library [9] and characterized on\r\nreal hardware up to four cores and simulated up to 32. This\r\ncharacterization addresses mainly TBB overheads for dynamic\r\nmanagement of parallelism.\r\nThe STAMP benchmark suite [16] is a set of codes intended\r\nto characterize transactional memory behavior. The codes in the\r\nsuite are also intended to capture the parallel behavior of new\r\nemerging algorithms in domains such as data mining, search and\r\nclassification. They use a variety of dynamic data structures such\r\nas lists, trees and graphs. The published characterization of these\r\nbenchmarks is mainly focused on simulated transactional mem\u0002ory behavior and does not address the parallelization potential.\r\nIn contrast, our study is a theoretical and practical characteri\u0002zation of irregular applications, quantifying the available paral\u0002lelism, the memory behavior, and the scalability on different ar\u0002chitectures.\r\nSeveral other studies have characterized older parallel bench\u0002mark suites, including Perfect Club [4], SPLASH-2 [22], NAS\r\nParallel Benchmarks [2], and SPEComp [1]. The codes in these\r\nbenchmarks are almost exclusively characteristic of the scien\u0002tific, high-performance computing domain of regular dense lin\u0002ear algebra. Many of these codes are no longer considered rep\u0002resentative of the behavior of workloads on current machines.\r\nThe Olden benchmarks [18] are small, hand-parallelized kernels\r\nthat operate over irregular data structures. They are intended for\r\nprogram analysis research for finding structural invariants rather\r\nthan for studying parallelism.\r\n6 Conclusions\r\nWe have identified a type of parallelism, called amorphous data\u0002parallelism, that arises naturally in iterative algorithms that op\u0002erate over sparse-graph data structures. To study this style of\r\nparallelism better, we have begun to collect the Lonestar suite of\r\nreal-world applications that exhibit amorphous data-parallelism,\r\nthe first five of which are Agglomerative Clustering, Barnes\u0002Hut, Delaunay Triangulation, Delaunay Refinement, and Survey\r\nPropagation. These applications span a range of domains, from\r\nsimulation to data-mining to graphics.\r\nWe have studied these algorithms and determined that, despite\r\nthe complex nature of their execution, there is significant paral\u0002lelism available to be exploited, and this parallelism scales with\r\nthe problem size. We have further shown that this potential par\u0002allelism can, indeed, be realized by a software parallelization\r\nsystem, achieving high speedups over sequential execution on a\r\nrange of architectures. Finally, we examined the low-level char-",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/47e9ae1d-95a8-4c0d-bf36-bf4609bc2303.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=972ed49ab62c3e8e7d24441428724c98d49c8ca5cc9c74ce3fcbc31a7770f60b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 909
      },
      {
        "segments": [
          {
            "segment_id": "1486bfd1-6eff-4021-808a-896b9b877d84",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 12,
            "page_width": 612,
            "page_height": 792,
            "content": "acteristics of these applications and found that the granularity of\r\nthe parallelism is quite high, presenting interesting challenges to\r\nthe development of run-time systems to exploit this parallelism.\r\nBecause these applications represent an important class of al\u0002gorithms that appear in numerous domains and have significant\r\npotential for parallelism, we feel they are worthwhile targets for\r\nparallelization research.\r\nReferences\r\n[1] V. Aslot, R. Eigenmann, G. Gaertner, W. B. Jones, and B. Parady.\r\nSpecomp: A new benchmark suite for measuring parallel com\u0002puter performance. In In Workshop on OpenMP Applications and\r\nTools, pages 1–10, 2001.\r\n[2] D. Bailey, T. Harris, W. Saphir, R. van der Wijngaart, A. Woo, and\r\nM. Yarrow. The NAS parallel benchmarks 2.0. Technical Report\r\nNAS-95-020, NASA Ames Research Center, Dec. 1995.\r\n[3] J. Barnes and P. Hut. A hierarchical O(N log N) force-calculation\r\nalgorithm. Nature, 324(4):446–559, December 1986.\r\n[4] M. Berry, D. Chen, P. Koss, D. Kuck, S. Lo, Y. Pang, L. Pointer,\r\nR. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox,\r\nP. Messina, D. Walker, C. Hsiung, J. Schwarzmeier, K. Lue,\r\nS. Orszag, F. Seidl, O. Johnson, and R. Goodrum. The perfect\r\nclub benchmarks: Effective performance evaluation of supercom\u0002puters. International Journal of Supercomputer Applications, 3:5–\r\n40, 1989.\r\n[5] C. Bienia, S. Kumar, J. P. Singh, and K. Li. The PARSEC bench\u0002mark suite: Characterization and architectural implications. In\r\nProceedings of the 17th International Conference on Parallel Ar\u0002chitectures and Compilation Techniques, October 2008.\r\n[6] A. Braunstein, M. Mezard, and R. Zecchina. Survey propagation: ´\r\nAn algorithm for satisfiability. Random Structures and Algorithms,\r\n27:201–226, 2005.\r\n[7] M. Burtscher, M. Kulkarni, D. Prountzos, and K. Pingali. On the\r\nscalability of an automatically parallelized irregular application. In\r\nLanguages and Compilers for Parallel Computing (LCPC), 2008.\r\n[8] L. P. Chew. Guaranteed-quality mesh generation for curved sur\u0002faces. In SCG ’93: Proceedings of the ninth annual symposium on\r\nComputational geometry, 1993.\r\n[9] G. Contreras and M. Martonosi. Characterizing and improving the\r\nperformance of the Intel Threading Building Blocks. In IISWC\r\n2008: IEEE International Symposium on Workload Characteriza\u0002tion, Seattle, WA, Sept. 2008.\r\n[10] T. Cormen, C. Leiserson, R. Rivest, and C. Stein, editors. Intro\u0002duction to Algorithms. MIT Press, 2001.\r\n[11] L. J. Guibas, D. E. Knuth, and M. Sharir. Randomized incremental\r\nconstruction of Delaunay and Voronoi diagrams. Algorithmica,\r\n7(1):381–413, December 1992.\r\n[12] M. Kulkarni, M. Burtscher, R. Inkulu, K. Pingali, and C. Cascaval.\r\nHow much parallelism is there in irregular applications? In Princi\u0002ples and Practices of Parallel Programming (PPoPP), pages 3–14,\r\n2009.\r\n[13] M. Kulkarni, K. Pingali, B. Walter, G. Ramanarayanan, K. Bala,\r\nand L. P. Chew. Optimistic parallelism requires abstractions. SIG\u0002PLAN Not. (Proceedings of PLDI 2007), 42(6):211–222, 2007.\r\n[14] J. Larus and R. Rajwar. Transactional Memory (Synthesis Lectures\r\non Computer Architecture). Morgan & Claypool Publishers, 2007.\r\n[15] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney,\r\nS. Wallace, V. J. Reddi, and K. Hazelwood. PIN: Building cus\u0002tomized program analysis tools with dynamic instrumentation. In\r\nProceedings of the 2005 ACM SIGPLAN Conference on Program\u0002ming Language Design and Implementation, June 2005.\r\n[16] C. C. Minh, J. Chung, C. Kozyrakis, and K. Olukotun. STAMP:\r\nStanford transactional applications for multi-processing. In IISWC\r\n2008: IEEE International Symposium on Workload Characteriza\u0002tion, Seattle, WA, Sept. 2008.\r\n[17] J. Misra. Distributed discrete-event simulation. ACM Comput.\r\nSurv., 18(1):39–65, 1986.\r\n[18] A. Rogers, M. C. Carlisle, J. H. Reppy, and L. J. Hendren. Sup\u0002porting dynamic data structures on distributed-memory machines.\r\nACM Trans. Program. Lang. Syst., 17(2):233–263, 1995.\r\n[19] P.-N. Tan, M. Steinbach, and V. Kumar, editors. Introduction to\r\nData Mining. Pearson Addison Wesley, 2005.\r\n[20] B. Walter, K. Bala, M. Kulkarni, and K. Pingali. Fast agglomer\u0002ative clustering for rendering. In IEEE Symposium on Interactive\r\nRay Tracing (RT), 2008.\r\n[21] B. Walter, S. Fernandez, A. Arbree, K. Bala, M. Donikian, and\r\nD. Greenberg. Lightcuts: a scalable approach to illumination.\r\nACM Transactions on Graphics (SIGGRAPH), 24(3):1098–1107,\r\nJuly 2005.\r\n[22] S. C. Woo, M. Ohara, E. Torrie, J. P. Singh, and A. Gupta. The\r\nSPLASH-2 programs: characterization and methodological con\u0002siderations. In ISCA ’95: Proceedings of the 22nd annual inter\u0002national symposium on Computer architecture, pages 24–36, New\r\nYork, NY, USA, 1995. ACM.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/1486bfd1-6eff-4021-808a-896b9b877d84.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=db03c991e2a4961b9fd0145da7f0ed807badc7d5eedb3e99e02b7ec8813fb4eb",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 678
      },
      {
        "segments": [
          {
            "segment_id": "1486bfd1-6eff-4021-808a-896b9b877d84",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 12,
            "page_width": 612,
            "page_height": 792,
            "content": "acteristics of these applications and found that the granularity of\r\nthe parallelism is quite high, presenting interesting challenges to\r\nthe development of run-time systems to exploit this parallelism.\r\nBecause these applications represent an important class of al\u0002gorithms that appear in numerous domains and have significant\r\npotential for parallelism, we feel they are worthwhile targets for\r\nparallelization research.\r\nReferences\r\n[1] V. Aslot, R. Eigenmann, G. Gaertner, W. B. Jones, and B. Parady.\r\nSpecomp: A new benchmark suite for measuring parallel com\u0002puter performance. In In Workshop on OpenMP Applications and\r\nTools, pages 1–10, 2001.\r\n[2] D. Bailey, T. Harris, W. Saphir, R. van der Wijngaart, A. Woo, and\r\nM. Yarrow. The NAS parallel benchmarks 2.0. Technical Report\r\nNAS-95-020, NASA Ames Research Center, Dec. 1995.\r\n[3] J. Barnes and P. Hut. A hierarchical O(N log N) force-calculation\r\nalgorithm. Nature, 324(4):446–559, December 1986.\r\n[4] M. Berry, D. Chen, P. Koss, D. Kuck, S. Lo, Y. Pang, L. Pointer,\r\nR. Roloff, A. Sameh, E. Clementi, S. Chin, D. Schneider, G. Fox,\r\nP. Messina, D. Walker, C. Hsiung, J. Schwarzmeier, K. Lue,\r\nS. Orszag, F. Seidl, O. Johnson, and R. Goodrum. The perfect\r\nclub benchmarks: Effective performance evaluation of supercom\u0002puters. International Journal of Supercomputer Applications, 3:5–\r\n40, 1989.\r\n[5] C. Bienia, S. Kumar, J. P. Singh, and K. Li. The PARSEC bench\u0002mark suite: Characterization and architectural implications. In\r\nProceedings of the 17th International Conference on Parallel Ar\u0002chitectures and Compilation Techniques, October 2008.\r\n[6] A. Braunstein, M. Mezard, and R. Zecchina. Survey propagation: ´\r\nAn algorithm for satisfiability. Random Structures and Algorithms,\r\n27:201–226, 2005.\r\n[7] M. Burtscher, M. Kulkarni, D. Prountzos, and K. Pingali. On the\r\nscalability of an automatically parallelized irregular application. In\r\nLanguages and Compilers for Parallel Computing (LCPC), 2008.\r\n[8] L. P. Chew. Guaranteed-quality mesh generation for curved sur\u0002faces. In SCG ’93: Proceedings of the ninth annual symposium on\r\nComputational geometry, 1993.\r\n[9] G. Contreras and M. Martonosi. Characterizing and improving the\r\nperformance of the Intel Threading Building Blocks. In IISWC\r\n2008: IEEE International Symposium on Workload Characteriza\u0002tion, Seattle, WA, Sept. 2008.\r\n[10] T. Cormen, C. Leiserson, R. Rivest, and C. Stein, editors. Intro\u0002duction to Algorithms. MIT Press, 2001.\r\n[11] L. J. Guibas, D. E. Knuth, and M. Sharir. Randomized incremental\r\nconstruction of Delaunay and Voronoi diagrams. Algorithmica,\r\n7(1):381–413, December 1992.\r\n[12] M. Kulkarni, M. Burtscher, R. Inkulu, K. Pingali, and C. Cascaval.\r\nHow much parallelism is there in irregular applications? In Princi\u0002ples and Practices of Parallel Programming (PPoPP), pages 3–14,\r\n2009.\r\n[13] M. Kulkarni, K. Pingali, B. Walter, G. Ramanarayanan, K. Bala,\r\nand L. P. Chew. Optimistic parallelism requires abstractions. SIG\u0002PLAN Not. (Proceedings of PLDI 2007), 42(6):211–222, 2007.\r\n[14] J. Larus and R. Rajwar. Transactional Memory (Synthesis Lectures\r\non Computer Architecture). Morgan & Claypool Publishers, 2007.\r\n[15] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney,\r\nS. Wallace, V. J. Reddi, and K. Hazelwood. PIN: Building cus\u0002tomized program analysis tools with dynamic instrumentation. In\r\nProceedings of the 2005 ACM SIGPLAN Conference on Program\u0002ming Language Design and Implementation, June 2005.\r\n[16] C. C. Minh, J. Chung, C. Kozyrakis, and K. Olukotun. STAMP:\r\nStanford transactional applications for multi-processing. In IISWC\r\n2008: IEEE International Symposium on Workload Characteriza\u0002tion, Seattle, WA, Sept. 2008.\r\n[17] J. Misra. Distributed discrete-event simulation. ACM Comput.\r\nSurv., 18(1):39–65, 1986.\r\n[18] A. Rogers, M. C. Carlisle, J. H. Reppy, and L. J. Hendren. Sup\u0002porting dynamic data structures on distributed-memory machines.\r\nACM Trans. Program. Lang. Syst., 17(2):233–263, 1995.\r\n[19] P.-N. Tan, M. Steinbach, and V. Kumar, editors. Introduction to\r\nData Mining. Pearson Addison Wesley, 2005.\r\n[20] B. Walter, K. Bala, M. Kulkarni, and K. Pingali. Fast agglomer\u0002ative clustering for rendering. In IEEE Symposium on Interactive\r\nRay Tracing (RT), 2008.\r\n[21] B. Walter, S. Fernandez, A. Arbree, K. Bala, M. Donikian, and\r\nD. Greenberg. Lightcuts: a scalable approach to illumination.\r\nACM Transactions on Graphics (SIGGRAPH), 24(3):1098–1107,\r\nJuly 2005.\r\n[22] S. C. Woo, M. Ohara, E. Torrie, J. P. Singh, and A. Gupta. The\r\nSPLASH-2 programs: characterization and methodological con\u0002siderations. In ISCA ’95: Proceedings of the 22nd annual inter\u0002national symposium on Computer architecture, pages 24–36, New\r\nYork, NY, USA, 1995. ACM.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/b8e0e52c-e94c-4791-b663-5104d75b4866/images/1486bfd1-6eff-4021-808a-896b9b877d84.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041436Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=db03c991e2a4961b9fd0145da7f0ed807badc7d5eedb3e99e02b7ec8813fb4eb",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 678
      }
    ],
    "extracted_json": {
      "title": "Document Metadata",
      "schema_type": "object",
      "extracted_fields": [
        {
          "name": "title",
          "field_type": "string",
          "value": "Parallelism profiles and parallelism intensity for three input sizes\n"
        },
        {
          "name": "author",
          "field_type": "string",
          "value": "Authors: Milind Kulkarni, Martin Burtscher, Calin Cascaval, and Keshav Pingali\n"
        },
        {
          "name": "date_published",
          "field_type": "string",
          "value": "2007"
        },
        {
          "name": "location",
          "field_type": "string",
          "value": "Figure 9, Figure 10, Table 1\n"
        }
      ]
    }
  }
}