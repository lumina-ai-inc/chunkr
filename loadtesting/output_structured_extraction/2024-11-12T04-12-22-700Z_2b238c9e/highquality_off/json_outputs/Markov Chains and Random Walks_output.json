{
  "file_name": "Markov Chains and Random Walks.pdf",
  "task_id": "975a956f-2b41-42fc-8332-48c83a74c4bb",
  "output": {
    "chunks": [
      {
        "segments": [
          {
            "segment_id": "614f7e27-0698-4613-a578-67822ff465f9",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 1,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "princeton university F’02 cos 597D: a theorist’s toolkit\r\nLecture 7: Markov Chains and Random Walks\r\nLecturer: Sanjeev Arora Scribe:Elena Nabieva\r\n1 Basics\r\nA Markov chain is a discrete-time stochastic process on n states defined in terms of a\r\ntransition probability matrix (M) with rows i and columns j.\r\nM =\r\n\r\nPij\u0001\r\nA transition probability Pij corresponds to the probability that the state at time step t + 1\r\nwill be j, given that the state at time t is i. Therefore, each row in the matrix M is a\r\ndistribution and ∀i, j ∈ SPij ≥ 0 and P\r\nj Pij = 1.\r\nLet the initial distribution be given by the row vector x ∈ Rn, xi ≥ 0 and P\r\ni\r\nxi = 1.\r\nAfter one step, the new distribution is xM. It is easy to see that xM is again a distribution.\r\nSometimes it is useful to think of x as describing a certain amount fluid sitting at each node,\r\nsuch that the sum of the amounts is 1. After one step, the fluid sitting at node i distributes\r\nto its neighbors, such that Pij fraction goes to j.\r\nWe stress that the evolution of a Markov chain is memoryless: the transition probability\r\nPij depends only on the state i and not on the time t or the sequence of transititions taken\r\nbefore this time.\r\nSuppose we take two steps in this Markov chain. The memoryless property implies that\r\nthe probability of going from i to j is P\r\nk PikPkj , which is just the (i, j)th entry of the\r\nmatrix M2. In general taking t steps in the Markov chain corresponds to the matrix Mt.\r\nDefinition 1 A distribution π for the Markov chain M is a stationary distribution if\r\nπM = π.\r\nNote that an alternative statement is that π is an eigenvector which has all nonnegative\r\ncoordinates and whose corresponding eigenvalue is 1.\r\nExample 1 Consider a Markov chain defined by the following random walk on the nodes\r\nof an n-cycle. At each step, stay at the same node with probability 1/2. Go left with\r\nprobability 1/4 and right with probability 1/4.\r\nThe uniform distribution, which assigns probability 1/n to each node, is a stationary\r\ndistribution for this chain, since it is unchanged after applying one step of the chain.\r\nDefinition 2 A Markov chain M is ergodic if there exists a unique stationary distribution\r\nπ and for every (initial) distribution x the limit limt→∞ xMt = π.\r\nTheorem 1\r\nThe following are necessary and sufficient conditions for ergodicity:\r\n1. connectivity: ∀i, j : Mt(i, j) > 0 for some t.\r\n1",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/975a956f-2b41-42fc-8332-48c83a74c4bb/images/614f7e27-0698-4613-a578-67822ff465f9.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041949Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=614dc25c8f9a4766525334cf75965e4534a21dd7bd2dec36f9765191f00c052d",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 438
      },
      {
        "segments": [
          {
            "segment_id": "f956910a-7d2e-4812-890f-ca3e9a217d4f",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 2,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "2\r\n2. aperiodicity: ∀i : gcd{t : Mt(i, j) > 0} = 1.\r\nRemark 1 Clearly, these conditions are necessary. If the Markov chain is disconnected it\r\ncannot have a unique stationary distribution —there is a different stationary distribution for\r\neach connected component. Similarly, a bipartite graph does not have a unique distribution:\r\nif the initial distribution places all probability on one side of the bipartite graph, then the\r\ndistribution at time t oscillates between the two sides depending on whether t is odd or\r\neven. Note that in a bipartite graph gcd{t : Mt(i, j) > 0} ≥ 2. The sufficiency of these\r\nconditions is proved using eigenvalue techniques (for inspiration see the analysis of mixing\r\ntime later on).\r\nBoth conditions are easily satisfied in practice. In particular, any Markov chain can be\r\nmade aperiodic by adding self-loops assigned probability 1/2.\r\nDefinition 3 An ergodic Markov chain is reversible if the stationary distribution π satisfies\r\nfor all i, j, πiPij = πjPji.\r\nUses of Markov Chains. A Markov Chain is a very convenient way to model many sit\u0002uations where the “memoryless” property makes sense. Examples including communication\r\ntheory (Markovian sources), linguistics (Markovian models of language production), speech\r\nrecognition, internet search (Google’s Pagerank algorithm is based upon a Markovian model\r\nof a random surfer).\r\n2 Mixing Times\r\nInformally, the mixing time of a Markov chain is the time it takes to reach “nearly uniform”\r\ndistribution from any arbitrary starting distribution.\r\nDefinition 4 The mixing time of an ergodic Markov chain M is t if for every starting\r\ndistribution x, the distribution xMtsatisfies\r\n\f\r\n\fxMt − π\r\n\f\r\n\f\r\n1\r\n≤ 1/4. (Here |·|1denotes the `1\r\nnorm and the constant “1/4” is arbitrary.)\r\nThe next exercise clarifies why we are interested in `1 norm.\r\nExercise 1\r\nP\r\nFor any distribution π on {1, 2, . . . , N}, and S ⊆ {1, 2, . . . , N} let π(S) =\r\ni∈S\r\nπi. Show that for any two distributions π, π0,\r\n\f\r\n\fπ − π\r\n0\r\n\f\r\n\f\r\n1\r\n= 2 max\r\nS⊆{1,...,N}\r\n\f\r\n\fπ(S) − π\r\n0\r\n(S)\r\n\f\r\n\f\r\n. (1)\r\nHere is another way to restate the property in (1). Suppose A is some deterministic\r\nalgorithm (we place no bounds on its complexity) that, given any number i ∈ {1, 2, . . . , N},\r\noutputs Yes or No. If |π − π\r\n0\r\n|\r\n1 ≤ \u000f then the probability that A outputs Yes on a random\r\ninput drawn according to π cannot be too different from the probability it outputs Yes on an\r\ninput drawn according to π\r\n0\r\n. For this reason, `1 distance is also called statistical difference.\r\nWe are interested in analysing the mixing time so that we can draw a sample from the\r\nstationary distribution.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/975a956f-2b41-42fc-8332-48c83a74c4bb/images/f956910a-7d2e-4812-890f-ca3e9a217d4f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041949Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=da94ffa265477c32875b4ffdb4df34f85a022b08e10e2c1c6b70c93ad16a5671",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 456
      },
      {
        "segments": [
          {
            "segment_id": "03ed3218-7cc1-4380-a9f3-eca3c770db03",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 3,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "3\r\nExample 2 (Mixing time of a cycle) Consider an n-cycle, i.e., a Markov chain with n states\r\nwhere, at each state, Pr(lef t) = Pr(right) = Pr(stay) = 1/3.\r\nSuppose the initial distribution concentrates all probability at state 0. Then t steps\r\ncorrespond to about 2t/3 random coin tosses and the index of the final state is\r\n(#(Heads) − #(Tails)) (mod n).\r\nClearly, it takes Ω(n\r\n2\r\n) steps for the walk to reach the other half of the circle with any\r\nreasonable probability, and the mixing time is Ω(n\r\n2\r\n). We will later see that this lowerbound\r\nis fairly tight.\r\n2.1 Approximate Counting and Sampling\r\nMarkov chains allow one to sample from very nontrivial sets, provided we know how to find\r\nat least one element of this set. The idea is to define a Markov chain whose state space is\r\nthe same as this set. The Markov chain is such that it has a unique stationary distribution,\r\nwhich is uniform. We know how to find one element of the set. We do a walk according\r\nto the Markov chain with this as the starting point, and after T = O(mixing time) steps,\r\noutput the node we are at. This is approximately a random sample from the set. We\r\nillustrate this idea later. First we discuss why sampling from large sets is important.\r\nUsually this set has exponential size set and it is only given implicitly. We give a few\r\nexamples of some interesting sets.\r\nExample 3 (Perfect matchings) For some given graph G = (V, E) the set of all perfect\r\nmatchings in G could be exponentially large compared to the size of the graph, and is only\r\nknow implicitly. We know how to generate some element of this set, since we can find a\r\nperfect matching (if one exists) in polynomial time. But how do we generate a random\r\nelement?\r\nExample 4 (0 − 1 knapsack) Given a1 . . . an, b ∈ Z\r\n+, the set of vectors (xi\r\nP\r\n, . . . , xn) s.t.\r\naixi ≤ b.\r\nIn both cases, determining the exact size of the set is in #P (the complexity class corre\u0002sponding to counting the number of solutions to an NP problem). In fact, we have the\r\nfollowing.\r\nTheorem 2 (Valiant, late 1970s)\r\nIf there exist a polynomial-time algorithm for counting the number of perfect matchings or\r\nthe number of solutions to the 0 − 1 knapsack counting problem, then P = NP (in fact,\r\nP = P#P).\r\nValiant’s Theorem does not rule out finding good approximations to this problem.\r\nDefinition 5 A Fully Polynomial Randomized Approximation Scheme (FPRAS) is a ran\u0002domized algorithm, which for any \u000f finds an answer in time polynomial in (\r\nn\r\n\u000f\r\nlog 1\r\nδ\r\n) that is\r\ncorrect within a multiplicative factor (1+\u000f) with probability (1-δ).\r\nIt turns out that approximate counting is equivalent to approximate sampling.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/975a956f-2b41-42fc-8332-48c83a74c4bb/images/03ed3218-7cc1-4380-a9f3-eca3c770db03.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041949Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=85f6b792224e324a12fb87a08c601b0e8ece8080901ab1cd6b78ca9915f338d3",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 484
      },
      {
        "segments": [
          {
            "segment_id": "4fc43ff0-9a7a-4437-b8ca-266d4c81a20f",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 4,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "4\r\nTheorem 3 (Jerrum, Valiant, Vazirani, 1984)\r\nIf we can sample almost uniformly, in polynomial time, from A = {(x1, . . . , xn): Paixi ≤\r\nb}, then we can design an FPRAS for the knapsack counting problem.\r\nConversely, given an FPRAS for knapsack counting, we can draw an almost uniform\r\nsample from A.\r\nRemark 2 By “sampling almost uniformly” we mean having a sampling algorithm whose\r\noutput distribution has `1 distance exp(−n\r\n2\r\n) (say) from the uniform distribution. For ease\r\nof exposition, we think of this as a uniform sample.\r\nProof: We first show how to count approximately assuming there is a polynomial time\r\nsampling algorithm. The idea is simple though the details require some care (which we\r\nsuppress here). Suppose we have a sampling algorithm for knapsack. Draw a few samples\r\nfrom A, and observe what fraction feature x1 = 0. Say it is p. Let A0 be the set of\r\nsolutions with x1 = 0. Then p = |A0| / |A|. Now since A0 is the set of (x2, . . . , xn) such\r\nthat P\r\ni≥2\r\naixi ≤ b − a1x1, it is also the set of solutions of a knapsack problem, but with\r\none fewer variable. Using the algorithm recursively, assume we can calculate |A0|. Then we\r\ncan calculate\r\n|A| = |A0| /p.\r\nNow if we do not know |A0| , p accurately but up to some accuracy, say (1 + \u000f). So we\r\nwill only know |A| up to accuracy (1 + \u000f)\r\n2 ≈ 1 + 2\u000f.\r\nActually the above is not accurate, since it ignores the possibility that p is so small that\r\nwe never see an element of A0 when we draw poly(n) samples from A. However, in that\r\ncase, the set A1 = A \\ A0 must be at least 1/2 of A and we can estimate its size. Then we\r\nproceed in the rest of the algorithm using A1.\r\nTherefore, by choosing \u000f appropriately so that (1 + \u000f)\r\nn\r\nis small, and using the Chernoff\r\nbound, we can achieve the desired bound on the error in polynomial time.\r\nThe converse is similar. To turn a counting algorithm into a sampling algorithm, we need\r\nto show how to output a random member of A. We do this bit by bit, first outputting x1,\r\nthen x2, and so on. To output x1, output 0 with probability p and 1 with probablity 1 − p,\r\nwhere p = |A0| / |A| is calculated by calling the counting algorithm twice. Having output\r\nx1 with the correct probability, we are left with a sampling problem on n − 1 variables,\r\nwhich we solve recursively. Again, we need some care because we only have an approximate\r\ncounting algorithm instead of an exact algorithm. Since we need to count the approximate\r\ncounting algorithm only 2n times, an error of (1 + \u000f) each time could turn into an error of\r\n(1 + \u000f)\r\n2n\r\n, which is about 1 + 2\u000f. ✷\r\nThus to count approximately, it suffices to sample from the uniform distribution. We\r\ndefine a Markov chain M on A whose stationary distribution is uniform. Then we show\r\nthat its mixing time is poly(n).\r\nThe Markov chain is as follows. If the current node is (x1, . . . , xn) (note a1x1 + a2x2 +\r\n. . . + anxn ≤ b) then\r\n1. with probability 1/2 remain at the same node\r\n2. else pick i ∈ {1, . . . , n}.\r\nLet y = (x1, . . . , xi−1, 1 − xi, xi+1, . . . , xn). If y ∈ A, go there. Else stay put.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/975a956f-2b41-42fc-8332-48c83a74c4bb/images/4fc43ff0-9a7a-4437-b8ca-266d4c81a20f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041949Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=749c068752d618518aed5c6287a47c3b04444905ccc1ea08ffe23941496a65a9",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 611
      },
      {
        "segments": [
          {
            "segment_id": "4fc43ff0-9a7a-4437-b8ca-266d4c81a20f",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 4,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "4\r\nTheorem 3 (Jerrum, Valiant, Vazirani, 1984)\r\nIf we can sample almost uniformly, in polynomial time, from A = {(x1, . . . , xn): Paixi ≤\r\nb}, then we can design an FPRAS for the knapsack counting problem.\r\nConversely, given an FPRAS for knapsack counting, we can draw an almost uniform\r\nsample from A.\r\nRemark 2 By “sampling almost uniformly” we mean having a sampling algorithm whose\r\noutput distribution has `1 distance exp(−n\r\n2\r\n) (say) from the uniform distribution. For ease\r\nof exposition, we think of this as a uniform sample.\r\nProof: We first show how to count approximately assuming there is a polynomial time\r\nsampling algorithm. The idea is simple though the details require some care (which we\r\nsuppress here). Suppose we have a sampling algorithm for knapsack. Draw a few samples\r\nfrom A, and observe what fraction feature x1 = 0. Say it is p. Let A0 be the set of\r\nsolutions with x1 = 0. Then p = |A0| / |A|. Now since A0 is the set of (x2, . . . , xn) such\r\nthat P\r\ni≥2\r\naixi ≤ b − a1x1, it is also the set of solutions of a knapsack problem, but with\r\none fewer variable. Using the algorithm recursively, assume we can calculate |A0|. Then we\r\ncan calculate\r\n|A| = |A0| /p.\r\nNow if we do not know |A0| , p accurately but up to some accuracy, say (1 + \u000f). So we\r\nwill only know |A| up to accuracy (1 + \u000f)\r\n2 ≈ 1 + 2\u000f.\r\nActually the above is not accurate, since it ignores the possibility that p is so small that\r\nwe never see an element of A0 when we draw poly(n) samples from A. However, in that\r\ncase, the set A1 = A \\ A0 must be at least 1/2 of A and we can estimate its size. Then we\r\nproceed in the rest of the algorithm using A1.\r\nTherefore, by choosing \u000f appropriately so that (1 + \u000f)\r\nn\r\nis small, and using the Chernoff\r\nbound, we can achieve the desired bound on the error in polynomial time.\r\nThe converse is similar. To turn a counting algorithm into a sampling algorithm, we need\r\nto show how to output a random member of A. We do this bit by bit, first outputting x1,\r\nthen x2, and so on. To output x1, output 0 with probability p and 1 with probablity 1 − p,\r\nwhere p = |A0| / |A| is calculated by calling the counting algorithm twice. Having output\r\nx1 with the correct probability, we are left with a sampling problem on n − 1 variables,\r\nwhich we solve recursively. Again, we need some care because we only have an approximate\r\ncounting algorithm instead of an exact algorithm. Since we need to count the approximate\r\ncounting algorithm only 2n times, an error of (1 + \u000f) each time could turn into an error of\r\n(1 + \u000f)\r\n2n\r\n, which is about 1 + 2\u000f. ✷\r\nThus to count approximately, it suffices to sample from the uniform distribution. We\r\ndefine a Markov chain M on A whose stationary distribution is uniform. Then we show\r\nthat its mixing time is poly(n).\r\nThe Markov chain is as follows. If the current node is (x1, . . . , xn) (note a1x1 + a2x2 +\r\n. . . + anxn ≤ b) then\r\n1. with probability 1/2 remain at the same node\r\n2. else pick i ∈ {1, . . . , n}.\r\nLet y = (x1, . . . , xi−1, 1 − xi, xi+1, . . . , xn). If y ∈ A, go there. Else stay put.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/975a956f-2b41-42fc-8332-48c83a74c4bb/images/4fc43ff0-9a7a-4437-b8ca-266d4c81a20f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041949Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=749c068752d618518aed5c6287a47c3b04444905ccc1ea08ffe23941496a65a9",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 611
      },
      {
        "segments": [
          {
            "segment_id": "2874d109-0ed5-4a3c-94c4-a04c2a8c726f",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 5,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "5\r\nNote that M is\r\n1. aperiodic because of self-loops\r\n2. connected because every sequence can be turned into the zero vector in a finite number\r\nof transformations, i.e., every node is connected to ~0.\r\nTherefore, M is ergodic, i.e., has a unique stationary distribution. Since the uniform dis\u0002tribution is stationary, it follows that the stationary distribution of M is uniform.\r\nNow the question is: how fast does M converge to the uniform distribution? If M mixes\r\nfast, we can get an efficient approximation algorithm for the knapsack counting: we get the\r\nsolution by running M for the mixing time and sampling from the resulting distribution\r\nafter the mixing time has elapsed.\r\nTheorem 4\r\n(Morris-Sinclair, 1999): The mixing time for M is O(n\r\n8\r\n).\r\nFact (see our remark later in our analysis of mixing time): running the M for a bit\r\nlonger than the mixing time results in a distribution that is extremely close to uniform.\r\nThus, we get the following sampling algorithm:\r\n1. Start with the zero vector as the initial distribution of M.\r\n2. Run M for O(n\r\n9\r\n) time.\r\n3. output the node at which the algorithm stops.\r\nThis results in a uniform sampling from A.\r\nThus Markov chains are useful for sampling from a distribution. Often, we are unable to\r\nprove any useful bounds on the mixing time (this is the case for many Markov chains used\r\nin simulated annealing and the Metropolis algorithm of statistical physics) but nevertheless\r\nin practice the chains are found to mix rapidly. Thus they are useful even though we do\r\nnot have a proof that they work.\r\n3 Bounding the mixing time\r\nFor simplicity we restrict attention to regular graphs.\r\nLet M be a Markov chain on a d-regular undirected graph with an adjacency matrix A.\r\nAssume that M is ergodic and that d includes any self-loops.\r\nThen, clearly M =\r\n1\r\ndA.\r\nSince M is ergodic, and since 1\r\nn\r\n~1 is a stationary distribution, then 1\r\nn\r\n~1 is the unique\r\nstationary distribution for M.\r\nThe question is how fast does M convege to 1\r\nn\r\n~1? Note that if x is a distribution, x can\r\nbe written as\r\nx = ~1\r\n1\r\nn\r\n+\r\nXn\r\ni=2\r\nαiei",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/975a956f-2b41-42fc-8332-48c83a74c4bb/images/2874d109-0ed5-4a3c-94c4-a04c2a8c726f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041949Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=09cbe5243e0680558dd7cac5408617996281d2922dbd0367f6bef7e79c2e4e5d",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 372
      },
      {
        "segments": [
          {
            "segment_id": "a8e0a1cd-9772-4ea0-ac09-bd6cb58923b3",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 6,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "6\r\nwhere ei are the eigenvectors of M which form an orthogonal basis and 1 is the first eigen\u0002vector with eigenvalue 1. (Clearly, x can be written as a combination of the eigenvectors;\r\nthe observation here is that the coefficient in front of the first eigenvector ~1 is ~1 · x/\r\n\f\r\n\f\r\n\f\r\n~1\r\n\f\r\n\f\r\n\f\r\n2\r\n2\r\nwhich is 1\r\nn\r\nP\r\ni\r\nxi =\r\n1\r\nn\r\n.)\r\nMtx = Mt−1(Mx)\r\n= Mt−1(\r\n1\r\nn\r\n~1 +Xn\r\ni=2\r\nαiλiei)\r\n= Mt−2(M(\r\n1\r\nn\r\n~1 +Xn\r\ni=2\r\nαiλiei))\r\n. . .\r\n=\r\n1\r\nn\r\n~1 +Xn\r\ni=2\r\nαiλ\r\nt\r\niei\r\nAlso\r\nk\r\nXn\r\ni=2\r\nαiλ\r\nt\r\nieik2 ≤ λ\r\nt\r\nmax\r\nwhere λmax is the second largest eigenvalue of M. (Note that we are using the fact that\r\nthe total `2 norm of any distribution is P\r\ni\r\nx\r\n2\r\ni ≤\r\nP\r\ni\r\nxi = 1.)\r\nThus we have proved\r\n\f\r\n\fMtx −\r\n1\r\nn\r\n1\r\n\f\r\n\f\r\n2\r\n≤ λ\r\nt\r\nmax. Mixing times were defined using `1 distance,\r\nbut Cauchy Schwartz inequality relates the `2 and `1 distances: |p|\r\n1 ≤\r\n√\r\nn |p|\r\n2\r\n. So we have\r\nproved:\r\nTheorem 5\r\nThe mixing time is at most O(\r\nlog n\r\nλmax\r\n).\r\nNote also that if we let the Markov chain run for O(k log n/λmax) steps then the distance\r\nto uniform distribution drops to exp(−k). This is why we were not very fussy about the\r\nconstant 1/4 in the definition of the mixing time earlier.\r\nFinally, we recall from the last lecture: for S ⊂ V , V ol(S) = P\r\ni∈S\r\ndi, where diis the\r\ndegree of node i, the Cheeger Constant is\r\nhG = min\r\nS⊂V,vol(S)≤\r\nV ol(V )\r\n2\r\n\f\r\n\fE(S, S\r\n\f\r\n\f\r\nV ol(S)\r\nIf µ is the smallest nonzero eigenvalue of the Laplacian L of M, then\r\n2hG ≥ µ ≥\r\nh\r\n2\r\nG\r\n2\r\nThe Laplacian for our graph is\r\nL = I − M\r\nTherefore,",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/975a956f-2b41-42fc-8332-48c83a74c4bb/images/a8e0a1cd-9772-4ea0-ac09-bd6cb58923b3.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041949Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=492427194f20073e3b851f61d445bc2ab300fb7fa33e4bc9a3b222ae619c6dc1",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 318
      },
      {
        "segments": [
          {
            "segment_id": "c90d5ec7-b82f-4be7-bd70-ec5da1cc5147",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 7,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "7\r\nspec(L) = {0 = µ1 ≤ µ2 ≤ . . . ≤ µn}\r\nand\r\nspec(M) = {1 = 1 − µ1 ≥ 1 − µ2 ≥ . . . ≥ 1 − µn}\r\nNote that λmax = (1 − µ2)\r\nt\r\n.\r\nTherefore,\r\nk\r\nXn\r\ni=2\r\nαiλ\r\nt\r\nieik2 ≤ (1 −\r\nh\r\n2\r\nG\r\n2\r\n)\r\nt√\r\nn\r\n.\r\nand we obtain the Jerrum-Sinclair inequality:\r\nkMtx −\r\n1\r\nn\r\n~1k2 ≤ (1 −\r\nh\r\n2\r\nG\r\n2\r\n)\r\nt√\r\nn.\r\nExamples:\r\n1. For n-cycle: λmax = (1 −\r\nc\r\nn2 )\r\nt\r\n, mixing time ≈ O(n\r\n2\r\nlog n) (c is some constant).\r\n2. For a hypercube on 2n nodes (with self-loops added), λmax = (1 −\r\nc\r\nn\r\n) (this was a\r\nhomework problem), so mixing time ≈ O(n log n) (c is some constant).\r\nObserve that the mixing time is much smaller than the number of nodes, i.e., the random\r\nwalk does not visit all nodes.\r\nFinally, we note that random walks also give a randomized way to check s−t connectivity\r\n(for undirected graphs) in logarithmic space, a surprising result since the usual method of\r\nchecking s − t connectivity, namely, breadth-first-search, seems to inherently require linear\r\nspace.\r\nThe main idea is that a random walk on a connected graph on n nodes mixes in O(n\r\n4\r\n)\r\ntime (the Cheeger constant must be at least 1/n2) and so a logarithmic space algorithm\r\ncan just do a random walk for O(n\r\n2\r\nlog n) steps (note that space O(log n) is required is\r\njust to store the current node and a counter for the number of steps) starting from s, and\r\nif it never sees t, it can output reject. This answer will be correct with high probability.\r\nThis application of random walks by Alleliunas, Karp, Karmarkar, Lipton and Lovasz 1979\r\nwas probably one of the first in theoretical computer science and it has been the subject of\r\nmuch further work recently.\r\n4 Analysis of Mixing Time for General Markov Chains\r\nThanks to Satyen Kale for providing this additional note\r\nIn the class we only analysed random walks on d-regular graphs and showed that they\r\nconverge exponentially fast with rate given by the second largest eigenvalue of the transition\r\nmatrix. Here, we prove the same fact for general ergodic Markov chains. We need a lemma\r\nfirst.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/975a956f-2b41-42fc-8332-48c83a74c4bb/images/c90d5ec7-b82f-4be7-bd70-ec5da1cc5147.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041949Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=06cab65050a79db20b45949161141dddbd09346d38158118d480e81277637683",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 391
      },
      {
        "segments": [
          {
            "segment_id": "4134c698-6178-46db-9fb8-4c4dcf6fa5b8",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 595.276,
              "height": 841.89
            },
            "page_number": 8,
            "page_width": 595.276,
            "page_height": 841.89,
            "content": "8\r\nLemma 6\r\nLet M be the transition matrix of an ergodic Markov chain with stationary distribution π\r\nand eigenvalues λ1(= 1) ≥ λ2 ≥ . . . ≥ λn, corresponding to eigenvectors v1(= π), v2, . . . vn.\r\nThen for any k ≥ 2,\r\nvk\r\n~1 = 0.\r\nProof: We have vkM = λkvk. Mulitplying by ~1 and noting that M~1 = ~1, we get\r\nvk\r\n~1 = λkvk\r\n~1.\r\nSince the Markov chain is ergodic, λk 6= 1, so vk\r\n~1 = 0 as required. ✷\r\nWe are now ready to prove the main result concerning the exponentially fast convergence\r\nof a general ergodic Markov chain:\r\nTheorem 7\r\nIn the setup of the lemma above, let λ = max {|λ2|, |λn|}. Then for any initial distribution\r\nx, we have\r\n||xMt − π||2 ≤ λ\r\nt\r\n||x||2.\r\nProof: Write x in terms of v1, v2, . . . , vn as\r\nx = α1π +\r\nXn\r\ni=2\r\nαivi.\r\nMultiplying the above equation by ~1, we get α1 = 1 (since x~1 = π~1 = 1). Therefore\r\nxMt = π +\r\nPn\r\ni=2 αiλ\r\nt\r\ni\r\nvi, and hence\r\n||xMt − π||2 ≤ ||Xn\r\ni=2\r\nαiλ\r\nt\r\ni\r\nvi||2 (2)\r\n≤ λ\r\nt\r\nq\r\nα\r\n2\r\n2 + · · · + α2\r\nn\r\n(3)\r\n≤ λ\r\nt\r\n||x||2, (4)\r\nas needed. ✷",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/975a956f-2b41-42fc-8332-48c83a74c4bb/images/4134c698-6178-46db-9fb8-4c4dcf6fa5b8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041949Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0b59f3c65a75eb18ecc0a1ab2ab84cc327f40f92c7e016552f071859a907e584",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 224
      }
    ],
    "extracted_json": {
      "title": "Document Metadata",
      "schema_type": "object",
      "extracted_fields": [
        {
          "name": "title",
          "field_type": "string",
          "value": "Mixing Times"
        },
        {
          "name": "author",
          "field_type": "string",
          "value": "Jerrum, Valiant, Vazirani"
        },
        {
          "name": "date_published",
          "field_type": "string",
          "value": "No information on `date_published` could be found in the provided text."
        },
        {
          "name": "location",
          "field_type": "string",
          "value": "princeton university"
        }
      ]
    }
  }
}