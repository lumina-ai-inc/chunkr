{
  "file_name": "KLEE - Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs (klee-osdi-2008).pdf",
  "task_id": "f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86",
  "output": {
    "chunks": [
      {
        "segments": [
          {
            "segment_id": "84807974-8227-4bb3-aefc-6b97b34b3eab",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 1,
            "page_width": 612,
            "page_height": 792,
            "content": "KLEE: Unassisted and Automatic Generation of High-Coverage\r\nTests for Complex Systems Programs\r\nCristian Cadar, Daniel Dunbar, Dawson Engler ∗\r\nStanford University\r\nAbstract\r\nWe present a new symbolic execution tool, KLEE, ca\u0002pable of automatically generating tests that achieve\r\nhigh coverage on a diverse set of complex and\r\nenvironmentally-intensive programs. We used KLEE to\r\nthoroughly check all 89 stand-alone programs in the\r\nGNU COREUTILS utility suite, which form the core\r\nuser-level environment installed on millions of Unix sys\u0002tems, and arguably are the single most heavily tested set\r\nof open-source programs in existence. KLEE-generated\r\ntests achieve high line coverage — on average over 90%\r\nper tool (median: over 94%) — and significantly beat\r\nthe coverage of the developers’ own hand-written test\r\nsuite. When we did the same for 75 equivalent tools in\r\nthe BUSYBOX embedded system suite, results were even\r\nbetter, including 100% coverage on 31 of them.\r\nWe also used KLEE as a bug finding tool, applying it to\r\n452 applications (over 430K total lines of code), where\r\nit found 56 serious bugs, including three in COREUTILS\r\nthat had been missed for over 15 years. Finally, we used\r\nKLEE to crosscheck purportedly identical BUSYBOX and\r\nCOREUTILS utilities, finding functional correctness er\u0002rors and a myriad of inconsistencies.\r\n1 Introduction\r\nMany classes of errors, such as functional correctness\r\nbugs, are difficult to find without executing a piece of\r\ncode. The importance of such testing — combined with\r\nthe difficulty and poor performance of random and man\u0002ual approaches — has led to much recent work in us\u0002ing symbolic execution to automatically generate test in\u0002puts [11, 14–16, 20–22, 24, 26, 27, 36]. At a high-level,\r\nthese tools use variations on the following idea: Instead\r\nof running code on manually- or randomly-constructed\r\ninput, they run it on symbolic input initially allowed to\r\nbe “anything.” They substitute program inputs with sym-\r\n∗Author names are in alphabetical order. Daniel Dunbar is the main\r\nauthor of the KLEE system.\r\nbolic values and replace corresponding concrete program\r\noperations with ones that manipulate symbolic values.\r\nWhen program execution branches based on a symbolic\r\nvalue, the system (conceptually) follows both branches,\r\non each path maintaining a set of constraints called the\r\npath condition which must hold on execution of that\r\npath. When a path terminates or hits a bug, a test case\r\ncan be generated by solving the current path condition\r\nfor concrete values. Assuming deterministic code, feed\u0002ing this concrete input to a raw, unmodified version of\r\nthe checked code will make it follow the same path and\r\nhit the same bug.\r\nResults are promising. However, while researchers\r\nhave shown such tools can sometimes get good cover\u0002age and find bugs on a small number of programs, it\r\nhas been an open question whether the approach has any\r\nhope of consistently achieving high coverage on real ap\u0002plications. Two common concerns are (1) the exponen\u0002tial number of paths through code and (2) the challenges\r\nin handling code that interacts with its surrounding envi\u0002ronment, such as the operating system, the network, or\r\nthe user (colloquially: “the environment problem”). Nei\u0002ther concern has been much helped by the fact that most\r\npast work, including ours, has usually reported results on\r\na limited set of hand-picked benchmarks and typically\r\nhas not included any coverage numbers.\r\nThis paper makes two contributions. First, we present\r\na new symbolic execution tool, KLEE, which we de\u0002signed for robust, deep checking of a broad range of ap\u0002plications, leveraging several years of lessons from our\r\nprevious tool, EXE [16]. KLEE employs a variety of con\u0002straint solving optimizations, represents program states\r\ncompactly, and uses search heuristics to get high code\r\ncoverage. Additionally, it uses a simple and straight\u0002forward approach to dealing with the external environ\u0002ment. These features improve KLEE’s performance by\r\nover an order of magnitude and let it check a broad range\r\nof system-intensive programs “out of the box.”",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/84807974-8227-4bb3-aefc-6b97b34b3eab.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=771e3e8c574a530581a10083ebc4d68135741b15401c2b2da462625c5bff6567",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 634
      },
      {
        "segments": [
          {
            "segment_id": "84807974-8227-4bb3-aefc-6b97b34b3eab",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 1,
            "page_width": 612,
            "page_height": 792,
            "content": "KLEE: Unassisted and Automatic Generation of High-Coverage\r\nTests for Complex Systems Programs\r\nCristian Cadar, Daniel Dunbar, Dawson Engler ∗\r\nStanford University\r\nAbstract\r\nWe present a new symbolic execution tool, KLEE, ca\u0002pable of automatically generating tests that achieve\r\nhigh coverage on a diverse set of complex and\r\nenvironmentally-intensive programs. We used KLEE to\r\nthoroughly check all 89 stand-alone programs in the\r\nGNU COREUTILS utility suite, which form the core\r\nuser-level environment installed on millions of Unix sys\u0002tems, and arguably are the single most heavily tested set\r\nof open-source programs in existence. KLEE-generated\r\ntests achieve high line coverage — on average over 90%\r\nper tool (median: over 94%) — and significantly beat\r\nthe coverage of the developers’ own hand-written test\r\nsuite. When we did the same for 75 equivalent tools in\r\nthe BUSYBOX embedded system suite, results were even\r\nbetter, including 100% coverage on 31 of them.\r\nWe also used KLEE as a bug finding tool, applying it to\r\n452 applications (over 430K total lines of code), where\r\nit found 56 serious bugs, including three in COREUTILS\r\nthat had been missed for over 15 years. Finally, we used\r\nKLEE to crosscheck purportedly identical BUSYBOX and\r\nCOREUTILS utilities, finding functional correctness er\u0002rors and a myriad of inconsistencies.\r\n1 Introduction\r\nMany classes of errors, such as functional correctness\r\nbugs, are difficult to find without executing a piece of\r\ncode. The importance of such testing — combined with\r\nthe difficulty and poor performance of random and man\u0002ual approaches — has led to much recent work in us\u0002ing symbolic execution to automatically generate test in\u0002puts [11, 14–16, 20–22, 24, 26, 27, 36]. At a high-level,\r\nthese tools use variations on the following idea: Instead\r\nof running code on manually- or randomly-constructed\r\ninput, they run it on symbolic input initially allowed to\r\nbe “anything.” They substitute program inputs with sym-\r\n∗Author names are in alphabetical order. Daniel Dunbar is the main\r\nauthor of the KLEE system.\r\nbolic values and replace corresponding concrete program\r\noperations with ones that manipulate symbolic values.\r\nWhen program execution branches based on a symbolic\r\nvalue, the system (conceptually) follows both branches,\r\non each path maintaining a set of constraints called the\r\npath condition which must hold on execution of that\r\npath. When a path terminates or hits a bug, a test case\r\ncan be generated by solving the current path condition\r\nfor concrete values. Assuming deterministic code, feed\u0002ing this concrete input to a raw, unmodified version of\r\nthe checked code will make it follow the same path and\r\nhit the same bug.\r\nResults are promising. However, while researchers\r\nhave shown such tools can sometimes get good cover\u0002age and find bugs on a small number of programs, it\r\nhas been an open question whether the approach has any\r\nhope of consistently achieving high coverage on real ap\u0002plications. Two common concerns are (1) the exponen\u0002tial number of paths through code and (2) the challenges\r\nin handling code that interacts with its surrounding envi\u0002ronment, such as the operating system, the network, or\r\nthe user (colloquially: “the environment problem”). Nei\u0002ther concern has been much helped by the fact that most\r\npast work, including ours, has usually reported results on\r\na limited set of hand-picked benchmarks and typically\r\nhas not included any coverage numbers.\r\nThis paper makes two contributions. First, we present\r\na new symbolic execution tool, KLEE, which we de\u0002signed for robust, deep checking of a broad range of ap\u0002plications, leveraging several years of lessons from our\r\nprevious tool, EXE [16]. KLEE employs a variety of con\u0002straint solving optimizations, represents program states\r\ncompactly, and uses search heuristics to get high code\r\ncoverage. Additionally, it uses a simple and straight\u0002forward approach to dealing with the external environ\u0002ment. These features improve KLEE’s performance by\r\nover an order of magnitude and let it check a broad range\r\nof system-intensive programs “out of the box.”",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/84807974-8227-4bb3-aefc-6b97b34b3eab.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=771e3e8c574a530581a10083ebc4d68135741b15401c2b2da462625c5bff6567",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 634
      },
      {
        "segments": [
          {
            "segment_id": "3844d037-f1c2-4317-82b8-ab97cde2f9de",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 2,
            "page_width": 612,
            "page_height": 792,
            "content": "Second, we show that KLEE’s automatically-generated\r\ntests get high coverage on a diverse set of real, com\u0002plicated, and environmentally-intensive programs. Our\r\nmost in-depth evaluation applies KLEE to all 89 pro\u0002grams 1\r\nin the latest stable version of GNU COREUTILS\r\n(version 6.10), which contains roughly 80,000 lines of\r\nlibrary code and 61,000 lines in the actual utilities [2].\r\nThese programs interact extensively with their environ\u0002ment to provide a variety of functions, including man\u0002aging the file system (e.g., ls, dd, chmod), display\u0002ing and configuring system properties (e.g., logname,\r\nprintenv, hostname), controlling command invo\u0002cation (e.g., nohup, nice, env), processing text files\r\n(e.g., sort, od, patch), and so on. They form the\r\ncore user-level environment installed on many Unix sys\u0002tems. They are used daily by millions of people, bug\r\nfixes are handled promptly, and new releases are pushed\r\nregularly. Moreover, their extensive interaction with the\r\nenvironment stress-tests symbolic execution where it has\r\nhistorically been weakest.\r\nFurther, finding bugs in COREUTILS is hard. They are\r\narguably the single most well-tested suite of open-source\r\napplications available (e.g., is there a program the reader\r\nhas used more under Unix than “ls”?). In 1995, ran\u0002dom testing of a subset of COREUTILS utilities found\r\nmarkedly fewer failures as compared to seven commer\u0002cial Unix systems [35]. The last COREUTILS vulnerabil\u0002ity reported on the SecurityFocus or US National Vulner\u0002ability databases was three years ago [5, 7].\r\nIn addition, we checked two other UNIX utility suites:\r\nBUSYBOX, a widely-used distribution for embedded sys\u0002tems [1], and the latest release for MINIX [4]. Finally, we\r\nchecked the HISTAR operating system kernel as a con\u0002trast to application code [39].\r\nOur experiments fall into three categories: (1) those\r\nwhere we do intensive runs to both find bugs and get high\r\ncoverage (COREUTILS, HISTAR, and 75 BUSYBOX util\u0002ities), (2) those where we quickly run over many appli\u0002cations to find bugs (an additional 204 BUSYBOX util\u0002ities and 77 MINIX utilities), and (3) those where we\r\ncrosscheck equivalent programs to find deeper correct\u0002ness bugs (67 BUSYBOX utilities vs. the equivalent 67 in\r\nCOREUTILS).\r\nIn total, we ran KLEE on more than 452 programs, con\u0002taining over 430K total lines of code. To the best of our\r\nknowledge, this represents an order of magnitude more\r\ncode and distinct programs than checked by prior sym\u0002bolic test generation work. Our experiments show:\r\n1 KLEE gets high coverage on a broad set of complex\r\nprograms. Its automatically generated tests covered\r\n84.5% of the total lines in COREUTILS and 90.5% in\r\nBUSYBOX (ignoring library code). On average these\r\n1We ignored utilities that are simply wrapper calls to others, such\r\nas arch (“uname -m”) and vdir (“ls -l -b”).\r\ntests hit over 90% of the lines in each tool (median:\r\nover 94%), achieving perfect 100% coverage in 16\r\nCOREUTILS tools and 31 BUSYBOX tools.\r\n2 KLEE can get significantly more code coverage than\r\na concentrated, sustained manual effort. The roughly\r\n89-hour run used to generate COREUTILS line cover\u0002age beat the developers’ own test suite — built incre\u0002mentally over fifteen years — by 16.8%!\r\n3 With one exception, KLEE achieved these high\u0002coverage results on unaltered applications. The sole\r\nexception, sort in COREUTILS, required a single\r\nedit to shrink a large buffer that caused problems for\r\nthe constraint solver.\r\n4 KLEE finds important errors in heavily-tested code. It\r\nfound ten fatal errors in COREUTILS (including three\r\nthat had escaped detection for 15 years), which ac\u0002count for more crashing bugs than were reported in\r\n2006, 2007 and 2008 combined. It further found 24\r\nbugs in BUSYBOX, 21 bugs in MINIX, and a security\r\nvulnerability in HISTAR– a total of 56 serious bugs.\r\n5 The fact that KLEE test cases can be run on the raw\r\nversion of the code (e.g., compiled with gcc) greatly\r\nsimplifies debugging and error reporting. For exam\u0002ple, all COREUTILS bugs were confirmed and fixed\r\nwithin two days and versions of the tests KLEE gen\u0002erated were included in the standard regression suite.\r\n6 KLEE is not limited to low-level programming er\u0002rors: when used to crosscheck purportedly identical\r\nBUSYBOX and GNU COREUTILS tools, it automat\u0002ically found functional correctness errors and a myr\u0002iad of inconsistencies.\r\n7 KLEE can also be applied to non-application code.\r\nWhen applied to the core of the HISTAR kernel, it\r\nachieved an average line coverage of 76.4% (with\r\ndisk) and 67.1% (without disk) and found a serious\r\nsecurity bug.\r\nThe next section gives an overview of our approach.\r\nSection 3 describes KLEE, focusing on its key optimiza\u0002tions. Section 4 discusses how to model the environment.\r\nThe heart of the paper is Section 5, which presents our\r\nexperimental results. Finally, Section 6 describes related\r\nwork and Section 7 concludes.\r\n2 Overview\r\nThis section explains how KLEE works by walking the\r\nreader through the testing of MINIX’s tr tool. Despite\r\nits small size — 169 lines, 83 of which are executable —\r\nit illustrates two problems common to the programs we\r\ncheck:\r\n1 Complexity. The code aims to translate and delete\r\ncharacters from its input. It hides this intent well be\u0002neath non-obvious input parsing code, tricky bound\u0002ary conditions, and hard-to-follow control flow. Fig\u0002ure 1 gives a representative snippet.\r\n2",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/3844d037-f1c2-4317-82b8-ab97cde2f9de.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d9a325b88eda3b139e3689ebc35f384f83e45d758fd814c5b0b87dea8502ba5a",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 843
      },
      {
        "segments": [
          {
            "segment_id": "3844d037-f1c2-4317-82b8-ab97cde2f9de",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 2,
            "page_width": 612,
            "page_height": 792,
            "content": "Second, we show that KLEE’s automatically-generated\r\ntests get high coverage on a diverse set of real, com\u0002plicated, and environmentally-intensive programs. Our\r\nmost in-depth evaluation applies KLEE to all 89 pro\u0002grams 1\r\nin the latest stable version of GNU COREUTILS\r\n(version 6.10), which contains roughly 80,000 lines of\r\nlibrary code and 61,000 lines in the actual utilities [2].\r\nThese programs interact extensively with their environ\u0002ment to provide a variety of functions, including man\u0002aging the file system (e.g., ls, dd, chmod), display\u0002ing and configuring system properties (e.g., logname,\r\nprintenv, hostname), controlling command invo\u0002cation (e.g., nohup, nice, env), processing text files\r\n(e.g., sort, od, patch), and so on. They form the\r\ncore user-level environment installed on many Unix sys\u0002tems. They are used daily by millions of people, bug\r\nfixes are handled promptly, and new releases are pushed\r\nregularly. Moreover, their extensive interaction with the\r\nenvironment stress-tests symbolic execution where it has\r\nhistorically been weakest.\r\nFurther, finding bugs in COREUTILS is hard. They are\r\narguably the single most well-tested suite of open-source\r\napplications available (e.g., is there a program the reader\r\nhas used more under Unix than “ls”?). In 1995, ran\u0002dom testing of a subset of COREUTILS utilities found\r\nmarkedly fewer failures as compared to seven commer\u0002cial Unix systems [35]. The last COREUTILS vulnerabil\u0002ity reported on the SecurityFocus or US National Vulner\u0002ability databases was three years ago [5, 7].\r\nIn addition, we checked two other UNIX utility suites:\r\nBUSYBOX, a widely-used distribution for embedded sys\u0002tems [1], and the latest release for MINIX [4]. Finally, we\r\nchecked the HISTAR operating system kernel as a con\u0002trast to application code [39].\r\nOur experiments fall into three categories: (1) those\r\nwhere we do intensive runs to both find bugs and get high\r\ncoverage (COREUTILS, HISTAR, and 75 BUSYBOX util\u0002ities), (2) those where we quickly run over many appli\u0002cations to find bugs (an additional 204 BUSYBOX util\u0002ities and 77 MINIX utilities), and (3) those where we\r\ncrosscheck equivalent programs to find deeper correct\u0002ness bugs (67 BUSYBOX utilities vs. the equivalent 67 in\r\nCOREUTILS).\r\nIn total, we ran KLEE on more than 452 programs, con\u0002taining over 430K total lines of code. To the best of our\r\nknowledge, this represents an order of magnitude more\r\ncode and distinct programs than checked by prior sym\u0002bolic test generation work. Our experiments show:\r\n1 KLEE gets high coverage on a broad set of complex\r\nprograms. Its automatically generated tests covered\r\n84.5% of the total lines in COREUTILS and 90.5% in\r\nBUSYBOX (ignoring library code). On average these\r\n1We ignored utilities that are simply wrapper calls to others, such\r\nas arch (“uname -m”) and vdir (“ls -l -b”).\r\ntests hit over 90% of the lines in each tool (median:\r\nover 94%), achieving perfect 100% coverage in 16\r\nCOREUTILS tools and 31 BUSYBOX tools.\r\n2 KLEE can get significantly more code coverage than\r\na concentrated, sustained manual effort. The roughly\r\n89-hour run used to generate COREUTILS line cover\u0002age beat the developers’ own test suite — built incre\u0002mentally over fifteen years — by 16.8%!\r\n3 With one exception, KLEE achieved these high\u0002coverage results on unaltered applications. The sole\r\nexception, sort in COREUTILS, required a single\r\nedit to shrink a large buffer that caused problems for\r\nthe constraint solver.\r\n4 KLEE finds important errors in heavily-tested code. It\r\nfound ten fatal errors in COREUTILS (including three\r\nthat had escaped detection for 15 years), which ac\u0002count for more crashing bugs than were reported in\r\n2006, 2007 and 2008 combined. It further found 24\r\nbugs in BUSYBOX, 21 bugs in MINIX, and a security\r\nvulnerability in HISTAR– a total of 56 serious bugs.\r\n5 The fact that KLEE test cases can be run on the raw\r\nversion of the code (e.g., compiled with gcc) greatly\r\nsimplifies debugging and error reporting. For exam\u0002ple, all COREUTILS bugs were confirmed and fixed\r\nwithin two days and versions of the tests KLEE gen\u0002erated were included in the standard regression suite.\r\n6 KLEE is not limited to low-level programming er\u0002rors: when used to crosscheck purportedly identical\r\nBUSYBOX and GNU COREUTILS tools, it automat\u0002ically found functional correctness errors and a myr\u0002iad of inconsistencies.\r\n7 KLEE can also be applied to non-application code.\r\nWhen applied to the core of the HISTAR kernel, it\r\nachieved an average line coverage of 76.4% (with\r\ndisk) and 67.1% (without disk) and found a serious\r\nsecurity bug.\r\nThe next section gives an overview of our approach.\r\nSection 3 describes KLEE, focusing on its key optimiza\u0002tions. Section 4 discusses how to model the environment.\r\nThe heart of the paper is Section 5, which presents our\r\nexperimental results. Finally, Section 6 describes related\r\nwork and Section 7 concludes.\r\n2 Overview\r\nThis section explains how KLEE works by walking the\r\nreader through the testing of MINIX’s tr tool. Despite\r\nits small size — 169 lines, 83 of which are executable —\r\nit illustrates two problems common to the programs we\r\ncheck:\r\n1 Complexity. The code aims to translate and delete\r\ncharacters from its input. It hides this intent well be\u0002neath non-obvious input parsing code, tricky bound\u0002ary conditions, and hard-to-follow control flow. Fig\u0002ure 1 gives a representative snippet.\r\n2",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/3844d037-f1c2-4317-82b8-ab97cde2f9de.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d9a325b88eda3b139e3689ebc35f384f83e45d758fd814c5b0b87dea8502ba5a",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 843
      },
      {
        "segments": [
          {
            "segment_id": "b610b470-a0c6-4d74-a07c-119b136f083d",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 3,
            "page_width": 612,
            "page_height": 792,
            "content": "2 Environmental Dependencies. Most of the code is\r\ncontrolled by values derived from environmental in\u0002put. Command line arguments determine what pro\u0002cedures execute, input values determine which way\r\nif-statements trigger, and the program depends on the\r\nability to read from the file system. Since inputs can\r\nbe invalid (or even malicious), the code must handle\r\nthese cases gracefully. It is not trivial to test all im\u0002portant values and boundary cases.\r\nThe code illustrates two additional common features.\r\nFirst, it has bugs, which KLEE finds and generates test\r\ncases for. Second, KLEE quickly achieves good code\r\ncoverage: in two minutes it generates 37 tests that cover\r\nall executable statements. 2\r\nKLEE has two goals: (1) hit every line of executable\r\ncode in the program and (2) detect at each dangerous op\u0002eration (e.g., dereference, assertion) if any input value\r\nexists that could cause an error. KLEE does so by running\r\nprograms symbolically: unlike normal execution, where\r\noperations produce concrete values from their operands,\r\nhere they generate constraints that exactly describe the\r\nset of values possible on a given path. When KLEE de\u0002tects an error or when a path reaches an exit call, KLEE\r\nsolves the current path’s constraints (called its path con\u0002dition) to produce a test case that will follow the same\r\npath when rerun on an unmodified version of the checked\r\nprogram (e.g, compiled with gcc).\r\nKLEE is designed so that the paths followed by the\r\nunmodified program will always follow the same path\r\nKLEE took (i.e., there are no false positives). However,\r\nnon-determinism in checked code and bugs in KLEE or\r\nits models have produced false positives in practice. The\r\nability to rerun tests outside of KLEE, in conjunction with\r\nstandard tools such as gdb and gcov is invaluable for\r\ndiagnosing such errors and for validating our results.\r\nWe next show how to use KLEE, then give an overview\r\nof how it works.\r\n2.1 Usage\r\nA user can start checking many real programs with KLEE\r\nin seconds: KLEE typically requires no source modifi\u0002cations or manual work. Users first compile their code\r\nto bytecode using the publicly-available LLVM com\u0002piler [33] for GNU C. We compiled tr using:\r\nllvm-gcc --emit-llvm -c tr.c -o tr.bc\r\nUsers then run KLEE on the generated bytecode, option\u0002ally stating the number, size, and type of symbolic inputs\r\nto test the code on. For tr we used the command:\r\nklee --max-time 2 --sym-args 1 10 10\r\n--sym-files 2 2000 --max-fail 1 tr.bc\r\n2The program has one line of dead code, an unreachable return\r\nstatement, which, reassuringly, KLEE cannot run.\r\n1 : void expand(char *arg, unsigned char *buffer) { 8\r\n2 : int i, ac; 9\r\n3 : while (*arg) { 10*\r\n4 : if (*arg == ’\\\\’) { 11*\r\n5 : arg++;\r\n6 : i = ac = 0;\r\n7 : if (*arg >= ’0’ && *arg <= ’7’) {\r\n8 : do {\r\n9 : ac = (ac << 3) + *arg++ − ’0’;\r\n10: i++;\r\n11: } while (i<4 && *arg>=’0’ && *arg<=’7’);\r\n12: *buffer++ = ac;\r\n13: } else if (*arg != ’\\0’)\r\n14: *buffer++ = *arg++;\r\n15: } else if (*arg == ’[’) { 12*\r\n16: arg++; 13\r\n17: i = *arg++; 14\r\n18: if (*arg++ != ’-’) { 15!\r\n19: *buffer++ = ’[’;\r\n20: arg −= 2;\r\n21: continue;\r\n22: }\r\n23: ac = *arg++;\r\n24: while (i <= ac) *buffer++ = i++;\r\n25: arg++; /* Skip ’]’ */\r\n26: } else\r\n27: *buffer++ = *arg++;\r\n28: }\r\n29: }\r\n30: . . .\r\n31: int main(int argc, char* argv[ ]) { 1\r\n32: int index = 1; 2\r\n33: if (argc > 1 && argv[index][0] == ’-’) { 3*\r\n34: . . . 4\r\n35: } 5\r\n36: . . . 6\r\n37: expand(argv[index++], index); 7\r\n38: . . .\r\n39: }\r\nFigure 1: Code snippet from MINIX’s tr, representative\r\nof the programs checked in this paper: tricky, non-obvious,\r\ndifficult to verify by inspection or testing. The order of the\r\nstatements on the path to the error at line 18 are numbered on\r\nthe right hand side.\r\nThe first option, --max-time, tells KLEE to check\r\ntr.bc for at most two minutes. The rest describe the\r\nsymbolic inputs. The option --sym-args 1 10 10\r\nsays to use zero to three command line arguments, the\r\nfirst 1 character long, the others 10 characters long. 3 The\r\noption --sym-files 2 2000 says to use standard\r\ninput and one file, each holding 2000 bytes of symbolic\r\ndata. The option --max-fail 1 says to fail at most\r\none system call along each program path (see § 4.2).\r\n2.2 Symbolic execution with KLEE\r\nWhen KLEE runs on tr, it finds a buffer overflow error\r\nat line 18 in Figure 1 and then produces a concrete test\r\n3Since strings in C are zero terminated, this essentially generates\r\narguments of up to that size.\r\n3",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/b610b470-a0c6-4d74-a07c-119b136f083d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=3578632e53e9b6e6034730b45fd7070783e92c89fb07e110159a3c1060cb7916",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 804
      },
      {
        "segments": [
          {
            "segment_id": "b610b470-a0c6-4d74-a07c-119b136f083d",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 3,
            "page_width": 612,
            "page_height": 792,
            "content": "2 Environmental Dependencies. Most of the code is\r\ncontrolled by values derived from environmental in\u0002put. Command line arguments determine what pro\u0002cedures execute, input values determine which way\r\nif-statements trigger, and the program depends on the\r\nability to read from the file system. Since inputs can\r\nbe invalid (or even malicious), the code must handle\r\nthese cases gracefully. It is not trivial to test all im\u0002portant values and boundary cases.\r\nThe code illustrates two additional common features.\r\nFirst, it has bugs, which KLEE finds and generates test\r\ncases for. Second, KLEE quickly achieves good code\r\ncoverage: in two minutes it generates 37 tests that cover\r\nall executable statements. 2\r\nKLEE has two goals: (1) hit every line of executable\r\ncode in the program and (2) detect at each dangerous op\u0002eration (e.g., dereference, assertion) if any input value\r\nexists that could cause an error. KLEE does so by running\r\nprograms symbolically: unlike normal execution, where\r\noperations produce concrete values from their operands,\r\nhere they generate constraints that exactly describe the\r\nset of values possible on a given path. When KLEE de\u0002tects an error or when a path reaches an exit call, KLEE\r\nsolves the current path’s constraints (called its path con\u0002dition) to produce a test case that will follow the same\r\npath when rerun on an unmodified version of the checked\r\nprogram (e.g, compiled with gcc).\r\nKLEE is designed so that the paths followed by the\r\nunmodified program will always follow the same path\r\nKLEE took (i.e., there are no false positives). However,\r\nnon-determinism in checked code and bugs in KLEE or\r\nits models have produced false positives in practice. The\r\nability to rerun tests outside of KLEE, in conjunction with\r\nstandard tools such as gdb and gcov is invaluable for\r\ndiagnosing such errors and for validating our results.\r\nWe next show how to use KLEE, then give an overview\r\nof how it works.\r\n2.1 Usage\r\nA user can start checking many real programs with KLEE\r\nin seconds: KLEE typically requires no source modifi\u0002cations or manual work. Users first compile their code\r\nto bytecode using the publicly-available LLVM com\u0002piler [33] for GNU C. We compiled tr using:\r\nllvm-gcc --emit-llvm -c tr.c -o tr.bc\r\nUsers then run KLEE on the generated bytecode, option\u0002ally stating the number, size, and type of symbolic inputs\r\nto test the code on. For tr we used the command:\r\nklee --max-time 2 --sym-args 1 10 10\r\n--sym-files 2 2000 --max-fail 1 tr.bc\r\n2The program has one line of dead code, an unreachable return\r\nstatement, which, reassuringly, KLEE cannot run.\r\n1 : void expand(char *arg, unsigned char *buffer) { 8\r\n2 : int i, ac; 9\r\n3 : while (*arg) { 10*\r\n4 : if (*arg == ’\\\\’) { 11*\r\n5 : arg++;\r\n6 : i = ac = 0;\r\n7 : if (*arg >= ’0’ && *arg <= ’7’) {\r\n8 : do {\r\n9 : ac = (ac << 3) + *arg++ − ’0’;\r\n10: i++;\r\n11: } while (i<4 && *arg>=’0’ && *arg<=’7’);\r\n12: *buffer++ = ac;\r\n13: } else if (*arg != ’\\0’)\r\n14: *buffer++ = *arg++;\r\n15: } else if (*arg == ’[’) { 12*\r\n16: arg++; 13\r\n17: i = *arg++; 14\r\n18: if (*arg++ != ’-’) { 15!\r\n19: *buffer++ = ’[’;\r\n20: arg −= 2;\r\n21: continue;\r\n22: }\r\n23: ac = *arg++;\r\n24: while (i <= ac) *buffer++ = i++;\r\n25: arg++; /* Skip ’]’ */\r\n26: } else\r\n27: *buffer++ = *arg++;\r\n28: }\r\n29: }\r\n30: . . .\r\n31: int main(int argc, char* argv[ ]) { 1\r\n32: int index = 1; 2\r\n33: if (argc > 1 && argv[index][0] == ’-’) { 3*\r\n34: . . . 4\r\n35: } 5\r\n36: . . . 6\r\n37: expand(argv[index++], index); 7\r\n38: . . .\r\n39: }\r\nFigure 1: Code snippet from MINIX’s tr, representative\r\nof the programs checked in this paper: tricky, non-obvious,\r\ndifficult to verify by inspection or testing. The order of the\r\nstatements on the path to the error at line 18 are numbered on\r\nthe right hand side.\r\nThe first option, --max-time, tells KLEE to check\r\ntr.bc for at most two minutes. The rest describe the\r\nsymbolic inputs. The option --sym-args 1 10 10\r\nsays to use zero to three command line arguments, the\r\nfirst 1 character long, the others 10 characters long. 3 The\r\noption --sym-files 2 2000 says to use standard\r\ninput and one file, each holding 2000 bytes of symbolic\r\ndata. The option --max-fail 1 says to fail at most\r\none system call along each program path (see § 4.2).\r\n2.2 Symbolic execution with KLEE\r\nWhen KLEE runs on tr, it finds a buffer overflow error\r\nat line 18 in Figure 1 and then produces a concrete test\r\n3Since strings in C are zero terminated, this essentially generates\r\narguments of up to that size.\r\n3",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/b610b470-a0c6-4d74-a07c-119b136f083d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=3578632e53e9b6e6034730b45fd7070783e92c89fb07e110159a3c1060cb7916",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 804
      },
      {
        "segments": [
          {
            "segment_id": "b2306aa4-6e07-4e19-9baf-557ebc627ccf",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 4,
            "page_width": 612,
            "page_height": 792,
            "content": "case (tr [ \"\" \"\") that hits it. Assuming the options\r\nof the previous subsection, KLEE runs tr as follows:\r\n1 KLEE constructs symbolic command line string argu\u0002ments whose contents have no constraints other than\r\nzero-termination. It then constrains the number of ar\u0002guments to be between 0 and 3, and their sizes to be\r\n1, 10 and 10 respectively. It then calls main with\r\nthese initial path constraints.\r\n2 When KLEE hits the branch argc > 1 at line 33,\r\nit uses its constraint solver STP [23] to see which di\u0002rections can execute given the current path condition.\r\nFor this branch, both directions are possible; KLEE\r\nforks execution and follows both paths, adding the\r\nconstraint argc > 1 on the false path and argc ≤ 1\r\non the true path.\r\n3 Given more than one active path, KLEE must pick\r\nwhich one to execute first. We describe its algorithm\r\nin Section 3.4. For now assume it follows the path\r\nthat reaches the bug. As it does so, KLEE adds further\r\nconstraints to the contents of arg, and forks for a\r\ntotal of five times (lines denoted with a “*”): twice\r\non line 33, and then on lines 3, 4, and 15 in expand.\r\n4 At each dangerous operation (e.g., pointer derefer\u0002ence), KLEE checks if any possible value allowed by\r\nthe current path condition would cause an error. On\r\nthe annotated path, KLEE detects no errors before line\r\n18. At that point, however, it determines that input\r\nvalues exist that allow the read of arg to go out of\r\nbounds: after taking the true branch at line 15, the\r\ncode increments arg twice without checking if the\r\nstring has ended. If it has, this increment skips the\r\nterminating ’\\0’ and points to invalid memory.\r\n5 KLEE generates concrete values for argc and argv\r\n(i.e., tr [ \"\" \"\") that when rerun on a raw ver\u0002sion of tr will hit this bug. It then continues follow\u0002ing the current path, adding the constraint that the\r\nerror does not occur (in order to find other errors).\r\n3 The KLEE Architecture\r\nKLEE is a complete redesign of our previous system\r\nEXE [16]. At a high level, KLEE functions as a hybrid\r\nbetween an operating system for symbolic processes and\r\nan interpreter. Each symbolic process has a register file,\r\nstack, heap, program counter, and path condition. To\r\navoid confusion with a Unix process, we refer to KLEE’s\r\nrepresentation of a symbolic process as a state. Programs\r\nare compiled to the LLVM [33] assembly language, a\r\nRISC-like virtual instruction set. KLEE directly inter\u0002prets this instruction set, and maps instructions to con\u0002straints without approximation (i.e. bit-level accuracy).\r\n4\r\n4KLEE does not currently support: symbolic floating point,\r\nlongjmp, threads, and assembly code. Additionally, memory objects\r\nare required to have concrete sizes.\r\n3.1 Basic architecture\r\nAt any one time, KLEE may be executing a large number\r\nof states. The core of KLEE is an interpreter loop which\r\nselects a state to run and then symbolically executes a\r\nsingle instruction in the context of that state. This loop\r\ncontinues until there are no states remaining, or a user\u0002defined timeout is reached.\r\nUnlike a normal process, storage locations for a state\r\n— registers, stack and heap objects — refer to expres\u0002sions (trees) instead of raw data values. The leaves of\r\nan expression are symbolic variables or constants, and\r\nthe interior nodes come from LLVM assembly language\r\noperations (e.g., arithmetic operations, bitwise manipu\u0002lation, comparisons, and memory accesses). Storage lo\u0002cations which hold a constant expression are said to be\r\nconcrete.\r\nSymbolic execution of the majority of instructions is\r\nstraightforward. For example, to symbolically execute\r\nan LLVM add instruction:\r\n%dst = add i32 %src0, %src1\r\nKLEE retrieves the addends from the %src0 and %src1\r\nregisters and writes a new expression Add(%src0,\r\n%src1) to the %dst register. For efficiency, the code\r\nthat builds expressions checks if all given operands are\r\nconcrete (i.e., constants) and, if so, performs the opera\u0002tion natively, returning a constant expression.\r\nConditional branches take a boolean expression\r\n(branch condition) and alter the instruction pointer of\r\nthe state based on whether the condition is true or false.\r\nKLEE queries the constraint solver to determine if the\r\nbranch condition is either provably true or provably false\r\nalong the current path; if so, the instruction pointer is\r\nupdated to the appropriate location. Otherwise, both\r\nbranches are possible: KLEE clones the state so that it\r\ncan explore both paths, updating the instruction pointer\r\nand path condition on each path appropriately.\r\nPotentially dangerous operations implicitly generate\r\nbranches that check if any input value exists that could\r\ncause an error. For example, a division instruction gen\u0002erates a branch that checks for a zero divisor. Such\r\nbranches work identically to normal branches. Thus,\r\neven when the check succeeds (i.e., an error is detected),\r\nexecution continues on the false path, which adds the\r\nnegation of the check as a constraint (e.g., making the\r\ndivisor not zero). If an error is detected, KLEE generates\r\na test case to trigger the error and terminates the state.\r\nAs with other dangerous operations, load and store in\u0002structions generate checks: in this case to check that the\r\naddress is in-bounds of a valid memory object. However,\r\nload and store operations present an additional compli\u0002cation. The most straightforward representation of the\r\nmemory used by checked code would be a flat byte ar\u0002ray. In this case, loads and stores would simply map to\r\n4",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/b2306aa4-6e07-4e19-9baf-557ebc627ccf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f74de3b732abfaf634511c867f16f60d05972ede5c9e870a3f68c7cd8880c245",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 896
      },
      {
        "segments": [
          {
            "segment_id": "b2306aa4-6e07-4e19-9baf-557ebc627ccf",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 4,
            "page_width": 612,
            "page_height": 792,
            "content": "case (tr [ \"\" \"\") that hits it. Assuming the options\r\nof the previous subsection, KLEE runs tr as follows:\r\n1 KLEE constructs symbolic command line string argu\u0002ments whose contents have no constraints other than\r\nzero-termination. It then constrains the number of ar\u0002guments to be between 0 and 3, and their sizes to be\r\n1, 10 and 10 respectively. It then calls main with\r\nthese initial path constraints.\r\n2 When KLEE hits the branch argc > 1 at line 33,\r\nit uses its constraint solver STP [23] to see which di\u0002rections can execute given the current path condition.\r\nFor this branch, both directions are possible; KLEE\r\nforks execution and follows both paths, adding the\r\nconstraint argc > 1 on the false path and argc ≤ 1\r\non the true path.\r\n3 Given more than one active path, KLEE must pick\r\nwhich one to execute first. We describe its algorithm\r\nin Section 3.4. For now assume it follows the path\r\nthat reaches the bug. As it does so, KLEE adds further\r\nconstraints to the contents of arg, and forks for a\r\ntotal of five times (lines denoted with a “*”): twice\r\non line 33, and then on lines 3, 4, and 15 in expand.\r\n4 At each dangerous operation (e.g., pointer derefer\u0002ence), KLEE checks if any possible value allowed by\r\nthe current path condition would cause an error. On\r\nthe annotated path, KLEE detects no errors before line\r\n18. At that point, however, it determines that input\r\nvalues exist that allow the read of arg to go out of\r\nbounds: after taking the true branch at line 15, the\r\ncode increments arg twice without checking if the\r\nstring has ended. If it has, this increment skips the\r\nterminating ’\\0’ and points to invalid memory.\r\n5 KLEE generates concrete values for argc and argv\r\n(i.e., tr [ \"\" \"\") that when rerun on a raw ver\u0002sion of tr will hit this bug. It then continues follow\u0002ing the current path, adding the constraint that the\r\nerror does not occur (in order to find other errors).\r\n3 The KLEE Architecture\r\nKLEE is a complete redesign of our previous system\r\nEXE [16]. At a high level, KLEE functions as a hybrid\r\nbetween an operating system for symbolic processes and\r\nan interpreter. Each symbolic process has a register file,\r\nstack, heap, program counter, and path condition. To\r\navoid confusion with a Unix process, we refer to KLEE’s\r\nrepresentation of a symbolic process as a state. Programs\r\nare compiled to the LLVM [33] assembly language, a\r\nRISC-like virtual instruction set. KLEE directly inter\u0002prets this instruction set, and maps instructions to con\u0002straints without approximation (i.e. bit-level accuracy).\r\n4\r\n4KLEE does not currently support: symbolic floating point,\r\nlongjmp, threads, and assembly code. Additionally, memory objects\r\nare required to have concrete sizes.\r\n3.1 Basic architecture\r\nAt any one time, KLEE may be executing a large number\r\nof states. The core of KLEE is an interpreter loop which\r\nselects a state to run and then symbolically executes a\r\nsingle instruction in the context of that state. This loop\r\ncontinues until there are no states remaining, or a user\u0002defined timeout is reached.\r\nUnlike a normal process, storage locations for a state\r\n— registers, stack and heap objects — refer to expres\u0002sions (trees) instead of raw data values. The leaves of\r\nan expression are symbolic variables or constants, and\r\nthe interior nodes come from LLVM assembly language\r\noperations (e.g., arithmetic operations, bitwise manipu\u0002lation, comparisons, and memory accesses). Storage lo\u0002cations which hold a constant expression are said to be\r\nconcrete.\r\nSymbolic execution of the majority of instructions is\r\nstraightforward. For example, to symbolically execute\r\nan LLVM add instruction:\r\n%dst = add i32 %src0, %src1\r\nKLEE retrieves the addends from the %src0 and %src1\r\nregisters and writes a new expression Add(%src0,\r\n%src1) to the %dst register. For efficiency, the code\r\nthat builds expressions checks if all given operands are\r\nconcrete (i.e., constants) and, if so, performs the opera\u0002tion natively, returning a constant expression.\r\nConditional branches take a boolean expression\r\n(branch condition) and alter the instruction pointer of\r\nthe state based on whether the condition is true or false.\r\nKLEE queries the constraint solver to determine if the\r\nbranch condition is either provably true or provably false\r\nalong the current path; if so, the instruction pointer is\r\nupdated to the appropriate location. Otherwise, both\r\nbranches are possible: KLEE clones the state so that it\r\ncan explore both paths, updating the instruction pointer\r\nand path condition on each path appropriately.\r\nPotentially dangerous operations implicitly generate\r\nbranches that check if any input value exists that could\r\ncause an error. For example, a division instruction gen\u0002erates a branch that checks for a zero divisor. Such\r\nbranches work identically to normal branches. Thus,\r\neven when the check succeeds (i.e., an error is detected),\r\nexecution continues on the false path, which adds the\r\nnegation of the check as a constraint (e.g., making the\r\ndivisor not zero). If an error is detected, KLEE generates\r\na test case to trigger the error and terminates the state.\r\nAs with other dangerous operations, load and store in\u0002structions generate checks: in this case to check that the\r\naddress is in-bounds of a valid memory object. However,\r\nload and store operations present an additional compli\u0002cation. The most straightforward representation of the\r\nmemory used by checked code would be a flat byte ar\u0002ray. In this case, loads and stores would simply map to\r\n4",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/b2306aa4-6e07-4e19-9baf-557ebc627ccf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f74de3b732abfaf634511c867f16f60d05972ede5c9e870a3f68c7cd8880c245",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 896
      },
      {
        "segments": [
          {
            "segment_id": "0848e33d-f708-48b7-ae00-e5d9c1f9d9d3",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 5,
            "page_width": 612,
            "page_height": 792,
            "content": "array read and write expressions respectively. Unfortu\u0002nately, our constraint solver STP would almost never be\r\nable to solve the resultant constraints (and neither would\r\nthe other constraint solvers we know of). Thus, as in\r\nEXE, KLEE maps every memory object in the checked\r\ncode to a distinct STP array (in a sense, mapping a flat\r\naddress space to a segmented one). This representation\r\ndramatically improves performance since it lets STP ig\u0002nore all arrays not referenced by a given expression.\r\nMany operations (such as bound checks or object-level\r\ncopy-on-write) require object-specific information. If a\r\npointer can refer to many objects, these operations be\u0002come difficult to perform. For simplicity, KLEE sidesteps\r\nthis problem as follows. When a dereferenced pointer p\r\ncan refer to N objects, KLEE clones the current state N\r\ntimes. In each state it constrains p to be within bounds\r\nof its respective object and then performs the appropri\u0002ate read or write operation. Although this method can\r\nbe expensive for pointers with large points-to sets, most\r\nprograms we have tested only use symbolic pointers that\r\nrefer to a single object, and KLEE is well-optimized for\r\nthis case.\r\n3.2 Compact state representation\r\nThe number of states grows quite quickly in practice:\r\noften even small programs generate tens or even hun\u0002dreds of thousands of concurrent states during the first\r\nfew minutes of interpretation. When we ran COREUTILS\r\nwith a 1GB memory cap, the maximum number of con\u0002current states recorded was 95,982 (for hostid), and\r\nthe average of this maximum for each tool was 51,385.\r\nThis explosion makes state size critical.\r\nSince KLEE tracks all memory objects, it can imple\u0002ment copy-on-write at the object level (rather than page\r\ngranularity), dramatically reducing per-state memory re\u0002quirements. By implementing the heap as an immutable\r\nmap, portions of the heap structure itself can also be\r\nshared amongst multiple states (similar to sharing por\u0002tions of page tables across fork()). Additionally, this\r\nheap structure can be cloned in constant time, which is\r\nimportant given the frequency of this operation.\r\nThis approach is in marked contrast to EXE, which\r\nused one native OS process per state. Internalizing the\r\nstate representation dramatically increased the number\r\nof states which can be concurrently explored, both by\r\ndecreasing the per-state cost and allowing states to share\r\nmemory at the object (rather than page) level. Addition\u0002ally, this greatly simplified the implementation of caches\r\nand search heuristics which operate across all states.\r\n3.3 Query optimization\r\nAlmost always, the cost of constraint solving dominates\r\neverything else — unsurprising, given that KLEE gen\u0002erates complicated queries for an NP-complete logic.\r\nThus, we spent a lot of effort on tricks to simplify ex\u0002pressions and ideally eliminate queries (no query is the\r\nfastest query) before they reach STP. Simplified queries\r\nmake solving faster, reduce memory consumption, and\r\nincrease the query cache’s hit rate (see below). The main\r\nquery optimizations are:\r\nExpression Rewriting. The most basic optimizations\r\nmirror those in a compiler: e.g., simple arithmetic sim\u0002plifications (x + 0 = x), strength reduction (x * 2\r\nn\r\n= x << n), linear simplification (2*x - x = x).\r\nConstraint Set Simplification. Symbolic execution\r\ntypically involves the addition of a large number of con\u0002straints to the path condition. The natural structure of\r\nprograms means that constraints on same variables tend\r\nto become more specific. For example, commonly an in\u0002exact constraint such as x < 10 gets added, followed\r\nsome time later by the constraint x = 5. KLEE actively\r\nsimplifies the constraint set by rewriting previous con\u0002straints when new equality constraints are added to the\r\nconstraint set. In this example, substituting the value for\r\nx into the first constraint simplifies it to true, which\r\nKLEE eliminates.\r\nImplied Value Concretization. When a constraint such\r\nas x + 1 = 10 is added to the path condition, then the\r\nvalue of x has effectively become concrete along that\r\npath. KLEE determines this fact (in this case that x = 9)\r\nand writes the concrete value back to memory. This en\u0002sures that subsequent accesses of that memory location\r\ncan return a cheap constant expression.\r\nConstraint Independence. Many constraints do not\r\noverlap in terms of the memory they reference. Con\u0002straint independence (taken from EXE) divides con\u0002straint sets into disjoint independent subsets based on the\r\nsymbolic variables they reference. By explicitly track\u0002ing these subsets, KLEE can frequently eliminate irrel\u0002evant constraints prior to sending a query to the con\u0002straint solver. For example, given the constraint set\r\n{i < j, j < 20, k > 0}, a query of whether i = 20\r\njust requires the first two constraints.\r\nCounter-example Cache. Redundant queries are fre\u0002quent, and a simple cache is effective at eliminating a\r\nlarge number of them. However, it is possible to build\r\na more sophisticated cache due to the particular struc\u0002ture of constraint sets. The counter-example cache maps\r\nsets of constraints to counter-examples (i.e., variable as\u0002signments), along with a special sentinel used when a set\r\nof constraints has no solution. This mapping is stored\r\nin a custom data structure — derived from the UBTree\r\nstructure of Hoffmann and Hoehler [28] — which al\u0002lows efficient searching for cache entries for both sub\u0002sets and supersets of a constraint set. By storing the\r\ncache in this fashion, the counter-example cache gains\r\nthree additional ways to eliminate queries. In the ex\u0002ample below, we assume that the counter-example cache\r\n5",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/0848e33d-f708-48b7-ae00-e5d9c1f9d9d3.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a64df3470e6620546ed3290fea4aa64f13c96475b64338a6ba464e5ee6941a2b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 877
      },
      {
        "segments": [
          {
            "segment_id": "0848e33d-f708-48b7-ae00-e5d9c1f9d9d3",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 5,
            "page_width": 612,
            "page_height": 792,
            "content": "array read and write expressions respectively. Unfortu\u0002nately, our constraint solver STP would almost never be\r\nable to solve the resultant constraints (and neither would\r\nthe other constraint solvers we know of). Thus, as in\r\nEXE, KLEE maps every memory object in the checked\r\ncode to a distinct STP array (in a sense, mapping a flat\r\naddress space to a segmented one). This representation\r\ndramatically improves performance since it lets STP ig\u0002nore all arrays not referenced by a given expression.\r\nMany operations (such as bound checks or object-level\r\ncopy-on-write) require object-specific information. If a\r\npointer can refer to many objects, these operations be\u0002come difficult to perform. For simplicity, KLEE sidesteps\r\nthis problem as follows. When a dereferenced pointer p\r\ncan refer to N objects, KLEE clones the current state N\r\ntimes. In each state it constrains p to be within bounds\r\nof its respective object and then performs the appropri\u0002ate read or write operation. Although this method can\r\nbe expensive for pointers with large points-to sets, most\r\nprograms we have tested only use symbolic pointers that\r\nrefer to a single object, and KLEE is well-optimized for\r\nthis case.\r\n3.2 Compact state representation\r\nThe number of states grows quite quickly in practice:\r\noften even small programs generate tens or even hun\u0002dreds of thousands of concurrent states during the first\r\nfew minutes of interpretation. When we ran COREUTILS\r\nwith a 1GB memory cap, the maximum number of con\u0002current states recorded was 95,982 (for hostid), and\r\nthe average of this maximum for each tool was 51,385.\r\nThis explosion makes state size critical.\r\nSince KLEE tracks all memory objects, it can imple\u0002ment copy-on-write at the object level (rather than page\r\ngranularity), dramatically reducing per-state memory re\u0002quirements. By implementing the heap as an immutable\r\nmap, portions of the heap structure itself can also be\r\nshared amongst multiple states (similar to sharing por\u0002tions of page tables across fork()). Additionally, this\r\nheap structure can be cloned in constant time, which is\r\nimportant given the frequency of this operation.\r\nThis approach is in marked contrast to EXE, which\r\nused one native OS process per state. Internalizing the\r\nstate representation dramatically increased the number\r\nof states which can be concurrently explored, both by\r\ndecreasing the per-state cost and allowing states to share\r\nmemory at the object (rather than page) level. Addition\u0002ally, this greatly simplified the implementation of caches\r\nand search heuristics which operate across all states.\r\n3.3 Query optimization\r\nAlmost always, the cost of constraint solving dominates\r\neverything else — unsurprising, given that KLEE gen\u0002erates complicated queries for an NP-complete logic.\r\nThus, we spent a lot of effort on tricks to simplify ex\u0002pressions and ideally eliminate queries (no query is the\r\nfastest query) before they reach STP. Simplified queries\r\nmake solving faster, reduce memory consumption, and\r\nincrease the query cache’s hit rate (see below). The main\r\nquery optimizations are:\r\nExpression Rewriting. The most basic optimizations\r\nmirror those in a compiler: e.g., simple arithmetic sim\u0002plifications (x + 0 = x), strength reduction (x * 2\r\nn\r\n= x << n), linear simplification (2*x - x = x).\r\nConstraint Set Simplification. Symbolic execution\r\ntypically involves the addition of a large number of con\u0002straints to the path condition. The natural structure of\r\nprograms means that constraints on same variables tend\r\nto become more specific. For example, commonly an in\u0002exact constraint such as x < 10 gets added, followed\r\nsome time later by the constraint x = 5. KLEE actively\r\nsimplifies the constraint set by rewriting previous con\u0002straints when new equality constraints are added to the\r\nconstraint set. In this example, substituting the value for\r\nx into the first constraint simplifies it to true, which\r\nKLEE eliminates.\r\nImplied Value Concretization. When a constraint such\r\nas x + 1 = 10 is added to the path condition, then the\r\nvalue of x has effectively become concrete along that\r\npath. KLEE determines this fact (in this case that x = 9)\r\nand writes the concrete value back to memory. This en\u0002sures that subsequent accesses of that memory location\r\ncan return a cheap constant expression.\r\nConstraint Independence. Many constraints do not\r\noverlap in terms of the memory they reference. Con\u0002straint independence (taken from EXE) divides con\u0002straint sets into disjoint independent subsets based on the\r\nsymbolic variables they reference. By explicitly track\u0002ing these subsets, KLEE can frequently eliminate irrel\u0002evant constraints prior to sending a query to the con\u0002straint solver. For example, given the constraint set\r\n{i < j, j < 20, k > 0}, a query of whether i = 20\r\njust requires the first two constraints.\r\nCounter-example Cache. Redundant queries are fre\u0002quent, and a simple cache is effective at eliminating a\r\nlarge number of them. However, it is possible to build\r\na more sophisticated cache due to the particular struc\u0002ture of constraint sets. The counter-example cache maps\r\nsets of constraints to counter-examples (i.e., variable as\u0002signments), along with a special sentinel used when a set\r\nof constraints has no solution. This mapping is stored\r\nin a custom data structure — derived from the UBTree\r\nstructure of Hoffmann and Hoehler [28] — which al\u0002lows efficient searching for cache entries for both sub\u0002sets and supersets of a constraint set. By storing the\r\ncache in this fashion, the counter-example cache gains\r\nthree additional ways to eliminate queries. In the ex\u0002ample below, we assume that the counter-example cache\r\n5",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/0848e33d-f708-48b7-ae00-e5d9c1f9d9d3.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a64df3470e6620546ed3290fea4aa64f13c96475b64338a6ba464e5ee6941a2b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 877
      },
      {
        "segments": [
          {
            "segment_id": "40f418db-a463-4dd5-85bd-7646c6e91f3f",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 6,
            "page_width": 612,
            "page_height": 792,
            "content": "Optimizations Queries Time (s) STP Time (s)\r\nNone 13717 300 281\r\nIndependence 13717 166 148\r\nCex. Cache 8174 177 156\r\nAll 699 20 10\r\nTable 1: Performance comparison of KLEE’s solver optimiza\u0002tions on COREUTILS. Each tool is run for 5 minutes without\r\noptimization, and rerun on the same workload with the given\r\noptimizations. The results are averaged across all applications.\r\ncurrently has entries for {i < 10, i = 10} (no solution)\r\nand {i < 10, j = 8} (satisfiable, with variable assign\u0002ments i → 5, j → 8).\r\n1 When a subset of a constraint set has no solution,\r\nthen neither does the original constraint set. Adding\r\nconstraints to an unsatisfiable constraint set cannot\r\nmake it satisfiable. For example, given the cache\r\nabove, {i < 10, i = 10, j = 12} is quickly deter\u0002mined to be unsatisfiable.\r\n2 When a superset of a constraint set has a solution,\r\nthat solution also satisfies the original constraint set.\r\nDropping constraints from a constraint set does not\r\ninvalidate a solution to that set. The assignment\r\ni → 5, j → 8, for example, satisfies either i < 10\r\nor j = 8 individually.\r\n3 When a subset of a constraint set has a solution, it is\r\nlikely that this is also a solution for the original set.\r\nThis is because the extra constraints often do not in\u0002validate the solution to the subset. Because checking\r\na potential solution is cheap, KLEE tries substituting\r\nin all solutions for subsets of the constraint set and\r\nreturns a satisfying solution, if found. For example,\r\nthe constraint set {i < 10, j = 8, i 6= 3} can still be\r\nsatisfied by i → 5, j → 8.\r\nTo demonstrate the effectiveness of these optimiza\u0002tions, we performed an experiment where COREUTILS\r\napplications were run for 5 minutes with both of these\r\noptimizations turned off. We then deterministically reran\r\nthe exact same workload with constraint independence\r\nand the counter-example cache enabled separately and\r\ntogether for the same number of instructions. This exper\u0002iment was done on a large sample of COREUTILS utili\u0002ties. The results in Table 1 show the averaged results.\r\nAs expected, the independence optimization by itself\r\ndoes not eliminate any queries, but the simplifications it\r\nperforms reduce the overall running time by almost half\r\n(45%). The counter-example cache reduces both the run\u0002ning time and the number of STP queries by 40%. How\u0002ever, the real win comes when both optimizations are en\u0002abled; in this case the hit rate for the counter-example\r\ncache greatly increases due to the queries first being sim\u0002plified via independence. For the sample runs, the aver\u00020\r\n100\r\n200\r\n300\r\n400\r\nAverage Time (s)\r\n0 0.2 0.4 0.6 0.8 1\r\nNum. Instructions (normalized)\r\nNone\r\nCex. Cache\r\nIndependence\r\nAll\r\nFigure 2: The effect of KLEE’s solver optimizations over\r\ntime, showing they become more effective over time, as the\r\ncaches fill and queries become more complicated. The num\u0002ber of executed instructions is normalized so that data can be\r\naggregated across all applications.\r\nage number of STP queries are reduced to 5% of the orig\u0002inal number and the average runtime decreases by more\r\nthan an order of magnitude.\r\nIt is also worth noting the degree to which STP time\r\n(time spent solving queries) dominates runtime. For the\r\noriginal runs, STP accounts for 92% of overall execution\r\ntime on average (the combined optimizations reduce this\r\nby almost 300%). With both optimizations enabled this\r\npercentage drops to 41%. Finally, Figure 2 shows the\r\nefficacy of KLEE’s optimizations increases with time —\r\nas the counter-example cache is filled and query sizes\r\nincrease, the speed-up from the optimizations also in\u0002creases.\r\n3.4 State scheduling\r\nKLEE selects the state to run at each instruction by inter\u0002leaving the following two search heuristics.\r\nRandom Path Selection maintains a binary tree record\u0002ing the program path followed for all active states, i.e. the\r\nleaves of the tree are the current states and the internal\r\nnodes are places where execution forked. States are se\u0002lected by traversing this tree from the root and randomly\r\nselecting the path to follow at branch points. Therefore,\r\nwhen a branch point is reached, the set of states in each\r\nsubtree has equal probability of being selected, regard\u0002less of the size of their subtrees. This strategy has two\r\nimportant properties. First, it favors states high in the\r\nbranch tree. These states have less constraints on their\r\nsymbolic inputs and so have greater freedom to reach un\u0002covered code. Second, and most importantly, this strat\u0002egy avoids starvation when some part of the program is\r\nrapidly creating new states (“fork bombing”) as it hap\u0002pens when a tight loop contains a symbolic condition.\r\nNote that the simply selecting a state at random has nei\u0002ther property.\r\n6",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/40f418db-a463-4dd5-85bd-7646c6e91f3f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a97702a1c1e086607dd638d068c2aa65b432d6e1a77304591879aafd63e2e56c",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 777
      },
      {
        "segments": [
          {
            "segment_id": "40f418db-a463-4dd5-85bd-7646c6e91f3f",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 6,
            "page_width": 612,
            "page_height": 792,
            "content": "Optimizations Queries Time (s) STP Time (s)\r\nNone 13717 300 281\r\nIndependence 13717 166 148\r\nCex. Cache 8174 177 156\r\nAll 699 20 10\r\nTable 1: Performance comparison of KLEE’s solver optimiza\u0002tions on COREUTILS. Each tool is run for 5 minutes without\r\noptimization, and rerun on the same workload with the given\r\noptimizations. The results are averaged across all applications.\r\ncurrently has entries for {i < 10, i = 10} (no solution)\r\nand {i < 10, j = 8} (satisfiable, with variable assign\u0002ments i → 5, j → 8).\r\n1 When a subset of a constraint set has no solution,\r\nthen neither does the original constraint set. Adding\r\nconstraints to an unsatisfiable constraint set cannot\r\nmake it satisfiable. For example, given the cache\r\nabove, {i < 10, i = 10, j = 12} is quickly deter\u0002mined to be unsatisfiable.\r\n2 When a superset of a constraint set has a solution,\r\nthat solution also satisfies the original constraint set.\r\nDropping constraints from a constraint set does not\r\ninvalidate a solution to that set. The assignment\r\ni → 5, j → 8, for example, satisfies either i < 10\r\nor j = 8 individually.\r\n3 When a subset of a constraint set has a solution, it is\r\nlikely that this is also a solution for the original set.\r\nThis is because the extra constraints often do not in\u0002validate the solution to the subset. Because checking\r\na potential solution is cheap, KLEE tries substituting\r\nin all solutions for subsets of the constraint set and\r\nreturns a satisfying solution, if found. For example,\r\nthe constraint set {i < 10, j = 8, i 6= 3} can still be\r\nsatisfied by i → 5, j → 8.\r\nTo demonstrate the effectiveness of these optimiza\u0002tions, we performed an experiment where COREUTILS\r\napplications were run for 5 minutes with both of these\r\noptimizations turned off. We then deterministically reran\r\nthe exact same workload with constraint independence\r\nand the counter-example cache enabled separately and\r\ntogether for the same number of instructions. This exper\u0002iment was done on a large sample of COREUTILS utili\u0002ties. The results in Table 1 show the averaged results.\r\nAs expected, the independence optimization by itself\r\ndoes not eliminate any queries, but the simplifications it\r\nperforms reduce the overall running time by almost half\r\n(45%). The counter-example cache reduces both the run\u0002ning time and the number of STP queries by 40%. How\u0002ever, the real win comes when both optimizations are en\u0002abled; in this case the hit rate for the counter-example\r\ncache greatly increases due to the queries first being sim\u0002plified via independence. For the sample runs, the aver\u00020\r\n100\r\n200\r\n300\r\n400\r\nAverage Time (s)\r\n0 0.2 0.4 0.6 0.8 1\r\nNum. Instructions (normalized)\r\nNone\r\nCex. Cache\r\nIndependence\r\nAll\r\nFigure 2: The effect of KLEE’s solver optimizations over\r\ntime, showing they become more effective over time, as the\r\ncaches fill and queries become more complicated. The num\u0002ber of executed instructions is normalized so that data can be\r\naggregated across all applications.\r\nage number of STP queries are reduced to 5% of the orig\u0002inal number and the average runtime decreases by more\r\nthan an order of magnitude.\r\nIt is also worth noting the degree to which STP time\r\n(time spent solving queries) dominates runtime. For the\r\noriginal runs, STP accounts for 92% of overall execution\r\ntime on average (the combined optimizations reduce this\r\nby almost 300%). With both optimizations enabled this\r\npercentage drops to 41%. Finally, Figure 2 shows the\r\nefficacy of KLEE’s optimizations increases with time —\r\nas the counter-example cache is filled and query sizes\r\nincrease, the speed-up from the optimizations also in\u0002creases.\r\n3.4 State scheduling\r\nKLEE selects the state to run at each instruction by inter\u0002leaving the following two search heuristics.\r\nRandom Path Selection maintains a binary tree record\u0002ing the program path followed for all active states, i.e. the\r\nleaves of the tree are the current states and the internal\r\nnodes are places where execution forked. States are se\u0002lected by traversing this tree from the root and randomly\r\nselecting the path to follow at branch points. Therefore,\r\nwhen a branch point is reached, the set of states in each\r\nsubtree has equal probability of being selected, regard\u0002less of the size of their subtrees. This strategy has two\r\nimportant properties. First, it favors states high in the\r\nbranch tree. These states have less constraints on their\r\nsymbolic inputs and so have greater freedom to reach un\u0002covered code. Second, and most importantly, this strat\u0002egy avoids starvation when some part of the program is\r\nrapidly creating new states (“fork bombing”) as it hap\u0002pens when a tight loop contains a symbolic condition.\r\nNote that the simply selecting a state at random has nei\u0002ther property.\r\n6",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/40f418db-a463-4dd5-85bd-7646c6e91f3f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a97702a1c1e086607dd638d068c2aa65b432d6e1a77304591879aafd63e2e56c",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 777
      },
      {
        "segments": [
          {
            "segment_id": "68753012-aaca-47ed-888a-ea6ab9d1b5c5",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 7,
            "page_width": 612,
            "page_height": 792,
            "content": "Coverage-Optimized Search tries to select states likely\r\nto cover new code in the immediate future. It uses heuris\u0002tics to compute a weight for each state and then ran\u0002domly selects a state according to these weights. Cur\u0002rently these heuristics take into account the minimum\r\ndistance to an uncovered instruction, the call stack of the\r\nstate, and whether the state recently covered new code.\r\nKLEE uses each strategy in a round robin fashion.\r\nWhile this can increase the time for a particularly effec\u0002tive strategy to achieve high coverage, it protects against\r\ncases where an individual strategy gets stuck. Further\u0002more, since strategies pick from the same state pool, in\u0002terleaving them can improve overall effectiveness.\r\nThe time to execute an individual instruction can vary\r\nwidely between simple instructions (e.g., addition) and\r\ninstructions which may use the constraint solver or fork\r\nexecution (branches, memory accesses). KLEE ensures\r\nthat a state which frequently executes expensive instruc\u0002tions will not dominate execution time by running each\r\nstate for a “time slice” defined by both a maximum num\u0002ber of instructions and a maximum amount of time.\r\n4 Environment Modeling\r\nWhen code reads values from its environment —\r\ncommand-line arguments, environment variables, file\r\ndata and metadata, network packets, etc — we conceptu\u0002ally want to return all values that the read could legally\r\nproduce, rather than just a single concrete value. When it\r\nwrites to its environment, the effects of these alterations\r\nshould be reflected in subsequent reads. The combina\u0002tion of these features allows the checked program to ex\u0002plore all potential actions and still have no false positives.\r\nMechanically, we handle the environment by redirect\u0002ing calls that access it to models that understand the se\u0002mantics of the desired action well enough to generate the\r\nrequired constraints. Crucially, these models are written\r\nin normal C code which the user can readily customize,\r\nextend, or even replace without having to understand the\r\ninternals of KLEE. We have about 2,500 lines of code to\r\ndefine simple models for roughly 40 system calls (e.g.,\r\nopen, read, write, stat, lseek, ftruncate,\r\nioctl).\r\n4.1 Example: modeling the file system\r\nFor each file system operation we check if the action is\r\nfor an actual concrete file on disk or a symbolic file. For\r\nconcrete files, we simply invoke the corresponding sys\u0002tem call in the running operating system. For symbolic\r\nfiles we emulate the operation’s effect on a simple sym\u0002bolic file system, private to each state.\r\nFigure 3 gives a rough sketch of the model for\r\nread(), eliding details for dealing with linking, reads\r\non standard input, and failures. The code maintains a set\r\nof file descriptors, created at file open(), and records\r\n1 : ssize t read(int fd, void *buf, size t count) {\r\n2 : if (is invalid(fd)) {\r\n3 : errno = EBADF;\r\n4 : return −1;\r\n5 : }\r\n6 : struct klee fd *f = &fds[fd];\r\n7 : if (is concrete file(f)) {\r\n8 : int r = pread(f−>real fd, buf, count, f−>off);\r\n9 : if (r != −1)\r\n10: f−>off += r;\r\n11: return r;\r\n12: } else {\r\n13: /* sym files are fixed size: don’t read beyond the end. */\r\n14: if (f−>off >= f−>size)\r\n15: return 0;\r\n16: count = min(count, f−>size − f−>off);\r\n17: memcpy(buf, f−>file data + f−>off, count);\r\n18: f−>off += count;\r\n19: return count;\r\n20: }\r\n21: }\r\nFigure 3: Sketch of KLEE’s model for read().\r\nfor each whether the associated file is symbolic or con\u0002crete. If fd refers to a concrete file, we use the operating\r\nsystem to read its contents by calling pread() (lines\r\n7-11). We use pread to multiplex access from KLEE’s\r\nmany states onto the one actual underlying file descrip\u0002tor. 5\r\nIf fd refers to a symbolic file, read() copies from\r\nthe underlying symbolic buffer holding the file contents\r\ninto the user supplied buffer (lines 13-19). This ensures\r\nthat multiple read() calls that access the same file use\r\nconsistent symbolic values.\r\nOur symbolic file system is crude, containing only a\r\nsingle directory with N symbolic files in it. KLEE users\r\nspecify both the number N and the size of these files.\r\nThis symbolic file system coexists with the real file sys\u0002tem, so applications can use both symbolic and concrete\r\nfiles. When the program calls open with a concrete\r\nname, we (attempt to) open the actual file. Thus, the call:\r\nint fd = open(\"/etc/fstab\", O_RDNLY);\r\nsets fd to point to the actual configuration file\r\n/etc/fstab.\r\nOn the other hand, calling open() with an uncon\u0002strained symbolic name matches each of the N symbolic\r\nfiles in turn, and will also fail once. For example, given\r\nN = 1, calling open() with a symbolic command-line\r\nargument argv[1]:\r\nint fd = open(argv[1], O_RDNLY);\r\nwill result in two paths: one in which fd points to the\r\nsingle symbolic file in the environment, and one in which\r\nfd is set to -1 indicating an error.\r\n5Since KLEE’s states execute within a single Unix process (the one\r\nused to run KLEE), then unless we duplicated file descriptors for each\r\n(which seemed expensive), a read by one would affect all the others.\r\n7",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/68753012-aaca-47ed-888a-ea6ab9d1b5c5.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=28c69b70ebe43ed5a4b0d78d80b6295558dcc1a1e349cb66a293b728a6ccbebe",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 842
      },
      {
        "segments": [
          {
            "segment_id": "68753012-aaca-47ed-888a-ea6ab9d1b5c5",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 7,
            "page_width": 612,
            "page_height": 792,
            "content": "Coverage-Optimized Search tries to select states likely\r\nto cover new code in the immediate future. It uses heuris\u0002tics to compute a weight for each state and then ran\u0002domly selects a state according to these weights. Cur\u0002rently these heuristics take into account the minimum\r\ndistance to an uncovered instruction, the call stack of the\r\nstate, and whether the state recently covered new code.\r\nKLEE uses each strategy in a round robin fashion.\r\nWhile this can increase the time for a particularly effec\u0002tive strategy to achieve high coverage, it protects against\r\ncases where an individual strategy gets stuck. Further\u0002more, since strategies pick from the same state pool, in\u0002terleaving them can improve overall effectiveness.\r\nThe time to execute an individual instruction can vary\r\nwidely between simple instructions (e.g., addition) and\r\ninstructions which may use the constraint solver or fork\r\nexecution (branches, memory accesses). KLEE ensures\r\nthat a state which frequently executes expensive instruc\u0002tions will not dominate execution time by running each\r\nstate for a “time slice” defined by both a maximum num\u0002ber of instructions and a maximum amount of time.\r\n4 Environment Modeling\r\nWhen code reads values from its environment —\r\ncommand-line arguments, environment variables, file\r\ndata and metadata, network packets, etc — we conceptu\u0002ally want to return all values that the read could legally\r\nproduce, rather than just a single concrete value. When it\r\nwrites to its environment, the effects of these alterations\r\nshould be reflected in subsequent reads. The combina\u0002tion of these features allows the checked program to ex\u0002plore all potential actions and still have no false positives.\r\nMechanically, we handle the environment by redirect\u0002ing calls that access it to models that understand the se\u0002mantics of the desired action well enough to generate the\r\nrequired constraints. Crucially, these models are written\r\nin normal C code which the user can readily customize,\r\nextend, or even replace without having to understand the\r\ninternals of KLEE. We have about 2,500 lines of code to\r\ndefine simple models for roughly 40 system calls (e.g.,\r\nopen, read, write, stat, lseek, ftruncate,\r\nioctl).\r\n4.1 Example: modeling the file system\r\nFor each file system operation we check if the action is\r\nfor an actual concrete file on disk or a symbolic file. For\r\nconcrete files, we simply invoke the corresponding sys\u0002tem call in the running operating system. For symbolic\r\nfiles we emulate the operation’s effect on a simple sym\u0002bolic file system, private to each state.\r\nFigure 3 gives a rough sketch of the model for\r\nread(), eliding details for dealing with linking, reads\r\non standard input, and failures. The code maintains a set\r\nof file descriptors, created at file open(), and records\r\n1 : ssize t read(int fd, void *buf, size t count) {\r\n2 : if (is invalid(fd)) {\r\n3 : errno = EBADF;\r\n4 : return −1;\r\n5 : }\r\n6 : struct klee fd *f = &fds[fd];\r\n7 : if (is concrete file(f)) {\r\n8 : int r = pread(f−>real fd, buf, count, f−>off);\r\n9 : if (r != −1)\r\n10: f−>off += r;\r\n11: return r;\r\n12: } else {\r\n13: /* sym files are fixed size: don’t read beyond the end. */\r\n14: if (f−>off >= f−>size)\r\n15: return 0;\r\n16: count = min(count, f−>size − f−>off);\r\n17: memcpy(buf, f−>file data + f−>off, count);\r\n18: f−>off += count;\r\n19: return count;\r\n20: }\r\n21: }\r\nFigure 3: Sketch of KLEE’s model for read().\r\nfor each whether the associated file is symbolic or con\u0002crete. If fd refers to a concrete file, we use the operating\r\nsystem to read its contents by calling pread() (lines\r\n7-11). We use pread to multiplex access from KLEE’s\r\nmany states onto the one actual underlying file descrip\u0002tor. 5\r\nIf fd refers to a symbolic file, read() copies from\r\nthe underlying symbolic buffer holding the file contents\r\ninto the user supplied buffer (lines 13-19). This ensures\r\nthat multiple read() calls that access the same file use\r\nconsistent symbolic values.\r\nOur symbolic file system is crude, containing only a\r\nsingle directory with N symbolic files in it. KLEE users\r\nspecify both the number N and the size of these files.\r\nThis symbolic file system coexists with the real file sys\u0002tem, so applications can use both symbolic and concrete\r\nfiles. When the program calls open with a concrete\r\nname, we (attempt to) open the actual file. Thus, the call:\r\nint fd = open(\"/etc/fstab\", O_RDNLY);\r\nsets fd to point to the actual configuration file\r\n/etc/fstab.\r\nOn the other hand, calling open() with an uncon\u0002strained symbolic name matches each of the N symbolic\r\nfiles in turn, and will also fail once. For example, given\r\nN = 1, calling open() with a symbolic command-line\r\nargument argv[1]:\r\nint fd = open(argv[1], O_RDNLY);\r\nwill result in two paths: one in which fd points to the\r\nsingle symbolic file in the environment, and one in which\r\nfd is set to -1 indicating an error.\r\n5Since KLEE’s states execute within a single Unix process (the one\r\nused to run KLEE), then unless we duplicated file descriptors for each\r\n(which seemed expensive), a read by one would affect all the others.\r\n7",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/68753012-aaca-47ed-888a-ea6ab9d1b5c5.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=28c69b70ebe43ed5a4b0d78d80b6295558dcc1a1e349cb66a293b728a6ccbebe",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 842
      },
      {
        "segments": [
          {
            "segment_id": "bd9c241b-7d9c-4c29-89d2-f787412b9896",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 8,
            "page_width": 612,
            "page_height": 792,
            "content": "Unsurprisingly, the choice of what interface to model\r\nhas a big impact on model complexity. Rather than hav\u0002ing our models at the system call level, we could have in\u0002stead built them at the C standard library level (fopen,\r\nfread, etc.). Doing so has the potential performance\r\nadvantage that, for concrete code, we could run these op\u0002erations natively. The major downside, however, is that\r\nthe standard library contains a huge number of functions\r\n— writing models for each would be tedious and error\u0002prone. By only modeling the much simpler, low-level\r\nsystem call API, we can get the richer functionality by\r\njust compiling one of the many implementations of the\r\nC standard library (we use uClibc [6]) and let it worry\r\nabout correctness. As a side-effect, we simultaneously\r\ncheck the library for errors as well.\r\n4.2 Failing system calls\r\nThe real environment can fail in unexpected ways (e.g.,\r\nwrite() fails because of a full disk). Such failures\r\ncan often lead to unexpected and hard to diagnose bugs.\r\nEven when applications do try to handle them, this code\r\nis rarely fully exercised by the regression suite. To help\r\ncatch such errors, KLEE will optionally simulate envi\u0002ronmental failures by failing system calls in a controlled\r\nmanner (similar to [38]). We made this mode optional\r\nsince not all applications care about failures — a simple\r\napplication may ignore disk crashes, while a mail server\r\nexpends a lot of code to handle them.\r\n4.3 Rerunning test cases\r\nKLEE-generated test cases are rerun on the unmodified\r\nnative binaries by supplying them to a replay driver we\r\nprovide. The individual test cases describe an instance\r\nof the symbolic environment. The driver uses this de\u0002scription to create actual operating system objects (files,\r\npipes, ttys, directories, links, etc.) containing the con\u0002crete values used in the test case. It then executes the un\u0002modified program using the concrete command-line ar\u0002guments from the test case. Our biggest challenge was\r\nmaking system calls fail outside of KLEE — we built a\r\nsimple utility that uses the ptrace debugging interface\r\nto skip the system calls that were supposed to fail and\r\ninstead return an error.\r\n5 Evaluation\r\nThis section describes our in-depth coverage experi\u0002ments for COREUTILS (§ 5.2) and BUSYBOX (§ 5.3)\r\nas well as errors found during quick bug-finding runs\r\n(§ 5.4). We use KLEE to find deep correctness errors by\r\ncrosschecking purportedly equivalent tool implementa\u0002tions (§ 5.5) and close with results for HISTAR (§5.6).\r\n5.1 Coverage methodology\r\nWe use line coverage as a conservative measure of KLEE\u0002produced test case effectiveness. We chose executable\r\n2000-30003000-40004000-50005000-60006000-70007000-80008000-9000\r\n9000-10000\r\nExecutable Lines of Code\r\n0\r\n10\r\n20\r\n30\r\n40\r\n50\r\n60\r\n5\r\n52\r\n16\r\n6\r\n4\r\n1\r\n3 2\r\nFigure 4: Histogram showing the number of COREUTILS\r\ntools that have a given number of executable lines of code\r\n(ELOC).\r\nline coverage as reported by gcov, because it is widely\u0002understood and uncontroversial. Of course, it grossly\r\nunderestimates KLEE’s thoroughness, since it ignores the\r\nfact that KLEE explores many different unique paths with\r\nall possible values. We expect a path-based metric would\r\nshow even more dramatic wins.\r\nWe measure coverage by running KLEE-generated test\r\ncases on a stand-alone version of each utility and using\r\ngcov to measure coverage. Running tests independently\r\nof KLEE eliminates the effect of bugs in KLEE and veri\u0002fies that the produced test case runs the code it claims.\r\nNote, our coverage results only consider code in the\r\ntool itself. They do not count library code since doing so\r\nmakes the results harder to interpret:\r\n1 It double-counts many lines, since often the same li\u0002brary function is called by many applications.\r\n2 It unfairly under-counts coverage. Often, the bulk of\r\na library function called by an application is effec\u0002tively dead code since the library code is general but\r\ncall sites are not. For example, printf is excep\u0002tionally complex, but the call printf(\"hello\")\r\ncan only hit a small a fraction (missing the code to\r\nprint integers, floating point, formatting, etc.).\r\nHowever, we do include library code when measuring\r\nthe raw size of the application: KLEE must successfully\r\nhandle this library code (and gets no credit for doing so)\r\nin order to exercise the code in the tool itself. We mea\u0002sure size in terms of executable lines of code (ELOC)\r\nby counting the total number of executable lines in the\r\nfinal executable after global optimization, which elimi\u0002nates uncalled functions and other dead code. This mea\u0002sure is usually a factor of three smaller than a simple line\r\ncount (using wc -l).\r\nIn our experiments KLEE minimizes the test cases it\r\n8",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/bd9c241b-7d9c-4c29-89d2-f787412b9896.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=61d37ab5f37626bcb3bc0de338a8bd0c22e851eb82c8f35a857fdbd4165421f1",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 751
      },
      {
        "segments": [
          {
            "segment_id": "bd9c241b-7d9c-4c29-89d2-f787412b9896",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 8,
            "page_width": 612,
            "page_height": 792,
            "content": "Unsurprisingly, the choice of what interface to model\r\nhas a big impact on model complexity. Rather than hav\u0002ing our models at the system call level, we could have in\u0002stead built them at the C standard library level (fopen,\r\nfread, etc.). Doing so has the potential performance\r\nadvantage that, for concrete code, we could run these op\u0002erations natively. The major downside, however, is that\r\nthe standard library contains a huge number of functions\r\n— writing models for each would be tedious and error\u0002prone. By only modeling the much simpler, low-level\r\nsystem call API, we can get the richer functionality by\r\njust compiling one of the many implementations of the\r\nC standard library (we use uClibc [6]) and let it worry\r\nabout correctness. As a side-effect, we simultaneously\r\ncheck the library for errors as well.\r\n4.2 Failing system calls\r\nThe real environment can fail in unexpected ways (e.g.,\r\nwrite() fails because of a full disk). Such failures\r\ncan often lead to unexpected and hard to diagnose bugs.\r\nEven when applications do try to handle them, this code\r\nis rarely fully exercised by the regression suite. To help\r\ncatch such errors, KLEE will optionally simulate envi\u0002ronmental failures by failing system calls in a controlled\r\nmanner (similar to [38]). We made this mode optional\r\nsince not all applications care about failures — a simple\r\napplication may ignore disk crashes, while a mail server\r\nexpends a lot of code to handle them.\r\n4.3 Rerunning test cases\r\nKLEE-generated test cases are rerun on the unmodified\r\nnative binaries by supplying them to a replay driver we\r\nprovide. The individual test cases describe an instance\r\nof the symbolic environment. The driver uses this de\u0002scription to create actual operating system objects (files,\r\npipes, ttys, directories, links, etc.) containing the con\u0002crete values used in the test case. It then executes the un\u0002modified program using the concrete command-line ar\u0002guments from the test case. Our biggest challenge was\r\nmaking system calls fail outside of KLEE — we built a\r\nsimple utility that uses the ptrace debugging interface\r\nto skip the system calls that were supposed to fail and\r\ninstead return an error.\r\n5 Evaluation\r\nThis section describes our in-depth coverage experi\u0002ments for COREUTILS (§ 5.2) and BUSYBOX (§ 5.3)\r\nas well as errors found during quick bug-finding runs\r\n(§ 5.4). We use KLEE to find deep correctness errors by\r\ncrosschecking purportedly equivalent tool implementa\u0002tions (§ 5.5) and close with results for HISTAR (§5.6).\r\n5.1 Coverage methodology\r\nWe use line coverage as a conservative measure of KLEE\u0002produced test case effectiveness. We chose executable\r\n2000-30003000-40004000-50005000-60006000-70007000-80008000-9000\r\n9000-10000\r\nExecutable Lines of Code\r\n0\r\n10\r\n20\r\n30\r\n40\r\n50\r\n60\r\n5\r\n52\r\n16\r\n6\r\n4\r\n1\r\n3 2\r\nFigure 4: Histogram showing the number of COREUTILS\r\ntools that have a given number of executable lines of code\r\n(ELOC).\r\nline coverage as reported by gcov, because it is widely\u0002understood and uncontroversial. Of course, it grossly\r\nunderestimates KLEE’s thoroughness, since it ignores the\r\nfact that KLEE explores many different unique paths with\r\nall possible values. We expect a path-based metric would\r\nshow even more dramatic wins.\r\nWe measure coverage by running KLEE-generated test\r\ncases on a stand-alone version of each utility and using\r\ngcov to measure coverage. Running tests independently\r\nof KLEE eliminates the effect of bugs in KLEE and veri\u0002fies that the produced test case runs the code it claims.\r\nNote, our coverage results only consider code in the\r\ntool itself. They do not count library code since doing so\r\nmakes the results harder to interpret:\r\n1 It double-counts many lines, since often the same li\u0002brary function is called by many applications.\r\n2 It unfairly under-counts coverage. Often, the bulk of\r\na library function called by an application is effec\u0002tively dead code since the library code is general but\r\ncall sites are not. For example, printf is excep\u0002tionally complex, but the call printf(\"hello\")\r\ncan only hit a small a fraction (missing the code to\r\nprint integers, floating point, formatting, etc.).\r\nHowever, we do include library code when measuring\r\nthe raw size of the application: KLEE must successfully\r\nhandle this library code (and gets no credit for doing so)\r\nin order to exercise the code in the tool itself. We mea\u0002sure size in terms of executable lines of code (ELOC)\r\nby counting the total number of executable lines in the\r\nfinal executable after global optimization, which elimi\u0002nates uncalled functions and other dead code. This mea\u0002sure is usually a factor of three smaller than a simple line\r\ncount (using wc -l).\r\nIn our experiments KLEE minimizes the test cases it\r\n8",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/bd9c241b-7d9c-4c29-89d2-f787412b9896.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=61d37ab5f37626bcb3bc0de338a8bd0c22e851eb82c8f35a857fdbd4165421f1",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 751
      },
      {
        "segments": [
          {
            "segment_id": "8853b0bd-22b2-46b9-913c-c71d0a609668",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 9,
            "page_width": 612,
            "page_height": 792,
            "content": "COREUTILS BUSYBOX\r\nCoverage KLEE Devel. KLEE Devel.\r\n(w/o lib) tests tests tests tests\r\n100% 16 1 31 4\r\n90-100% 40 6 24 3\r\n80-90% 21 20 10 15\r\n70-80% 7 23 5 6\r\n60-70% 5 15 2 7\r\n50-60% - 10 - 4\r\n40-50% - 6 - -\r\n30-40% - 3 - 2\r\n20-30% - 1 - 1\r\n10-20% - 3 - -\r\n0-10% - 1 - 30\r\nOverall cov. 84.5% 67.7% 90.5% 44.8%\r\nMed cov/App 94.7% 72.5% 97.5% 58.9%\r\nAve cov/App 90.9% 68.4% 93.5% 43.7%\r\nTable 2: Number of COREUTILS tools which achieve line\r\ncoverage in the given ranges for KLEE and developers’ tests\r\n(library code not included). The last rows shows the aggre\u0002gate coverage achieved by each method and the average and\r\nmedian coverage per application.\r\ngenerates by only emitting tests cases for paths that hit a\r\nnew statement or branch in the main utility code. A user\r\nthat wants high library coverage can change this setting.\r\n5.2 GNU COREUTILS\r\nWe now give KLEE coverage results for all 89 GNU\r\nCOREUTILS utilities.\r\nFigure 4 breaks down the tools by executable lines\r\nof code (ELOC), including library code the tool calls.\r\nWhile relatively small, the tools are not toys — the small\u0002est five have between 2K and 3K ELOC, over half (52)\r\nhave between 3K and 4K, and ten have over 6K.\r\nPrevious work, ours included, has evaluated\r\nconstraint-based execution on a small number of\r\nhand-selected benchmarks. Reporting results for the\r\nentire COREUTILS suite, the worst along with the best,\r\nprevents us from hand-picking results or unintentionally\r\ncheating through the use of fragile optimizations.\r\nAlmost all tools were tested using the same command\r\n(command arguments explained in § 2.1):\r\n./run <tool-name> --max-time 60\r\n--sym-args 10 2 2\r\n--sym-files 2 8\r\n[--max-fail 1]\r\nAs specified by the --max-time option, we ran each\r\ntool for about 60 minutes (some finished before this limit,\r\na few up to three minutes after). For eight tools where the\r\ncoverage results of these values were unsatisfactory, we\r\nconsulted the man page and increased the number and\r\nsize of arguments and files. We found this easy to do,\r\n0%\r\n20%\r\n40%\r\n60%\r\n80%\r\n100%\r\nCoverage (ELOC %)\r\n1 25 50 75\r\nBase + Fail\r\nBase\r\nFigure 5: Line coverage for each application with and without\r\nfailing system calls.\r\nso presumably a tool implementer or user would as well.\r\nAfter these runs completed, we improved them by failing\r\nsystem calls (see § 4.2).\r\n5.2.1 Line coverage results\r\nThe first two columns in Table 2 give aggregate line\r\ncoverage results. On average our tests cover 90.9% of\r\nthe lines in each tool (median: 94.7%), with an overall\r\n(aggregate) coverage across all tools of 84.5%. We get\r\n100% line coverage on 16 tools, over 90% on 56 tools,\r\nand over 80% on 77 tools (86.5% of all tools). The min\u0002imum coverage achieved on any tool is 62.6%.\r\nWe believe such high coverage on a broad swath of ap\u0002plications “out of the box” convincingly shows the power\r\nof the approach, especially since it is across the entire\r\ntool suite rather than focusing on a few particular appli\u0002cations.\r\nImportantly, KLEE generates high coverage with few\r\ntest cases: for our non-failing runs, it needs a total of\r\n3,321 tests, with a per-tool average of 37 (median: 33).\r\nThe maximum number needed was 129 (for the “[” tool)\r\nand six needed 5. As a crude measure of path complexity,\r\nwe counted the number of static branches run by each test\r\ncase using gcov6(i.e., an executed branch counts once\r\nno matter how many times the branch ran dynamically).\r\nThe average path length was 76 (median: 53), the maxi\u0002mum was 512 and (to pick a random number) 160 were\r\nat least 250 branches long.\r\nFigure 5 shows the coverage KLEE achieved on each\r\ntool, with and without failing system call invocations.\r\nHitting system call failure paths is useful for getting the\r\nlast few lines of high-coverage tools, rather than signif\u0002icantly improving the overall results (which it improves\r\nfrom 79.9% to 84.5%). The one exception is pwd which\r\nrequires system call failures to go from a dismal 21.2%\r\nto 72.6%. The second best improvement for a single tool\r\nis a more modest 13.1% extra coverage on the df tool.\r\n6\r\nIn gcov terminology, a branch is a possible branch direction, i.e.\r\na simple if statement has two branches.\r\n9",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/8853b0bd-22b2-46b9-913c-c71d0a609668.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=00e4e028d3e86ef9108a76927c31ee6df2ff4c2b5ef4913eb5735e549414d94b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 723
      },
      {
        "segments": [
          {
            "segment_id": "8853b0bd-22b2-46b9-913c-c71d0a609668",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 9,
            "page_width": 612,
            "page_height": 792,
            "content": "COREUTILS BUSYBOX\r\nCoverage KLEE Devel. KLEE Devel.\r\n(w/o lib) tests tests tests tests\r\n100% 16 1 31 4\r\n90-100% 40 6 24 3\r\n80-90% 21 20 10 15\r\n70-80% 7 23 5 6\r\n60-70% 5 15 2 7\r\n50-60% - 10 - 4\r\n40-50% - 6 - -\r\n30-40% - 3 - 2\r\n20-30% - 1 - 1\r\n10-20% - 3 - -\r\n0-10% - 1 - 30\r\nOverall cov. 84.5% 67.7% 90.5% 44.8%\r\nMed cov/App 94.7% 72.5% 97.5% 58.9%\r\nAve cov/App 90.9% 68.4% 93.5% 43.7%\r\nTable 2: Number of COREUTILS tools which achieve line\r\ncoverage in the given ranges for KLEE and developers’ tests\r\n(library code not included). The last rows shows the aggre\u0002gate coverage achieved by each method and the average and\r\nmedian coverage per application.\r\ngenerates by only emitting tests cases for paths that hit a\r\nnew statement or branch in the main utility code. A user\r\nthat wants high library coverage can change this setting.\r\n5.2 GNU COREUTILS\r\nWe now give KLEE coverage results for all 89 GNU\r\nCOREUTILS utilities.\r\nFigure 4 breaks down the tools by executable lines\r\nof code (ELOC), including library code the tool calls.\r\nWhile relatively small, the tools are not toys — the small\u0002est five have between 2K and 3K ELOC, over half (52)\r\nhave between 3K and 4K, and ten have over 6K.\r\nPrevious work, ours included, has evaluated\r\nconstraint-based execution on a small number of\r\nhand-selected benchmarks. Reporting results for the\r\nentire COREUTILS suite, the worst along with the best,\r\nprevents us from hand-picking results or unintentionally\r\ncheating through the use of fragile optimizations.\r\nAlmost all tools were tested using the same command\r\n(command arguments explained in § 2.1):\r\n./run <tool-name> --max-time 60\r\n--sym-args 10 2 2\r\n--sym-files 2 8\r\n[--max-fail 1]\r\nAs specified by the --max-time option, we ran each\r\ntool for about 60 minutes (some finished before this limit,\r\na few up to three minutes after). For eight tools where the\r\ncoverage results of these values were unsatisfactory, we\r\nconsulted the man page and increased the number and\r\nsize of arguments and files. We found this easy to do,\r\n0%\r\n20%\r\n40%\r\n60%\r\n80%\r\n100%\r\nCoverage (ELOC %)\r\n1 25 50 75\r\nBase + Fail\r\nBase\r\nFigure 5: Line coverage for each application with and without\r\nfailing system calls.\r\nso presumably a tool implementer or user would as well.\r\nAfter these runs completed, we improved them by failing\r\nsystem calls (see § 4.2).\r\n5.2.1 Line coverage results\r\nThe first two columns in Table 2 give aggregate line\r\ncoverage results. On average our tests cover 90.9% of\r\nthe lines in each tool (median: 94.7%), with an overall\r\n(aggregate) coverage across all tools of 84.5%. We get\r\n100% line coverage on 16 tools, over 90% on 56 tools,\r\nand over 80% on 77 tools (86.5% of all tools). The min\u0002imum coverage achieved on any tool is 62.6%.\r\nWe believe such high coverage on a broad swath of ap\u0002plications “out of the box” convincingly shows the power\r\nof the approach, especially since it is across the entire\r\ntool suite rather than focusing on a few particular appli\u0002cations.\r\nImportantly, KLEE generates high coverage with few\r\ntest cases: for our non-failing runs, it needs a total of\r\n3,321 tests, with a per-tool average of 37 (median: 33).\r\nThe maximum number needed was 129 (for the “[” tool)\r\nand six needed 5. As a crude measure of path complexity,\r\nwe counted the number of static branches run by each test\r\ncase using gcov6(i.e., an executed branch counts once\r\nno matter how many times the branch ran dynamically).\r\nThe average path length was 76 (median: 53), the maxi\u0002mum was 512 and (to pick a random number) 160 were\r\nat least 250 branches long.\r\nFigure 5 shows the coverage KLEE achieved on each\r\ntool, with and without failing system call invocations.\r\nHitting system call failure paths is useful for getting the\r\nlast few lines of high-coverage tools, rather than signif\u0002icantly improving the overall results (which it improves\r\nfrom 79.9% to 84.5%). The one exception is pwd which\r\nrequires system call failures to go from a dismal 21.2%\r\nto 72.6%. The second best improvement for a single tool\r\nis a more modest 13.1% extra coverage on the df tool.\r\n6\r\nIn gcov terminology, a branch is a possible branch direction, i.e.\r\na simple if statement has two branches.\r\n9",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/8853b0bd-22b2-46b9-913c-c71d0a609668.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=00e4e028d3e86ef9108a76927c31ee6df2ff4c2b5ef4913eb5735e549414d94b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 723
      },
      {
        "segments": [
          {
            "segment_id": "0d9c7354-9be1-4f1f-83e6-7a5579392fbb",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 10,
            "page_width": 612,
            "page_height": 792,
            "content": "−100%\r\n−50%\r\n0%\r\n50%\r\n100%\r\nklee vs. Manual (ELOC %)\r\n1 10 25 50 75\r\nFigure 6: Relative coverage difference between KLEE and\r\nthe COREUTILS manual test suite, computed by subtracting\r\nthe executable lines of code covered by manual tests (Lman)\r\nfrom KLEE tests (Lklee) and dividing by the total possible:\r\n(Lklee − Lman)/Ltotal. Higher bars are better for KLEE,\r\nwhich beats manual testing on all but 9 applications, often\r\nsignificantly.\r\n5.2.2 Comparison against developer test suites\r\nEach utility in COREUTILS comes with an extensive\r\nmanually-written test suite extended each time a new bug\r\nfix or extra feature is added. 7 As Table 2 shows, KLEE\r\nbeats developer tests handily on all aggregate measures:\r\noverall total line coverage (84.5% versus 67.7%), aver\u0002age coverage per tool (90.9% versus 68.4%) and median\r\ncoverage per tool (94.7% versus 72.5%). At a more de\u0002tailed level, KLEE gets 100% coverage on 16 tools and\r\nover 90% coverage on 56 while the developer tests get\r\n100% on a single utility (true) and reach over 90% on\r\nonly 7. Finally, the developers tests get below 60% cov\u0002erage on 24 tools while KLEE always achieves over 60%.\r\nIn total, an 89 hour run of KLEE (about one hour per ap\u0002plication) exceeds the coverage of a test suite built over\r\na period of fifteen years by 16.8%!\r\nFigure 6 gives a relative view of KLEE versus devel\u0002oper tests by subtracting the lines hit by manual testing\r\nfrom those hit by KLEE and dividing this by the total pos\u0002sible. A bar above zero indicates that KLEE beat the man\u0002ual test (and by how much); a bar below shows the oppo\u0002site. KLEE beats manual testing, often significantly, on\r\nthe vast majority of the applications.\r\nTo guard against hidden bias in line coverage, we\r\nalso compared the taken branch coverage (as reported by\r\ngcov) of the manual and KLEE test suites. While the\r\nabsolute coverage for both test suites decreases, KLEE’s\r\nrelative improvement over the developers’ tests remains:\r\n7We ran the test suite using the commands: env RUN EXPENSIVE\r\nTESTS=YES RUN VERY EXPENSIVE TESTS=YES make\r\ncheck and make check-root (as root). A small number of tests\r\n(14 out of 393) which require special configuration were not run; from\r\nmanual inspection we do not expect these to have a significant impact\r\non our results.\r\npaste -d\\\\ abcdefghijklmnopqrstuvwxyz\r\npr -e t2.txt\r\ntac -r t3.txt t3.txt\r\nmkdir -Z a b\r\nmkfifo -Z a b\r\nmknod -Z a b p\r\nmd5sum -c t1.txt\r\nptx -F\\\\ abcdefghijklmnopqrstuvwxyz\r\nptx x t4.txt\r\nseq -f %0 1\r\nt1.txt: \"\\t \\tMD5(\"\r\nt2.txt: \"\\b\\b\\b\\b\\b\\b\\b\\t\"\r\nt3.txt: \"\\n\"\r\nt4.txt: \"a\"\r\nFigure 7: KLEE-generated command lines and inputs (modi\u0002fied for readability) that cause program crashes in COREUTILS\r\nversion 6.10 when run on Fedora Core 7 with SELinux on a\r\nPentium machine.\r\nKLEE achieves 76.9% overall branch coverage, while the\r\ndevelopers’ tests get only 56.5%.\r\nFinally, it is important to note that although KLEE’s\r\nruns significantly beat the developers’ tests in terms of\r\ncoverage, KLEE only checks for low-level errors and vi\u0002olations of user-level asserts. In contrast, developer tests\r\ntypically validate that the application output matches the\r\nexpected one. We partially address this limitation by val\u0002idating the output of these utilities against the output pro\u0002duces by a different implementation (see § 5.5).\r\n5.2.3 Bugs found\r\nKLEE found ten unique bugs in COREUTILS (usually\r\nmemory error crashes). Figure 7 gives the command\r\nlines used to trigger them. The first three errors ex\u0002isted since at least 1992, so should theoretically crash any\r\nCOREUTILS distribution up to 6.10. The others are more\r\nrecent, and do not crash older COREUTILS distributions.\r\nWhile one bug (in seq) had been fixed in the develop\u0002ers’ unreleased version, the other bugs were confirmed\r\nand fixed within two days of our report. In addition, ver\u0002sions of the KLEE-generated test cases for the new bugs\r\nwere added to the official COREUTILS test suite.\r\nAs an illustrative example, we discuss the bug in pr\r\n(used to paginate files before printing) hit by the invoca\u0002tion “pr -e t2.txt” in Figure 7. The code contain\u0002ing the bug is shown in Figure 8. On the path that hits\r\nthe bug, both chars per input tab and chars per c\r\nequal tab width (let’s call it T). Line 2665 computes\r\nwidth = (T − input position mod T) using the\r\nmacro on line 602. The root cause of the bug is the in\u0002correct assumption that 0 ≤ x mod y < y, which only\r\nholds for positive integers. When input position\r\nis positive, width will be less than T since 0 ≤\r\ninput position mod T < T. However, in the pres\u000210",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/0d9c7354-9be1-4f1f-83e6-7a5579392fbb.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c167592c49598d7bf6ca6911ed5da3c4b19e7ddf53008d1159068c71a8b23876",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 761
      },
      {
        "segments": [
          {
            "segment_id": "0d9c7354-9be1-4f1f-83e6-7a5579392fbb",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 10,
            "page_width": 612,
            "page_height": 792,
            "content": "−100%\r\n−50%\r\n0%\r\n50%\r\n100%\r\nklee vs. Manual (ELOC %)\r\n1 10 25 50 75\r\nFigure 6: Relative coverage difference between KLEE and\r\nthe COREUTILS manual test suite, computed by subtracting\r\nthe executable lines of code covered by manual tests (Lman)\r\nfrom KLEE tests (Lklee) and dividing by the total possible:\r\n(Lklee − Lman)/Ltotal. Higher bars are better for KLEE,\r\nwhich beats manual testing on all but 9 applications, often\r\nsignificantly.\r\n5.2.2 Comparison against developer test suites\r\nEach utility in COREUTILS comes with an extensive\r\nmanually-written test suite extended each time a new bug\r\nfix or extra feature is added. 7 As Table 2 shows, KLEE\r\nbeats developer tests handily on all aggregate measures:\r\noverall total line coverage (84.5% versus 67.7%), aver\u0002age coverage per tool (90.9% versus 68.4%) and median\r\ncoverage per tool (94.7% versus 72.5%). At a more de\u0002tailed level, KLEE gets 100% coverage on 16 tools and\r\nover 90% coverage on 56 while the developer tests get\r\n100% on a single utility (true) and reach over 90% on\r\nonly 7. Finally, the developers tests get below 60% cov\u0002erage on 24 tools while KLEE always achieves over 60%.\r\nIn total, an 89 hour run of KLEE (about one hour per ap\u0002plication) exceeds the coverage of a test suite built over\r\na period of fifteen years by 16.8%!\r\nFigure 6 gives a relative view of KLEE versus devel\u0002oper tests by subtracting the lines hit by manual testing\r\nfrom those hit by KLEE and dividing this by the total pos\u0002sible. A bar above zero indicates that KLEE beat the man\u0002ual test (and by how much); a bar below shows the oppo\u0002site. KLEE beats manual testing, often significantly, on\r\nthe vast majority of the applications.\r\nTo guard against hidden bias in line coverage, we\r\nalso compared the taken branch coverage (as reported by\r\ngcov) of the manual and KLEE test suites. While the\r\nabsolute coverage for both test suites decreases, KLEE’s\r\nrelative improvement over the developers’ tests remains:\r\n7We ran the test suite using the commands: env RUN EXPENSIVE\r\nTESTS=YES RUN VERY EXPENSIVE TESTS=YES make\r\ncheck and make check-root (as root). A small number of tests\r\n(14 out of 393) which require special configuration were not run; from\r\nmanual inspection we do not expect these to have a significant impact\r\non our results.\r\npaste -d\\\\ abcdefghijklmnopqrstuvwxyz\r\npr -e t2.txt\r\ntac -r t3.txt t3.txt\r\nmkdir -Z a b\r\nmkfifo -Z a b\r\nmknod -Z a b p\r\nmd5sum -c t1.txt\r\nptx -F\\\\ abcdefghijklmnopqrstuvwxyz\r\nptx x t4.txt\r\nseq -f %0 1\r\nt1.txt: \"\\t \\tMD5(\"\r\nt2.txt: \"\\b\\b\\b\\b\\b\\b\\b\\t\"\r\nt3.txt: \"\\n\"\r\nt4.txt: \"a\"\r\nFigure 7: KLEE-generated command lines and inputs (modi\u0002fied for readability) that cause program crashes in COREUTILS\r\nversion 6.10 when run on Fedora Core 7 with SELinux on a\r\nPentium machine.\r\nKLEE achieves 76.9% overall branch coverage, while the\r\ndevelopers’ tests get only 56.5%.\r\nFinally, it is important to note that although KLEE’s\r\nruns significantly beat the developers’ tests in terms of\r\ncoverage, KLEE only checks for low-level errors and vi\u0002olations of user-level asserts. In contrast, developer tests\r\ntypically validate that the application output matches the\r\nexpected one. We partially address this limitation by val\u0002idating the output of these utilities against the output pro\u0002duces by a different implementation (see § 5.5).\r\n5.2.3 Bugs found\r\nKLEE found ten unique bugs in COREUTILS (usually\r\nmemory error crashes). Figure 7 gives the command\r\nlines used to trigger them. The first three errors ex\u0002isted since at least 1992, so should theoretically crash any\r\nCOREUTILS distribution up to 6.10. The others are more\r\nrecent, and do not crash older COREUTILS distributions.\r\nWhile one bug (in seq) had been fixed in the develop\u0002ers’ unreleased version, the other bugs were confirmed\r\nand fixed within two days of our report. In addition, ver\u0002sions of the KLEE-generated test cases for the new bugs\r\nwere added to the official COREUTILS test suite.\r\nAs an illustrative example, we discuss the bug in pr\r\n(used to paginate files before printing) hit by the invoca\u0002tion “pr -e t2.txt” in Figure 7. The code contain\u0002ing the bug is shown in Figure 8. On the path that hits\r\nthe bug, both chars per input tab and chars per c\r\nequal tab width (let’s call it T). Line 2665 computes\r\nwidth = (T − input position mod T) using the\r\nmacro on line 602. The root cause of the bug is the in\u0002correct assumption that 0 ≤ x mod y < y, which only\r\nholds for positive integers. When input position\r\nis positive, width will be less than T since 0 ≤\r\ninput position mod T < T. However, in the pres\u000210",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/0d9c7354-9be1-4f1f-83e6-7a5579392fbb.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c167592c49598d7bf6ca6911ed5da3c4b19e7ddf53008d1159068c71a8b23876",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 761
      },
      {
        "segments": [
          {
            "segment_id": "59d44c2f-799a-4bde-9ae8-04e11043fadf",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 11,
            "page_width": 612,
            "page_height": 792,
            "content": "602: #define TAB WIDTH(c , h ) ((c ) − ((h ) % (c )))\r\n. . .\r\n1322: clump buff = xmalloc(MAX(8,chars per input tab));\r\n. . . // (set s to clump buff)\r\n2665: width = TAB WIDTH(chars per c, input position);\r\n2666:\r\n2667: if (untabify input)\r\n2668: {\r\n2669: for (i = width; i; −−i)\r\n2670: *s++ = ’ ’;\r\n2671: chars = width;\r\n2672: }\r\nFigure 8: Code snippet from pr where a memory\r\noverflow of clump buff via pointer s is possible if\r\nchars per input tab == chars per c and\r\ninput position < 0.\r\nence of backspaces, input position can become neg\u0002ative, so (−T < input position mod T < T). Con\u0002sequently, width can be as large as 2T − 1.\r\nThe bug arises when the code allocates a buffer\r\nclump buff of size T (line 1322) and then writes width\r\ncharacters into this buffer (lines 2669–2670) via the\r\npointer s (initially set to clump buff). Because width\r\ncan be as large as 2T −1, a memory overflow is possible.\r\nThis is a prime example of the power of symbolic ex\u0002ecution in finding complex errors in code which is hard\r\nto reason about manually — this bug has existed in pr\r\nsince at least 1992, when COREUTILS was first added to\r\na CVS repository.\r\n5.2.4 Comparison with random tests\r\nIn our opinion, the COREUTILS manual tests are un\u0002usually comprehensive. However, we compare to ran\u0002dom testing both to guard against deficiencies, and to get\r\na feel for how constraint-based reasoning compares to\r\nblind random guessing. We tried to make the comparison\r\napples-to-apples by building a tool that takes the same\r\ncommand line as KLEE, and generates random values for\r\nthe specified type, number, and size range of inputs. It\r\nthen runs the checked program on these values using the\r\nsame replay infrastructure as KLEE. For time reasons,\r\nwe randomly chose 15 benchmarks (shown in Figure 9)\r\nand ran them for 65 minutes (to always exceed the time\r\ngiven to KLEE) with the same command lines used when\r\nrun with KLEE.\r\nFigure 9 shows the coverage for these programs\r\nachieved by random, manual, and KLEE tests. Unsurpris\u0002ingly, given the complexity of COREUTILS programs and\r\nthe concerted effort of the COREUTILS maintainers, the\r\nmanual tests get significantly more coverage than ran\u0002dom. KLEE handily beats both.\r\nBecause gcov introduces some overhead, we also\r\nperformed a second experiment in which we ran each\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nstat\r\nnohup\r\npinky\r\ncsplit\r\nginstall\r\nfmt\r\ndf\r\njoin\r\nexpr\r\nseq\r\nunexpand\r\ntsort\r\ntee\r\nbase64\r\nsum\r\nRandom Devel klee\r\nFigure 9: Coverage of random vs. manual vs. KLEE testing\r\nfor 15 randomly-chosen COREUTILS utilities. Manual testing\r\nbeats random on average, while KLEE beats both by a signifi\u0002cant margin.\r\ntool natively without gcov for 65 minutes (using the\r\nsame random seed as the first run), recorded the number\r\nof test cases generated, and then reran using gcov for\r\nthat number. This run completely eliminates the gcov\r\noverhead, and overall it generates 44% more tests than\r\nduring the initial run.\r\nHowever, these 44% extra tests increase the average\r\ncoverage per tool by only 1%, with 11 out of 15 utili\u0002ties not seeing any improvement — showing that random\r\ngets stuck for most applications. We have seen this pat\u0002tern repeatedly in previous work: random quickly gets\r\nthe cases it can, and then revisits them over and over. In\u0002tuitively, satisfying even a single 32-bit equality requires\r\ncorrectly guessing one value out of four billion. Cor\u0002rectly getting a sequence of such conditionals is hope\u0002less. Utilities such as csplit (the worst performer), il\u0002lustrate this dynamic well: their input has structure, and\r\nthe difficulty of blindly guessing values that satisfy its\r\nrules causes most inputs to be rejected.\r\nOne unexpected result was that for 11 of these 15\r\nprograms, KLEE explores paths to termination (i.e., the\r\nchecked code calls exit()) only a few times slower\r\nthan random does! KLEE explored paths to termina\u0002tion in roughly the same time for three programs and,\r\nin fact, was actually faster for three others (seq, tee,\r\nand nohup). We were surprised by these numbers, be\u0002cause we had assumed a constraint-based tool would run\r\norders of magnitude more slowly than raw testing on a\r\nper-path basis, but would have the advantage of explor\u0002ing more unique paths over time (with all values) because\r\nit did not get stuck. While the overhead on four pro\u0002grams matched this expectation (where constraint solver\r\noverhead made paths ran 7x to 220x more slowly than\r\n11",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/59d44c2f-799a-4bde-9ae8-04e11043fadf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0fa7fe9d31899468525099803ecd78a86f901976e457a37943f2870883670717",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 748
      },
      {
        "segments": [
          {
            "segment_id": "59d44c2f-799a-4bde-9ae8-04e11043fadf",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 11,
            "page_width": 612,
            "page_height": 792,
            "content": "602: #define TAB WIDTH(c , h ) ((c ) − ((h ) % (c )))\r\n. . .\r\n1322: clump buff = xmalloc(MAX(8,chars per input tab));\r\n. . . // (set s to clump buff)\r\n2665: width = TAB WIDTH(chars per c, input position);\r\n2666:\r\n2667: if (untabify input)\r\n2668: {\r\n2669: for (i = width; i; −−i)\r\n2670: *s++ = ’ ’;\r\n2671: chars = width;\r\n2672: }\r\nFigure 8: Code snippet from pr where a memory\r\noverflow of clump buff via pointer s is possible if\r\nchars per input tab == chars per c and\r\ninput position < 0.\r\nence of backspaces, input position can become neg\u0002ative, so (−T < input position mod T < T). Con\u0002sequently, width can be as large as 2T − 1.\r\nThe bug arises when the code allocates a buffer\r\nclump buff of size T (line 1322) and then writes width\r\ncharacters into this buffer (lines 2669–2670) via the\r\npointer s (initially set to clump buff). Because width\r\ncan be as large as 2T −1, a memory overflow is possible.\r\nThis is a prime example of the power of symbolic ex\u0002ecution in finding complex errors in code which is hard\r\nto reason about manually — this bug has existed in pr\r\nsince at least 1992, when COREUTILS was first added to\r\na CVS repository.\r\n5.2.4 Comparison with random tests\r\nIn our opinion, the COREUTILS manual tests are un\u0002usually comprehensive. However, we compare to ran\u0002dom testing both to guard against deficiencies, and to get\r\na feel for how constraint-based reasoning compares to\r\nblind random guessing. We tried to make the comparison\r\napples-to-apples by building a tool that takes the same\r\ncommand line as KLEE, and generates random values for\r\nthe specified type, number, and size range of inputs. It\r\nthen runs the checked program on these values using the\r\nsame replay infrastructure as KLEE. For time reasons,\r\nwe randomly chose 15 benchmarks (shown in Figure 9)\r\nand ran them for 65 minutes (to always exceed the time\r\ngiven to KLEE) with the same command lines used when\r\nrun with KLEE.\r\nFigure 9 shows the coverage for these programs\r\nachieved by random, manual, and KLEE tests. Unsurpris\u0002ingly, given the complexity of COREUTILS programs and\r\nthe concerted effort of the COREUTILS maintainers, the\r\nmanual tests get significantly more coverage than ran\u0002dom. KLEE handily beats both.\r\nBecause gcov introduces some overhead, we also\r\nperformed a second experiment in which we ran each\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\nstat\r\nnohup\r\npinky\r\ncsplit\r\nginstall\r\nfmt\r\ndf\r\njoin\r\nexpr\r\nseq\r\nunexpand\r\ntsort\r\ntee\r\nbase64\r\nsum\r\nRandom Devel klee\r\nFigure 9: Coverage of random vs. manual vs. KLEE testing\r\nfor 15 randomly-chosen COREUTILS utilities. Manual testing\r\nbeats random on average, while KLEE beats both by a signifi\u0002cant margin.\r\ntool natively without gcov for 65 minutes (using the\r\nsame random seed as the first run), recorded the number\r\nof test cases generated, and then reran using gcov for\r\nthat number. This run completely eliminates the gcov\r\noverhead, and overall it generates 44% more tests than\r\nduring the initial run.\r\nHowever, these 44% extra tests increase the average\r\ncoverage per tool by only 1%, with 11 out of 15 utili\u0002ties not seeing any improvement — showing that random\r\ngets stuck for most applications. We have seen this pat\u0002tern repeatedly in previous work: random quickly gets\r\nthe cases it can, and then revisits them over and over. In\u0002tuitively, satisfying even a single 32-bit equality requires\r\ncorrectly guessing one value out of four billion. Cor\u0002rectly getting a sequence of such conditionals is hope\u0002less. Utilities such as csplit (the worst performer), il\u0002lustrate this dynamic well: their input has structure, and\r\nthe difficulty of blindly guessing values that satisfy its\r\nrules causes most inputs to be rejected.\r\nOne unexpected result was that for 11 of these 15\r\nprograms, KLEE explores paths to termination (i.e., the\r\nchecked code calls exit()) only a few times slower\r\nthan random does! KLEE explored paths to termina\u0002tion in roughly the same time for three programs and,\r\nin fact, was actually faster for three others (seq, tee,\r\nand nohup). We were surprised by these numbers, be\u0002cause we had assumed a constraint-based tool would run\r\norders of magnitude more slowly than raw testing on a\r\nper-path basis, but would have the advantage of explor\u0002ing more unique paths over time (with all values) because\r\nit did not get stuck. While the overhead on four pro\u0002grams matched this expectation (where constraint solver\r\noverhead made paths ran 7x to 220x more slowly than\r\n11",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/59d44c2f-799a-4bde-9ae8-04e11043fadf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0fa7fe9d31899468525099803ecd78a86f901976e457a37943f2870883670717",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 748
      },
      {
        "segments": [
          {
            "segment_id": "1464a0ac-6dbd-4d53-bded-d74842675388",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 12,
            "page_width": 612,
            "page_height": 792,
            "content": "native execution), the performance tradeoff for the oth\u0002ers is more nuanced. Assume we have a branch deep in\r\nthe program. Covering both true and false directions us\u0002ing traditional testing requires running the program from\r\nstart to finish twice: once for the true path and again\r\nfor the false. In contrast, while KLEE runs each instruc\u0002tion more slowly than native execution, it only needs to\r\nrun the instruction path before the branch once, since it\r\nforks execution at the branch point (a fast operation given\r\nits object-level copy-on-write implementation). As path\r\nlength grows, this ability to avoid redundantly rerunning\r\npath prefixes gets increasingly important.\r\nWith that said, the reader should view the per-path\r\ncosts of random and KLEE as very crude estimates. First,\r\nthe KLEE infrastructure random uses to run tests adds\r\nabout 13ms of per-test overhead, as compared to around\r\n1ms for simply invoking a program from a script. This\r\ncode runs each test case in a sandbox directory, makes\r\na clean environment, and creates various system objects\r\nwith random contents (e.g., files, pipes, tty’s). It then\r\nruns the tested program with a watchdog to terminate\r\ninfinite loops. While a dedicated testing tool must do\r\nroughly similar actions, presumably it could shave some\r\nmilliseconds. However, this fixed cost matters only for\r\nshort program runs, such as when the code exits with an\r\nerror. In cases where random can actually make progress\r\nand explore deeper program paths, the inefficiency of re\u0002running path prefixes starts to dominate. Further, we con\u0002servatively compute the path completion rate for KLEE:\r\nwhen its time expires, roughly 30% of the states it has\r\ncreated are still alive, and we give it no credit for the\r\nwork it did on them.\r\n5.3 BUSYBOX utilities\r\nBUSYBOX is a widely-used implementation of standard\r\nUNIX utilities for embedded systems that aims for small\r\nexecutable sizes [1]. Where there is overlap, it aims to\r\nreplicate COREUTILS functionality, although often pro\u0002viding fewer features. We ran our experiments on a bug\u0002patched version of BUSYBOX 1.10.2. We ran the 75\r\nutilities 8in the BUSYBOX “coreutils” subdirectory\r\n(14K lines of code, with another 16K of library code),\r\nusing the same command lines as when checking CORE\u0002UTILS, except we did not fail system calls.\r\nAs Table 2 shows, KLEE does even better than on\r\nCOREUTILS: over 90.5% total line coverage, on aver\u0002age covering 93.5% per tool with a median of 97.5%. It\r\ngot 100% coverage on 31 and over 90% on 55 utilities.\r\nBUSYBOX has a less comprehensive manual test suite\r\nthan COREUTILS (in fact, many applications don’t seem\r\nto have any tests). Thus, KLEE beats the developers tests\r\nby roughly a factor of two: 90.5% total line coverage ver\u00028We are actually measuring coverage on 72 files because several\r\nutilities are implemented in the same file.\r\ndate -I\r\nls --co\r\nchown a.a -\r\nkill -l a\r\nsetuidgid a \"\"\r\nprintf \"% *\" B\r\nod t1.txt\r\nod t2.txt\r\nprintf %\r\nprintf %Lo\r\ntr [\r\ntr [=\r\ntr [a-z\r\nt1.txt: a\r\nt2.txt: A\r\nt3.txt: \\t\\n\r\ncut -f t3.txt\r\ninstall --m\r\nnmeter -\r\nenvdir\r\nsetuidgid\r\nenvuidgid\r\nenvdir -\r\narp -Ainet\r\ntar tf /\r\ntop d\r\nsetarch \"\" \"\"\r\n<full-path>/linux32\r\n<full-path>/linux64\r\nhexdump -e \"\"\r\nping6 -\r\nFigure 10: KLEE-generated command lines and inputs (modi\u0002fied for readability) that cause program crashes in BUSYBOX.\r\nWhen multiple applications crash because of the same shared\r\n(buggy) piece of code, we group them by shading.\r\nsus only 44.8% for the developers’ suite. The developers\r\ndo better on only one benchmark, cp.\r\n5.4 Bug-finding: MINIX + all BUSYBOX tools\r\nTo demonstrate KLEE’s applicability to bug finding, we\r\nused KLEE to check all 279 BUSYBOX tools and 84\r\nMINIX tools [4] in a series of short runs. These 360+\r\napplications cover a wide range of functionality, such\r\nas networking tools, text editors, login utilities, archiv\u0002ing tools, etc. While the tests generated by KLEE dur\u0002ing these runs are not sufficient to achieve high coverage\r\n(due to incomplete modeling), we did find many bugs\r\nquickly: 21 bugs in BUSYBOX and another 21 in MINIX\r\nhave been reported (many additional reports await in\u0002spection). Figure 10 gives the command lines for the\r\nBUSYBOX bugs. All bugs were memory errors and were\r\nfixed promptly, with the exception of date which had\r\nbeen fixed in an unreleased tree. We have not heard back\r\nfrom the MINIX developers.\r\n5.5 Checking tool equivalence\r\nThus far, we have focused on finding generic errors that\r\ndo not require knowledge of a program’s intended be\u0002havior. We now show how to do much deeper checking,\r\nincluding verifying full functional correctness on a finite\r\nset of explored paths.\r\nKLEE makes no approximations: its constraints have\r\nperfect accuracy down to the level of a single bit. If\r\nKLEE reaches an assert and its constraint solver states\r\nthe false branch of the assert cannot execute given the\r\ncurrent path constraints, then it has proved that no value\r\nexists on the current path that could violate the assertion,\r\n12",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/1464a0ac-6dbd-4d53-bded-d74842675388.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=554d5e5462723da1dd69a3bb580c4777037ec23a96e35602f16eef81ff7d8de3",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 815
      },
      {
        "segments": [
          {
            "segment_id": "1464a0ac-6dbd-4d53-bded-d74842675388",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 12,
            "page_width": 612,
            "page_height": 792,
            "content": "native execution), the performance tradeoff for the oth\u0002ers is more nuanced. Assume we have a branch deep in\r\nthe program. Covering both true and false directions us\u0002ing traditional testing requires running the program from\r\nstart to finish twice: once for the true path and again\r\nfor the false. In contrast, while KLEE runs each instruc\u0002tion more slowly than native execution, it only needs to\r\nrun the instruction path before the branch once, since it\r\nforks execution at the branch point (a fast operation given\r\nits object-level copy-on-write implementation). As path\r\nlength grows, this ability to avoid redundantly rerunning\r\npath prefixes gets increasingly important.\r\nWith that said, the reader should view the per-path\r\ncosts of random and KLEE as very crude estimates. First,\r\nthe KLEE infrastructure random uses to run tests adds\r\nabout 13ms of per-test overhead, as compared to around\r\n1ms for simply invoking a program from a script. This\r\ncode runs each test case in a sandbox directory, makes\r\na clean environment, and creates various system objects\r\nwith random contents (e.g., files, pipes, tty’s). It then\r\nruns the tested program with a watchdog to terminate\r\ninfinite loops. While a dedicated testing tool must do\r\nroughly similar actions, presumably it could shave some\r\nmilliseconds. However, this fixed cost matters only for\r\nshort program runs, such as when the code exits with an\r\nerror. In cases where random can actually make progress\r\nand explore deeper program paths, the inefficiency of re\u0002running path prefixes starts to dominate. Further, we con\u0002servatively compute the path completion rate for KLEE:\r\nwhen its time expires, roughly 30% of the states it has\r\ncreated are still alive, and we give it no credit for the\r\nwork it did on them.\r\n5.3 BUSYBOX utilities\r\nBUSYBOX is a widely-used implementation of standard\r\nUNIX utilities for embedded systems that aims for small\r\nexecutable sizes [1]. Where there is overlap, it aims to\r\nreplicate COREUTILS functionality, although often pro\u0002viding fewer features. We ran our experiments on a bug\u0002patched version of BUSYBOX 1.10.2. We ran the 75\r\nutilities 8in the BUSYBOX “coreutils” subdirectory\r\n(14K lines of code, with another 16K of library code),\r\nusing the same command lines as when checking CORE\u0002UTILS, except we did not fail system calls.\r\nAs Table 2 shows, KLEE does even better than on\r\nCOREUTILS: over 90.5% total line coverage, on aver\u0002age covering 93.5% per tool with a median of 97.5%. It\r\ngot 100% coverage on 31 and over 90% on 55 utilities.\r\nBUSYBOX has a less comprehensive manual test suite\r\nthan COREUTILS (in fact, many applications don’t seem\r\nto have any tests). Thus, KLEE beats the developers tests\r\nby roughly a factor of two: 90.5% total line coverage ver\u00028We are actually measuring coverage on 72 files because several\r\nutilities are implemented in the same file.\r\ndate -I\r\nls --co\r\nchown a.a -\r\nkill -l a\r\nsetuidgid a \"\"\r\nprintf \"% *\" B\r\nod t1.txt\r\nod t2.txt\r\nprintf %\r\nprintf %Lo\r\ntr [\r\ntr [=\r\ntr [a-z\r\nt1.txt: a\r\nt2.txt: A\r\nt3.txt: \\t\\n\r\ncut -f t3.txt\r\ninstall --m\r\nnmeter -\r\nenvdir\r\nsetuidgid\r\nenvuidgid\r\nenvdir -\r\narp -Ainet\r\ntar tf /\r\ntop d\r\nsetarch \"\" \"\"\r\n<full-path>/linux32\r\n<full-path>/linux64\r\nhexdump -e \"\"\r\nping6 -\r\nFigure 10: KLEE-generated command lines and inputs (modi\u0002fied for readability) that cause program crashes in BUSYBOX.\r\nWhen multiple applications crash because of the same shared\r\n(buggy) piece of code, we group them by shading.\r\nsus only 44.8% for the developers’ suite. The developers\r\ndo better on only one benchmark, cp.\r\n5.4 Bug-finding: MINIX + all BUSYBOX tools\r\nTo demonstrate KLEE’s applicability to bug finding, we\r\nused KLEE to check all 279 BUSYBOX tools and 84\r\nMINIX tools [4] in a series of short runs. These 360+\r\napplications cover a wide range of functionality, such\r\nas networking tools, text editors, login utilities, archiv\u0002ing tools, etc. While the tests generated by KLEE dur\u0002ing these runs are not sufficient to achieve high coverage\r\n(due to incomplete modeling), we did find many bugs\r\nquickly: 21 bugs in BUSYBOX and another 21 in MINIX\r\nhave been reported (many additional reports await in\u0002spection). Figure 10 gives the command lines for the\r\nBUSYBOX bugs. All bugs were memory errors and were\r\nfixed promptly, with the exception of date which had\r\nbeen fixed in an unreleased tree. We have not heard back\r\nfrom the MINIX developers.\r\n5.5 Checking tool equivalence\r\nThus far, we have focused on finding generic errors that\r\ndo not require knowledge of a program’s intended be\u0002havior. We now show how to do much deeper checking,\r\nincluding verifying full functional correctness on a finite\r\nset of explored paths.\r\nKLEE makes no approximations: its constraints have\r\nperfect accuracy down to the level of a single bit. If\r\nKLEE reaches an assert and its constraint solver states\r\nthe false branch of the assert cannot execute given the\r\ncurrent path constraints, then it has proved that no value\r\nexists on the current path that could violate the assertion,\r\n12",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/1464a0ac-6dbd-4d53-bded-d74842675388.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=554d5e5462723da1dd69a3bb580c4777037ec23a96e35602f16eef81ff7d8de3",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 815
      },
      {
        "segments": [
          {
            "segment_id": "55a3a9b5-942c-409d-a611-c273f2b9ead7",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 13,
            "page_width": 612,
            "page_height": 792,
            "content": "1 : unsigned mod opt(unsigned x, unsigned y) {\r\n2 : if((y & −y) == y) // power of two?\r\n3 : return x & (y−1);\r\n4 : else\r\n5 : return x % y;\r\n6 : }\r\n7 : unsigned mod(unsigned x, unsigned y) {\r\n8 : return x % y;\r\n9 : }\r\n10: int main() {\r\n11: unsigned x,y;\r\n12: make symbolic(&x, sizeof(x));\r\n13: make symbolic(&y, sizeof(y));\r\n14: assert(mod(x,y) == mod opt(x,y));\r\n15: return 0;\r\n16: }\r\nFigure 11: Trivial program illustrating equivalence checking.\r\nKLEE proves total equivalence when y 6= 0.\r\nmodulo bugs in KLEE or non-determinism in the code. 9\r\nImportantly, KLEE will do such proofs for any condition\r\nthe programmer expresses as C code, from a simple non\u0002null pointer check, to one verifying the correctness of a\r\nprogram’s output.\r\nThis property can be leveraged to perform deeper\r\nchecking as follows. Assume we have two procedures\r\nf and f’ that take a single argument and purport to im\u0002plement the same interface. We can verify functional\r\nequivalence on a per-path basis by simply feeding them\r\nthe same symbolic argument and asserting they return\r\nthe same value: assert(f(x) == f’(x)). Each\r\ntime KLEE follows a path that reaches this assertion, it\r\nchecks if any value exists on that path that violates it. If\r\nit finds none exists, then it has proven functional equiv\u0002alence on that path. By implication, if one function is\r\ncorrect along the path, then equivalence proves the other\r\none is as well. Conversely, if the functions compute dif\u0002ferent values along the path and the assert fires, then\r\nKLEE will produce a test case demonstrating this differ\u0002ence. These are both powerful results, completely be\u0002yond the reach of traditional testing. One way to look at\r\nKLEE is that it automatically translates a path through a\r\nC program into a form that a theorem prover can reason\r\nabout. As a result, proving path equivalence just takes a\r\nfew lines of C code (the assertion above), rather than an\r\nenormous manual exercise in theorem proving.\r\nNote that equivalence results only hold on the finite set\r\nof paths that KLEE explores. Like traditional testing, it\r\ncannot make statements about paths it misses. However,\r\nif KLEE is able to exhaust all paths then it has shown total\r\nequivalence of the functions. Although not tractable in\r\ngeneral, many isolated algorithms can be tested this way,\r\nat least up to some input size.\r\nWe help make these points concrete using the con\u00029Code that depends on the values of memory addresses will not\r\nsatisfy determinism since KLEE will almost certainly allocate memory\r\nobjects at different addresses than native runs.\r\ntrived example in Figure 11, which crosschecks a triv\u0002ial modulo implementation (mod) against one that opti\u0002mizes for modulo by powers of two (mod opt). It first\r\nmakes the inputs x and y symbolic and then uses the\r\nassert (line 14) to check for differences. Two code\r\npaths reach this assert, depending on whether the\r\ntest for power-of-two (line 2) succeeds or fails. (Along\r\nthe way, KLEE generates a division-by-zero test case for\r\nwhen y = 0.) The true path uses the solver to check that\r\nthe constraint (y& − y) == y implies (x&(y − 1)) ==\r\nx%y holds for all values. This query succeeds. The\r\nfalse path checks the vacuous tautology that the con\u0002straint (y& − y) 6= y implies that x%y == x%y also\r\nholds. The KLEE checking run then terminates, which\r\nmeans that KLEE has proved equivalence for all non-zero\r\nvalues using only a few lines of code.\r\nThis methodology is useful in a broad range of con\u0002texts. Most standardized interfaces — such as libraries,\r\nnetworking servers, or compilers — have multiple im\u0002plementations (a partial motivation for and consequence\r\nof standardization). In addition, there are other common\r\ncases where multiple implementations exist:\r\n1 f is a simple reference implementation and f’ a real\u0002world optimized version.\r\n2 f’ is a patched version of f that purports only to\r\nremove bugs (so should have strictly fewer crashes)\r\nor refactor code without changing functionality.\r\n3 f has an inverse, which means we can change our\r\nequivalence check to verify f\r\n−1\r\n(f(x)) ≡ x, such as:\r\nassert(uncompress(compress(x))==x).\r\nExperimental results. We show that this technique\r\ncan find deep correctness errors and scale to real pro\u0002grams by crosschecking 67 COREUTILS tools against\r\ntheir allegedly equivalent BUSYBOX implementations.\r\nFor example, given the same input, the BUSYBOX and\r\nCOREUTILS versions of wc should output the same num\u0002ber of lines, words and bytes. In fact, both the BUSYBOX\r\nand COREUTILS tools intend to conform to IEEE Stan\u0002dard 1003.1 [3] which specifies their behavior.\r\nWe built a simple infrastructure to make crosschecking\r\nautomatic. Given two tools, it renames all their global\r\nsymbols and then links them together. It then runs both\r\nwith the same symbolic environment (same symbolic ar\u0002guments, files, etc.) and compares the data printed to\r\nstdout. When it detects a mismatch, it generates a test\r\ncase that can be run to natively to confirm the difference.\r\nTable 3 shows a subset of the mismatches found by\r\nKLEE. The first three lines show hard correctness er\u0002rors (which were promptly fixed by developers), while\r\nthe others mostly reveal missing functionality. As an ex\u0002ample of a serious correctness bug, the first line gives the\r\ninputs that when run on BUSYBOX’s comm causes it to\r\nbehave as if two non-identical files were identical.\r\n13",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/55a3a9b5-942c-409d-a611-c273f2b9ead7.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=423b81852cdbe3c0fed50f9921a011577be6f4c7c7f3c53d3993344d66a8c09e",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 892
      },
      {
        "segments": [
          {
            "segment_id": "55a3a9b5-942c-409d-a611-c273f2b9ead7",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 13,
            "page_width": 612,
            "page_height": 792,
            "content": "1 : unsigned mod opt(unsigned x, unsigned y) {\r\n2 : if((y & −y) == y) // power of two?\r\n3 : return x & (y−1);\r\n4 : else\r\n5 : return x % y;\r\n6 : }\r\n7 : unsigned mod(unsigned x, unsigned y) {\r\n8 : return x % y;\r\n9 : }\r\n10: int main() {\r\n11: unsigned x,y;\r\n12: make symbolic(&x, sizeof(x));\r\n13: make symbolic(&y, sizeof(y));\r\n14: assert(mod(x,y) == mod opt(x,y));\r\n15: return 0;\r\n16: }\r\nFigure 11: Trivial program illustrating equivalence checking.\r\nKLEE proves total equivalence when y 6= 0.\r\nmodulo bugs in KLEE or non-determinism in the code. 9\r\nImportantly, KLEE will do such proofs for any condition\r\nthe programmer expresses as C code, from a simple non\u0002null pointer check, to one verifying the correctness of a\r\nprogram’s output.\r\nThis property can be leveraged to perform deeper\r\nchecking as follows. Assume we have two procedures\r\nf and f’ that take a single argument and purport to im\u0002plement the same interface. We can verify functional\r\nequivalence on a per-path basis by simply feeding them\r\nthe same symbolic argument and asserting they return\r\nthe same value: assert(f(x) == f’(x)). Each\r\ntime KLEE follows a path that reaches this assertion, it\r\nchecks if any value exists on that path that violates it. If\r\nit finds none exists, then it has proven functional equiv\u0002alence on that path. By implication, if one function is\r\ncorrect along the path, then equivalence proves the other\r\none is as well. Conversely, if the functions compute dif\u0002ferent values along the path and the assert fires, then\r\nKLEE will produce a test case demonstrating this differ\u0002ence. These are both powerful results, completely be\u0002yond the reach of traditional testing. One way to look at\r\nKLEE is that it automatically translates a path through a\r\nC program into a form that a theorem prover can reason\r\nabout. As a result, proving path equivalence just takes a\r\nfew lines of C code (the assertion above), rather than an\r\nenormous manual exercise in theorem proving.\r\nNote that equivalence results only hold on the finite set\r\nof paths that KLEE explores. Like traditional testing, it\r\ncannot make statements about paths it misses. However,\r\nif KLEE is able to exhaust all paths then it has shown total\r\nequivalence of the functions. Although not tractable in\r\ngeneral, many isolated algorithms can be tested this way,\r\nat least up to some input size.\r\nWe help make these points concrete using the con\u00029Code that depends on the values of memory addresses will not\r\nsatisfy determinism since KLEE will almost certainly allocate memory\r\nobjects at different addresses than native runs.\r\ntrived example in Figure 11, which crosschecks a triv\u0002ial modulo implementation (mod) against one that opti\u0002mizes for modulo by powers of two (mod opt). It first\r\nmakes the inputs x and y symbolic and then uses the\r\nassert (line 14) to check for differences. Two code\r\npaths reach this assert, depending on whether the\r\ntest for power-of-two (line 2) succeeds or fails. (Along\r\nthe way, KLEE generates a division-by-zero test case for\r\nwhen y = 0.) The true path uses the solver to check that\r\nthe constraint (y& − y) == y implies (x&(y − 1)) ==\r\nx%y holds for all values. This query succeeds. The\r\nfalse path checks the vacuous tautology that the con\u0002straint (y& − y) 6= y implies that x%y == x%y also\r\nholds. The KLEE checking run then terminates, which\r\nmeans that KLEE has proved equivalence for all non-zero\r\nvalues using only a few lines of code.\r\nThis methodology is useful in a broad range of con\u0002texts. Most standardized interfaces — such as libraries,\r\nnetworking servers, or compilers — have multiple im\u0002plementations (a partial motivation for and consequence\r\nof standardization). In addition, there are other common\r\ncases where multiple implementations exist:\r\n1 f is a simple reference implementation and f’ a real\u0002world optimized version.\r\n2 f’ is a patched version of f that purports only to\r\nremove bugs (so should have strictly fewer crashes)\r\nor refactor code without changing functionality.\r\n3 f has an inverse, which means we can change our\r\nequivalence check to verify f\r\n−1\r\n(f(x)) ≡ x, such as:\r\nassert(uncompress(compress(x))==x).\r\nExperimental results. We show that this technique\r\ncan find deep correctness errors and scale to real pro\u0002grams by crosschecking 67 COREUTILS tools against\r\ntheir allegedly equivalent BUSYBOX implementations.\r\nFor example, given the same input, the BUSYBOX and\r\nCOREUTILS versions of wc should output the same num\u0002ber of lines, words and bytes. In fact, both the BUSYBOX\r\nand COREUTILS tools intend to conform to IEEE Stan\u0002dard 1003.1 [3] which specifies their behavior.\r\nWe built a simple infrastructure to make crosschecking\r\nautomatic. Given two tools, it renames all their global\r\nsymbols and then links them together. It then runs both\r\nwith the same symbolic environment (same symbolic ar\u0002guments, files, etc.) and compares the data printed to\r\nstdout. When it detects a mismatch, it generates a test\r\ncase that can be run to natively to confirm the difference.\r\nTable 3 shows a subset of the mismatches found by\r\nKLEE. The first three lines show hard correctness er\u0002rors (which were promptly fixed by developers), while\r\nthe others mostly reveal missing functionality. As an ex\u0002ample of a serious correctness bug, the first line gives the\r\ninputs that when run on BUSYBOX’s comm causes it to\r\nbehave as if two non-identical files were identical.\r\n13",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/55a3a9b5-942c-409d-a611-c273f2b9ead7.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=423b81852cdbe3c0fed50f9921a011577be6f4c7c7f3c53d3993344d66a8c09e",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 892
      },
      {
        "segments": [
          {
            "segment_id": "01135fd3-ba5f-49a9-80dd-0d1e66887d21",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 14,
            "page_width": 612,
            "page_height": 792,
            "content": "Input BUSYBOX COREUTILS\r\ncomm t1.txt t2.txt [does not show difference] [shows difference]\r\ntee - [does not copy twice to stdout] [does]\r\ntee \"\" <t1.txt [infinite loop] [terminates]\r\ncksum / \"4294967295 0 /\" \"/: Is a directory\"\r\nsplit / \"/: Is a directory\"\r\ntr [duplicates input on stdout] \"missing operand\"\r\n[ 0 ‘‘<’’ 1 ] \"binary operator expected\"\r\nsum -s <t1.txt \"97 1 -\" \"97 1\"\r\ntail -2l [rejects] [accepts]\r\nunexpand -f [accepts] [rejects]\r\nsplit - [rejects] [accepts]\r\nls --color-blah [accepts] [rejects]\r\nt1.txt: a t2.txt: b\r\nTable 3: Very small subset of the mismatches KLEE found between the BUSYBOX and COREUTILS versions of equivalent utili\u0002ties. The first three are serious correctness errors; most of the others are revealing missing functionality.\r\nTest Random KLEE ELOC\r\nWith Disk 50.1% 67.1% 4617\r\nNo Disk 48.0% 76.4% 2662\r\nTable 4: Coverage on the HISTAR kernel for runs with up to\r\nthree system calls, configured with and without a disk. For\r\ncomparison we did the same runs using random inputs for one\r\nmillion trials.\r\n5.6 The HiStar OS kernel\r\nWe have also applied KLEE to checking non-application\r\ncode by using it to check the HiStar [39] kernel. We used\r\na simple test driver based on a user-mode HISTAR ker\u0002nel. The driver creates the core kernel data structures and\r\ninitializes a single process with access to a single page of\r\nuser memory. It then calls the test function in Figure 12,\r\nwhich makes the user memory symbolic and executes a\r\npredefined number of system calls using entirely sym\u0002bolic arguments. As the system call number is encoded\r\nin the first argument, this simple driver effectively tests\r\nall (sequences of) system calls in the kernel.\r\nAlthough the setup is restrictive, in practice we have\r\nfound that it can quickly generate test cases — sequences\r\nof system call vectors and memory contents — which\r\ncover a large portion of the kernel code and uncover\r\ninteresting behaviors. Table 4 shows the coverage ob\u0002tained for the core kernel for runs with and without a\r\ndisk. When configured with a disk, a majority of the un\u0002covered code can only be triggered when there are a large\r\nnumber of kernel objects. This currently does not happen\r\nin our testing environment; we are investigating ways to\r\nexercise this code adequately during testing. As a quick\r\ncomparison, we ran one million random tests through\r\nthe same driver (similar to § 5.2.4). As Table 4 shows,\r\nKLEE’s tests achieve significantly more coverage than\r\nrandom testing both for runs with (+17.0%) and without\r\n(+28.4%) a disk.\r\n1 : static void test(void *upage, unsigned num calls) {\r\n2 : make symbolic(upage, PGSIZE);\r\n3 : for (int i=0; i<num calls; i++) {\r\n4 : uint64 t args[8];\r\n5 : for (int j=0; j<8; j++)\r\n6 : make symbolic(&args[j], sizeof(args[j]));\r\n7 : kern syscall(args[0], args[1], args[2], args[3],\r\n8 : args[4], args[5], args[6], args[7]);\r\n9 : }\r\n10: sys self halt();\r\n11: }\r\nFigure 12: Test driver for HISTAR: it makes a single page of\r\nuser memory symbolic and executes a user-specified number\r\nof system calls with entirely symbolic arguments.\r\nKLEE’s constraint-based reasoning allowed it to find a\r\ntricky, critical security bug in the 32-bit version of HIS\u0002TAR. Figure 13 shows the code for the function contain\u0002ing the bug. The function safe addptr is supposed\r\nto set *of to true if the addition overflows. However,\r\nbecause the inputs are 64 bit long, the test used is insuf\u0002ficient (it should be (r < a) || (r < b)) and the\r\nfunction can fail to indicate overflow for large values of\r\nb.\r\nThe safe addptr function validates user memory\r\naddresses prior to copying data to or from user space. A\r\nkernel routine takes a user address and a size and com\u0002putes if the user is allowed to access the memory in that\r\nrange; this routine uses the overflow to prevent access\r\nwhen a computation could overflow. This bug in com\u0002puting overflow therefore allows a malicious process to\r\ngain access to memory regions outside its control.\r\n6 Related Work\r\nMany recent tools are based on symbolic execution [11,\r\n14–16, 20–22, 24, 26, 27, 36]. We contrast how KLEE\r\ndeals with the environment and path explosion problems.\r\nTo the best of our knowledge, traditional symbolic ex\u000214",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/01135fd3-ba5f-49a9-80dd-0d1e66887d21.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=397cf592cec18aa045be57acd6930ede4c28cc221979f6ffff163c0455aad00b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 700
      },
      {
        "segments": [
          {
            "segment_id": "01135fd3-ba5f-49a9-80dd-0d1e66887d21",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 14,
            "page_width": 612,
            "page_height": 792,
            "content": "Input BUSYBOX COREUTILS\r\ncomm t1.txt t2.txt [does not show difference] [shows difference]\r\ntee - [does not copy twice to stdout] [does]\r\ntee \"\" <t1.txt [infinite loop] [terminates]\r\ncksum / \"4294967295 0 /\" \"/: Is a directory\"\r\nsplit / \"/: Is a directory\"\r\ntr [duplicates input on stdout] \"missing operand\"\r\n[ 0 ‘‘<’’ 1 ] \"binary operator expected\"\r\nsum -s <t1.txt \"97 1 -\" \"97 1\"\r\ntail -2l [rejects] [accepts]\r\nunexpand -f [accepts] [rejects]\r\nsplit - [rejects] [accepts]\r\nls --color-blah [accepts] [rejects]\r\nt1.txt: a t2.txt: b\r\nTable 3: Very small subset of the mismatches KLEE found between the BUSYBOX and COREUTILS versions of equivalent utili\u0002ties. The first three are serious correctness errors; most of the others are revealing missing functionality.\r\nTest Random KLEE ELOC\r\nWith Disk 50.1% 67.1% 4617\r\nNo Disk 48.0% 76.4% 2662\r\nTable 4: Coverage on the HISTAR kernel for runs with up to\r\nthree system calls, configured with and without a disk. For\r\ncomparison we did the same runs using random inputs for one\r\nmillion trials.\r\n5.6 The HiStar OS kernel\r\nWe have also applied KLEE to checking non-application\r\ncode by using it to check the HiStar [39] kernel. We used\r\na simple test driver based on a user-mode HISTAR ker\u0002nel. The driver creates the core kernel data structures and\r\ninitializes a single process with access to a single page of\r\nuser memory. It then calls the test function in Figure 12,\r\nwhich makes the user memory symbolic and executes a\r\npredefined number of system calls using entirely sym\u0002bolic arguments. As the system call number is encoded\r\nin the first argument, this simple driver effectively tests\r\nall (sequences of) system calls in the kernel.\r\nAlthough the setup is restrictive, in practice we have\r\nfound that it can quickly generate test cases — sequences\r\nof system call vectors and memory contents — which\r\ncover a large portion of the kernel code and uncover\r\ninteresting behaviors. Table 4 shows the coverage ob\u0002tained for the core kernel for runs with and without a\r\ndisk. When configured with a disk, a majority of the un\u0002covered code can only be triggered when there are a large\r\nnumber of kernel objects. This currently does not happen\r\nin our testing environment; we are investigating ways to\r\nexercise this code adequately during testing. As a quick\r\ncomparison, we ran one million random tests through\r\nthe same driver (similar to § 5.2.4). As Table 4 shows,\r\nKLEE’s tests achieve significantly more coverage than\r\nrandom testing both for runs with (+17.0%) and without\r\n(+28.4%) a disk.\r\n1 : static void test(void *upage, unsigned num calls) {\r\n2 : make symbolic(upage, PGSIZE);\r\n3 : for (int i=0; i<num calls; i++) {\r\n4 : uint64 t args[8];\r\n5 : for (int j=0; j<8; j++)\r\n6 : make symbolic(&args[j], sizeof(args[j]));\r\n7 : kern syscall(args[0], args[1], args[2], args[3],\r\n8 : args[4], args[5], args[6], args[7]);\r\n9 : }\r\n10: sys self halt();\r\n11: }\r\nFigure 12: Test driver for HISTAR: it makes a single page of\r\nuser memory symbolic and executes a user-specified number\r\nof system calls with entirely symbolic arguments.\r\nKLEE’s constraint-based reasoning allowed it to find a\r\ntricky, critical security bug in the 32-bit version of HIS\u0002TAR. Figure 13 shows the code for the function contain\u0002ing the bug. The function safe addptr is supposed\r\nto set *of to true if the addition overflows. However,\r\nbecause the inputs are 64 bit long, the test used is insuf\u0002ficient (it should be (r < a) || (r < b)) and the\r\nfunction can fail to indicate overflow for large values of\r\nb.\r\nThe safe addptr function validates user memory\r\naddresses prior to copying data to or from user space. A\r\nkernel routine takes a user address and a size and com\u0002putes if the user is allowed to access the memory in that\r\nrange; this routine uses the overflow to prevent access\r\nwhen a computation could overflow. This bug in com\u0002puting overflow therefore allows a malicious process to\r\ngain access to memory regions outside its control.\r\n6 Related Work\r\nMany recent tools are based on symbolic execution [11,\r\n14–16, 20–22, 24, 26, 27, 36]. We contrast how KLEE\r\ndeals with the environment and path explosion problems.\r\nTo the best of our knowledge, traditional symbolic ex\u000214",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/01135fd3-ba5f-49a9-80dd-0d1e66887d21.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=397cf592cec18aa045be57acd6930ede4c28cc221979f6ffff163c0455aad00b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 700
      },
      {
        "segments": [
          {
            "segment_id": "674de125-914b-4f5a-9b4a-a2f8cdc795b4",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 15,
            "page_width": 612,
            "page_height": 792,
            "content": "1 : uintptr t safe addptr(int *of, uint64 t a, uint64 t b) {\r\n2 : uintptr t r = a + b;\r\n3 : if (r < a)\r\n4 : *of = 1;\r\n5 : return r;\r\n6 : }\r\nFigure 13: HISTAR function containing an important security\r\nvulnerability. The function is supposed to set *of to true\r\nif the addition overflows but can fail to do so in the 32-bit\r\nversion for very large values of b.\r\necution systems [17, 18, 32] are static in a strict sense and\r\ndo not interact with the running environment at all. They\r\neither cannot handle programs that make use of the en\u0002vironment or require a complete working model. More\r\nrecent work in test generation [16, 26, 36] does allow ex\u0002ternal interactions, but forces them to use entirely con\u0002crete procedure call arguments, which limits the behav\u0002iors they can explore: a concrete external call will do ex\u0002actly what it did, rather than all things it could potentially\r\ndo. In KLEE, we strive for a functional balance between\r\nthese two alternatives; we allow both interaction with the\r\noutside environment and supply a model to simulate in\u0002teraction with a symbolic one.\r\nThe path explosion problem has instead received more\r\nattention [11, 22, 24, 27, 34]. Similarly to the search\r\nheuristics presented in Section 3, search strategies pro\u0002posed in the past include Best First Search [16], Gener\u0002ational Search [27], and Hybrid Concolic Testing [34].\r\nOrthogonal to search heuristics, researchers have ad\u0002dressed the path explosion problem by testing paths com\u0002positionally [8, 24], and by tracking the values read and\r\nwritten by the program [11].\r\nLike KLEE, other symbolic execution systems imple\u0002ment their own optimizations before sending the queries\r\nto the underlying constraint solver, such as the simple\r\nsyntactic transformations presented in [36], and the con\u0002straint subsumption optimization discussed in [27].\r\nSimilar to symbolic execution systems, model check\u0002ers have been used to find bugs in both the design and\r\nthe implementation of software [10, 12, 19, 25, 29, 30].\r\nThese approaches often require a lot of manual effort to\r\nbuild test harnesses. However, the approaches are some\u0002what complementary to KLEE: the tests KLEE generates\r\ncan be used to drive the model checked code, similar to\r\nthe approach embraced by Java PathFinder [31, 37].\r\nPreviously, we showed that symbolic execution can\r\nfind correctness errors by crosschecking various imple\u0002mentations of the same library function [15]; this paper\r\nshows that the technique scales to real programs. Subse\u0002quent to our initial work, others applied similar ideas to\r\nfinding correctness errors in applications such as network\r\nprotocol implementations [13] and PHP scripts [9].\r\n7 Conclusion\r\nOur long-term goal is to take an arbitrary program and\r\nroutinely get 90%+ code coverage, crushing it under test\r\ncases for all interesting inputs. While there is still a long\r\nway to go to reach this goal, our results show that the ap\u0002proach works well across a broad range of real code. Our\r\nsystem KLEE, automatically generated tests that, on av\u0002erage, covered over 90% of the lines (in aggregate over\r\n80%) in roughly 160 complex, system-intensive appli\u0002cations “out of the box.” This coverage significantly\r\nexceeded that of their corresponding hand-written test\r\nsuites, including one built over a period of 15 years.\r\nIn total, we used KLEE to check 452 applications (with\r\nover 430K lines of code), where it found 56 serious bugs,\r\nincluding ten in COREUTILS, arguably the most heavily\u0002tested collection of open-source applications. To the best\r\nof our knowledge, this represents an order of magnitude\r\nmore code and distinct programs than checked by prior\r\nsymbolic test generation work. Further, because KLEE’s\r\nconstraints have no approximations, its reasoning allow\r\nit to prove properties of paths (or find counter-examples\r\nwithout false positives). We used this ability both to\r\nprove path equivalence across many real, purportedly\r\nidentical applications, and to find functional correctness\r\nerrors in them.\r\nThe techniques we describe should work well with\r\nother tools and provide similar help in handling a broad\r\nclass of applications.\r\n8 Acknowledgements\r\nWe thank the GNU COREUTILS developers, particularly\r\nthe COREUTILS maintainer Jim Meyering for promptly\r\nconfirming our reported bugs and answering many ques\u0002tions. We similarly thank the developers of BUSYBOX,\r\nparticularly the BUSYBOX maintainer, Denys Vlasenko.\r\nWe also thank Nickolai Zeldovich, the designer of HIS\u0002TAR, for his great help in checking HISTAR, including\r\nwriting a user-level driver for us. We thank our shepard\r\nTerence Kelly, the helpful OSDI reviewers, and Philip\r\nGuo for valuable comments on the text. This research\r\nwas supported by DHS grant FA8750-05-2-0142, NSF\r\nTRUST grant CCF-0424422, and NSF CAREER award\r\nCNS-0238570-001. A Junglee Graduate Fellowship par\u0002tially supported Cristian Cadar.\r\nReferences\r\n[1] Busybox. www.busybox.net, August 2008.\r\n[2] Coreutils. www.gnu.org/software/coreutils, August\r\n2008.\r\n[3] IEEE Std 1003.1, 2004 edition. www.unix.org/version3/\r\nieee_std.html, May 2008.\r\n[4] MINIX 3. www.minix3.org, August 2008.\r\n[5] SecurityFocus, www.securityfocus.com, March 2008.\r\n[6] uCLibc. www.uclibc.org, May 2008.\r\n15",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/674de125-914b-4f5a-9b4a-a2f8cdc795b4.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=72059f16a5271c60923334274f53b43fd7c4f167d5e3a34bc2e813b72c67813e",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 799
      },
      {
        "segments": [
          {
            "segment_id": "674de125-914b-4f5a-9b4a-a2f8cdc795b4",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 15,
            "page_width": 612,
            "page_height": 792,
            "content": "1 : uintptr t safe addptr(int *of, uint64 t a, uint64 t b) {\r\n2 : uintptr t r = a + b;\r\n3 : if (r < a)\r\n4 : *of = 1;\r\n5 : return r;\r\n6 : }\r\nFigure 13: HISTAR function containing an important security\r\nvulnerability. The function is supposed to set *of to true\r\nif the addition overflows but can fail to do so in the 32-bit\r\nversion for very large values of b.\r\necution systems [17, 18, 32] are static in a strict sense and\r\ndo not interact with the running environment at all. They\r\neither cannot handle programs that make use of the en\u0002vironment or require a complete working model. More\r\nrecent work in test generation [16, 26, 36] does allow ex\u0002ternal interactions, but forces them to use entirely con\u0002crete procedure call arguments, which limits the behav\u0002iors they can explore: a concrete external call will do ex\u0002actly what it did, rather than all things it could potentially\r\ndo. In KLEE, we strive for a functional balance between\r\nthese two alternatives; we allow both interaction with the\r\noutside environment and supply a model to simulate in\u0002teraction with a symbolic one.\r\nThe path explosion problem has instead received more\r\nattention [11, 22, 24, 27, 34]. Similarly to the search\r\nheuristics presented in Section 3, search strategies pro\u0002posed in the past include Best First Search [16], Gener\u0002ational Search [27], and Hybrid Concolic Testing [34].\r\nOrthogonal to search heuristics, researchers have ad\u0002dressed the path explosion problem by testing paths com\u0002positionally [8, 24], and by tracking the values read and\r\nwritten by the program [11].\r\nLike KLEE, other symbolic execution systems imple\u0002ment their own optimizations before sending the queries\r\nto the underlying constraint solver, such as the simple\r\nsyntactic transformations presented in [36], and the con\u0002straint subsumption optimization discussed in [27].\r\nSimilar to symbolic execution systems, model check\u0002ers have been used to find bugs in both the design and\r\nthe implementation of software [10, 12, 19, 25, 29, 30].\r\nThese approaches often require a lot of manual effort to\r\nbuild test harnesses. However, the approaches are some\u0002what complementary to KLEE: the tests KLEE generates\r\ncan be used to drive the model checked code, similar to\r\nthe approach embraced by Java PathFinder [31, 37].\r\nPreviously, we showed that symbolic execution can\r\nfind correctness errors by crosschecking various imple\u0002mentations of the same library function [15]; this paper\r\nshows that the technique scales to real programs. Subse\u0002quent to our initial work, others applied similar ideas to\r\nfinding correctness errors in applications such as network\r\nprotocol implementations [13] and PHP scripts [9].\r\n7 Conclusion\r\nOur long-term goal is to take an arbitrary program and\r\nroutinely get 90%+ code coverage, crushing it under test\r\ncases for all interesting inputs. While there is still a long\r\nway to go to reach this goal, our results show that the ap\u0002proach works well across a broad range of real code. Our\r\nsystem KLEE, automatically generated tests that, on av\u0002erage, covered over 90% of the lines (in aggregate over\r\n80%) in roughly 160 complex, system-intensive appli\u0002cations “out of the box.” This coverage significantly\r\nexceeded that of their corresponding hand-written test\r\nsuites, including one built over a period of 15 years.\r\nIn total, we used KLEE to check 452 applications (with\r\nover 430K lines of code), where it found 56 serious bugs,\r\nincluding ten in COREUTILS, arguably the most heavily\u0002tested collection of open-source applications. To the best\r\nof our knowledge, this represents an order of magnitude\r\nmore code and distinct programs than checked by prior\r\nsymbolic test generation work. Further, because KLEE’s\r\nconstraints have no approximations, its reasoning allow\r\nit to prove properties of paths (or find counter-examples\r\nwithout false positives). We used this ability both to\r\nprove path equivalence across many real, purportedly\r\nidentical applications, and to find functional correctness\r\nerrors in them.\r\nThe techniques we describe should work well with\r\nother tools and provide similar help in handling a broad\r\nclass of applications.\r\n8 Acknowledgements\r\nWe thank the GNU COREUTILS developers, particularly\r\nthe COREUTILS maintainer Jim Meyering for promptly\r\nconfirming our reported bugs and answering many ques\u0002tions. We similarly thank the developers of BUSYBOX,\r\nparticularly the BUSYBOX maintainer, Denys Vlasenko.\r\nWe also thank Nickolai Zeldovich, the designer of HIS\u0002TAR, for his great help in checking HISTAR, including\r\nwriting a user-level driver for us. We thank our shepard\r\nTerence Kelly, the helpful OSDI reviewers, and Philip\r\nGuo for valuable comments on the text. This research\r\nwas supported by DHS grant FA8750-05-2-0142, NSF\r\nTRUST grant CCF-0424422, and NSF CAREER award\r\nCNS-0238570-001. A Junglee Graduate Fellowship par\u0002tially supported Cristian Cadar.\r\nReferences\r\n[1] Busybox. www.busybox.net, August 2008.\r\n[2] Coreutils. www.gnu.org/software/coreutils, August\r\n2008.\r\n[3] IEEE Std 1003.1, 2004 edition. www.unix.org/version3/\r\nieee_std.html, May 2008.\r\n[4] MINIX 3. www.minix3.org, August 2008.\r\n[5] SecurityFocus, www.securityfocus.com, March 2008.\r\n[6] uCLibc. www.uclibc.org, May 2008.\r\n15",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/674de125-914b-4f5a-9b4a-a2f8cdc795b4.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=72059f16a5271c60923334274f53b43fd7c4f167d5e3a34bc2e813b72c67813e",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 799
      },
      {
        "segments": [
          {
            "segment_id": "aab00a4c-67c6-4815-ba34-ec541d24270c",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 16,
            "page_width": 612,
            "page_height": 792,
            "content": "[7] United States National Vulnerability Database, nvd.nist.\r\ngov, March 2008.\r\n[8] ANAND, S., GODEFROID, P., AND TILLMANN, N. Demand\u0002driven compositional symbolic execution. In Proceedings of\r\nTools and Algorithms for the Construction and Analysis of Sys\u0002tems (TACAS 2008).\r\n[9] ARTZI, S., KIEZUN ˙ , A., DOLBY, J., TIP, F., DIG, D., PARAD\u0002KAR, A., AND ERNST, M. D. Finding bugs in dynamic web\r\napplications. In Proceedings of the International Symposium on\r\nSoftware Testing and Analysis (ISSTA 2008).\r\n[10] BALL, T., AND RAJAMANI, S. Automatically validating tempo\u0002ral safety properties of interfaces. In Proceedings of the 8th Inter\u0002national SPIN Workshop on Model Checking of Software (SPIN\r\n2001).\r\n[11] BOONSTOPPEL, P., CADAR, C., AND ENGLER, D. RWset: At\u0002tacking path explosion in constraint-based test generation. In\r\nProceedings of Tools and Algorithms for the Construction and\r\nAnalysis of Systems (TACAS 2008).\r\n[12] BRAT, G., HAVELUND, K., PARK, S., AND VISSER, W. Model\r\nchecking programs. In IEEE International Conference on Auto\u0002mated Software Engineering (ASE 2000).\r\n[13] BRUMLEY, D., CABALLERO, J., LIANG, Z., NEWSOME, J.,\r\nAND SONG, D. Towards automatic discovery of deviations in\r\nbinary implementations with applications to error detection and\r\nfingerprint generation. In Proceedings of USENIX Security Sym\u0002posium (USENIX Security 2007).\r\n[14] BRUMLEY, D., NEWSOME, J., SONG, D., WANG, H., AND\r\nJHA, S. Towards automatic generation of vulnerability-based sig\u0002natures. In Proceedings of the 2006 IEEE Symposium on Security\r\nand Privacy (IEEE S&P 2006).\r\n[15] CADAR, C., AND ENGLER, D. Execution generated test cases:\r\nHow to make systems code crash itself. In Proceedings of the\r\n12th International SPIN Workshop on Model Checking of Soft\u0002ware (SPIN 2005).\r\n[16] CADAR, C., GANESH, V., PAWLOWSKI, P., DILL, D., AND\r\nENGLER, D. EXE: Automatically generating inputs of death.\r\nIn Proceedings of the 13th ACM Conference on Computer and\r\nCommunications Security (CCS 2006).\r\n[17] CLARKE, E., AND KROENING, D. Hardware verification using\r\nANSI-C programs as a reference. In Proceedings of the Asia and\r\nSouth Pacific Design Automation Conference (ASP-DAC 2003).\r\n[18] CLARKE, E., KROENING, D., AND LERDA, F. A tool for check\u0002ing ANSI-C programs. In Proceedings of Tools and Algorithms\r\nfor the Construction and Analysis of Systems (TACAS 2004).\r\n[19] CORBETT, J., DWYER, M., HATCLIFF, J., LAUBACH, S.,\r\nPASAREANU, C., ROBBY, AND ZHENG, H. Bandera: Extracting\r\nfinite-state models from Java source code. In Proceedings of the\r\nInternational Conference on Software Engineering (ICSE 2000).\r\n[20] COSTA, M., CASTRO, M., ZHOU, L., ZHANG, L., AND\r\nPEINADO, M. Bouncer: Securing software by blocking bad in\u0002put. In Proceedings of the 21th ACM Symposium on Operating\r\nSystems Principles (SOSP 2007).\r\n[21] COSTA, M., CROWCROFT, J., CASTRO, M., ROWSTRON, A.,\r\nZHOU, L., ZHANG, L., AND BARHAM, P. Vigilante: end-to-end\r\ncontainment of Internet worms. In Proceedings of the 20th ACM\r\nSymposium on Operating Systems Principles (SOSP 2005).\r\n[22] EMMI, M., MAJUMDAR, R., AND SEN, K. Dynamic test input\r\ngeneration for database applications. In International Symposium\r\non Software Testing and Analysis (ISSTA 2007).\r\n[23] GANESH, V., AND DILL, D. L. A decision procedure for bit\u0002vectors and arrays. In Proceedings of the 19th International Con\u0002ference on Computer Aided Verification (CAV 2007).\r\n[24] GODEFROID, P. Compositional dynamic test generation. In Pro\u0002ceedings of the 34th Symposium on Principles of Programming\r\nLanguages (POPL 2007).\r\n[25] GODEFROID, P. Model Checking for Programming Languages\r\nusing VeriSoft. In Proceedings of the 24th ACM Symposium on\r\nPrinciples of Programming Languages (POPL 1997).\r\n[26] GODEFROID, P., KLARLUND, N., AND SEN, K. DART: Di\u0002rected automated random testing. In Proceedings of the Con\u0002ference on Programming Language Design and Implementation\r\n(PLDI 2005).\r\n[27] GODEFROID, P., LEVIN, M. Y., AND MOLNAR, D. Automated\r\nwhitebox fuzz testing. In Proceedings of Network and Distributed\r\nSystems Security (NDSS 2008).\r\n[28] HOFFMANN, J., AND KOEHLER, J. A new method to index and\r\nquery sets. In Proceedings of the Sixteenth International Joint\r\nConference on Artificial Intelligence (IJCAI 1999).\r\n[29] HOLZMANN, G. J. From code to models. In Proceedings of\r\n2nd International Conference on Applications of Concurrency to\r\nSystem Design (ACSD 2001).\r\n[30] HOLZMANN, G. J. The model checker SPIN. Software Engi\u0002neering 23, 5 (1997), 279–295.\r\n[31] KHURSHID, S., PASAREANU, C. S., AND VISSER, W. Gen\u0002eralized symbolic execution for model checking and testing. In\r\nProceedings of Tools and Algorithms for the Construction and\r\nAnalysis of Systems (TACAS 2003).\r\n[32] KROENING, D., CLARKE, E., AND YORAV, K. Behavioral con\u0002sistency of C and Verilog programs using bounded model check\u0002ing. In Proceedings of the 40th Design Automation Conference\r\n(DAC 2003).\r\n[33] LATTNER, C., AND ADVE, V. LLVM: A compilation framework\r\nfor lifelong program analysis & transformation. In Proceedings\r\nof the international symposium on Code generation and optimiza\u0002tion (CGO 2004).\r\n[34] MAJUMDAR, R., AND SEN, K. Hybrid concolic testing. In Pro\u0002ceedings of the 29th International Conference on Software Engi\u0002neering (ICSE 2007).\r\n[35] MILLER, B., KOSKI, D., LEE, C. P., MAGANTY, V., MURTHY,\r\nR., NATARAJAN, A., AND STEIDL, J. Fuzz revisited: A re\u0002examination of the reliability of UNIX utilities and services.\r\nTech. rep., University of Wisconsin - Madison, 1995.\r\n[36] SEN, K., MARINOV, D., AND AGHA, G. CUTE: A concolic\r\nunit testing engine for C. In In 5th joint meeting of the European\r\nSoftware Engineering Conference and ACM Symposium on the\r\nFoundations of Software Engineering (ESEC/FSE 2005).\r\n[37] VISSER, W., PASAREANU, C. S., AND KHURSHID, S. Test\r\ninput generation with Java PathFinder. In Proceedings of the\r\n2004 ACM SIGSOFT International Symposium on Software Test\u0002ing and Analysis (ISSTA 2004).\r\n[38] YANG, J., SAR, C., AND ENGLER, D. eXplode: a lightweight,\r\ngeneral system for finding serious storage system errors. In Pro\u0002ceedings of the 7th Symposium on Operating Systems Design and\r\nImplementation (OSDI 2006).\r\n[39] ZELDOVICH, N., BOYD-WICKIZER, S., KOHLER, E., AND\r\nMAZIERES ` , D. Making information flow explicit in HiStar. In\r\nProceedings of the 7th Symposium on Operating Systems Design\r\nand Implementation (OSDI 2006).\r\n16",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/aab00a4c-67c6-4815-ba34-ec541d24270c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=086edce37512c473ad3a086ae7dcec6f633af320fcede0bc174feb9131642903",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 939
      },
      {
        "segments": [
          {
            "segment_id": "aab00a4c-67c6-4815-ba34-ec541d24270c",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 16,
            "page_width": 612,
            "page_height": 792,
            "content": "[7] United States National Vulnerability Database, nvd.nist.\r\ngov, March 2008.\r\n[8] ANAND, S., GODEFROID, P., AND TILLMANN, N. Demand\u0002driven compositional symbolic execution. In Proceedings of\r\nTools and Algorithms for the Construction and Analysis of Sys\u0002tems (TACAS 2008).\r\n[9] ARTZI, S., KIEZUN ˙ , A., DOLBY, J., TIP, F., DIG, D., PARAD\u0002KAR, A., AND ERNST, M. D. Finding bugs in dynamic web\r\napplications. In Proceedings of the International Symposium on\r\nSoftware Testing and Analysis (ISSTA 2008).\r\n[10] BALL, T., AND RAJAMANI, S. Automatically validating tempo\u0002ral safety properties of interfaces. In Proceedings of the 8th Inter\u0002national SPIN Workshop on Model Checking of Software (SPIN\r\n2001).\r\n[11] BOONSTOPPEL, P., CADAR, C., AND ENGLER, D. RWset: At\u0002tacking path explosion in constraint-based test generation. In\r\nProceedings of Tools and Algorithms for the Construction and\r\nAnalysis of Systems (TACAS 2008).\r\n[12] BRAT, G., HAVELUND, K., PARK, S., AND VISSER, W. Model\r\nchecking programs. In IEEE International Conference on Auto\u0002mated Software Engineering (ASE 2000).\r\n[13] BRUMLEY, D., CABALLERO, J., LIANG, Z., NEWSOME, J.,\r\nAND SONG, D. Towards automatic discovery of deviations in\r\nbinary implementations with applications to error detection and\r\nfingerprint generation. In Proceedings of USENIX Security Sym\u0002posium (USENIX Security 2007).\r\n[14] BRUMLEY, D., NEWSOME, J., SONG, D., WANG, H., AND\r\nJHA, S. Towards automatic generation of vulnerability-based sig\u0002natures. In Proceedings of the 2006 IEEE Symposium on Security\r\nand Privacy (IEEE S&P 2006).\r\n[15] CADAR, C., AND ENGLER, D. Execution generated test cases:\r\nHow to make systems code crash itself. In Proceedings of the\r\n12th International SPIN Workshop on Model Checking of Soft\u0002ware (SPIN 2005).\r\n[16] CADAR, C., GANESH, V., PAWLOWSKI, P., DILL, D., AND\r\nENGLER, D. EXE: Automatically generating inputs of death.\r\nIn Proceedings of the 13th ACM Conference on Computer and\r\nCommunications Security (CCS 2006).\r\n[17] CLARKE, E., AND KROENING, D. Hardware verification using\r\nANSI-C programs as a reference. In Proceedings of the Asia and\r\nSouth Pacific Design Automation Conference (ASP-DAC 2003).\r\n[18] CLARKE, E., KROENING, D., AND LERDA, F. A tool for check\u0002ing ANSI-C programs. In Proceedings of Tools and Algorithms\r\nfor the Construction and Analysis of Systems (TACAS 2004).\r\n[19] CORBETT, J., DWYER, M., HATCLIFF, J., LAUBACH, S.,\r\nPASAREANU, C., ROBBY, AND ZHENG, H. Bandera: Extracting\r\nfinite-state models from Java source code. In Proceedings of the\r\nInternational Conference on Software Engineering (ICSE 2000).\r\n[20] COSTA, M., CASTRO, M., ZHOU, L., ZHANG, L., AND\r\nPEINADO, M. Bouncer: Securing software by blocking bad in\u0002put. In Proceedings of the 21th ACM Symposium on Operating\r\nSystems Principles (SOSP 2007).\r\n[21] COSTA, M., CROWCROFT, J., CASTRO, M., ROWSTRON, A.,\r\nZHOU, L., ZHANG, L., AND BARHAM, P. Vigilante: end-to-end\r\ncontainment of Internet worms. In Proceedings of the 20th ACM\r\nSymposium on Operating Systems Principles (SOSP 2005).\r\n[22] EMMI, M., MAJUMDAR, R., AND SEN, K. Dynamic test input\r\ngeneration for database applications. In International Symposium\r\non Software Testing and Analysis (ISSTA 2007).\r\n[23] GANESH, V., AND DILL, D. L. A decision procedure for bit\u0002vectors and arrays. In Proceedings of the 19th International Con\u0002ference on Computer Aided Verification (CAV 2007).\r\n[24] GODEFROID, P. Compositional dynamic test generation. In Pro\u0002ceedings of the 34th Symposium on Principles of Programming\r\nLanguages (POPL 2007).\r\n[25] GODEFROID, P. Model Checking for Programming Languages\r\nusing VeriSoft. In Proceedings of the 24th ACM Symposium on\r\nPrinciples of Programming Languages (POPL 1997).\r\n[26] GODEFROID, P., KLARLUND, N., AND SEN, K. DART: Di\u0002rected automated random testing. In Proceedings of the Con\u0002ference on Programming Language Design and Implementation\r\n(PLDI 2005).\r\n[27] GODEFROID, P., LEVIN, M. Y., AND MOLNAR, D. Automated\r\nwhitebox fuzz testing. In Proceedings of Network and Distributed\r\nSystems Security (NDSS 2008).\r\n[28] HOFFMANN, J., AND KOEHLER, J. A new method to index and\r\nquery sets. In Proceedings of the Sixteenth International Joint\r\nConference on Artificial Intelligence (IJCAI 1999).\r\n[29] HOLZMANN, G. J. From code to models. In Proceedings of\r\n2nd International Conference on Applications of Concurrency to\r\nSystem Design (ACSD 2001).\r\n[30] HOLZMANN, G. J. The model checker SPIN. Software Engi\u0002neering 23, 5 (1997), 279–295.\r\n[31] KHURSHID, S., PASAREANU, C. S., AND VISSER, W. Gen\u0002eralized symbolic execution for model checking and testing. In\r\nProceedings of Tools and Algorithms for the Construction and\r\nAnalysis of Systems (TACAS 2003).\r\n[32] KROENING, D., CLARKE, E., AND YORAV, K. Behavioral con\u0002sistency of C and Verilog programs using bounded model check\u0002ing. In Proceedings of the 40th Design Automation Conference\r\n(DAC 2003).\r\n[33] LATTNER, C., AND ADVE, V. LLVM: A compilation framework\r\nfor lifelong program analysis & transformation. In Proceedings\r\nof the international symposium on Code generation and optimiza\u0002tion (CGO 2004).\r\n[34] MAJUMDAR, R., AND SEN, K. Hybrid concolic testing. In Pro\u0002ceedings of the 29th International Conference on Software Engi\u0002neering (ICSE 2007).\r\n[35] MILLER, B., KOSKI, D., LEE, C. P., MAGANTY, V., MURTHY,\r\nR., NATARAJAN, A., AND STEIDL, J. Fuzz revisited: A re\u0002examination of the reliability of UNIX utilities and services.\r\nTech. rep., University of Wisconsin - Madison, 1995.\r\n[36] SEN, K., MARINOV, D., AND AGHA, G. CUTE: A concolic\r\nunit testing engine for C. In In 5th joint meeting of the European\r\nSoftware Engineering Conference and ACM Symposium on the\r\nFoundations of Software Engineering (ESEC/FSE 2005).\r\n[37] VISSER, W., PASAREANU, C. S., AND KHURSHID, S. Test\r\ninput generation with Java PathFinder. In Proceedings of the\r\n2004 ACM SIGSOFT International Symposium on Software Test\u0002ing and Analysis (ISSTA 2004).\r\n[38] YANG, J., SAR, C., AND ENGLER, D. eXplode: a lightweight,\r\ngeneral system for finding serious storage system errors. In Pro\u0002ceedings of the 7th Symposium on Operating Systems Design and\r\nImplementation (OSDI 2006).\r\n[39] ZELDOVICH, N., BOYD-WICKIZER, S., KOHLER, E., AND\r\nMAZIERES ` , D. Making information flow explicit in HiStar. In\r\nProceedings of the 7th Symposium on Operating Systems Design\r\nand Implementation (OSDI 2006).\r\n16",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/f73b4a5f-b9a2-48e7-a1d8-ad3f7a147f86/images/aab00a4c-67c6-4815-ba34-ec541d24270c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041532Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=086edce37512c473ad3a086ae7dcec6f633af320fcede0bc174feb9131642903",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 939
      }
    ],
    "extracted_json": {
      "title": "Document Metadata",
      "schema_type": "object",
      "extracted_fields": [
        {
          "name": "title",
          "field_type": "string",
          "value": "No response"
        },
        {
          "name": "author",
          "field_type": "string",
          "value": "```json\n{\"author\": \"Cristian Cadar, Daniel Dunbar, Dawson Engler\"}\n```"
        },
        {
          "name": "date_published",
          "field_type": "string",
          "value": "No response"
        },
        {
          "name": "location",
          "field_type": "string",
          "value": "No response"
        }
      ]
    }
  }
}