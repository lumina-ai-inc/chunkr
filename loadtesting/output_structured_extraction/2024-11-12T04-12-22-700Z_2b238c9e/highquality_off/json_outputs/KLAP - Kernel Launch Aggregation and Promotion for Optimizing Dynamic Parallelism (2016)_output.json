{
  "file_name": "KLAP - Kernel Launch Aggregation and Promotion for Optimizing Dynamic Parallelism (2016).pdf",
  "task_id": "32ff25b9-c174-4ac1-8665-749a83230489",
  "output": {
    "chunks": [
      {
        "segments": [
          {
            "segment_id": "7f3907c0-f85d-415c-954d-936ffa3f6995",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 1,
            "page_width": 612,
            "page_height": 792,
            "content": "KLAP: Kernel Launch Aggregation and Promotion\r\nfor Optimizing Dynamic Parallelism\r\nIzzat El Hajj∗‡, Juan Gomez-Luna ´\r\n†\r\n, Cheng Li∗, Li-Wen Chang∗, Dejan Milojicic‡and Wen-mei Hwu∗\r\n∗University of Illinois at Urbana-Champaign\r\n†Universidad de Cordoba ´\r\n‡Hewlett-Packard Labs\r\nelhajj2@illinois.edu, el1goluj@uco.es, {cli99, lchang20}@illinois.edu, dejan.milojicic@hpe.com, w-hwu@illinois.edu\r\nAbstract—Dynamic parallelism on GPUs simplifies the pro\u0002gramming of many classes of applications that generate paral\u0002lelizable work not known prior to execution. However, modern\r\nGPUs architectures do not support dynamic parallelism effi\u0002ciently due to the high kernel launch overhead, limited number\r\nof simultaneous kernels, and limited depth of dynamic calls a\r\ndevice can support.\r\nIn this paper, we propose Kernel Launch Aggregation and\r\nPromotion (KLAP), a set of compiler techniques that improve the\r\nperformance of kernels which use dynamic parallelism. Kernel\r\nlaunch aggregation fuses kernels launched by threads in the same\r\nwarp, block, or kernel into a single aggregated kernel, thereby\r\nreducing the total number of kernels spawned and increasing\r\nthe amount of work per kernel to improve occupancy. Kernel\r\nlaunch promotion enables early launch of child kernels to extract\r\nmore parallelism between parents and children, and to aggregate\r\nkernel launches across generations mitigating the problem of\r\nlimited depth.\r\nWe implement our techniques in a real compiler and show that\r\nkernel launch aggregation obtains a geometric mean speedup of\r\n6.58× over regular dynamic parallelism. We also show that kernel\r\nlaunch promotion enables cases that were not originally possible,\r\nimproving throughput by a geometric mean of 30.44×.\r\nI. INTRODUCTION\r\nMany modern GPUs come with support for dynamic paral\u0002lelism. Dynamic parallelism [1], [2] is the ability of a kernel\r\nrunning on a GPU to spawn child kernels from the GPU\r\nwithout returning to the host. This feature makes it easier\r\nto program many classes of applications that dynamically\r\ngenerate variable amounts of parallel work not known prior to\r\nexecution. Such applications include graph traversal [3], mesh\r\nrefinement [4], and other kinds of algorithms. Dynamic par\u0002allelism also simplifies the programming of applications with\r\ncomplex inter-block dependence such as producer-consumer\r\nalgorithms [5].\r\nAlthough dynamic parallelism improves developer produc\u0002tivity and code maintainability [3], [6], [7], [8], current hard\u0002ware support for it can be very inefficient in practice. One\r\nlimitation of the current hardware in supporting dynamic paral\u0002lelism efficiently is the high overhead of launching subkernels\r\nfrom the device [6], [7]. Another limitation is that the number\r\nof kernels that can be in flight at a time is limited [6], [9].\r\nThe effect of both these limitations is exacerbated when many\r\nthreads of a parent kernel each launch a small child kernel. In\r\nthis case, the many subkernel launches will incur the launch\r\noverhead multiple times, and the small granularity of the\r\nkernels will result in low occupancy, underutilizing the GPU\r\nresources. Yet another limitation of dynamic parallelism is the\r\nbound on the depth of the call stack, which is problematic for\r\ncomputation patterns with high amounts of recursion and long\r\ndependence chains [6] such as producer-consumer algorithms.\r\nHardware and software approaches have been proposed\r\nfor improving the performance of code that uses dynamic\r\nparallelism on GPUs. Dynamic thread block launch [9] pro\u0002poses architectural changes that enable kernels to dynamically\r\nlaunch lightweight thread blocks. Free launch [10] is a soft\u0002ware approach that eliminates subkernel launches entirely by\r\nreusing parent threads on the GPU to perform the work of\r\nchild kernels.\r\nIn this paper, we propose Kernel Launch Aggregation and\r\nPromotion (KLAP), a set of compiler techniques that improve\r\nthe performance of kernels using dynamic parallelism on\r\nmodern GPUs. KLAP applies kernel launch aggregation to\r\nfuse kernels launched by threads in the same warp, block, or\r\nkernel together into a single launch. Aggregation thus reduces\r\nmany fine-grain kernels into fewer coarser-grain ones, thereby\r\nincurring fewer launches and allowing more work to be\r\nscheduled simultaneously for better occupancy. For producer\u0002consumer computation patterns, KLAP employs kernel launch\r\npromotion whereby kernels are launched by the parent prema\u0002turely. Promotion enables overlapping the independent part of\r\nthe child kernel with its parent and also aggregating kernel\r\nlaunches across multiple descendants which mitigates the\r\nproblem of limited depth.\r\nKLAP does not require any new architecture support and is\r\ntherefore compatible with current GPUs that support dynamic\r\nparallelism. Moreover, KLAP does not reuse parent threads\r\nnor does it eliminate dynamic kernel launches entirely, but\r\nrather uses the dynamic kernel launch capability in a more\r\nefficient manner. Leveraging the dynamic parallelism capabil\u0002ity affords KLAP more flexibility and generality than can be\r\nachieved by relying entirely on thread reuse which suffers the\r\nlimitations associated with persistent threads.\r\nWe make the following contributions:\r\n• We propose kernel launch aggregation, a novel com\u0002978-1-5090-3508-3/16/$31.00 \rc 2016 IEEE piler technique which improves performance of dynamic",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/7f3907c0-f85d-415c-954d-936ffa3f6995.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=32981ad411ce5f80d7c5d870120af4f55e8f78dc987a0945aedcee7d7f7c7453",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 767
      },
      {
        "segments": [
          {
            "segment_id": "7f3907c0-f85d-415c-954d-936ffa3f6995",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 1,
            "page_width": 612,
            "page_height": 792,
            "content": "KLAP: Kernel Launch Aggregation and Promotion\r\nfor Optimizing Dynamic Parallelism\r\nIzzat El Hajj∗‡, Juan Gomez-Luna ´\r\n†\r\n, Cheng Li∗, Li-Wen Chang∗, Dejan Milojicic‡and Wen-mei Hwu∗\r\n∗University of Illinois at Urbana-Champaign\r\n†Universidad de Cordoba ´\r\n‡Hewlett-Packard Labs\r\nelhajj2@illinois.edu, el1goluj@uco.es, {cli99, lchang20}@illinois.edu, dejan.milojicic@hpe.com, w-hwu@illinois.edu\r\nAbstract—Dynamic parallelism on GPUs simplifies the pro\u0002gramming of many classes of applications that generate paral\u0002lelizable work not known prior to execution. However, modern\r\nGPUs architectures do not support dynamic parallelism effi\u0002ciently due to the high kernel launch overhead, limited number\r\nof simultaneous kernels, and limited depth of dynamic calls a\r\ndevice can support.\r\nIn this paper, we propose Kernel Launch Aggregation and\r\nPromotion (KLAP), a set of compiler techniques that improve the\r\nperformance of kernels which use dynamic parallelism. Kernel\r\nlaunch aggregation fuses kernels launched by threads in the same\r\nwarp, block, or kernel into a single aggregated kernel, thereby\r\nreducing the total number of kernels spawned and increasing\r\nthe amount of work per kernel to improve occupancy. Kernel\r\nlaunch promotion enables early launch of child kernels to extract\r\nmore parallelism between parents and children, and to aggregate\r\nkernel launches across generations mitigating the problem of\r\nlimited depth.\r\nWe implement our techniques in a real compiler and show that\r\nkernel launch aggregation obtains a geometric mean speedup of\r\n6.58× over regular dynamic parallelism. We also show that kernel\r\nlaunch promotion enables cases that were not originally possible,\r\nimproving throughput by a geometric mean of 30.44×.\r\nI. INTRODUCTION\r\nMany modern GPUs come with support for dynamic paral\u0002lelism. Dynamic parallelism [1], [2] is the ability of a kernel\r\nrunning on a GPU to spawn child kernels from the GPU\r\nwithout returning to the host. This feature makes it easier\r\nto program many classes of applications that dynamically\r\ngenerate variable amounts of parallel work not known prior to\r\nexecution. Such applications include graph traversal [3], mesh\r\nrefinement [4], and other kinds of algorithms. Dynamic par\u0002allelism also simplifies the programming of applications with\r\ncomplex inter-block dependence such as producer-consumer\r\nalgorithms [5].\r\nAlthough dynamic parallelism improves developer produc\u0002tivity and code maintainability [3], [6], [7], [8], current hard\u0002ware support for it can be very inefficient in practice. One\r\nlimitation of the current hardware in supporting dynamic paral\u0002lelism efficiently is the high overhead of launching subkernels\r\nfrom the device [6], [7]. Another limitation is that the number\r\nof kernels that can be in flight at a time is limited [6], [9].\r\nThe effect of both these limitations is exacerbated when many\r\nthreads of a parent kernel each launch a small child kernel. In\r\nthis case, the many subkernel launches will incur the launch\r\noverhead multiple times, and the small granularity of the\r\nkernels will result in low occupancy, underutilizing the GPU\r\nresources. Yet another limitation of dynamic parallelism is the\r\nbound on the depth of the call stack, which is problematic for\r\ncomputation patterns with high amounts of recursion and long\r\ndependence chains [6] such as producer-consumer algorithms.\r\nHardware and software approaches have been proposed\r\nfor improving the performance of code that uses dynamic\r\nparallelism on GPUs. Dynamic thread block launch [9] pro\u0002poses architectural changes that enable kernels to dynamically\r\nlaunch lightweight thread blocks. Free launch [10] is a soft\u0002ware approach that eliminates subkernel launches entirely by\r\nreusing parent threads on the GPU to perform the work of\r\nchild kernels.\r\nIn this paper, we propose Kernel Launch Aggregation and\r\nPromotion (KLAP), a set of compiler techniques that improve\r\nthe performance of kernels using dynamic parallelism on\r\nmodern GPUs. KLAP applies kernel launch aggregation to\r\nfuse kernels launched by threads in the same warp, block, or\r\nkernel together into a single launch. Aggregation thus reduces\r\nmany fine-grain kernels into fewer coarser-grain ones, thereby\r\nincurring fewer launches and allowing more work to be\r\nscheduled simultaneously for better occupancy. For producer\u0002consumer computation patterns, KLAP employs kernel launch\r\npromotion whereby kernels are launched by the parent prema\u0002turely. Promotion enables overlapping the independent part of\r\nthe child kernel with its parent and also aggregating kernel\r\nlaunches across multiple descendants which mitigates the\r\nproblem of limited depth.\r\nKLAP does not require any new architecture support and is\r\ntherefore compatible with current GPUs that support dynamic\r\nparallelism. Moreover, KLAP does not reuse parent threads\r\nnor does it eliminate dynamic kernel launches entirely, but\r\nrather uses the dynamic kernel launch capability in a more\r\nefficient manner. Leveraging the dynamic parallelism capabil\u0002ity affords KLAP more flexibility and generality than can be\r\nachieved by relying entirely on thread reuse which suffers the\r\nlimitations associated with persistent threads.\r\nWe make the following contributions:\r\n• We propose kernel launch aggregation, a novel com\u0002978-1-5090-3508-3/16/$31.00 \rc 2016 IEEE piler technique which improves performance of dynamic",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/7f3907c0-f85d-415c-954d-936ffa3f6995.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=32981ad411ce5f80d7c5d870120af4f55e8f78dc987a0945aedcee7d7f7c7453",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 767
      },
      {
        "segments": [
          {
            "segment_id": "e8cb105f-72df-4dc1-86b2-dc954e31d9fb",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 2,
            "page_width": 612,
            "page_height": 792,
            "content": "Kernel\r\nBlock\r\nWarp\r\nThread\r\n(a) Original Kernel (b) Warp-Granularity Kernel Launch Aggregation\r\n(c) Block-Granularity Kernel Launch Aggregation (d) Kernel-Granularity Kernel Launch Aggregation\r\n--- terminate parent, launch child from host ---\r\nKernel Launch\r\nFig. 1. Kernel Launch Aggregation\r\nparallelism on GPUs by reducing the number of kernel\r\nlaunches and improving occupancy.\r\n• We propose kernel launch promotion, a compiler trans\u0002formation that enables work overlap and kernel launch\r\naggregation and mitigates the problem of limited depth\r\nfor producer-consumer computation patterns.\r\n• We implement our techniques in a real compiler and\r\nevaluate its performance on real hardware for multiple\r\nGPU architectures supporting dynamic parallelism.\r\n• We show that kernel launch aggregation obtains a geo\u0002metric mean speedup of 6.58× over regular dynamic par\u0002allelism, and that kernel launch promotion enables cases\r\nthat were not originally possible, improving throughput\r\nby a geometric mean of 30.44×.\r\nThe rest of this paper is organized as follows: Section II\r\ndescribes kernel launch aggregation, Section III describes\r\nkernel launch promotion, Section IV evaluates our techniques,\r\nSection V outlines related work, and Section VI concludes.\r\nII. KERNEL LAUNCH AGGREGATION\r\nKernel launch aggregation is a transformation whereby\r\nkernels that were originally launched by multiple threads are\r\naggregated into a single kernel which is launched once. The\r\ngranularity of aggregation is the scope of threads across which\r\nthe kernel launches are aggregated. For example, kernel launch\r\naggregation at warp granularity means that kernels launched\r\nby threads in the same warp are aggregated into a single kernel\r\nwhich is launched by one of the threads in that warp; on the\r\nother hand, kernels launched by threads in different warps\r\nremain separate.\r\nIn this paper, kernel launch aggregation is done at three\r\ndifferent granularities: warp, block, and kernel. Aggregation at\r\nwarp and block granularity is described in Section II-A while\r\naggregation at kernel granularity is described in Section II-B.\r\nA. Warp and Block Granularity\r\nFigure 1(b) illustrates the transformation that takes place\r\nwhen kernel launch aggregation at warp granularity is applied\r\nto the example in Figure 1(a). In this toy example, the first\r\nwarp in the parent kernel originally had two threads each\r\nlaunching a child kernel. In the transformed version, the\r\ntwo child kernels are aggregated into the same kernel which\r\nis launched by one of the two threads in the parent warp.\r\nThis transformation effectively reduces the number of kernel\r\nlaunches by up to a factor of the warp size.\r\nThe transformation at block granularity illustrated in Fig\u0002ure 1(c) is very similar. Here, only one thread per block\r\nlaunches a kernel on behalf of all the threads in the block.\r\nThus, the number of kernel launches is effectively reduced by\r\nup to a factor of the block size.\r\nThe code transformation to perform warp (or block) gran\u0002ularity aggregation is shown in Figure 2 and an example of\r\nwhat this code does is shown in Figure 3. Pseudocode is used\r\nand handling of corner cases is omitted for brevity and clarity.\r\nFor readers interested in specifics, detailed code is shown in\r\nFigure 12 at the end of the paper.\r\nFigure 2(c) shows how kernel calls inside kernel functions\r\nare transformed from that in Figure 2(a) to call an aggregated\r\nkernel. The first step in the transformed code is for the warp\r\n(or block) to allocate global arrays to store the arguments\r\nand configurations to be passed to the aggregated kernel (line\r\n05). These arrays are needed because different parent threads\r\nmay pass different arguments and configurations to their child\r\nkernels, therefore each thread must store its passed values in\r\nglobal arrays, and these arrays are passed to the aggregated\r\nchild instead. Next, each thread stores its arguments and\r\nconfigurations in the allocated arrays (lines 06-07). The sum of\r\nthe number of blocks in all the children is calculated as the new\r\nnumber of blocks in the aggregated kernel (line 08). Likewise,\r\nthe maximum number of threads per block in all the children\r\nis calculated as the new number of threads in the aggregated\r\nkernel (line 09) to make sure all blocks in the aggregated\r\nchild kernel have enough threads. Thus, our technique does\r\nnot assume that the number of blocks and threads in the\r\nlaunched kernels are known at compile time or that they are",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/e8cb105f-72df-4dc1-86b2-dc954e31d9fb.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=aae8fc894d0cf85be51672c0c30c0b06a303de058c7fe284c37b275105711978",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 701
      },
      {
        "segments": [
          {
            "segment_id": "e8cb105f-72df-4dc1-86b2-dc954e31d9fb",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 2,
            "page_width": 612,
            "page_height": 792,
            "content": "Kernel\r\nBlock\r\nWarp\r\nThread\r\n(a) Original Kernel (b) Warp-Granularity Kernel Launch Aggregation\r\n(c) Block-Granularity Kernel Launch Aggregation (d) Kernel-Granularity Kernel Launch Aggregation\r\n--- terminate parent, launch child from host ---\r\nKernel Launch\r\nFig. 1. Kernel Launch Aggregation\r\nparallelism on GPUs by reducing the number of kernel\r\nlaunches and improving occupancy.\r\n• We propose kernel launch promotion, a compiler trans\u0002formation that enables work overlap and kernel launch\r\naggregation and mitigates the problem of limited depth\r\nfor producer-consumer computation patterns.\r\n• We implement our techniques in a real compiler and\r\nevaluate its performance on real hardware for multiple\r\nGPU architectures supporting dynamic parallelism.\r\n• We show that kernel launch aggregation obtains a geo\u0002metric mean speedup of 6.58× over regular dynamic par\u0002allelism, and that kernel launch promotion enables cases\r\nthat were not originally possible, improving throughput\r\nby a geometric mean of 30.44×.\r\nThe rest of this paper is organized as follows: Section II\r\ndescribes kernel launch aggregation, Section III describes\r\nkernel launch promotion, Section IV evaluates our techniques,\r\nSection V outlines related work, and Section VI concludes.\r\nII. KERNEL LAUNCH AGGREGATION\r\nKernel launch aggregation is a transformation whereby\r\nkernels that were originally launched by multiple threads are\r\naggregated into a single kernel which is launched once. The\r\ngranularity of aggregation is the scope of threads across which\r\nthe kernel launches are aggregated. For example, kernel launch\r\naggregation at warp granularity means that kernels launched\r\nby threads in the same warp are aggregated into a single kernel\r\nwhich is launched by one of the threads in that warp; on the\r\nother hand, kernels launched by threads in different warps\r\nremain separate.\r\nIn this paper, kernel launch aggregation is done at three\r\ndifferent granularities: warp, block, and kernel. Aggregation at\r\nwarp and block granularity is described in Section II-A while\r\naggregation at kernel granularity is described in Section II-B.\r\nA. Warp and Block Granularity\r\nFigure 1(b) illustrates the transformation that takes place\r\nwhen kernel launch aggregation at warp granularity is applied\r\nto the example in Figure 1(a). In this toy example, the first\r\nwarp in the parent kernel originally had two threads each\r\nlaunching a child kernel. In the transformed version, the\r\ntwo child kernels are aggregated into the same kernel which\r\nis launched by one of the two threads in the parent warp.\r\nThis transformation effectively reduces the number of kernel\r\nlaunches by up to a factor of the warp size.\r\nThe transformation at block granularity illustrated in Fig\u0002ure 1(c) is very similar. Here, only one thread per block\r\nlaunches a kernel on behalf of all the threads in the block.\r\nThus, the number of kernel launches is effectively reduced by\r\nup to a factor of the block size.\r\nThe code transformation to perform warp (or block) gran\u0002ularity aggregation is shown in Figure 2 and an example of\r\nwhat this code does is shown in Figure 3. Pseudocode is used\r\nand handling of corner cases is omitted for brevity and clarity.\r\nFor readers interested in specifics, detailed code is shown in\r\nFigure 12 at the end of the paper.\r\nFigure 2(c) shows how kernel calls inside kernel functions\r\nare transformed from that in Figure 2(a) to call an aggregated\r\nkernel. The first step in the transformed code is for the warp\r\n(or block) to allocate global arrays to store the arguments\r\nand configurations to be passed to the aggregated kernel (line\r\n05). These arrays are needed because different parent threads\r\nmay pass different arguments and configurations to their child\r\nkernels, therefore each thread must store its passed values in\r\nglobal arrays, and these arrays are passed to the aggregated\r\nchild instead. Next, each thread stores its arguments and\r\nconfigurations in the allocated arrays (lines 06-07). The sum of\r\nthe number of blocks in all the children is calculated as the new\r\nnumber of blocks in the aggregated kernel (line 08). Likewise,\r\nthe maximum number of threads per block in all the children\r\nis calculated as the new number of threads in the aggregated\r\nkernel (line 09) to make sure all blocks in the aggregated\r\nchild kernel have enough threads. Thus, our technique does\r\nnot assume that the number of blocks and threads in the\r\nlaunched kernels are known at compile time or that they are",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/e8cb105f-72df-4dc1-86b2-dc954e31d9fb.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=aae8fc894d0cf85be51672c0c30c0b06a303de058c7fe284c37b275105711978",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 701
      },
      {
        "segments": [
          {
            "segment_id": "27c6911f-9bdb-41f3-890a-d6dd10131978",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 3,
            "page_width": 612,
            "page_height": 792,
            "content": "01 kernel<<<gD,bD>>>(args) \r\n(a) Original Kernel Call \r\n05 allocate arrays for args, gD, and bD\r\n06 store args in arg arrays \r\n07 store gD in gD array, and bD in bD array \r\n08 new gD = sum of gD array across warp/block \r\n09 new bD = max of bD array across warp/block \r\n10 if(threadIdx == launcher thread in warp/block) { \r\n11 kernel_agg<<<new gD,new bD>>> \r\n12 (arg arrays, gD array, bD array) \r\n13 } \r\n(c) Transformed Kernel Call (called in a kernel) \r\n02 __global__ void kernel(params) { \r\n03 kernel body \r\n04 } (b) Original Kernel \r\n(d) Transformed Kernel (called from a kernel) \r\n14 __global__ void kernel_agg(param arrays, gD array, bD array) { \r\n15 calculate index of parent thread\r\n16 load params from param arrays\r\n17 load actual gridDim/blockDim from gD/bD arrays\r\n18 calculate actual blockIdx\r\n19 if(threadIdx < actual blockDim) {\r\n20 kernel body (with kernel launches transformed and with \r\n21 using actual gridDim/blockDim/blockIdx) \r\n22 }\r\n23 } \r\nFig. 2. Code Generation for Aggregation at Warp and Block Granularity\r\n(a) Original Block\r\nparam=x\r\ngD=1\r\nbD=4\r\nparam=y\r\ngD=2\r\nbD=3\r\n(b) Block-Granularity Aggregation Logic Example\r\nparam_arr[]={x,-,y,-}\r\ngD_arr[]={1,0,2,0}\r\nbD_arr[]={4,0,3,0}\r\ngD=sum(gD_arr)=3\r\nbD=max(bD_arr)=4\r\ngD_scan={1,1,3,3}\r\ngD_scan[p-1] ≤ bI < gD_scan[p]\r\nparam=param_arr[p]\r\ngD’=gD_arr[p]\r\nbD’=bD_arr[p]\r\nbI’=bI-gDscan[p-1]\r\ngD : gridDim\r\nbD : blockDim\r\nbI : blockIdx\r\np : parent\r\n threadIdx\r\nbI=0\r\np=0\r\nparam=x\r\ngD’=1\r\nbD’=4\r\nbI’=0\r\nbI=1\r\np=2\r\nparam=y\r\ngD’=2\r\nbD’=3\r\nbI’=0\r\nbI=2\r\np=2\r\nparam=y\r\ngD’=2\r\nbD’=3\r\nbI’=1\r\nFig. 3. Aggregation Example\r\nuniform across parent threads. Finally, one of the threads in\r\nthe warp (or block) launches a single aggregated kernel on\r\nbehalf of the others (line 10). For block granularity, a barrier\r\nsynchronization is needed before the launch to ensure that\r\nall the threads in the block have completed their preparation\r\nof the arguments and configurations. In the aggregated kernel\r\nlaunch, the new configurations are used (line 11), arguments\r\nare replaced with argument arrays, and arrays containing the\r\nconfigurations for each original child are added (line 12).\r\nIn addition to transforming kernel launches in all original\r\nkernels, an aggregated version of each original kernel must\r\nalso be created. Figure 2(d) shows how the kernel in Fig\u0002ure 2(b) is transformed into an aggregated version. First, all\r\nparameters are converted into parameter (param) arrays and\r\nconfiguration arrays are appended to the parameter list (line\r\n14). Next, before the kernel body, logic is added for the\r\nblock to identify which thread in the parent warp (or block)\r\nwas its original parent (line 15). After identifying its original\r\nparent, the block is then able to load its actual configurations\r\nand parameters (lines 16-18). Threads that were not in the\r\noriginal child kernel are then masked out (line 19). Finally,\r\nin the kernel body, all kernel launches are transformed into\r\naggregated kernel launches, and all uses of blockDim and\r\nblockIdx are replaced with the actual values (lines 20-21).\r\nFor the block to identify its original parent, it needs to\r\nexecute a scan (prefix sum) on the gD (gridDim) array then\r\nsearch for its position (given by the aggregated blockIdx\r\nvalue) between the scanned values (using p-ary search [11]). In\r\npractice, since all child blocks need to scan the same gD array,\r\nthe scan is instead performed once by the parent before the\r\narray is passed to the aggregated child kernel. Conveniently,\r\nthe scan can be performed along with the preparation of the\r\nconfiguration and parameter arrays in the parent, making it\r\nincur little additional overhead. Since the child kernel needs\r\nboth the scan value and the original gD value, it can recover\r\nthe original gD value by subtracting adjacent scan elements.\r\nThe scan is performed using CUB [12].\r\nThe transformed code requires that all threads are active to\r\nperform the scan and max operations. To handle control di\u0002vergence, a preprocessing pass performs control-flow-to-data\u0002flow conversion to convert divergent launches to non-divergent\r\npredicated launches so that all threads reach the launch point.\r\nPredication is achieved by multiplying the predicate with the\r\ngrid dimension such that launches by inactive threads become\r\nlaunches of zero blocks.\r\nB. Kernel Granularity\r\nFigure 1(d) illustrates the transformation that takes place\r\nwhen kernel launch aggregation is applied at kernel granu\u0002larity. At this granularity, all the original child kernels are\r\naggregated into a single kernel. Because there is no global\r\nsynchronization on the GPU, a single thread cannot be chosen\r\nto launch the kernel on behalf of the others once the others are\r\nready. Instead, the child kernels are postponed and launched\r\nfrom the host after the parent kernel terminates. In order\r\nto postpone the kernel launches, this transformation requires\r\nthat parent kernels do not explicitly synchronize with their\r\nchild kernels, so kernels with explicit synchronization are not\r\nsupported at this granularity.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/27c6911f-9bdb-41f3-890a-d6dd10131978.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=340b345e9ea03bc83cf8fd4b5afabf1a38a8aefa8bcf874052515b4899d3081c",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 768
      },
      {
        "segments": [
          {
            "segment_id": "27c6911f-9bdb-41f3-890a-d6dd10131978",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 3,
            "page_width": 612,
            "page_height": 792,
            "content": "01 kernel<<<gD,bD>>>(args) \r\n(a) Original Kernel Call \r\n05 allocate arrays for args, gD, and bD\r\n06 store args in arg arrays \r\n07 store gD in gD array, and bD in bD array \r\n08 new gD = sum of gD array across warp/block \r\n09 new bD = max of bD array across warp/block \r\n10 if(threadIdx == launcher thread in warp/block) { \r\n11 kernel_agg<<<new gD,new bD>>> \r\n12 (arg arrays, gD array, bD array) \r\n13 } \r\n(c) Transformed Kernel Call (called in a kernel) \r\n02 __global__ void kernel(params) { \r\n03 kernel body \r\n04 } (b) Original Kernel \r\n(d) Transformed Kernel (called from a kernel) \r\n14 __global__ void kernel_agg(param arrays, gD array, bD array) { \r\n15 calculate index of parent thread\r\n16 load params from param arrays\r\n17 load actual gridDim/blockDim from gD/bD arrays\r\n18 calculate actual blockIdx\r\n19 if(threadIdx < actual blockDim) {\r\n20 kernel body (with kernel launches transformed and with \r\n21 using actual gridDim/blockDim/blockIdx) \r\n22 }\r\n23 } \r\nFig. 2. Code Generation for Aggregation at Warp and Block Granularity\r\n(a) Original Block\r\nparam=x\r\ngD=1\r\nbD=4\r\nparam=y\r\ngD=2\r\nbD=3\r\n(b) Block-Granularity Aggregation Logic Example\r\nparam_arr[]={x,-,y,-}\r\ngD_arr[]={1,0,2,0}\r\nbD_arr[]={4,0,3,0}\r\ngD=sum(gD_arr)=3\r\nbD=max(bD_arr)=4\r\ngD_scan={1,1,3,3}\r\ngD_scan[p-1] ≤ bI < gD_scan[p]\r\nparam=param_arr[p]\r\ngD’=gD_arr[p]\r\nbD’=bD_arr[p]\r\nbI’=bI-gDscan[p-1]\r\ngD : gridDim\r\nbD : blockDim\r\nbI : blockIdx\r\np : parent\r\n threadIdx\r\nbI=0\r\np=0\r\nparam=x\r\ngD’=1\r\nbD’=4\r\nbI’=0\r\nbI=1\r\np=2\r\nparam=y\r\ngD’=2\r\nbD’=3\r\nbI’=0\r\nbI=2\r\np=2\r\nparam=y\r\ngD’=2\r\nbD’=3\r\nbI’=1\r\nFig. 3. Aggregation Example\r\nuniform across parent threads. Finally, one of the threads in\r\nthe warp (or block) launches a single aggregated kernel on\r\nbehalf of the others (line 10). For block granularity, a barrier\r\nsynchronization is needed before the launch to ensure that\r\nall the threads in the block have completed their preparation\r\nof the arguments and configurations. In the aggregated kernel\r\nlaunch, the new configurations are used (line 11), arguments\r\nare replaced with argument arrays, and arrays containing the\r\nconfigurations for each original child are added (line 12).\r\nIn addition to transforming kernel launches in all original\r\nkernels, an aggregated version of each original kernel must\r\nalso be created. Figure 2(d) shows how the kernel in Fig\u0002ure 2(b) is transformed into an aggregated version. First, all\r\nparameters are converted into parameter (param) arrays and\r\nconfiguration arrays are appended to the parameter list (line\r\n14). Next, before the kernel body, logic is added for the\r\nblock to identify which thread in the parent warp (or block)\r\nwas its original parent (line 15). After identifying its original\r\nparent, the block is then able to load its actual configurations\r\nand parameters (lines 16-18). Threads that were not in the\r\noriginal child kernel are then masked out (line 19). Finally,\r\nin the kernel body, all kernel launches are transformed into\r\naggregated kernel launches, and all uses of blockDim and\r\nblockIdx are replaced with the actual values (lines 20-21).\r\nFor the block to identify its original parent, it needs to\r\nexecute a scan (prefix sum) on the gD (gridDim) array then\r\nsearch for its position (given by the aggregated blockIdx\r\nvalue) between the scanned values (using p-ary search [11]). In\r\npractice, since all child blocks need to scan the same gD array,\r\nthe scan is instead performed once by the parent before the\r\narray is passed to the aggregated child kernel. Conveniently,\r\nthe scan can be performed along with the preparation of the\r\nconfiguration and parameter arrays in the parent, making it\r\nincur little additional overhead. Since the child kernel needs\r\nboth the scan value and the original gD value, it can recover\r\nthe original gD value by subtracting adjacent scan elements.\r\nThe scan is performed using CUB [12].\r\nThe transformed code requires that all threads are active to\r\nperform the scan and max operations. To handle control di\u0002vergence, a preprocessing pass performs control-flow-to-data\u0002flow conversion to convert divergent launches to non-divergent\r\npredicated launches so that all threads reach the launch point.\r\nPredication is achieved by multiplying the predicate with the\r\ngrid dimension such that launches by inactive threads become\r\nlaunches of zero blocks.\r\nB. Kernel Granularity\r\nFigure 1(d) illustrates the transformation that takes place\r\nwhen kernel launch aggregation is applied at kernel granu\u0002larity. At this granularity, all the original child kernels are\r\naggregated into a single kernel. Because there is no global\r\nsynchronization on the GPU, a single thread cannot be chosen\r\nto launch the kernel on behalf of the others once the others are\r\nready. Instead, the child kernels are postponed and launched\r\nfrom the host after the parent kernel terminates. In order\r\nto postpone the kernel launches, this transformation requires\r\nthat parent kernels do not explicitly synchronize with their\r\nchild kernels, so kernels with explicit synchronization are not\r\nsupported at this granularity.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/27c6911f-9bdb-41f3-890a-d6dd10131978.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=340b345e9ea03bc83cf8fd4b5afabf1a38a8aefa8bcf874052515b4899d3081c",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 768
      },
      {
        "segments": [
          {
            "segment_id": "c842dca3-eb97-4509-a1eb-729d69ade58a",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 4,
            "page_width": 612,
            "page_height": 792,
            "content": "The code transformation for kernel granularity aggrega\u0002tion is omitted for brevity. Compared with warp and block\r\ngranularity aggregation, it has two main differences. The first\r\ndifference is that after the parent kernel has performed all the\r\nsetup operations for the aggregated child kernel call, the call\r\nwill not take place. Instead, the aggregated child will be called\r\nfrom the host function after the parent kernel has returned.\r\nThis effectively enforces a barrier synchronization among all\r\nparents in the grid before launching the aggregated kernel.\r\nThe second difference is in computing the aggregated kernel\r\nconfigurations. At the warp and block granularity, a regular\r\ntree-based scan is used. However, a tree-based scan at kernel\r\ngranularity has two limitations. First, it would require ad\u0002ditional kernels to be launched between the parent and the\r\nchild to perform the scan. Second, it will be inefficient due to\r\nthe potentially large number of zero values from threads that\r\ndon’t perform a launch (while these zeros exist at the other\r\ngranularities, their overhead is not as large). For this reason,\r\nwe employ a sequential out of order scan using atomicAdd\r\nwhich does not store zeros and can be performed in the parent\r\nkernel directly.\r\nOne challenge for kernel-granularity aggregation is when\r\nchild-kernel launches in the parent kernel are contained in\r\nloops. In this case, the number of launches of each child kernel\r\nmust be tracked and passed to the host so the host can launch\r\nthe right number of children after the parent kernel terminates.\r\nOur implementation currently does not support this case, but\r\nit is technically feasible and the subject of future work.\r\nC. Optimizations\r\nThis subsection discusses some optimizations that we per\u0002form to improve the efficiency of the generated code. One\r\nsource of inefficiency is performing dynamic memory alloca\u0002tions in the kernel. To avoid such allocations when creating\r\nglobal arrays for storing parameters and configurations, we\r\ninstead allocate a single global memory pool from the host\r\ncode and use atomic operations to grab memory from that\r\npool instead of calling cudaMalloc in the kernel.\r\nA related optimization is aggregating calls to cudaMalloc\r\nthat were part of the original code. At warp (or block)\r\ngranularity, we transform calls to cudaMalloc by each\r\nthread in the warp (or block) into code that: (1) sums up the\r\ntotal allocated memory by the warp (or block), (2) uses one\r\nthread in the warp (or block) to allocate that total memory\r\non behalf of the others, then (3) redistributes the allocated\r\nmemory to all threads. At kernel granularity, cudaMalloc\r\ncannot be aggregated because it is a blocking call. In this case,\r\nwe aggregate cudaMalloc at block-granularity instead.\r\nAnother optimization is avoiding the overhead of creating\r\narrays for arguments that are uniform across the granularity\r\nof aggregation. For example, if we are performing block\u0002granularity aggregation, and the compiler can prove that an\r\nargument has the same value for all threads in the block [13],\r\n[14], then an array does not need to be created for that argu\u0002ment. Instead the argument is passed as is to the aggregated\r\nchild kernel as a single value.\r\nAggregation Granularity\r\nNo-agg W-agg B-agg K-agg\r\n+ fewer launches\r\n+ coarser kernels\r\n+ work is available sooner\r\n+ less aggregation overhead\r\nFig. 4. Aggregation Granularity Tradeoffs\r\nD. Tradeoffs\r\nThere are various advantages and disadvantages of increas\u0002ing the granularity of aggregation as shown in Figure 4. With\r\ncoarser-grain aggregation, there are fewer kernel launches and\r\nmore work per kernel. Therefore, the kernel launch overhead\r\nis amortized over a larger amount of work and resources are\r\nbetter utilized. On the other hand, with finer-grain aggregation,\r\nthreads launching aggregated kernels have to wait for fewer\r\nthreads before performing the launch, making work from\r\nthe aggregated kernel available sooner to utilize the GPU.\r\nMoreover, with finer-grain aggregation, there is less overhead\r\nfrom the aggregation logic because the scan operation to\r\ncompute launch configurations are on a smaller scale, and the\r\nconfiguration arrays to be searched to identify parent threads\r\nare also smaller.\r\nIII. KERNEL LAUNCH PROMOTION\r\nKernel launch promotion applies to a common class of\r\nproducer-consumer algorithms whereby each kernel contains\r\na single block and calls itself recursively as shown in Fig\u0002ure 5(a). This class of algorithms is common in applications\r\nhaving complex inter-block dependence [5], [15].\r\nImplementing these patterns using dynamic parallelism\r\ngreatly simplifies the expression of inter-block dependence,\r\nbut has several limitations. These limitations are: (1) many\r\nfine-grain kernel launches, (2) a deep kernel call stack, and\r\n(3) a long serial dependence chain of single-block kernels. To\r\naddress these problems, this section proposes kernel launch\r\npromotion.\r\nKernel launch promotion is a transformation whereby kernel\r\ncalls are promoted to the beginning of a kernel to launch child\r\nkernels prematurely. Ordering between parent and child is then\r\nenforced via release-acquire synchronization. Promotion also\r\nenables two mutually orthogonal optimizations: aggregation\r\nand overlap. The benefit of aggregation is that it reduces the\r\nnumber of kernels and increases their granularity, as well as\r\nreduces the depth of the kernel call stack. The benefit of\r\noverlap is that it extracts more parallelism from the long serial\r\ndependence chain. These benefits are summarized in Figure 6.\r\nThe following subsections detail basic promotion (Sec\u0002tion III-A) and promotion with aggregation (Section III-B),\r\noverlap (Section III-C), and both together (Section III-D).\r\nA. Basic Promotion\r\nBasic promotion is the transformation where kernel calls are\r\nhoisted to the beginning of the kernel. Figure 5(b) illustrates\r\nthe transformation that takes place when basic promotion is",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/c842dca3-eb97-4509-a1eb-729d69ade58a.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=1fae7ccc46add1b48721f7c7dfde31c75a666d10cf8b8dee73399ae0d98f343c",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 902
      },
      {
        "segments": [
          {
            "segment_id": "c842dca3-eb97-4509-a1eb-729d69ade58a",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 4,
            "page_width": 612,
            "page_height": 792,
            "content": "The code transformation for kernel granularity aggrega\u0002tion is omitted for brevity. Compared with warp and block\r\ngranularity aggregation, it has two main differences. The first\r\ndifference is that after the parent kernel has performed all the\r\nsetup operations for the aggregated child kernel call, the call\r\nwill not take place. Instead, the aggregated child will be called\r\nfrom the host function after the parent kernel has returned.\r\nThis effectively enforces a barrier synchronization among all\r\nparents in the grid before launching the aggregated kernel.\r\nThe second difference is in computing the aggregated kernel\r\nconfigurations. At the warp and block granularity, a regular\r\ntree-based scan is used. However, a tree-based scan at kernel\r\ngranularity has two limitations. First, it would require ad\u0002ditional kernels to be launched between the parent and the\r\nchild to perform the scan. Second, it will be inefficient due to\r\nthe potentially large number of zero values from threads that\r\ndon’t perform a launch (while these zeros exist at the other\r\ngranularities, their overhead is not as large). For this reason,\r\nwe employ a sequential out of order scan using atomicAdd\r\nwhich does not store zeros and can be performed in the parent\r\nkernel directly.\r\nOne challenge for kernel-granularity aggregation is when\r\nchild-kernel launches in the parent kernel are contained in\r\nloops. In this case, the number of launches of each child kernel\r\nmust be tracked and passed to the host so the host can launch\r\nthe right number of children after the parent kernel terminates.\r\nOur implementation currently does not support this case, but\r\nit is technically feasible and the subject of future work.\r\nC. Optimizations\r\nThis subsection discusses some optimizations that we per\u0002form to improve the efficiency of the generated code. One\r\nsource of inefficiency is performing dynamic memory alloca\u0002tions in the kernel. To avoid such allocations when creating\r\nglobal arrays for storing parameters and configurations, we\r\ninstead allocate a single global memory pool from the host\r\ncode and use atomic operations to grab memory from that\r\npool instead of calling cudaMalloc in the kernel.\r\nA related optimization is aggregating calls to cudaMalloc\r\nthat were part of the original code. At warp (or block)\r\ngranularity, we transform calls to cudaMalloc by each\r\nthread in the warp (or block) into code that: (1) sums up the\r\ntotal allocated memory by the warp (or block), (2) uses one\r\nthread in the warp (or block) to allocate that total memory\r\non behalf of the others, then (3) redistributes the allocated\r\nmemory to all threads. At kernel granularity, cudaMalloc\r\ncannot be aggregated because it is a blocking call. In this case,\r\nwe aggregate cudaMalloc at block-granularity instead.\r\nAnother optimization is avoiding the overhead of creating\r\narrays for arguments that are uniform across the granularity\r\nof aggregation. For example, if we are performing block\u0002granularity aggregation, and the compiler can prove that an\r\nargument has the same value for all threads in the block [13],\r\n[14], then an array does not need to be created for that argu\u0002ment. Instead the argument is passed as is to the aggregated\r\nchild kernel as a single value.\r\nAggregation Granularity\r\nNo-agg W-agg B-agg K-agg\r\n+ fewer launches\r\n+ coarser kernels\r\n+ work is available sooner\r\n+ less aggregation overhead\r\nFig. 4. Aggregation Granularity Tradeoffs\r\nD. Tradeoffs\r\nThere are various advantages and disadvantages of increas\u0002ing the granularity of aggregation as shown in Figure 4. With\r\ncoarser-grain aggregation, there are fewer kernel launches and\r\nmore work per kernel. Therefore, the kernel launch overhead\r\nis amortized over a larger amount of work and resources are\r\nbetter utilized. On the other hand, with finer-grain aggregation,\r\nthreads launching aggregated kernels have to wait for fewer\r\nthreads before performing the launch, making work from\r\nthe aggregated kernel available sooner to utilize the GPU.\r\nMoreover, with finer-grain aggregation, there is less overhead\r\nfrom the aggregation logic because the scan operation to\r\ncompute launch configurations are on a smaller scale, and the\r\nconfiguration arrays to be searched to identify parent threads\r\nare also smaller.\r\nIII. KERNEL LAUNCH PROMOTION\r\nKernel launch promotion applies to a common class of\r\nproducer-consumer algorithms whereby each kernel contains\r\na single block and calls itself recursively as shown in Fig\u0002ure 5(a). This class of algorithms is common in applications\r\nhaving complex inter-block dependence [5], [15].\r\nImplementing these patterns using dynamic parallelism\r\ngreatly simplifies the expression of inter-block dependence,\r\nbut has several limitations. These limitations are: (1) many\r\nfine-grain kernel launches, (2) a deep kernel call stack, and\r\n(3) a long serial dependence chain of single-block kernels. To\r\naddress these problems, this section proposes kernel launch\r\npromotion.\r\nKernel launch promotion is a transformation whereby kernel\r\ncalls are promoted to the beginning of a kernel to launch child\r\nkernels prematurely. Ordering between parent and child is then\r\nenforced via release-acquire synchronization. Promotion also\r\nenables two mutually orthogonal optimizations: aggregation\r\nand overlap. The benefit of aggregation is that it reduces the\r\nnumber of kernels and increases their granularity, as well as\r\nreduces the depth of the kernel call stack. The benefit of\r\noverlap is that it extracts more parallelism from the long serial\r\ndependence chain. These benefits are summarized in Figure 6.\r\nThe following subsections detail basic promotion (Sec\u0002tion III-A) and promotion with aggregation (Section III-B),\r\noverlap (Section III-C), and both together (Section III-D).\r\nA. Basic Promotion\r\nBasic promotion is the transformation where kernel calls are\r\nhoisted to the beginning of the kernel. Figure 5(b) illustrates\r\nthe transformation that takes place when basic promotion is",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/c842dca3-eb97-4509-a1eb-729d69ade58a.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=1fae7ccc46add1b48721f7c7dfde31c75a666d10cf8b8dee73399ae0d98f343c",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 902
      },
      {
        "segments": [
          {
            "segment_id": "ac26d806-81ec-4fd4-8fe6-9a011dcc06cf",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 5,
            "page_width": 612,
            "page_height": 792,
            "content": "(a) Original Kernel (c) Promotion with\r\n Aggregation (PA)\r\n(e) Promotion with Aggregation \r\n& Overlap (PAO)\r\n(d) Promotion with\r\n Overlap (PO)\r\n…\r\nE2\r\nP2\r\nL\r\nE1\r\nP1\r\nL\r\nE0\r\nP0\r\nL\r\n…\r\nE2\r\nP2\r\nR\r\nE1\r\nP1\r\nR\r\nE0\r\nP0\r\nR\r\nL …\r\nA\r\nA\r\nL\r\nPd,0\r\nPi,0\r\nR\r\nE0\r\nPi,1\r\nPi,2\r\nA\r\nA\r\nPd,1\r\nR\r\nE1\r\n…\r\nPd,2\r\nR\r\nE2\r\n… R\r\nA,R …\r\nA,R\r\n…\r\nE2\r\nP2\r\nR\r\nE1\r\nP1\r\nR\r\nE0\r\nP0\r\nR\r\nL\r\nA\r\nA\r\n…\r\nL\r\nL\r\n(b) Promotion (P)\r\nP = Prologue\r\nL = Launch\r\nE = Epilogue\r\nR = Release\r\nA = Acquire\r\nPi = Prologue \r\nindependent \r\nportion\r\nPd = Prologue \r\ndependent \r\nportion\r\nPi,0\r\nPd,0\r\nR\r\nE0\r\nPi,1\r\nPi,2 A\r\nA\r\nPd,1\r\nR\r\nE1\r\n…\r\nPd,2\r\nR\r\nE2\r\nL\r\n…\r\nL\r\nL\r\nFig. 5. Kernel Launch Promotion\r\nOverlap\r\nNo Yes\r\nAggregation\r\nNo\r\nP PO\r\nYes\r\nPA PAO\r\n+ less aggregation overhead\r\n+ fewer launches\r\n+ coarser kernels\r\n+ more depth\r\n+ more parallelism\r\nFig. 6. Tradeoffs of Optimizations Enabled by Promotion\r\napplied to the example shown in Figure 5(a). In the original\r\nkernel, the kernel call divides the kernel into two different sec\u0002tions called the prologue and the epilogue. In the transformed\r\ncode, the kernel call is moved to the beginning of the kernel\r\nbefore the prologue. In place of the original kernel call, logic\r\nis inserted to release a flag that the child will acquire to know\r\nwhen to execute. In all but the first kernel instance (which\r\nis launched from the host), logic is also inserted before the\r\nprologue to acquire the release from the parent.\r\nThe code transformation to perform basic promotion is\r\nshown in Figure 7. Pseudocode is used and handling of corner\r\ncases is omitted for brevity and clarity. Figure 7(b) shows the\r\ntransformation of the kernel in Figure 7(a) for the first kernel\r\ninstance which is launched from the host. In the transforma\u0002tion, a distinction is made between the arguments which are\r\navailable at the beginning of the kernel and arguments that are\r\nnot available and need to be postponed. For the arguments that\r\nare not available, the launcher thread allocates buffers (line 10)\r\nand passes them to the child where the arguments will later be\r\nstored. A flag is also allocated for the parent to communicate\r\nwith the child to release it (line 11). The child is then launched\r\nprematurely (lines 12-13).\r\nAfter the prologue, the launcher thread stores the postponed\r\narguments in the buffers (line 17) and executes a memory fence\r\n(line 18) to make sure all data is visible to the child before it\r\nis released. The launcher thread then sets the flag to release\r\nthe child (line 19). In this paper, release is implemented in\r\nCUDA as a non-cached store while acquire is implemented as\r\na polling loop with a volatile load. In OpenCL 2.0 [16], the\r\nbuilt in support for release and acquire can also be used.\r\nFigure 7(c) shows the transformation of the kernel in Fig\u0002ure 7(a) for the remaining kernel instances which are launched\r\nby device kernels. There are two main differences between\r\nthis code and that of the first instance in Figure 7(b). The\r\nfirst difference is that instead of values for the postponed\r\nparameters being passed to the kernel, parameter buffers are\r\npassed as well as the flag (line 24). The second difference is\r\nthat before the prologue, code is inserted to acquire the flag\r\nthen load the postponed parameter values from the buffers\r\n(lines 31-32).\r\nThe transformation described requires the launch condition\r\n(not shown in the figure) to be promotable with the kernel\r\nlaunch. In cases where the condition is dependent on the\r\nprologue, launches can be performed speculatively and an\r\nabort flag can be used to abort the trailing launches.\r\nB. Promotion with Aggregation\r\nFigure 5(c) illustrates the transformation that takes place\r\nwhen aggregation is applied to the promoted kernel launch. In\r\nthis transformation, instead of each parent launching its direct\r\nchild as with basic promotion, a parent launches a large pool of\r\ndescendants and creates parameter buffers and flags for each of\r\nthese descendants. The size of this pool defines the granularity\r\nof aggregation. The descendants communicate via the flags to\r\nrelease each other one after the other. The block index within\r\nthe pool of descendants is acquired dynamically [17], thus\r\navoiding deadlock situations where child blocks get scheduled\r\nbefore their parents and starve them. If the pool of descendants\r\nis exhausted, the last descendant in the pool launches a new\r\npool. When the final descendant is reached, it sets a bit in the\r\nflag for the remaining unused blocks in the pool to abort.\r\nWe note that aggregation in this context is different from\r\nthe aggregation described in Section II. The aggregation in",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/ac26d806-81ec-4fd4-8fe6-9a011dcc06cf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a349de360107155dac3c819c853e49a794c32fc44b66fb24a43071a80909dbcd",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 788
      },
      {
        "segments": [
          {
            "segment_id": "ac26d806-81ec-4fd4-8fe6-9a011dcc06cf",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 5,
            "page_width": 612,
            "page_height": 792,
            "content": "(a) Original Kernel (c) Promotion with\r\n Aggregation (PA)\r\n(e) Promotion with Aggregation \r\n& Overlap (PAO)\r\n(d) Promotion with\r\n Overlap (PO)\r\n…\r\nE2\r\nP2\r\nL\r\nE1\r\nP1\r\nL\r\nE0\r\nP0\r\nL\r\n…\r\nE2\r\nP2\r\nR\r\nE1\r\nP1\r\nR\r\nE0\r\nP0\r\nR\r\nL …\r\nA\r\nA\r\nL\r\nPd,0\r\nPi,0\r\nR\r\nE0\r\nPi,1\r\nPi,2\r\nA\r\nA\r\nPd,1\r\nR\r\nE1\r\n…\r\nPd,2\r\nR\r\nE2\r\n… R\r\nA,R …\r\nA,R\r\n…\r\nE2\r\nP2\r\nR\r\nE1\r\nP1\r\nR\r\nE0\r\nP0\r\nR\r\nL\r\nA\r\nA\r\n…\r\nL\r\nL\r\n(b) Promotion (P)\r\nP = Prologue\r\nL = Launch\r\nE = Epilogue\r\nR = Release\r\nA = Acquire\r\nPi = Prologue \r\nindependent \r\nportion\r\nPd = Prologue \r\ndependent \r\nportion\r\nPi,0\r\nPd,0\r\nR\r\nE0\r\nPi,1\r\nPi,2 A\r\nA\r\nPd,1\r\nR\r\nE1\r\n…\r\nPd,2\r\nR\r\nE2\r\nL\r\n…\r\nL\r\nL\r\nFig. 5. Kernel Launch Promotion\r\nOverlap\r\nNo Yes\r\nAggregation\r\nNo\r\nP PO\r\nYes\r\nPA PAO\r\n+ less aggregation overhead\r\n+ fewer launches\r\n+ coarser kernels\r\n+ more depth\r\n+ more parallelism\r\nFig. 6. Tradeoffs of Optimizations Enabled by Promotion\r\napplied to the example shown in Figure 5(a). In the original\r\nkernel, the kernel call divides the kernel into two different sec\u0002tions called the prologue and the epilogue. In the transformed\r\ncode, the kernel call is moved to the beginning of the kernel\r\nbefore the prologue. In place of the original kernel call, logic\r\nis inserted to release a flag that the child will acquire to know\r\nwhen to execute. In all but the first kernel instance (which\r\nis launched from the host), logic is also inserted before the\r\nprologue to acquire the release from the parent.\r\nThe code transformation to perform basic promotion is\r\nshown in Figure 7. Pseudocode is used and handling of corner\r\ncases is omitted for brevity and clarity. Figure 7(b) shows the\r\ntransformation of the kernel in Figure 7(a) for the first kernel\r\ninstance which is launched from the host. In the transforma\u0002tion, a distinction is made between the arguments which are\r\navailable at the beginning of the kernel and arguments that are\r\nnot available and need to be postponed. For the arguments that\r\nare not available, the launcher thread allocates buffers (line 10)\r\nand passes them to the child where the arguments will later be\r\nstored. A flag is also allocated for the parent to communicate\r\nwith the child to release it (line 11). The child is then launched\r\nprematurely (lines 12-13).\r\nAfter the prologue, the launcher thread stores the postponed\r\narguments in the buffers (line 17) and executes a memory fence\r\n(line 18) to make sure all data is visible to the child before it\r\nis released. The launcher thread then sets the flag to release\r\nthe child (line 19). In this paper, release is implemented in\r\nCUDA as a non-cached store while acquire is implemented as\r\na polling loop with a volatile load. In OpenCL 2.0 [16], the\r\nbuilt in support for release and acquire can also be used.\r\nFigure 7(c) shows the transformation of the kernel in Fig\u0002ure 7(a) for the remaining kernel instances which are launched\r\nby device kernels. There are two main differences between\r\nthis code and that of the first instance in Figure 7(b). The\r\nfirst difference is that instead of values for the postponed\r\nparameters being passed to the kernel, parameter buffers are\r\npassed as well as the flag (line 24). The second difference is\r\nthat before the prologue, code is inserted to acquire the flag\r\nthen load the postponed parameter values from the buffers\r\n(lines 31-32).\r\nThe transformation described requires the launch condition\r\n(not shown in the figure) to be promotable with the kernel\r\nlaunch. In cases where the condition is dependent on the\r\nprologue, launches can be performed speculatively and an\r\nabort flag can be used to abort the trailing launches.\r\nB. Promotion with Aggregation\r\nFigure 5(c) illustrates the transformation that takes place\r\nwhen aggregation is applied to the promoted kernel launch. In\r\nthis transformation, instead of each parent launching its direct\r\nchild as with basic promotion, a parent launches a large pool of\r\ndescendants and creates parameter buffers and flags for each of\r\nthese descendants. The size of this pool defines the granularity\r\nof aggregation. The descendants communicate via the flags to\r\nrelease each other one after the other. The block index within\r\nthe pool of descendants is acquired dynamically [17], thus\r\navoiding deadlock situations where child blocks get scheduled\r\nbefore their parents and starve them. If the pool of descendants\r\nis exhausted, the last descendant in the pool launches a new\r\npool. When the final descendant is reached, it sets a bit in the\r\nflag for the remaining unused blocks in the pool to abort.\r\nWe note that aggregation in this context is different from\r\nthe aggregation described in Section II. The aggregation in",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/ac26d806-81ec-4fd4-8fe6-9a011dcc06cf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a349de360107155dac3c819c853e49a794c32fc44b66fb24a43071a80909dbcd",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 788
      },
      {
        "segments": [
          {
            "segment_id": "334862a8-77fd-47db-9fdd-eb7950d02a53",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 6,
            "page_width": 612,
            "page_height": 792,
            "content": "01 __global__ void kernel(paramsavail, paramspost) { \r\n02 prologue \r\n03 if(launcher thread) { \r\n04 kernel<<<1,nThreads>>>(argsavail, argspost) \r\n05 } \r\n06 epilogue\r\n07 } \r\n08 __global__ void kernel(paramsavail, paramspost) { \r\n09 if(launcher thread) { \r\n10 allocate postponed arg buffers\r\n11 allocate child flag\r\n12 kernel_from_kernel<<<1,nThreads>>> \r\n13 (argsavail, postponed arg buffers, child flag) \r\n14 } \r\n15 prologue \r\n16 if(launcher thread) { \r\n17 store argspost in postponed arg buffers\r\n18 memory fence \r\n19 set child flag to release child\r\n20 } \r\n21 epilogue\r\n22 } \r\nargsavail : arguments available at the beginning of the kernel\r\nargspost : arguments whose values are “postponed” because they are not \r\n available at the beginning of the kernel\r\nparamsavail : parameters corresponding to available arguments \r\nparamspost : parameters corresponding to postponed arguments \r\n23 __global__ void kernel_from_kernel(paramsavail, \r\n24 postponed param buffers, flag) { \r\n25 if(launcher thread) { \r\n26 allocate postponed arg buffers\r\n27 allocate child flag\r\n28 kernel_from_kernel<<<1,nThreads>>> \r\n29 (argsavail, postponed arg buffers, child flag) \r\n30 } \r\n31 wait to acquire flag\r\n32 load paramspost from postponed param buffers\r\n33 prologue \r\n34 if(launcher thread) { \r\n35 store argspost in postponed arg buffers \r\n36 memory fence\r\n37 set flag to release child\r\n38 } \r\n39 epilogue\r\n40 } \r\nFig. 7. Code Generation for Basic Promotion\r\nSection II is horizontal, meaning that it aggregates kernel\r\nlaunches by threads in the same kernel at the same level of\r\ndepth in the call stack. On the other hand, aggregation in this\r\ncontext is vertical, meaning that it aggregates kernel launches\r\nacross multiple levels of depth in the call stack.\r\nThe benefits of promotion with aggregation are twofold.\r\nFirst, the number of kernel calls is reduced and their granu\u0002larity is increased which results in better amortization of the\r\nlaunch overhead and better utilization of the device. Second,\r\nthe architectural limitation of the depth of descent is mitigated\r\nbecause vertical aggregation divides the depth of the kernel\r\ncall stack by a factor equal to the aggregation granularity (size\r\nof the pool in the aggregated kernel).\r\nC. Promotion with Overlap\r\nPromotion with overlap is based on the observation that\r\nportions of the prologue of a child kernel can be executed\r\nindependently from the parent. Informally, this independent\r\nportion must satisfy two conditions: (1) it must not use any\r\npostponed parameters and (2) it must not have any data\r\ndependence with the prologue of the parent. If these two\r\nconditions are met, then this portion of the prologue can be\r\nexecuted in parallel with the parent before it releases the child.\r\nFigure 5(d) illustrates the transformation that takes place\r\nwhen overlap is applied with promotion. In this transformation,\r\nthe prologue is divided into two regions – the independent\r\nregion (Pi) and dependent region (Pd) – and the independent\r\nregion is hoisted before the acquire logic. Here, Pi and Pd\r\nmust satisfy the conditions that Pi,x and Pd,x do not write\r\nto any memory referenced by Pi,y where x < y, and Pi,y\r\ndoes not write to any memory referenced by Pi,x and Pd,x\r\nwhere x < y. In this paper, a simple programmer annotation\r\nis used to indicate the boundary between Pi and Pd. However,\r\ndataflow analysis can also be used to detect these regions and\r\nis the subject of future work.\r\nD. Promotion with Aggregation and Overlap\r\nFigure 5(e) illustrates the transformation that takes place\r\nwhen both aggregation and overlap are applied with promo\u0002tion. The two optimizations are orthogonal and interoperate\r\nnicely without much added complexity. The most noteworthy\r\ndifference is that the transformed kernel now has two release\u0002acquire chains. The first chain enforces the launch condition,\r\nthus ensuring that only the thread blocks that are supposed to\r\nexecute do, while the trailing ones abort. The second chain\r\nenforces the dependence between parents and children.\r\nIV. EVALUATION\r\nA. Methodology and Implementation Details\r\nWe implement our compiler in Clang version 3.8.0 as a\r\nsource-to-source (CUDA-to-CUDA) translator. Although this\r\nversion does not compile code that uses dynamic parallelism to\r\nLLVM IR, we modify the semantic checker to accept kernel\r\ncalls inside kernel functions to enable the source-to-source\r\ntransformation to take place.\r\nThe benchmarks and datasets used in the evaluation are\r\nshown in Table I. Aggregation and promotion are evaluated\r\non different benchmarks because they target different patterns.\r\nFor the aggregation benchmarks, a few (bt, ccl, qt) employ\r\nCUDA Dynamic Parallelism (CDP) originally, while the rest\r\nwere ported to use CDP from original codes with intra\u0002thread nested loops. For example, in bfs, the loop over the\r\nedges of a node is converted to a kernel launch with one\r\nthread processing each edge. For the promotion benchmarks,\r\nwe chose algorithms which require communication between\r\nadjacent thread blocks, and implemented them using CDP.\r\nEach promotion benchmark is tested on three datasets: small\r\nwhich is selected to create 2 recurrences, medium which is\r\nselected to create 25 recurrences (the maximum CDP can\r\nhandle), and large which is the maximum problem size the\r\ndevice can handle or the maximum recurrence that aggregation\r\nat granularity 128 can handle (whichever maxes out first).",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/334862a8-77fd-47db-9fdd-eb7950d02a53.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=bac25e21320beaaf3e4bb3720aa92706b360e4055ae26e22bf0d3c8df7ecafc8",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 826
      },
      {
        "segments": [
          {
            "segment_id": "334862a8-77fd-47db-9fdd-eb7950d02a53",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 6,
            "page_width": 612,
            "page_height": 792,
            "content": "01 __global__ void kernel(paramsavail, paramspost) { \r\n02 prologue \r\n03 if(launcher thread) { \r\n04 kernel<<<1,nThreads>>>(argsavail, argspost) \r\n05 } \r\n06 epilogue\r\n07 } \r\n08 __global__ void kernel(paramsavail, paramspost) { \r\n09 if(launcher thread) { \r\n10 allocate postponed arg buffers\r\n11 allocate child flag\r\n12 kernel_from_kernel<<<1,nThreads>>> \r\n13 (argsavail, postponed arg buffers, child flag) \r\n14 } \r\n15 prologue \r\n16 if(launcher thread) { \r\n17 store argspost in postponed arg buffers\r\n18 memory fence \r\n19 set child flag to release child\r\n20 } \r\n21 epilogue\r\n22 } \r\nargsavail : arguments available at the beginning of the kernel\r\nargspost : arguments whose values are “postponed” because they are not \r\n available at the beginning of the kernel\r\nparamsavail : parameters corresponding to available arguments \r\nparamspost : parameters corresponding to postponed arguments \r\n23 __global__ void kernel_from_kernel(paramsavail, \r\n24 postponed param buffers, flag) { \r\n25 if(launcher thread) { \r\n26 allocate postponed arg buffers\r\n27 allocate child flag\r\n28 kernel_from_kernel<<<1,nThreads>>> \r\n29 (argsavail, postponed arg buffers, child flag) \r\n30 } \r\n31 wait to acquire flag\r\n32 load paramspost from postponed param buffers\r\n33 prologue \r\n34 if(launcher thread) { \r\n35 store argspost in postponed arg buffers \r\n36 memory fence\r\n37 set flag to release child\r\n38 } \r\n39 epilogue\r\n40 } \r\nFig. 7. Code Generation for Basic Promotion\r\nSection II is horizontal, meaning that it aggregates kernel\r\nlaunches by threads in the same kernel at the same level of\r\ndepth in the call stack. On the other hand, aggregation in this\r\ncontext is vertical, meaning that it aggregates kernel launches\r\nacross multiple levels of depth in the call stack.\r\nThe benefits of promotion with aggregation are twofold.\r\nFirst, the number of kernel calls is reduced and their granu\u0002larity is increased which results in better amortization of the\r\nlaunch overhead and better utilization of the device. Second,\r\nthe architectural limitation of the depth of descent is mitigated\r\nbecause vertical aggregation divides the depth of the kernel\r\ncall stack by a factor equal to the aggregation granularity (size\r\nof the pool in the aggregated kernel).\r\nC. Promotion with Overlap\r\nPromotion with overlap is based on the observation that\r\nportions of the prologue of a child kernel can be executed\r\nindependently from the parent. Informally, this independent\r\nportion must satisfy two conditions: (1) it must not use any\r\npostponed parameters and (2) it must not have any data\r\ndependence with the prologue of the parent. If these two\r\nconditions are met, then this portion of the prologue can be\r\nexecuted in parallel with the parent before it releases the child.\r\nFigure 5(d) illustrates the transformation that takes place\r\nwhen overlap is applied with promotion. In this transformation,\r\nthe prologue is divided into two regions – the independent\r\nregion (Pi) and dependent region (Pd) – and the independent\r\nregion is hoisted before the acquire logic. Here, Pi and Pd\r\nmust satisfy the conditions that Pi,x and Pd,x do not write\r\nto any memory referenced by Pi,y where x < y, and Pi,y\r\ndoes not write to any memory referenced by Pi,x and Pd,x\r\nwhere x < y. In this paper, a simple programmer annotation\r\nis used to indicate the boundary between Pi and Pd. However,\r\ndataflow analysis can also be used to detect these regions and\r\nis the subject of future work.\r\nD. Promotion with Aggregation and Overlap\r\nFigure 5(e) illustrates the transformation that takes place\r\nwhen both aggregation and overlap are applied with promo\u0002tion. The two optimizations are orthogonal and interoperate\r\nnicely without much added complexity. The most noteworthy\r\ndifference is that the transformed kernel now has two release\u0002acquire chains. The first chain enforces the launch condition,\r\nthus ensuring that only the thread blocks that are supposed to\r\nexecute do, while the trailing ones abort. The second chain\r\nenforces the dependence between parents and children.\r\nIV. EVALUATION\r\nA. Methodology and Implementation Details\r\nWe implement our compiler in Clang version 3.8.0 as a\r\nsource-to-source (CUDA-to-CUDA) translator. Although this\r\nversion does not compile code that uses dynamic parallelism to\r\nLLVM IR, we modify the semantic checker to accept kernel\r\ncalls inside kernel functions to enable the source-to-source\r\ntransformation to take place.\r\nThe benchmarks and datasets used in the evaluation are\r\nshown in Table I. Aggregation and promotion are evaluated\r\non different benchmarks because they target different patterns.\r\nFor the aggregation benchmarks, a few (bt, ccl, qt) employ\r\nCUDA Dynamic Parallelism (CDP) originally, while the rest\r\nwere ported to use CDP from original codes with intra\u0002thread nested loops. For example, in bfs, the loop over the\r\nedges of a node is converted to a kernel launch with one\r\nthread processing each edge. For the promotion benchmarks,\r\nwe chose algorithms which require communication between\r\nadjacent thread blocks, and implemented them using CDP.\r\nEach promotion benchmark is tested on three datasets: small\r\nwhich is selected to create 2 recurrences, medium which is\r\nselected to create 25 recurrences (the maximum CDP can\r\nhandle), and large which is the maximum problem size the\r\ndevice can handle or the maximum recurrence that aggregation\r\nat granularity 128 can handle (whichever maxes out first).",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/334862a8-77fd-47db-9fdd-eb7950d02a53.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=bac25e21320beaaf3e4bb3720aa92706b360e4055ae26e22bf0d3c8df7ecafc8",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 826
      },
      {
        "segments": [
          {
            "segment_id": "372a5bed-1be1-4552-964d-3e4c5a3470ed",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 7,
            "page_width": 612,
            "page_height": 792,
            "content": "Aggregation\r\nName Description Dataset Thread Block Sizes\r\nbfs Breadth First Search [18] Random, 10000 nodes, 1000 degree parent=1024, child=32\r\nbh Barnes Hut Tree [19] 4096 bodies, 4 time-steps parent=256, child=256\r\nbt Bezier Lines Tessellation [20] 25600 lines parent=64, child=32\r\nccl Connected Component Labelling [21] 8 frames, 4 host streams parent=2, child=256\r\ngc Graph Coloring [22] 1 4096 0.01 (bcsstk13.mtx [23]) parent=256, child=256\r\nmstf Minimum Spanning Tree (find) [19] rmat12.sym.gr [19] parent=1024, child=1024\r\nmstv Minimum Spanning Tree (verify) [19] rmat12.sym.gr [19] parent=1024, child=1024\r\nqt Quadtree [20] 40000 points, 12 depth, 1 min.node parent=128, child=128\r\nsp Survey Propagation [19] random-42000-10000-3.cnf [19], 10000 literals parent=384, child=64\r\nsssp Single-Source Shortest Path [19] rmat12.sym.gr [19] parent=128, child=128\r\nPromotion\r\nName Description Dataset Thread Block Sizes\r\nlos Line of Sight [20] small=511, medium=6399, large=49407 parent=256, child=256\r\npd Padding [5] small=120×120, medium=450×450, large=4600×4600 parent=512, child=512\r\npt Partition [24] small=16384, medium=204800, large=25174016 parent=512, child=512\r\nsc Stream Compaction [15] small=16384, medium=204800, large=25174016 parent=512, child=512\r\nunq Unique [24] small=16384, medium=204800, large=25174016 parent=512, child=512\r\nupd Unpadding [5] small=120×120, medium=450×450, large=4600×4600 parent=512, child=512\r\nTABLE I\r\nBENCHMARKS\r\nWe run our experiments on both Kepler and Maxwell\r\narchitectures. The Kepler GPU is an NVIDIA Tesla K40c\r\ncoupled with an 8-core Intel Core i7 920 (2.67 GHz). The\r\nMaxwell GPU is an NVIDIA GeForce GTX 980 coupled with\r\na 4-core Intel Core i3 530 (2.93 GHz). Both machines use\r\nCUDA SDK 7.5.\r\nWe enable per-thread default streams [25] for all bench\u0002marks to allow kernels launched by threads in the same\r\nblock to execute in parallel (default semantic is to serialize\r\nthem). Enabling per-thread default streams is needed for the\r\nbenchmarks to be amenable to aggregation, otherwise the\r\nserialization semantic would be violated. In addition, enabling\r\ndefault streams is good for the baseline CDP versions because\r\nit makes them faster (geomean 1.90× on Kepler and 1.83×\r\non Maxwell). Further, we observe that using private streams is\r\nsometimes faster than per-thread default streams, so when that\r\nis the case, private streams are used in the baseline instead.\r\nWe use cudaDeviceSetLimit to adjust the fixed-size\r\npool of the pending launch buffer appropriately for the baseline\r\nCDP version. Without the right size, the cost of overflowing\r\nthe launch buffer pool would greatly penalize the execution\r\ntime [26].\r\nFor the profiling results in Figure 9, we obtain the exe\u0002cution time breakdowns by incrementally deactivating parts\r\nof the code and measuring the resulting time difference. We\r\ndeactivate code regions using conditionals that are always false\r\nbut that cannot be proven so by the compiler, thus preventing\r\nthe possibility of dead code elimination in the active regions.\r\nFor iterative kernels with data-dependent convergence criteria\r\n(bfs, mstf, mstv, sp, sssp), we only profile the longest-running\r\niteration because deactivating code of one iteration changes\r\nthe behavior of later iterations. Likewise, for recursive kernels\r\n(qt), we only profile the longest running recurrence.\r\nThe results in Figure 10 are presented using throughput for\r\neach benchmark. All of them use effective memory throughput\r\n(GB/s) except los which uses ray length per second. The reason\r\nwe use throughput is to make the numbers for small, medium,\r\nand large datasets comparable since the large dataset does not\r\nhave a CDP baseline because CDP does not work.\r\nFor the profiling results in Figure 11, we use performance\r\ncounters from the CUDA Profiler [27] to measure achieved\r\noccupancy and executed instruction count.\r\nB. Aggregation\r\nThe overall speedup of kernel launch aggregation over CDP\r\nis shown in Figure 8 for each benchmark at warp (W), block\r\n(B), and kernel (K) granularity. We show results for both\r\nKepler and Maxwell. The similarity of the results demonstrate\r\nthe portability of our technique across architectures. Because\r\nthe results are very similar, we only discuss Kepler results in\r\nthe rest of this section.\r\nAll but two benchmarks show speedup over the baseline\r\nCDP version for all granularities. All but one show im\u0002provement as granularity increases, with geomean speedups\r\nof 3.98×, 4.94×, and 6.58× for W, B, and K respectively.\r\nTwo benchmarks do not have results for kernel-granularity\r\naggregation: ccl because it has explicit synchronization and\r\nsp because the kernel is called in a loop (see Section II-B).\r\nThe breakdown of the execution time of each benchmark\r\nis shown in Figure 9 for the original CDP version as well as\r\naggregation at each granularity. In the following paragraphs,\r\nwe discuss each benchmark in the context of these results.\r\nbfs, bt, gc, mstf, mstv, sp. For all six benchmarks, we\r\nobserve that the original CDP version was dominated by\r\nthe kernel launch overhead. As the aggregation granularity\r\nis increased and fewer kernels are launched, the launch\r\noverhead decreases at the expense of additional aggregation\r\nlogic, resulting in a net performance gain. We also observe a\r\ndecrease in the amount of time spent doing real work. This is\r\ndue to the improvement in occupancy. Profiling results show\r\nthat occupancy for bfs, gc, mstf, mstv, and sp improves by\r\na geomean of 2.81×, 3.24× and 3.51× for W, B, and K\r\nrespectively.\r\nsssp. This benchmark behaves very similarly to the previous\r\nsix, with the difference that performance at kernel granularity",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/372a5bed-1be1-4552-964d-3e4c5a3470ed.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5e4b1915e594f63d378ab625252c845c43c3c3f7afb95b885413ca59eedba75b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 839
      },
      {
        "segments": [
          {
            "segment_id": "372a5bed-1be1-4552-964d-3e4c5a3470ed",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 7,
            "page_width": 612,
            "page_height": 792,
            "content": "Aggregation\r\nName Description Dataset Thread Block Sizes\r\nbfs Breadth First Search [18] Random, 10000 nodes, 1000 degree parent=1024, child=32\r\nbh Barnes Hut Tree [19] 4096 bodies, 4 time-steps parent=256, child=256\r\nbt Bezier Lines Tessellation [20] 25600 lines parent=64, child=32\r\nccl Connected Component Labelling [21] 8 frames, 4 host streams parent=2, child=256\r\ngc Graph Coloring [22] 1 4096 0.01 (bcsstk13.mtx [23]) parent=256, child=256\r\nmstf Minimum Spanning Tree (find) [19] rmat12.sym.gr [19] parent=1024, child=1024\r\nmstv Minimum Spanning Tree (verify) [19] rmat12.sym.gr [19] parent=1024, child=1024\r\nqt Quadtree [20] 40000 points, 12 depth, 1 min.node parent=128, child=128\r\nsp Survey Propagation [19] random-42000-10000-3.cnf [19], 10000 literals parent=384, child=64\r\nsssp Single-Source Shortest Path [19] rmat12.sym.gr [19] parent=128, child=128\r\nPromotion\r\nName Description Dataset Thread Block Sizes\r\nlos Line of Sight [20] small=511, medium=6399, large=49407 parent=256, child=256\r\npd Padding [5] small=120×120, medium=450×450, large=4600×4600 parent=512, child=512\r\npt Partition [24] small=16384, medium=204800, large=25174016 parent=512, child=512\r\nsc Stream Compaction [15] small=16384, medium=204800, large=25174016 parent=512, child=512\r\nunq Unique [24] small=16384, medium=204800, large=25174016 parent=512, child=512\r\nupd Unpadding [5] small=120×120, medium=450×450, large=4600×4600 parent=512, child=512\r\nTABLE I\r\nBENCHMARKS\r\nWe run our experiments on both Kepler and Maxwell\r\narchitectures. The Kepler GPU is an NVIDIA Tesla K40c\r\ncoupled with an 8-core Intel Core i7 920 (2.67 GHz). The\r\nMaxwell GPU is an NVIDIA GeForce GTX 980 coupled with\r\na 4-core Intel Core i3 530 (2.93 GHz). Both machines use\r\nCUDA SDK 7.5.\r\nWe enable per-thread default streams [25] for all bench\u0002marks to allow kernels launched by threads in the same\r\nblock to execute in parallel (default semantic is to serialize\r\nthem). Enabling per-thread default streams is needed for the\r\nbenchmarks to be amenable to aggregation, otherwise the\r\nserialization semantic would be violated. In addition, enabling\r\ndefault streams is good for the baseline CDP versions because\r\nit makes them faster (geomean 1.90× on Kepler and 1.83×\r\non Maxwell). Further, we observe that using private streams is\r\nsometimes faster than per-thread default streams, so when that\r\nis the case, private streams are used in the baseline instead.\r\nWe use cudaDeviceSetLimit to adjust the fixed-size\r\npool of the pending launch buffer appropriately for the baseline\r\nCDP version. Without the right size, the cost of overflowing\r\nthe launch buffer pool would greatly penalize the execution\r\ntime [26].\r\nFor the profiling results in Figure 9, we obtain the exe\u0002cution time breakdowns by incrementally deactivating parts\r\nof the code and measuring the resulting time difference. We\r\ndeactivate code regions using conditionals that are always false\r\nbut that cannot be proven so by the compiler, thus preventing\r\nthe possibility of dead code elimination in the active regions.\r\nFor iterative kernels with data-dependent convergence criteria\r\n(bfs, mstf, mstv, sp, sssp), we only profile the longest-running\r\niteration because deactivating code of one iteration changes\r\nthe behavior of later iterations. Likewise, for recursive kernels\r\n(qt), we only profile the longest running recurrence.\r\nThe results in Figure 10 are presented using throughput for\r\neach benchmark. All of them use effective memory throughput\r\n(GB/s) except los which uses ray length per second. The reason\r\nwe use throughput is to make the numbers for small, medium,\r\nand large datasets comparable since the large dataset does not\r\nhave a CDP baseline because CDP does not work.\r\nFor the profiling results in Figure 11, we use performance\r\ncounters from the CUDA Profiler [27] to measure achieved\r\noccupancy and executed instruction count.\r\nB. Aggregation\r\nThe overall speedup of kernel launch aggregation over CDP\r\nis shown in Figure 8 for each benchmark at warp (W), block\r\n(B), and kernel (K) granularity. We show results for both\r\nKepler and Maxwell. The similarity of the results demonstrate\r\nthe portability of our technique across architectures. Because\r\nthe results are very similar, we only discuss Kepler results in\r\nthe rest of this section.\r\nAll but two benchmarks show speedup over the baseline\r\nCDP version for all granularities. All but one show im\u0002provement as granularity increases, with geomean speedups\r\nof 3.98×, 4.94×, and 6.58× for W, B, and K respectively.\r\nTwo benchmarks do not have results for kernel-granularity\r\naggregation: ccl because it has explicit synchronization and\r\nsp because the kernel is called in a loop (see Section II-B).\r\nThe breakdown of the execution time of each benchmark\r\nis shown in Figure 9 for the original CDP version as well as\r\naggregation at each granularity. In the following paragraphs,\r\nwe discuss each benchmark in the context of these results.\r\nbfs, bt, gc, mstf, mstv, sp. For all six benchmarks, we\r\nobserve that the original CDP version was dominated by\r\nthe kernel launch overhead. As the aggregation granularity\r\nis increased and fewer kernels are launched, the launch\r\noverhead decreases at the expense of additional aggregation\r\nlogic, resulting in a net performance gain. We also observe a\r\ndecrease in the amount of time spent doing real work. This is\r\ndue to the improvement in occupancy. Profiling results show\r\nthat occupancy for bfs, gc, mstf, mstv, and sp improves by\r\na geomean of 2.81×, 3.24× and 3.51× for W, B, and K\r\nrespectively.\r\nsssp. This benchmark behaves very similarly to the previous\r\nsix, with the difference that performance at kernel granularity",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/372a5bed-1be1-4552-964d-3e4c5a3470ed.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5e4b1915e594f63d378ab625252c845c43c3c3f7afb95b885413ca59eedba75b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 839
      },
      {
        "segments": [
          {
            "segment_id": "9097ccd6-f5d8-4600-9ce6-cfae25d0cb49",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 8,
            "page_width": 612,
            "page_height": 792,
            "content": "0.5\r\n1\r\n2\r\n4\r\n8\r\n16\r\n32\r\nbfs bh bt ccl gc mstfmstv qt sp sssp geo\r\nSpeedup over CDP \r\n(higher is better)\r\nW B K\r\n(a) Kepler (b) Maxwell\r\n0.5\r\n1\r\n2\r\n4\r\n8\r\n16\r\n32\r\nbfs bh bt ccl gc mstfmstv qt sp sssp geo\r\nSpeedup over CDP \r\n(higher is better)\r\nW B K\r\n34.6\r\nFig. 8. Speedup of Kernel Launch Aggregation\r\n0%\r\n10%\r\n20%\r\n30%\r\n40%\r\n50%\r\n60%\r\n70%\r\n80%\r\n90%\r\n100%\r\n110%\r\nCDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\n- CDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\n- CDP\r\nW\r\nB\r\nK\r\nbfs\r\n(1 iter.)\r\nbh bt ccl gc mstf\r\n(1 iter.)\r\nmstv\r\n(1 iter.)\r\nqt\r\n(1 recur.)\r\nsp\r\n(1 iter.)\r\nsssp\r\n(1 iter.)\r\nNormalized Execution Time \r\n(lower is better)\r\nReal Work Launch Overhead Aggregation Logic\r\nFig. 9. Breakdown of Execution Time in Kernel Launch Aggregation\r\naggregation is slightly worse than that at block granularity.\r\nThat is because block-granularity aggregation finds a better\r\noccupancy sweet spot, with occupancy improving by 6.35×,\r\n7.95×, and 6.68× for W, B, and K respectively.\r\nbh. This benchmark originally contains long running chil\u0002dren threads so the kernel launch overhead does not dominate\r\nperformance. For this reason, there is no benefit to be gained\r\nfrom reducing the launch overhead. However, the benchmark\r\nstill benefits from improved occupancy as with the previous\r\nseven. In fact, the occupancy improves by a factor of 3.83×,\r\n3.83× and 3.82× for W, B, and K respectively. These factors\r\nare comparable to the factors of improvement in the time spent\r\nperforming real work shown in the graph.\r\nccl. This is a unique benchmark because the parent kernel\r\nonly contains a single thread block with two threads. For this\r\nreason, there is not much to be gained from aggregating two\r\nlaunches into one. Instead, some overhead is incurred from\r\nthe aggregation logic without having much value. However,\r\nthis benchmark demonstrates that our technique does not\r\nsignificantly harm benchmarks not benefiting from it.\r\nqt. This is a recursive benchmark and also unique because\r\nonly one thread per block launches a kernel. Therefore warp\r\nand block granularity aggregation do not have any impact\r\non the number of kernels launched – they just incur slightly\r\nextra overhead. This benchmark again demonstrates that our\r\ntechnique does not harm irrelevant benchmarks. For kernel\u0002granularity aggregation, the launch overhead is significantly\r\nreduced.\r\nComparing aggregation with non-CDP, 6 out of the 7\r\nbenchmarks having non-CDP versions show speedup from\r\naggregation ranging from 1.2× to 3.7× (geomean 1.6×) over\r\nthe non-CDP versions. The 7th is bh for which the algorithmic\r\nchanges required to make it amenable to CDP made the naive\r\nCDP version significantly slower and hard to recover from.\r\nWe mention these metrics for quality assurance, but note that\r\nthe main advantage of CDP over non-CDP is programmability,\r\nnot performance.\r\nOur results do not show enough variation between granu\u0002larities to motivate employing a selection technique. However,\r\nif needed, one can be employed similar to that in related\r\nwork [10].\r\nC. Promotion\r\nThe overall throughput improvement of kernel launch pro\u0002motion is shown in Figure 10 for both Kepler and Maxwell.\r\nAgain, the similarity of the results demonstrate the portability\r\nof our technique across architectures, and we only discuss\r\nKepler results in the rest of this section.\r\nFor each benchmark, we show results for the small (S),\r\nmedium (M), and large (L) datasets. We compare the original\r\nCDP version with basic promotion (P), promotion with aggre\u0002gation where the granularity of aggregation is 2 (PA-2) and",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/9097ccd6-f5d8-4600-9ce6-cfae25d0cb49.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f6275b1e31839b8709cf5e16d81f9fe2537361dab4450130289ca1f66b40c145",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 596
      },
      {
        "segments": [
          {
            "segment_id": "9097ccd6-f5d8-4600-9ce6-cfae25d0cb49",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 8,
            "page_width": 612,
            "page_height": 792,
            "content": "0.5\r\n1\r\n2\r\n4\r\n8\r\n16\r\n32\r\nbfs bh bt ccl gc mstfmstv qt sp sssp geo\r\nSpeedup over CDP \r\n(higher is better)\r\nW B K\r\n(a) Kepler (b) Maxwell\r\n0.5\r\n1\r\n2\r\n4\r\n8\r\n16\r\n32\r\nbfs bh bt ccl gc mstfmstv qt sp sssp geo\r\nSpeedup over CDP \r\n(higher is better)\r\nW B K\r\n34.6\r\nFig. 8. Speedup of Kernel Launch Aggregation\r\n0%\r\n10%\r\n20%\r\n30%\r\n40%\r\n50%\r\n60%\r\n70%\r\n80%\r\n90%\r\n100%\r\n110%\r\nCDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\n- CDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\nK\r\nCDP\r\nW\r\nB\r\n- CDP\r\nW\r\nB\r\nK\r\nbfs\r\n(1 iter.)\r\nbh bt ccl gc mstf\r\n(1 iter.)\r\nmstv\r\n(1 iter.)\r\nqt\r\n(1 recur.)\r\nsp\r\n(1 iter.)\r\nsssp\r\n(1 iter.)\r\nNormalized Execution Time \r\n(lower is better)\r\nReal Work Launch Overhead Aggregation Logic\r\nFig. 9. Breakdown of Execution Time in Kernel Launch Aggregation\r\naggregation is slightly worse than that at block granularity.\r\nThat is because block-granularity aggregation finds a better\r\noccupancy sweet spot, with occupancy improving by 6.35×,\r\n7.95×, and 6.68× for W, B, and K respectively.\r\nbh. This benchmark originally contains long running chil\u0002dren threads so the kernel launch overhead does not dominate\r\nperformance. For this reason, there is no benefit to be gained\r\nfrom reducing the launch overhead. However, the benchmark\r\nstill benefits from improved occupancy as with the previous\r\nseven. In fact, the occupancy improves by a factor of 3.83×,\r\n3.83× and 3.82× for W, B, and K respectively. These factors\r\nare comparable to the factors of improvement in the time spent\r\nperforming real work shown in the graph.\r\nccl. This is a unique benchmark because the parent kernel\r\nonly contains a single thread block with two threads. For this\r\nreason, there is not much to be gained from aggregating two\r\nlaunches into one. Instead, some overhead is incurred from\r\nthe aggregation logic without having much value. However,\r\nthis benchmark demonstrates that our technique does not\r\nsignificantly harm benchmarks not benefiting from it.\r\nqt. This is a recursive benchmark and also unique because\r\nonly one thread per block launches a kernel. Therefore warp\r\nand block granularity aggregation do not have any impact\r\non the number of kernels launched – they just incur slightly\r\nextra overhead. This benchmark again demonstrates that our\r\ntechnique does not harm irrelevant benchmarks. For kernel\u0002granularity aggregation, the launch overhead is significantly\r\nreduced.\r\nComparing aggregation with non-CDP, 6 out of the 7\r\nbenchmarks having non-CDP versions show speedup from\r\naggregation ranging from 1.2× to 3.7× (geomean 1.6×) over\r\nthe non-CDP versions. The 7th is bh for which the algorithmic\r\nchanges required to make it amenable to CDP made the naive\r\nCDP version significantly slower and hard to recover from.\r\nWe mention these metrics for quality assurance, but note that\r\nthe main advantage of CDP over non-CDP is programmability,\r\nnot performance.\r\nOur results do not show enough variation between granu\u0002larities to motivate employing a selection technique. However,\r\nif needed, one can be employed similar to that in related\r\nwork [10].\r\nC. Promotion\r\nThe overall throughput improvement of kernel launch pro\u0002motion is shown in Figure 10 for both Kepler and Maxwell.\r\nAgain, the similarity of the results demonstrate the portability\r\nof our technique across architectures, and we only discuss\r\nKepler results in the rest of this section.\r\nFor each benchmark, we show results for the small (S),\r\nmedium (M), and large (L) datasets. We compare the original\r\nCDP version with basic promotion (P), promotion with aggre\u0002gation where the granularity of aggregation is 2 (PA-2) and",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/9097ccd6-f5d8-4600-9ce6-cfae25d0cb49.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f6275b1e31839b8709cf5e16d81f9fe2537361dab4450130289ca1f66b40c145",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 596
      },
      {
        "segments": [
          {
            "segment_id": "0a6c4c98-6c50-417f-8965-20ef525f8ef7",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 9,
            "page_width": 612,
            "page_height": 792,
            "content": " 1/8\r\n 1/4\r\n 1/2\r\n1\r\n2\r\n4\r\n8\r\n16\r\n32\r\n64\r\nS M L S M L S M L S M L S M L S M L S M L\r\nlos pd pt sc unq upd geomean\r\nNormalized Throughput \r\n(higher is better)\r\nCDP P PA-2 PA PO PAO-2 PAO\r\n 1/8\r\n 1/4\r\n 1/2\r\n1\r\n2\r\n4\r\n8\r\n16\r\n32\r\n64\r\nS M L S M L S M L S M L S M L S M L S M L\r\nNormalized Throughput\r\nlos pd pt sc unq upd geomean\r\n \r\n(higher is better)\r\nCDP P PA-2 PA PO PAO-2 PAO\r\n(a) Kepler\r\n(b) Maxwell\r\nFig. 10. Throughput of Kernel Launch Promotion\r\n0\r\n0.1\r\n0.2\r\n0.3\r\n0.4\r\n0.5\r\n0.6\r\n0.7\r\n0.8\r\nlos pd pt sc unq upd\r\nAchieved Occupancy \r\n(higher is better)\r\nCDP P PA-2 PA PO PAO-2 PAO\r\n0\r\n0.5\r\n1\r\n1.5\r\n2\r\n2.5\r\n3\r\n3.5\r\n4\r\nlos pd pt sc unq upd\r\nInstructions per Second \r\n(billions \r\n– higher is better)\r\nCDP P PA-2 PA PO PAO-2 PAO\r\n(a) Achieved Occupancy (b) Instructions per Second\r\nFig. 11. Profile of Kernel Launch Promotion\r\n128 (PA), promotion with overlap (PO), and promotion with\r\naggregation and overlap where the granularity of aggregation\r\nis 2 (PAO-2) and 128 (PAO).\r\nSmall datasets. The small datasets are designed to create a\r\nchain of only two kernel launches. While not realistic, they\r\nare intended to show how the overhead of the promotion,\r\naggregation, and overlap logic can cause performance to\r\ndegrade if the dataset is not big enough. In particular, we\r\npoint out how the larger aggregation granularity (PA and PAO)\r\nresults in the most overhead among all when the spawned\r\nchildren are not used. This extreme case demonstrates the\r\ntradeoff of aggregation granularity in the overhead it adds\r\nto the benchmark to aggregate the kernel launch as well as\r\nterminate unused thread blocks.\r\nMedium datasets. The medium datasets are the maximum\r\nsize that can be executed in CDP, beyond which the call depth\r\nlimit is no longer sufficient. All benchmarks show speedup at\r\nthis scale. PAO on the medium dataset has a geomean speedup\r\nof 5.27× over CDP on the medium dataset. One interesting\r\nobservation is that across the benchmarks, PO alone shows\r\nlittle speedup over P, and PA alone shows moderate speedup\r\nover P, however PAO shows higher speedup greater than the\r\nproduct of the two. This indicates that aggregation and overlap\r\nmutually benefit each other. We show why shortly when we\r\ndiscuss profiling results.\r\nLarge datasets. For the large datasets, only PA and PAO\r\ncan complete while the others are limited by the maximum\r\ncall depth. This demonstrates the power of our technique in\r\novercoming the call depth limitation through vertical aggrega\u0002tion. PAO on the large datasets achieves a throughput that is\r\n30.44× and 21.81× higher than that achieved by CDP on the\r\nsmall and medium datasets respectively.\r\nProfiling. The profiling results for each of the promotion\r\ntransformations on the medium datasets are shown in Fig\u0002ure 11. In Figure 11(a), PA and PAO both achieve significantly\r\nbetter occupancy than the other versions. This demonstrates\r\nthe power of the aggregation optimization in improving the\r\noccupancy of dynamic parallelism on the GPU. Despite having\r\nthe same occupancy, Figure 11(b) shows that PAO executes\r\nmore instructions per second than PA. This demonstrates the",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/0a6c4c98-6c50-417f-8965-20ef525f8ef7.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=ebf4fdc9a1677ddbe7fcd130a87209c288a5148c73fde17d7b7d56bd8f4b353a",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 546
      },
      {
        "segments": [
          {
            "segment_id": "0a6c4c98-6c50-417f-8965-20ef525f8ef7",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 9,
            "page_width": 612,
            "page_height": 792,
            "content": " 1/8\r\n 1/4\r\n 1/2\r\n1\r\n2\r\n4\r\n8\r\n16\r\n32\r\n64\r\nS M L S M L S M L S M L S M L S M L S M L\r\nlos pd pt sc unq upd geomean\r\nNormalized Throughput \r\n(higher is better)\r\nCDP P PA-2 PA PO PAO-2 PAO\r\n 1/8\r\n 1/4\r\n 1/2\r\n1\r\n2\r\n4\r\n8\r\n16\r\n32\r\n64\r\nS M L S M L S M L S M L S M L S M L S M L\r\nNormalized Throughput\r\nlos pd pt sc unq upd geomean\r\n \r\n(higher is better)\r\nCDP P PA-2 PA PO PAO-2 PAO\r\n(a) Kepler\r\n(b) Maxwell\r\nFig. 10. Throughput of Kernel Launch Promotion\r\n0\r\n0.1\r\n0.2\r\n0.3\r\n0.4\r\n0.5\r\n0.6\r\n0.7\r\n0.8\r\nlos pd pt sc unq upd\r\nAchieved Occupancy \r\n(higher is better)\r\nCDP P PA-2 PA PO PAO-2 PAO\r\n0\r\n0.5\r\n1\r\n1.5\r\n2\r\n2.5\r\n3\r\n3.5\r\n4\r\nlos pd pt sc unq upd\r\nInstructions per Second \r\n(billions \r\n– higher is better)\r\nCDP P PA-2 PA PO PAO-2 PAO\r\n(a) Achieved Occupancy (b) Instructions per Second\r\nFig. 11. Profile of Kernel Launch Promotion\r\n128 (PA), promotion with overlap (PO), and promotion with\r\naggregation and overlap where the granularity of aggregation\r\nis 2 (PAO-2) and 128 (PAO).\r\nSmall datasets. The small datasets are designed to create a\r\nchain of only two kernel launches. While not realistic, they\r\nare intended to show how the overhead of the promotion,\r\naggregation, and overlap logic can cause performance to\r\ndegrade if the dataset is not big enough. In particular, we\r\npoint out how the larger aggregation granularity (PA and PAO)\r\nresults in the most overhead among all when the spawned\r\nchildren are not used. This extreme case demonstrates the\r\ntradeoff of aggregation granularity in the overhead it adds\r\nto the benchmark to aggregate the kernel launch as well as\r\nterminate unused thread blocks.\r\nMedium datasets. The medium datasets are the maximum\r\nsize that can be executed in CDP, beyond which the call depth\r\nlimit is no longer sufficient. All benchmarks show speedup at\r\nthis scale. PAO on the medium dataset has a geomean speedup\r\nof 5.27× over CDP on the medium dataset. One interesting\r\nobservation is that across the benchmarks, PO alone shows\r\nlittle speedup over P, and PA alone shows moderate speedup\r\nover P, however PAO shows higher speedup greater than the\r\nproduct of the two. This indicates that aggregation and overlap\r\nmutually benefit each other. We show why shortly when we\r\ndiscuss profiling results.\r\nLarge datasets. For the large datasets, only PA and PAO\r\ncan complete while the others are limited by the maximum\r\ncall depth. This demonstrates the power of our technique in\r\novercoming the call depth limitation through vertical aggrega\u0002tion. PAO on the large datasets achieves a throughput that is\r\n30.44× and 21.81× higher than that achieved by CDP on the\r\nsmall and medium datasets respectively.\r\nProfiling. The profiling results for each of the promotion\r\ntransformations on the medium datasets are shown in Fig\u0002ure 11. In Figure 11(a), PA and PAO both achieve significantly\r\nbetter occupancy than the other versions. This demonstrates\r\nthe power of the aggregation optimization in improving the\r\noccupancy of dynamic parallelism on the GPU. Despite having\r\nthe same occupancy, Figure 11(b) shows that PAO executes\r\nmore instructions per second than PA. This demonstrates the",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/0a6c4c98-6c50-417f-8965-20ef525f8ef7.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=ebf4fdc9a1677ddbe7fcd130a87209c288a5148c73fde17d7b7d56bd8f4b353a",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 546
      },
      {
        "segments": [
          {
            "segment_id": "e0833cce-af1f-4055-a6fb-09c115a1e2ec",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 10,
            "page_width": 612,
            "page_height": 792,
            "content": "effectiveness of the overlap optimization in making more work\r\navailable sooner. It is interesting that the overlap optimization\r\ndoes not improve instruction throughout when applied alone,\r\nbut only when applied with aggregation. That is because\r\nwithout aggregation, PO has low occupancy so it cannot take\r\nadvantage of available instructions.\r\nV. RELATED WORK\r\nMultiple studies [9], [6], [7] have identified the inefficiency\r\nof the current practice of dynamic parallelism, and have\r\nproposed different solutions to overcome these inefficiencies.\r\nA. Kernel Launch Aggregation\r\nHardware-based Aggregation. Dynamic Thread Block\r\nLaunch (DTBL) [9] performs kernel aggregation in hardware\r\nvia aggregation tables for buffering kernel calls. This work\r\nis further enhanced with a locality-aware scheduler [28].\r\nOrr et al. [29] earlier proposed a similar hardware-based\r\naggregation scheme for fine-grain tasks in HSA processors.\r\nBoth techniques require hardware modification and are not\r\navailable on current GPUs, whereas KLAP is a compiler-based\r\napproach which performs aggregation on existing devices.\r\nOnce hardware is available, we expect that hardware- and\r\nsoftware-based aggregation can operate synergistically. On the\r\none hand, hardware improvements to dynamic parallelism can\r\nimprove KLAP’s performance further. In return, KLAP can\r\nalso assist hardware techniques by reducing pressure on the\r\naggregation table/buffer to avoid spilling to memory when\r\nthere is not enough table space.\r\nAn important difference between KLAP and DTBL is that\r\nKLAP aggregates kernels before they are launched to reduce\r\nthe number of launches, whereas DTBL aggregates them after\r\nthey are launched but makes the launch more lightweight.\r\nIt is plausible that a KLAP-like approach where kernels are\r\naggregated before launching can also be done in hardware.\r\nCompiler-based Optimization of Dynamic Parallelism.\r\nCUDA-NP [7] is a compiler approach that takes advantage of\r\nnested parallelism within threads by assigning them additional\r\nslave threads in the same thread block to perform their child\r\ntasks. This approach, however, is limited by the parallelism\r\navailable within a single thread block.\r\nThe most similar work to our kernel launch aggregation\r\nis Free Launch (FL) [10] which performs aggregation-like\r\ntransformations and eliminates subkernel calls entirely by\r\nreusing parent threads to perform child computation. Thus,\r\nFL can potentially eliminate more kernel launch overhead and\r\nachieve higher speedup than KLAP. The best FL technique\r\nrelies on using persistent threads [30]. In KLAP, we do not\r\neliminate subkernel calls but rather we demonstrate that CDP\r\ncan work efficiently after proper aggregation techniques are\r\napplied, delivering comparable speedups. Moreover, by using\r\nCDP, we avoid the use of persistent threads. This approach\r\nhas several advantages.\r\nFirst, KLAP can handle general cases with variable child\r\nblock sizes and does not need to know the maximum child\r\nblock size on the host prior to execution. On the other hand,\r\nbecause FL uses persistent threads, the maximum child block\r\nsize must be known on the host prior to execution in order to\r\nensure that the persistent thread blocks have enough threads to\r\nexecute the child blocks. Otherwise, the child threads would\r\nneed to be coarsened to reduce the block size or the maximum\r\npossible block size would need to be used, which may not\r\nachieve the best occupancy.\r\nSecond, KLAP transforms each kernel separately, indepen\u0002dent of its caller and callee kernels. This makes our compiler\r\nmore scalable and our transformations less complex (hence,\r\nmore robust) as the number of kernels involved in the call\r\nhierarchy increases. Our approach already supports multi\u0002depth and recursive call lineages naturally without the need\r\nfor additional support. Moreover, our approach guarantees\r\nmemory consistency between parent and child via the semantic\r\nof kernel calls, and does not need to place memory fences\r\nwithin arbitrary control flow paths of the parent kernel, which\r\ncan be both difficult and error-prone.\r\nThird, KLAP does not need to deal with the caveats of\r\npersistent threads. For example, kernels with persistent threads\r\nmust grab all the resources they require for the entirety of their\r\nexecution, even if they do not need them during some parts\r\nof their lifetime. This means that such kernels cannot share\r\ntheir resources with co-runner kernels. On the other hand,\r\nKLAP kernels behave like regular kernels and act flexibly in\r\ncollaborative environments.\r\nWe also note that the speedups we report are not directly\r\ncomparable to those reported by FL for two reasons. The\r\nfirst reason is that we use a faster baseline which uses\r\nprivate streams more efficiently. The second reason is that\r\nour benchmarks use a variety of children block sizes, whereas\r\nmost of FL’s benchmarks use large parent block size (1024)\r\nand small children block sizes (32). Setting the children block\r\nsize to 32 enables FL’s transformation to execute multiple child\r\nblocks concurrently in the same parent block (each parent warp\r\nexecutes a child block). To establish a direct comparison, we\r\nreached out to the authors who shared their bfs code with\r\nus [31]. For the configurations they use, their code is 2.08×\r\nfaster than ours. For other configurations, the difference is as\r\nlow as 1.26×. This verifies that CDP can indeed be efficient\r\nif the proper compiler transformations are applied.\r\nOther Related Work. Guevara et al. [32] merge a few\r\nindependent kernels launched from the host together to achieve\r\nconcurrency. This issue was solved by Fermi’s concurrent ker\u0002nel execution. KLAP merges many identical kernels launched\r\nfrom the device to reduce the number of launches. Li et\r\nal. [33] propose a set of parallelization templates that optimize\r\nirregular nested loops and parallel recursive computations,\r\nparticularly for tree and graph algorithms. KLAP applies\r\ncompiler transformations to convert naive CDP into more\r\nefficient aggregated CDP. Ren et al. [34] propose a vector\r\nparallelization transformation to “aggregate” similar tasks in\r\nrecursive task-parallel programs for better utilization of vector\r\nhardware. KLAP focuses on aggregation techniques for data\u0002parallel programs in CUDA or OpenCL.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/e0833cce-af1f-4055-a6fb-09c115a1e2ec.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=91961e9532d013b713e47b3efd0872e57e245b439ba59791fb2e95e7749f8f7d",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 944
      },
      {
        "segments": [
          {
            "segment_id": "e0833cce-af1f-4055-a6fb-09c115a1e2ec",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 10,
            "page_width": 612,
            "page_height": 792,
            "content": "effectiveness of the overlap optimization in making more work\r\navailable sooner. It is interesting that the overlap optimization\r\ndoes not improve instruction throughout when applied alone,\r\nbut only when applied with aggregation. That is because\r\nwithout aggregation, PO has low occupancy so it cannot take\r\nadvantage of available instructions.\r\nV. RELATED WORK\r\nMultiple studies [9], [6], [7] have identified the inefficiency\r\nof the current practice of dynamic parallelism, and have\r\nproposed different solutions to overcome these inefficiencies.\r\nA. Kernel Launch Aggregation\r\nHardware-based Aggregation. Dynamic Thread Block\r\nLaunch (DTBL) [9] performs kernel aggregation in hardware\r\nvia aggregation tables for buffering kernel calls. This work\r\nis further enhanced with a locality-aware scheduler [28].\r\nOrr et al. [29] earlier proposed a similar hardware-based\r\naggregation scheme for fine-grain tasks in HSA processors.\r\nBoth techniques require hardware modification and are not\r\navailable on current GPUs, whereas KLAP is a compiler-based\r\napproach which performs aggregation on existing devices.\r\nOnce hardware is available, we expect that hardware- and\r\nsoftware-based aggregation can operate synergistically. On the\r\none hand, hardware improvements to dynamic parallelism can\r\nimprove KLAP’s performance further. In return, KLAP can\r\nalso assist hardware techniques by reducing pressure on the\r\naggregation table/buffer to avoid spilling to memory when\r\nthere is not enough table space.\r\nAn important difference between KLAP and DTBL is that\r\nKLAP aggregates kernels before they are launched to reduce\r\nthe number of launches, whereas DTBL aggregates them after\r\nthey are launched but makes the launch more lightweight.\r\nIt is plausible that a KLAP-like approach where kernels are\r\naggregated before launching can also be done in hardware.\r\nCompiler-based Optimization of Dynamic Parallelism.\r\nCUDA-NP [7] is a compiler approach that takes advantage of\r\nnested parallelism within threads by assigning them additional\r\nslave threads in the same thread block to perform their child\r\ntasks. This approach, however, is limited by the parallelism\r\navailable within a single thread block.\r\nThe most similar work to our kernel launch aggregation\r\nis Free Launch (FL) [10] which performs aggregation-like\r\ntransformations and eliminates subkernel calls entirely by\r\nreusing parent threads to perform child computation. Thus,\r\nFL can potentially eliminate more kernel launch overhead and\r\nachieve higher speedup than KLAP. The best FL technique\r\nrelies on using persistent threads [30]. In KLAP, we do not\r\neliminate subkernel calls but rather we demonstrate that CDP\r\ncan work efficiently after proper aggregation techniques are\r\napplied, delivering comparable speedups. Moreover, by using\r\nCDP, we avoid the use of persistent threads. This approach\r\nhas several advantages.\r\nFirst, KLAP can handle general cases with variable child\r\nblock sizes and does not need to know the maximum child\r\nblock size on the host prior to execution. On the other hand,\r\nbecause FL uses persistent threads, the maximum child block\r\nsize must be known on the host prior to execution in order to\r\nensure that the persistent thread blocks have enough threads to\r\nexecute the child blocks. Otherwise, the child threads would\r\nneed to be coarsened to reduce the block size or the maximum\r\npossible block size would need to be used, which may not\r\nachieve the best occupancy.\r\nSecond, KLAP transforms each kernel separately, indepen\u0002dent of its caller and callee kernels. This makes our compiler\r\nmore scalable and our transformations less complex (hence,\r\nmore robust) as the number of kernels involved in the call\r\nhierarchy increases. Our approach already supports multi\u0002depth and recursive call lineages naturally without the need\r\nfor additional support. Moreover, our approach guarantees\r\nmemory consistency between parent and child via the semantic\r\nof kernel calls, and does not need to place memory fences\r\nwithin arbitrary control flow paths of the parent kernel, which\r\ncan be both difficult and error-prone.\r\nThird, KLAP does not need to deal with the caveats of\r\npersistent threads. For example, kernels with persistent threads\r\nmust grab all the resources they require for the entirety of their\r\nexecution, even if they do not need them during some parts\r\nof their lifetime. This means that such kernels cannot share\r\ntheir resources with co-runner kernels. On the other hand,\r\nKLAP kernels behave like regular kernels and act flexibly in\r\ncollaborative environments.\r\nWe also note that the speedups we report are not directly\r\ncomparable to those reported by FL for two reasons. The\r\nfirst reason is that we use a faster baseline which uses\r\nprivate streams more efficiently. The second reason is that\r\nour benchmarks use a variety of children block sizes, whereas\r\nmost of FL’s benchmarks use large parent block size (1024)\r\nand small children block sizes (32). Setting the children block\r\nsize to 32 enables FL’s transformation to execute multiple child\r\nblocks concurrently in the same parent block (each parent warp\r\nexecutes a child block). To establish a direct comparison, we\r\nreached out to the authors who shared their bfs code with\r\nus [31]. For the configurations they use, their code is 2.08×\r\nfaster than ours. For other configurations, the difference is as\r\nlow as 1.26×. This verifies that CDP can indeed be efficient\r\nif the proper compiler transformations are applied.\r\nOther Related Work. Guevara et al. [32] merge a few\r\nindependent kernels launched from the host together to achieve\r\nconcurrency. This issue was solved by Fermi’s concurrent ker\u0002nel execution. KLAP merges many identical kernels launched\r\nfrom the device to reduce the number of launches. Li et\r\nal. [33] propose a set of parallelization templates that optimize\r\nirregular nested loops and parallel recursive computations,\r\nparticularly for tree and graph algorithms. KLAP applies\r\ncompiler transformations to convert naive CDP into more\r\nefficient aggregated CDP. Ren et al. [34] propose a vector\r\nparallelization transformation to “aggregate” similar tasks in\r\nrecursive task-parallel programs for better utilization of vector\r\nhardware. KLAP focuses on aggregation techniques for data\u0002parallel programs in CUDA or OpenCL.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/e0833cce-af1f-4055-a6fb-09c115a1e2ec.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=91961e9532d013b713e47b3efd0872e57e245b439ba59791fb2e95e7749f8f7d",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 944
      },
      {
        "segments": [
          {
            "segment_id": "d59b8a97-9db9-4aba-843a-3163ba58b479",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 11,
            "page_width": 612,
            "page_height": 792,
            "content": "B. Kernel Launch Promotion\r\nDecoupled Software Pipelining [35] extracts parallelism\r\nfrom sequential loops by prioritizing execution of instructions\r\non the (recurrence) critical path. Promotion builds on this\r\nidea and extracts parallelism from long dependence chains by\r\npromoting (thus prioritizing) launches on the critical path.\r\nProducer-consumer patterns on GPUs have received mod\u0002erate attention. Kernel Weaver [36] fuses producer-consumer\r\nkernels performing relational algebra operations, but this was\r\nbefore dynamic parallelism was introduced. KLAP specifically\r\ntargets producer-consumer patterns expressed with dynamic\r\nparallelism. Our benchmarks include relational operations.\r\nGomez-Luna et al. [5] introduce a set of GPU algorithms ´\r\n(called data sliding algorithms) that perform promotion with\r\naggregation and overlap through libraries. However, Gomez- ´\r\nLuna et al. do not connect promotion techniques with recursion\r\nusing dynamic parallelism for better programmability. KLAP\r\nmakes this connection, and introduces the promotion tech\u0002niques to resolve the depth limitation of dynamic parallelism.\r\nIt applies compiler transformations to convert naive CDP to\r\npromoted CDP. KLAP further isolates the effects of promo\u0002tion, aggregation, and overlap.\r\nVI. CONCLUSION\r\nIn this paper, we have presented KLAP, a set of compiler\r\ntechniques that improve the performance of programs that use\r\ndynamic parallelism on current hardware. KLAP is comprised\r\nof two main transformation techniques: kernel launch aggre\u0002gation and kernel launch promotion.\r\nKernel launch aggregation fuses kernels launched by mul\u0002tiple threads into a single aggregated kernel launch. It can\r\nbe applied at warp, block, or kernel granularity. The benefit\r\nof aggregation is that it reduces the number of launches and\r\nmakes kernels coarser which improves device occupancy.\r\nKernel launch promotion optimizes kernels with producer\u0002consumer relations by launching children kernels earlier than\r\ntheir original call site and enforcing dependence via release\u0002acquire chains. Promotion also enables two further optimiza\u0002tions: aggregation and overlap. Aggregation vertically fuses\r\ndescendants into a single aggregated kernel which improves\r\noccupancy and addresses the problem of limited call depth.\r\nOverlap increases instruction throughput by executing the\r\nindependent part of a child kernel concurrently with its parent.\r\nWe have shown that kernel launch aggregation at varying\r\ngranularities and kernel launch promotion with aggregation\r\nand overlap result in significant speedups on multiple architec\u0002tures for a variety of applications using dynamic parallelism.\r\nACKNOWLEDGMENTS\r\nThis work is supported by the NVIDIA GPU Center of\r\nExcellence at the University of Illinois, Hewlett-Packard Enter\u0002prise Labs, the Starnet Center for Future Architecture Research\r\n(C-FAR), and the Blue Waters PAID Use of Accelerators (NSF\r\nOCI 07-25070 490595).\r\n__global__ void child(float* param1, unsigned int param2) {\r\n doChildWork(blockIdx.x, blockDim.x);\r\n}\r\n__global__ void parent(float* param1, unsigned int param2) {\r\n ...\r\n if(cond) {\r\n foo();\r\n child <<< gD, bD >>> (arg1, arg2);\r\n }\r\n ...\r\n} Original Code\r\n__global__ void child_agg(float ** __param1_array, unsigned int* __param2_array,\r\n unsigned int* __gD_array, unsigned int* __bD_array, char* __mem_pool,\r\n unsigned int* __free_idx) {\r\n // Identify parent\r\n unsigned int __parent_id = __block_find_parent_id(__gD_array, blockIdx.x);\r\n // Load params/configs\r\n float * param1 = __param1_array[__parent_id];\r\n unsigned int param2 = __param2_array[__parent_id];\r\n unsigned int __blockDim_x = __bD_array[__parent_id];\r\n unsigned int __blockIdx_x =\r\n blockIdx.x - ((__parent_id == 0)?0:__gD_array[__parent_id - 1]);\r\n // Execute original kernel code\r\n if(threadIdx.x < __blockDim_x) {\r\n doChildWork(__blockIdx_x, __blockDim_x);\r\n} }\r\n__global__ void parent(float* param1, unsigned int param2, char* __mem_pool,\r\n unsigned int* __free_idx) {\r\n ...\r\n unsigned int __pred0 = (cond)?1:0;\r\n if(__pred0) {\r\n foo();\r\n }\r\n // Setup aggregated kernel launch\r\n { // Allocate memory for param/config arrays\r\n unsigned int __i = threadIdx.x;\r\n __shared__ char* __local_mem_pool;\r\n if(threadIdx.x == 0) {\r\n unsigned int __local_mem_pool_size = blockDim.x*(sizeof(float*)\r\n + sizeof(unsigned int) + 2*sizeof(unsigned int) /*gD,bD*/);\r\n __local_mem_pool = \r\n __mem_pool + atomicAdd(__free_idx, __local_mem_pool_size);\r\n }\r\n __syncthreads();\r\n char* __my_pool = __local_mem_pool;\r\n float ** __param1_array = (float **) __my_pool;\r\n __my_pool += blockDim.x*sizeof(float *);\r\n unsigned int* __param2_array = (unsigned int*) __my_pool;\r\n __my_pool += blockDim.x*sizeof(unsigned int);\r\n unsigned int* __gD_array = (unsigned int*) __my_pool;\r\n __my_pool += blockDim.x*sizeof(unsigned int);\r\n unsigned int* __bD_array = (unsigned int*) __my_pool;\r\n // Store params/configs\r\n __param1_array[__i] = arg1;\r\n __param2_array[__i] = arg2;\r\n __gD_array[__i] = __pred0 * gD;\r\n __bD_array[__i] = bD;\r\n // Calculate aggregated configs\r\n unsigned int __sum_gD = __block_inclusive_scan(__gD_array);\r\n unsigned int __max_bD = __block_max(__bD_array);\r\n // Launch aggregated kernel\r\n if(threadIdx.x == blockDim.x - 1) {\r\n if(__sum_gD > 0) {\r\n child_agg <<< __sum_gD, __max_bD >>> (__param1_array,\r\n __param2_array, __gD_array, __bD_array, __mem_pool,\r\n __free_idx);\r\n} } } }\r\n Transformed Code (block-granularity aggregation)\r\nFig. 12. Detailed Code for Block-granularity Aggregation",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/d59b8a97-9db9-4aba-843a-3163ba58b479.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a8ec110ddd27194bd62ef720e3e4f81633fe9d0015fc5c2d2b9349aca3705ef0",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 683
      },
      {
        "segments": [
          {
            "segment_id": "d59b8a97-9db9-4aba-843a-3163ba58b479",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 11,
            "page_width": 612,
            "page_height": 792,
            "content": "B. Kernel Launch Promotion\r\nDecoupled Software Pipelining [35] extracts parallelism\r\nfrom sequential loops by prioritizing execution of instructions\r\non the (recurrence) critical path. Promotion builds on this\r\nidea and extracts parallelism from long dependence chains by\r\npromoting (thus prioritizing) launches on the critical path.\r\nProducer-consumer patterns on GPUs have received mod\u0002erate attention. Kernel Weaver [36] fuses producer-consumer\r\nkernels performing relational algebra operations, but this was\r\nbefore dynamic parallelism was introduced. KLAP specifically\r\ntargets producer-consumer patterns expressed with dynamic\r\nparallelism. Our benchmarks include relational operations.\r\nGomez-Luna et al. [5] introduce a set of GPU algorithms ´\r\n(called data sliding algorithms) that perform promotion with\r\naggregation and overlap through libraries. However, Gomez- ´\r\nLuna et al. do not connect promotion techniques with recursion\r\nusing dynamic parallelism for better programmability. KLAP\r\nmakes this connection, and introduces the promotion tech\u0002niques to resolve the depth limitation of dynamic parallelism.\r\nIt applies compiler transformations to convert naive CDP to\r\npromoted CDP. KLAP further isolates the effects of promo\u0002tion, aggregation, and overlap.\r\nVI. CONCLUSION\r\nIn this paper, we have presented KLAP, a set of compiler\r\ntechniques that improve the performance of programs that use\r\ndynamic parallelism on current hardware. KLAP is comprised\r\nof two main transformation techniques: kernel launch aggre\u0002gation and kernel launch promotion.\r\nKernel launch aggregation fuses kernels launched by mul\u0002tiple threads into a single aggregated kernel launch. It can\r\nbe applied at warp, block, or kernel granularity. The benefit\r\nof aggregation is that it reduces the number of launches and\r\nmakes kernels coarser which improves device occupancy.\r\nKernel launch promotion optimizes kernels with producer\u0002consumer relations by launching children kernels earlier than\r\ntheir original call site and enforcing dependence via release\u0002acquire chains. Promotion also enables two further optimiza\u0002tions: aggregation and overlap. Aggregation vertically fuses\r\ndescendants into a single aggregated kernel which improves\r\noccupancy and addresses the problem of limited call depth.\r\nOverlap increases instruction throughput by executing the\r\nindependent part of a child kernel concurrently with its parent.\r\nWe have shown that kernel launch aggregation at varying\r\ngranularities and kernel launch promotion with aggregation\r\nand overlap result in significant speedups on multiple architec\u0002tures for a variety of applications using dynamic parallelism.\r\nACKNOWLEDGMENTS\r\nThis work is supported by the NVIDIA GPU Center of\r\nExcellence at the University of Illinois, Hewlett-Packard Enter\u0002prise Labs, the Starnet Center for Future Architecture Research\r\n(C-FAR), and the Blue Waters PAID Use of Accelerators (NSF\r\nOCI 07-25070 490595).\r\n__global__ void child(float* param1, unsigned int param2) {\r\n doChildWork(blockIdx.x, blockDim.x);\r\n}\r\n__global__ void parent(float* param1, unsigned int param2) {\r\n ...\r\n if(cond) {\r\n foo();\r\n child <<< gD, bD >>> (arg1, arg2);\r\n }\r\n ...\r\n} Original Code\r\n__global__ void child_agg(float ** __param1_array, unsigned int* __param2_array,\r\n unsigned int* __gD_array, unsigned int* __bD_array, char* __mem_pool,\r\n unsigned int* __free_idx) {\r\n // Identify parent\r\n unsigned int __parent_id = __block_find_parent_id(__gD_array, blockIdx.x);\r\n // Load params/configs\r\n float * param1 = __param1_array[__parent_id];\r\n unsigned int param2 = __param2_array[__parent_id];\r\n unsigned int __blockDim_x = __bD_array[__parent_id];\r\n unsigned int __blockIdx_x =\r\n blockIdx.x - ((__parent_id == 0)?0:__gD_array[__parent_id - 1]);\r\n // Execute original kernel code\r\n if(threadIdx.x < __blockDim_x) {\r\n doChildWork(__blockIdx_x, __blockDim_x);\r\n} }\r\n__global__ void parent(float* param1, unsigned int param2, char* __mem_pool,\r\n unsigned int* __free_idx) {\r\n ...\r\n unsigned int __pred0 = (cond)?1:0;\r\n if(__pred0) {\r\n foo();\r\n }\r\n // Setup aggregated kernel launch\r\n { // Allocate memory for param/config arrays\r\n unsigned int __i = threadIdx.x;\r\n __shared__ char* __local_mem_pool;\r\n if(threadIdx.x == 0) {\r\n unsigned int __local_mem_pool_size = blockDim.x*(sizeof(float*)\r\n + sizeof(unsigned int) + 2*sizeof(unsigned int) /*gD,bD*/);\r\n __local_mem_pool = \r\n __mem_pool + atomicAdd(__free_idx, __local_mem_pool_size);\r\n }\r\n __syncthreads();\r\n char* __my_pool = __local_mem_pool;\r\n float ** __param1_array = (float **) __my_pool;\r\n __my_pool += blockDim.x*sizeof(float *);\r\n unsigned int* __param2_array = (unsigned int*) __my_pool;\r\n __my_pool += blockDim.x*sizeof(unsigned int);\r\n unsigned int* __gD_array = (unsigned int*) __my_pool;\r\n __my_pool += blockDim.x*sizeof(unsigned int);\r\n unsigned int* __bD_array = (unsigned int*) __my_pool;\r\n // Store params/configs\r\n __param1_array[__i] = arg1;\r\n __param2_array[__i] = arg2;\r\n __gD_array[__i] = __pred0 * gD;\r\n __bD_array[__i] = bD;\r\n // Calculate aggregated configs\r\n unsigned int __sum_gD = __block_inclusive_scan(__gD_array);\r\n unsigned int __max_bD = __block_max(__bD_array);\r\n // Launch aggregated kernel\r\n if(threadIdx.x == blockDim.x - 1) {\r\n if(__sum_gD > 0) {\r\n child_agg <<< __sum_gD, __max_bD >>> (__param1_array,\r\n __param2_array, __gD_array, __bD_array, __mem_pool,\r\n __free_idx);\r\n} } } }\r\n Transformed Code (block-granularity aggregation)\r\nFig. 12. Detailed Code for Block-granularity Aggregation",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/d59b8a97-9db9-4aba-843a-3163ba58b479.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a8ec110ddd27194bd62ef720e3e4f81633fe9d0015fc5c2d2b9349aca3705ef0",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 683
      },
      {
        "segments": [
          {
            "segment_id": "51b22fca-99ae-4e59-8144-62c7758985fb",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 12,
            "page_width": 612,
            "page_height": 792,
            "content": "REFERENCES\r\n[1] S. Jones, “Introduction to dynamic parallelism,” in GPU Technology\r\nConference Presentation, 2012.\r\n[2] W. H. Wen-mei, Heterogeneous System Architecture: A new compute\r\nplatform infrastructure. Morgan Kaufmann, 2015.\r\n[3] P. Zhang, E. Holk, J. Matty, S. Misurda, M. Zalewski, J. Chu, S. McMil\u0002lan, and A. Lumsdaine, “Dynamic parallelism for simple and efficient\r\ngpu graph algorithms,” in Proceedings of the 5th Workshop on Irregular\r\nApplications: Architectures and Algorithms, IA3 ’15, pp. 11:1–11:4,\r\nACM, 2015.\r\n[4] M. L. Sætra, A. R. Brodtkorb, and K.-A. Lie, “Efficient gpu\u0002implementation of adaptive mesh refinement for the shallow-water\r\nequations,” Journal of Scientific Computing, vol. 63, no. 1, pp. 23–48,\r\n2015.\r\n[5] J. Gomez-Luna, L.-W. Chang, I.-J. Sung, W.-M. Hwu, and N. Guil, “In- ´\r\nplace data sliding algorithms for many-core architectures,” in Parallel\r\nProcessing (ICPP), 2015 44th International Conference on, pp. 210–\r\n219, IEEE, 2015.\r\n[6] J. Wang and S. Yalamanchili, “Characterization and analysis of dynamic\r\nparallelism in unstructured GPU applications,” in Workload Character\u0002ization (IISWC), 2014 IEEE International Symposium on, pp. 51–60,\r\nIEEE, 2014.\r\n[7] Y. Yang and H. Zhou, “CUDA-NP: Realizing nested thread-level par\u0002allelism in GPGPU applications,” in ACM SIGPLAN Notices, vol. 49,\r\npp. 93–106, ACM, 2014.\r\n[8] “A CUDA dynamic parallelism case study: PANDA.”\r\nhttps://devblogs.nvidia.com/parallelforall/a-cuda-dynamic-parallelism\u0002case-study-panda/. Accessed: 2016-04-01.\r\n[9] J. Wang, N. Rubin, A. Sidelnik, and S. Yalamanchili, “Dynamic thread\r\nblock launch: A lightweight execution mechanism to support irregular\r\napplications on GPUs,” in Proceedings of the 42nd Annual International\r\nSymposium on Computer Architecture, pp. 528–540, ACM, 2015.\r\n[10] G. Chen and X. Shen, “Free launch: optimizing GPU dynamic kernel\r\nlaunches through thread reuse,” in Proceedings of the 48th International\r\nSymposium on Microarchitecture, pp. 407–419, ACM, 2015.\r\n[11] T. Kaldewey, J. Hagen, A. Di Blas, and E. Sedlar, “Parallel search on\r\nvideo cards,” in Proceedings of the First USENIX Conference on Hot\r\nTopics in Parallelism, HotPar’09, p. 9, USENIX Association, 2009.\r\n[12] D. Merrill, “CUB:kernel-level software reuse and library design,” in\r\nGPU Technology Conference Presentation, 2013.\r\n[13] P. Ja¨askel ¨ ainen, C. S. de La Lama, E. Schnetter, K. Raiskila, J. Takala, ¨\r\nand H. Berg, “pocl: A performance-portable OpenCL implementation,”\r\nInternational Journal of Parallel Programming, vol. 43, no. 5, pp. 752–\r\n785, 2015.\r\n[14] K. Asanovic, S. W. Keckler, Y. Lee, R. Krashinsky, and V. Grover,\r\n“Convergence and scalarization for data-parallel architectures,” in Pro\u0002ceedings of the 2013 IEEE/ACM International Symposium on Code\r\nGeneration and Optimization (CGO), pp. 1–11, IEEE Computer Society,\r\n2013.\r\n[15] M. Billeter, O. Olsson, and U. Assarsson, “Efficient stream compaction\r\non wide SIMD many-core architectures,” in Proceedings of the Con\u0002ference on High Performance Graphics 2009, HPG ’09, pp. 159–166,\r\nACM, 2009.\r\n[16] L. Howes and A. Munshi, “The OpenCL specification, version 2.0,”\r\nKhronos Group, 2015.\r\n[17] S. Yan, G. Long, and Y. Zhang, “StreamScan: Fast scan algorithms for\r\nGPUs without global barrier synchronization,” in Proceedings of the\r\n18th ACM SIGPLAN Symposium on Principles and Practice of Parallel\r\nProgramming, PPoPP ’13, pp. 229–238, ACM, 2013.\r\n[18] A. Danalis, G. Marin, C. McCurdy, J. S. Meredith, P. C. Roth, K. Spaf\u0002ford, V. Tipparaju, and J. S. Vetter, “The scalable heterogeneous comput\u0002ing (SHOC) benchmark suite,” in Proceedings of the 3rd Workshop on\r\nGeneral-Purpose Computation on Graphics Processing Units, GPGPU\u00023, pp. 63–74, ACM, 2010.\r\n[19] M. Burtscher, R. Nasre, and K. Pingali, “A quantitative study of irregular\r\nprograms on GPUs,” in Workload Characterization (IISWC), 2012 IEEE\r\nInternational Symposium on, pp. 141–151, Nov 2012.\r\n[20] NVIDIA, “CUDA samples v. 7.5,” 2015.\r\n[21] Y. Ukidave, F. N. Paravecino, L. Yu, C. Kalra, A. Momeni, Z. Chen,\r\nN. Materise, B. Daley, P. Mistry, and D. Kaeli, “NUPAR: A bench\u0002mark suite for modern GPU architectures,” in Proceedings of the\r\n6th ACM/SPEC International Conference on Performance Engineering,\r\nICPE ’15, pp. 253–264, ACM, 2015.\r\n[22] A. V. P. Grosset, P. Zhu, S. Liu, S. Venkatasubramanian, and M. Hall,\r\n“Evaluating graph coloring on GPUs,” in Proceedings of the 16th ACM\r\nSymposium on Principles and Practice of Parallel Programming, PPoPP\r\n’11, pp. 297–298, ACM, 2011.\r\n[23] “Matrix market.” http://math.nist.gov/MatrixMarket/. Accessed: 2016-\r\n04-01.\r\n[24] N. Bell and J. Hoberock, “Thrust: a productivity-oriented library for\r\ncuda,” GPU Computing Gems: Jade Edition, 2012.\r\n[25] “GPU pro tip: CUDA 7 streams simplify concurrency.”\r\nhttp://devblogs.nvidia.com/parallelforall/gpu-pro-tip-cuda-7-streams\u0002simplify-concurrency/. Accessed: 2016-04-01.\r\n[26] “CUDA dynamic parallelism API and principles.” https://devblogs.\r\nnvidia.com/parallelforall/cuda-dynamic-parallelism-api-principles/. Ac\u0002cessed: 2016-04-10.\r\n[27] NVIDIA, “Profiler user’s guide v. 7.5,” 2015.\r\n[28] J. Wang, N. Rubin, A. Sidelnik, and S. Yalamanchili, “Laperm: Lo\u0002cality aware scheduler for dynamic parallelism on gpus,” in The 43rd\r\nInternational Symposium on Computer Architecture (ISCA), June 2016.\r\n[29] M. S. Orr, B. M. Beckmann, S. K. Reinhardt, and D. A. Wood, “Fine\u0002grain task aggregation and coordination on GPUs,” in ACM SIGARCH\r\nComputer Architecture News, vol. 42, pp. 181–192, IEEE Press, 2014.\r\n[30] K. Gupta, J. A. Stuart, and J. D. Owens, “A study of persistent threads\r\nstyle GPU programming for gpgpu workloads,” in Innovative Parallel\r\nComputing (InPar), 2012, pp. 1–14, IEEE, 2012.\r\n[31] G. Chen and X. Shen. private communication.\r\n[32] M. Guevara, C. Gregg, K. Hazelwood, and K. Skadron, “Enabling task\r\nparallelism in the cuda scheduler,” in Workshop on Programming Models\r\nfor Emerging Architectures, vol. 9, 2009.\r\n[33] D. Li, H. Wu, and M. Becchi, “Nested parallelism on GPU: Exploring\r\nparallelization templates for irregular loops and recursive computations,”\r\nin Parallel Processing (ICPP), 2015 44th International Conference on,\r\npp. 979–988, IEEE, 2015.\r\n[34] B. Ren, Y. Jo, S. Krishnamoorthy, K. Agrawal, and M. Kulkarni, “Effi\u0002cient execution of recursive programs on commodity vector hardware,”\r\nin Proceedings of the 36th ACM SIGPLAN Conference on Programming\r\nLanguage Design and Implementation, pp. 509–520, ACM, 2015.\r\n[35] R. Rangan, N. Vachharajani, M. Vachharajani, and D. I. August, “Decou\u0002pled software pipelining with the synchronization array,” in Proceedings\r\nof the 13th International Conference on Parallel Architectures and\r\nCompilation Techniques, pp. 177–188, IEEE Computer Society, 2004.\r\n[36] H. Wu, G. Diamos, S. Cadambi, and S. Yalamanchili, “Kernel weaver:\r\nAutomatically fusing database primitives for efficient GPU computa\u0002tion,” in Proceedings of the 2012 45th Annual IEEE/ACM International\r\nSymposium on Microarchitecture, pp. 107–118, IEEE Computer Society,\r\n2012.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/51b22fca-99ae-4e59-8144-62c7758985fb.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c2cb129e7304d5c536678248f276cba52ec277dc461408ff859db832693ea43f",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 987
      },
      {
        "segments": [
          {
            "segment_id": "51b22fca-99ae-4e59-8144-62c7758985fb",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 12,
            "page_width": 612,
            "page_height": 792,
            "content": "REFERENCES\r\n[1] S. Jones, “Introduction to dynamic parallelism,” in GPU Technology\r\nConference Presentation, 2012.\r\n[2] W. H. Wen-mei, Heterogeneous System Architecture: A new compute\r\nplatform infrastructure. Morgan Kaufmann, 2015.\r\n[3] P. Zhang, E. Holk, J. Matty, S. Misurda, M. Zalewski, J. Chu, S. McMil\u0002lan, and A. Lumsdaine, “Dynamic parallelism for simple and efficient\r\ngpu graph algorithms,” in Proceedings of the 5th Workshop on Irregular\r\nApplications: Architectures and Algorithms, IA3 ’15, pp. 11:1–11:4,\r\nACM, 2015.\r\n[4] M. L. Sætra, A. R. Brodtkorb, and K.-A. Lie, “Efficient gpu\u0002implementation of adaptive mesh refinement for the shallow-water\r\nequations,” Journal of Scientific Computing, vol. 63, no. 1, pp. 23–48,\r\n2015.\r\n[5] J. Gomez-Luna, L.-W. Chang, I.-J. Sung, W.-M. Hwu, and N. Guil, “In- ´\r\nplace data sliding algorithms for many-core architectures,” in Parallel\r\nProcessing (ICPP), 2015 44th International Conference on, pp. 210–\r\n219, IEEE, 2015.\r\n[6] J. Wang and S. Yalamanchili, “Characterization and analysis of dynamic\r\nparallelism in unstructured GPU applications,” in Workload Character\u0002ization (IISWC), 2014 IEEE International Symposium on, pp. 51–60,\r\nIEEE, 2014.\r\n[7] Y. Yang and H. Zhou, “CUDA-NP: Realizing nested thread-level par\u0002allelism in GPGPU applications,” in ACM SIGPLAN Notices, vol. 49,\r\npp. 93–106, ACM, 2014.\r\n[8] “A CUDA dynamic parallelism case study: PANDA.”\r\nhttps://devblogs.nvidia.com/parallelforall/a-cuda-dynamic-parallelism\u0002case-study-panda/. Accessed: 2016-04-01.\r\n[9] J. Wang, N. Rubin, A. Sidelnik, and S. Yalamanchili, “Dynamic thread\r\nblock launch: A lightweight execution mechanism to support irregular\r\napplications on GPUs,” in Proceedings of the 42nd Annual International\r\nSymposium on Computer Architecture, pp. 528–540, ACM, 2015.\r\n[10] G. Chen and X. Shen, “Free launch: optimizing GPU dynamic kernel\r\nlaunches through thread reuse,” in Proceedings of the 48th International\r\nSymposium on Microarchitecture, pp. 407–419, ACM, 2015.\r\n[11] T. Kaldewey, J. Hagen, A. Di Blas, and E. Sedlar, “Parallel search on\r\nvideo cards,” in Proceedings of the First USENIX Conference on Hot\r\nTopics in Parallelism, HotPar’09, p. 9, USENIX Association, 2009.\r\n[12] D. Merrill, “CUB:kernel-level software reuse and library design,” in\r\nGPU Technology Conference Presentation, 2013.\r\n[13] P. Ja¨askel ¨ ainen, C. S. de La Lama, E. Schnetter, K. Raiskila, J. Takala, ¨\r\nand H. Berg, “pocl: A performance-portable OpenCL implementation,”\r\nInternational Journal of Parallel Programming, vol. 43, no. 5, pp. 752–\r\n785, 2015.\r\n[14] K. Asanovic, S. W. Keckler, Y. Lee, R. Krashinsky, and V. Grover,\r\n“Convergence and scalarization for data-parallel architectures,” in Pro\u0002ceedings of the 2013 IEEE/ACM International Symposium on Code\r\nGeneration and Optimization (CGO), pp. 1–11, IEEE Computer Society,\r\n2013.\r\n[15] M. Billeter, O. Olsson, and U. Assarsson, “Efficient stream compaction\r\non wide SIMD many-core architectures,” in Proceedings of the Con\u0002ference on High Performance Graphics 2009, HPG ’09, pp. 159–166,\r\nACM, 2009.\r\n[16] L. Howes and A. Munshi, “The OpenCL specification, version 2.0,”\r\nKhronos Group, 2015.\r\n[17] S. Yan, G. Long, and Y. Zhang, “StreamScan: Fast scan algorithms for\r\nGPUs without global barrier synchronization,” in Proceedings of the\r\n18th ACM SIGPLAN Symposium on Principles and Practice of Parallel\r\nProgramming, PPoPP ’13, pp. 229–238, ACM, 2013.\r\n[18] A. Danalis, G. Marin, C. McCurdy, J. S. Meredith, P. C. Roth, K. Spaf\u0002ford, V. Tipparaju, and J. S. Vetter, “The scalable heterogeneous comput\u0002ing (SHOC) benchmark suite,” in Proceedings of the 3rd Workshop on\r\nGeneral-Purpose Computation on Graphics Processing Units, GPGPU\u00023, pp. 63–74, ACM, 2010.\r\n[19] M. Burtscher, R. Nasre, and K. Pingali, “A quantitative study of irregular\r\nprograms on GPUs,” in Workload Characterization (IISWC), 2012 IEEE\r\nInternational Symposium on, pp. 141–151, Nov 2012.\r\n[20] NVIDIA, “CUDA samples v. 7.5,” 2015.\r\n[21] Y. Ukidave, F. N. Paravecino, L. Yu, C. Kalra, A. Momeni, Z. Chen,\r\nN. Materise, B. Daley, P. Mistry, and D. Kaeli, “NUPAR: A bench\u0002mark suite for modern GPU architectures,” in Proceedings of the\r\n6th ACM/SPEC International Conference on Performance Engineering,\r\nICPE ’15, pp. 253–264, ACM, 2015.\r\n[22] A. V. P. Grosset, P. Zhu, S. Liu, S. Venkatasubramanian, and M. Hall,\r\n“Evaluating graph coloring on GPUs,” in Proceedings of the 16th ACM\r\nSymposium on Principles and Practice of Parallel Programming, PPoPP\r\n’11, pp. 297–298, ACM, 2011.\r\n[23] “Matrix market.” http://math.nist.gov/MatrixMarket/. Accessed: 2016-\r\n04-01.\r\n[24] N. Bell and J. Hoberock, “Thrust: a productivity-oriented library for\r\ncuda,” GPU Computing Gems: Jade Edition, 2012.\r\n[25] “GPU pro tip: CUDA 7 streams simplify concurrency.”\r\nhttp://devblogs.nvidia.com/parallelforall/gpu-pro-tip-cuda-7-streams\u0002simplify-concurrency/. Accessed: 2016-04-01.\r\n[26] “CUDA dynamic parallelism API and principles.” https://devblogs.\r\nnvidia.com/parallelforall/cuda-dynamic-parallelism-api-principles/. Ac\u0002cessed: 2016-04-10.\r\n[27] NVIDIA, “Profiler user’s guide v. 7.5,” 2015.\r\n[28] J. Wang, N. Rubin, A. Sidelnik, and S. Yalamanchili, “Laperm: Lo\u0002cality aware scheduler for dynamic parallelism on gpus,” in The 43rd\r\nInternational Symposium on Computer Architecture (ISCA), June 2016.\r\n[29] M. S. Orr, B. M. Beckmann, S. K. Reinhardt, and D. A. Wood, “Fine\u0002grain task aggregation and coordination on GPUs,” in ACM SIGARCH\r\nComputer Architecture News, vol. 42, pp. 181–192, IEEE Press, 2014.\r\n[30] K. Gupta, J. A. Stuart, and J. D. Owens, “A study of persistent threads\r\nstyle GPU programming for gpgpu workloads,” in Innovative Parallel\r\nComputing (InPar), 2012, pp. 1–14, IEEE, 2012.\r\n[31] G. Chen and X. Shen. private communication.\r\n[32] M. Guevara, C. Gregg, K. Hazelwood, and K. Skadron, “Enabling task\r\nparallelism in the cuda scheduler,” in Workshop on Programming Models\r\nfor Emerging Architectures, vol. 9, 2009.\r\n[33] D. Li, H. Wu, and M. Becchi, “Nested parallelism on GPU: Exploring\r\nparallelization templates for irregular loops and recursive computations,”\r\nin Parallel Processing (ICPP), 2015 44th International Conference on,\r\npp. 979–988, IEEE, 2015.\r\n[34] B. Ren, Y. Jo, S. Krishnamoorthy, K. Agrawal, and M. Kulkarni, “Effi\u0002cient execution of recursive programs on commodity vector hardware,”\r\nin Proceedings of the 36th ACM SIGPLAN Conference on Programming\r\nLanguage Design and Implementation, pp. 509–520, ACM, 2015.\r\n[35] R. Rangan, N. Vachharajani, M. Vachharajani, and D. I. August, “Decou\u0002pled software pipelining with the synchronization array,” in Proceedings\r\nof the 13th International Conference on Parallel Architectures and\r\nCompilation Techniques, pp. 177–188, IEEE Computer Society, 2004.\r\n[36] H. Wu, G. Diamos, S. Cadambi, and S. Yalamanchili, “Kernel weaver:\r\nAutomatically fusing database primitives for efficient GPU computa\u0002tion,” in Proceedings of the 2012 45th Annual IEEE/ACM International\r\nSymposium on Microarchitecture, pp. 107–118, IEEE Computer Society,\r\n2012.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/32ff25b9-c174-4ac1-8665-749a83230489/images/51b22fca-99ae-4e59-8144-62c7758985fb.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041422Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c2cb129e7304d5c536678248f276cba52ec277dc461408ff859db832693ea43f",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 987
      }
    ],
    "extracted_json": {
      "title": "Document Metadata",
      "schema_type": "object",
      "extracted_fields": [
        {
          "name": "title",
          "field_type": "string",
          "value": "```json\n{\"title\": \"KLAP: Kernel Launch Aggregation and Promotion for Optimizing Dynamic Parallelism\"}\n```"
        },
        {
          "name": "author",
          "field_type": "string",
          "value": "Izzat El Hajj, Juan Gomez-Luna, Cheng Li, Li-Wen Chang, Dejan Milojicic, Wen-mei Hwu\n"
        },
        {
          "name": "date_published",
          "field_type": "string",
          "value": "2016\n"
        },
        {
          "name": "location",
          "field_type": "string",
          "value": "Medium datasets.\nLarge datasets.\n"
        }
      ]
    }
  }
}