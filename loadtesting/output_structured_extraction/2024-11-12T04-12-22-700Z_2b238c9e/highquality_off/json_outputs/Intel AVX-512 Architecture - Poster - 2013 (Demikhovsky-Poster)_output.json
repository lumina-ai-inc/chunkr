{
  "file_name": "Intel AVX-512 Architecture - Poster - 2013 (Demikhovsky-Poster).pdf",
  "task_id": "70b15ad8-069a-493a-83ef-34f70ac63255",
  "output": {
    "chunks": [
      {
        "segments": [
          {
            "segment_id": "a0a23555-e97c-4c3e-932c-cda7c24fa465",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 3370.8,
              "height": 2384.28
            },
            "page_number": 1,
            "page_width": 3370.8,
            "page_height": 2384.28,
            "content": "Intel® AVX-512 Architecture \r\nComprehensive vector extension for HPC and enterprise\r\n 512-bit wide vectors, 32 SIMD \r\nregisters\r\n 8 new mask registers\r\n Embedded Rounding Control\r\n Embedded Broadcast\r\n New Math instructions\r\n 2-source shuffles\r\n Gather and Scatter\r\n Compress and Expand\r\n Conflict Detection\r\nAVX-512 – What’s new?\r\nKNL\r\nSSE*\r\nAVX\r\nAVX2\r\nSNB\r\nSSE*\r\nAVX\r\nHSW\r\nSSE*\r\nAVX\r\nAVX2\r\nNHM\r\nSSE*\r\nAVX\u0002512\r\nAVX-512 \r\nFoundation\r\nExponential and \r\nReciprocal\r\nPrefetching\r\nConflict Detection\r\n32 SIMD registers 512 bit wide\r\nMore And Bigger Registers\r\nSparse computations are hard for vectorization\r\nCode above is wrong if any values within B[i] are duplicated\r\nVPCONFLICT instruction detects elements with conflicts\r\nConflict Detection\r\nfor(i=0; i<16; i++) { A[B[i]]++; }\r\nindex = vload &B[i] // Load 16 B[i]\r\nold_val = vgather A, index // Grab A[B[i]]\r\nnew_val = vadd old_val, +1.0 // Compute new values\r\nvscatter A, index, new_val // Update A[B[i]]\r\nindex = vload &B[i] // Load 16 B[i]\r\npending_elem = 0xFFFF;\r\ndo { \r\n curr_elem = get_conflict_free_subset(index, pending_elem)\r\n old_val = vgather {curr_elem} A, index // Grab A[B[i]]\r\n new_val = vadd old_val, +1.0 // Compute new values\r\n vscatter A {curr_elem}, index, new_val // Update A[B[i]]\r\n pending_elem = pending_elem ^ curr_elem // remove done idx\r\n} while (pending_elem)\r\nCompress And Expand\r\nCompress values from 512-bit vectors compound of f64, f32, i64, i32 \r\nelements using mask and store in register or memory\r\nVCOMPRESSPD zmm1/mV {k1}, zmm2\r\nVEXPANDPS zmm1 {k1}{z}, zmm2/mV\r\nA0 A1 A2 A3\r\nA1 A2 A3 A6\r\nA4 A5 A6 A7\r\nA7\r\nMask: k[] = 01110011 Zeroed in the \r\nregister form\r\ncompress\r\nX A0 A1 A2\r\nA0 A1 A2 A3\r\nX X A3 A4\r\nA4\r\nMask: k[] = 01110011\r\nAll “X” are \r\nzeroed or \r\nremain \r\nunchanged\r\nexpand\r\nfor (i =0; i < N; i++) {\r\n if (topVal > b[i]) {\r\n *dst = a[i]; \r\n dst++;\r\n }\r\n}\r\nCMP %regMask, ops\r\n… \r\nADD %regA1, x1, y1\r\n…\r\nADD %regA2 = x2, y2\r\nBLEND %regA, %regMask, %regA1, %regA2\r\nPredication Scheme \r\nIf (condition) {\r\n A = ..\r\n} else {\r\n A = ..\r\n}\r\nSource code\r\nMachine code\r\n%Mask = cmp (condition)\r\n…\r\n%A1 = \r\n…\r\n%A2 =\r\n%A = SELECT %Mask, %A1, %A2\r\nLLVM IR\r\nMask = cmp (condition)\r\nNot-Mask = not(Mask) \r\n{Mask} C1 = \r\n{Mask} B1 = \r\n{Mask} A = B1+C1\r\n \r\n{Not-Mask} C2 = \r\n{Not-Mask} B2 = \r\n{Not-Mask} A = B2+C2\r\nGoal:\r\nTo set predicates for instructions that calculate A1 \r\nand A2 (Mask and Not-Mask)\r\nResult: \r\nIf the mask is all-zero, instruction will not be \r\nexecuted. \r\nMask Propagation Pass – design ideas \r\ntopVal = \r\nMask = cmp() \r\n \r\nC1 = topVal*2 \r\nB1 = \r\nA1 = B1 + C1 \r\nC2 = \r\nB2 = \r\nA2 = B2 + C2 \r\nA = BLEND(Mask, A1, A2) \r\nA new Machine Pass:\r\n• Before register allocation\r\n• Start from the “blend” operands and go up recursively till mask definition\r\n• Check all users of the destination operand before applying the mask\r\nPredicated memory accesses in LLVM IR \r\nwould be helpful !\r\n Mask Propagation Pass does not guarantee full mask propagation \r\nover the whole path from blend to compare\r\n Load/Store operations require exact masking\r\n FP operations require masking if exceptions are not suppressed\r\n– IR generators should use compiler intrinsics\r\ntopVal = \r\nMask = cmp() \r\n \r\n C1 = topVal*2 \r\n B1 = \r\n A1 = B1 + C1 \r\n C2 = \r\n B2 = \r\n A2 = B2 + C2 \r\nA = BLEND(Mask, A1, A2) \r\nMask\r\nMask\r\nMask\r\ntopVal = \r\nMask = cmp() \r\n!Mask = Not(Mask) \r\n C1 = topVal*2 \r\n B1 = \r\n A1 = B1 + C1 \r\n C2 = \r\n B2 = \r\n A2 = B2 + C2 \r\n A = BLEND(Mask, A1, A2) \r\nMask\r\nMask\r\n!Mask\r\n!Mask\r\n!Mask\r\nMask\r\ntopVal = \r\nMask = cmp() \r\n!Mask = Not(Mask) \r\n C1 = topVal*2 \r\n B1 = \r\n A = B1 + C1 \r\n C2 = \r\n B2 = \r\n A = B2 + C2 \r\nMask\r\nMask\r\nMask\r\n!Mask\r\n!Mask\r\n!Mask\r\nMasking Masking in LLVM\r\nUnmasked elements remain \r\nunchanged:\r\nVADDPD zmm1 {k1}, zmm2, zmm3\r\nOr zeroed:\r\nVADDPD zmm1 {k1} {z}, zmm2, zmm3\r\nfloat32 A[N], B[N], C[N];\r\nfor(i=0; i<16; i++)\r\n{\r\n if (B[i] != 0)\r\n A[i] = A[i] / B[i]; \r\n else\r\n A[i] = A[i] / C[i]; \r\n}\r\nVMOVUPS zmm2, A\r\nVCMPPS k1, zmm0, B\r\nVDIVPS zmm1 {k1}{z}, zmm2, B\r\nKNOT k2, k1\r\nVDIVPS zmm1 {k2}, zmm2, C\r\nVMOVUPS A, zmm1\r\nA source from memory is repeated across all the \r\nelements. \r\n vbroadcastss zmm3, [rax]\r\n vaddps zmm1, zmm2, zmm3\r\n \r\n vaddps zmm1, zmm2, [rax] {1to16}\r\nEmbedded Broadcast\r\n• Static (per instruction) rounding rode\r\n• No need to access MXCSR any more!\r\nvaddps zmm7 {k6}, zmm2, zmm4 {rd}\r\nvcvtdq2ps zmm1, zmm2, {ru}\r\nAll exceptions are always suspended by using \r\nembedded RC\r\nEmbedded Rounding Control\r\n Memory fault suppression\r\n Avoid FP exceptions\r\n Avoid extra blends\r\nzmm1 a7 a6 a5 a4 a3 a2 a1 a0\r\nzmm2 b7 b6 b5 b4 b3 b2 b1 b0\r\nzmm3\r\nk1\r\nzmm1 b7+c7 a6 b5+c5 b4+c4 b3+c3 b2+c2 a1 a0\r\n+ + + + + + + +\r\n1 0 1 1 1 1 0 0\r\nc7 c6 c5 c4 c3 c2 c1 c0\r\nXMM0-15 128-bits\r\nYMM0-15 256-bits\r\nZMM0-31 512-bits\r\n• INFORMATION IN THIS DOCUMENT IS PROVIDED IN CONNECTION WITH INTEL PRODUCTS. NO LICENSE, EXPRESS OR IMPLIED, BY ESTOPPEL OR OTHERWISE, TO ANY INTELLECTUAL PROPERTY RIGHTS IS GRANTED BY THIS DOCUMENT. EXCEPT AS PROVIDED IN INTEL'S TERMS AND CONDITIONS OF SALE FOR SUCH PRODUCTS, INTEL ASSUMES NO LIABILITY WHATSOEVER AND INTEL DISCLAIMS ANY EXPRESS OR IMPLIED WARRANTY, RELATING TO SALE AND/OR USE OF INTEL PRODUCTS INCLUDING LIABILITY OR WARRANTIES RELATING TO FITNESS FOR A PARTICULAR PURPOSE, MERCHANTABILITY, OR INFRINGEMENT OF ANY PATENT, COPYRIGHT OR OTHER INTELLECTUAL PROPERTY RIGHT. \r\n• A \"Mission Critical Application\" is any application in which failure of the Intel Product could result, directly or indirectly, in personal injury or death. SHOULD YOU PURCHASE OR USE INTEL'S PRODUCTS FOR ANY SUCH MISSION CRITICAL APPLICATION, YOU SHALL INDEMNIFY AND HOLD INTEL AND ITS SUBSIDIARIES, SUBCONTRACTORS AND AFFILIATES, AND THE DIRECTORS, OFFICERS, AND EMPLOYEES OF EACH, HARMLESS AGAINST ALL CLAIMS COSTS, DAMAGES, AND EXPENSES AND REASONABLE ATTORNEYS' FEES ARISING OUT OF, DIRECTLY OR INDIRECTLY, ANY CLAIM OF PRODUCT LIABILITY, PERSONAL INJURY, OR DEATH ARISING IN ANY WAY OUT OF SUCH MISSION CRITICAL APPLICATION, WHETHER OR NOT INTEL OR \r\nITS SUBCONTRACTOR WAS NEGLIGENT IN THE DESIGN, MANUFACTURE, OR WARNING OF THE INTEL PRODUCT OR ANY OF ITS PARTS. \r\n• Intel may make changes to specifications and product descriptions at any time, without notice. Designers must not rely on the absence or characteristics of any features or instructions marked \"reserved\" or \"undefined\". Intel reserves these for future definition and shall have no responsibility whatsoever for conflicts or incompatibilities arising from future changes to them. The information here is subject to change without notice. Do not finalize a design with this information. \r\n• The products described in this document may contain design defects or errors known as errata which may cause the product to deviate from published specifications. Current characterized errata are available on request. \r\n• Contact your local Intel sales office or your distributor to obtain the latest specifications and before placing your product order. \r\n• Copies of documents which have an order number and are referenced in this document, or other Intel literature, may be obtained by calling 1-800-548-4725, or go to: http://www.intel.com/design/literature.htm\r\n• Intel's compilers may or may not optimize to the same degree for non-Intel microprocessors for optimizations that are not unique to Intel microprocessors. These optimizations include SSE2, SSE3, and SSE3 instruction sets and other optimizations. Intel does not guarantee the availability, functionality, or effectiveness of any optimization on microprocessors not manufactured by Intel. \r\n• Microprocessor-dependent optimizations in this product are intended for use with Intel microprocessors. Certain optimizations not specific to Intel microarchitecture are reserved for Intel microprocessors. Please refer to the applicable product User and Reference Guides for more information regarding the specific instruction sets covered by this notice.\r\n• Copyright © 2013 Intel Corporation. All rights reserved. Intel and the Intel logo are trademarks of Intel Corporation in the U.S and other countries.\r\nElena Demikhovsky\r\nIntel® Software and Services Group\r\nIsrael",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/70b15ad8-069a-493a-83ef-34f70ac63255/images/a0a23555-e97c-4c3e-932c-cda7c24fa465.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T042310Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=020a5230dfb0ad6d8e2548164baf1019e0b9495d8563061ec9dceb0d720cf216",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 1324
      },
      {
        "segments": [
          {
            "segment_id": "a0a23555-e97c-4c3e-932c-cda7c24fa465",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 3370.8,
              "height": 2384.28
            },
            "page_number": 1,
            "page_width": 3370.8,
            "page_height": 2384.28,
            "content": "Intel® AVX-512 Architecture \r\nComprehensive vector extension for HPC and enterprise\r\n 512-bit wide vectors, 32 SIMD \r\nregisters\r\n 8 new mask registers\r\n Embedded Rounding Control\r\n Embedded Broadcast\r\n New Math instructions\r\n 2-source shuffles\r\n Gather and Scatter\r\n Compress and Expand\r\n Conflict Detection\r\nAVX-512 – What’s new?\r\nKNL\r\nSSE*\r\nAVX\r\nAVX2\r\nSNB\r\nSSE*\r\nAVX\r\nHSW\r\nSSE*\r\nAVX\r\nAVX2\r\nNHM\r\nSSE*\r\nAVX\u0002512\r\nAVX-512 \r\nFoundation\r\nExponential and \r\nReciprocal\r\nPrefetching\r\nConflict Detection\r\n32 SIMD registers 512 bit wide\r\nMore And Bigger Registers\r\nSparse computations are hard for vectorization\r\nCode above is wrong if any values within B[i] are duplicated\r\nVPCONFLICT instruction detects elements with conflicts\r\nConflict Detection\r\nfor(i=0; i<16; i++) { A[B[i]]++; }\r\nindex = vload &B[i] // Load 16 B[i]\r\nold_val = vgather A, index // Grab A[B[i]]\r\nnew_val = vadd old_val, +1.0 // Compute new values\r\nvscatter A, index, new_val // Update A[B[i]]\r\nindex = vload &B[i] // Load 16 B[i]\r\npending_elem = 0xFFFF;\r\ndo { \r\n curr_elem = get_conflict_free_subset(index, pending_elem)\r\n old_val = vgather {curr_elem} A, index // Grab A[B[i]]\r\n new_val = vadd old_val, +1.0 // Compute new values\r\n vscatter A {curr_elem}, index, new_val // Update A[B[i]]\r\n pending_elem = pending_elem ^ curr_elem // remove done idx\r\n} while (pending_elem)\r\nCompress And Expand\r\nCompress values from 512-bit vectors compound of f64, f32, i64, i32 \r\nelements using mask and store in register or memory\r\nVCOMPRESSPD zmm1/mV {k1}, zmm2\r\nVEXPANDPS zmm1 {k1}{z}, zmm2/mV\r\nA0 A1 A2 A3\r\nA1 A2 A3 A6\r\nA4 A5 A6 A7\r\nA7\r\nMask: k[] = 01110011 Zeroed in the \r\nregister form\r\ncompress\r\nX A0 A1 A2\r\nA0 A1 A2 A3\r\nX X A3 A4\r\nA4\r\nMask: k[] = 01110011\r\nAll “X” are \r\nzeroed or \r\nremain \r\nunchanged\r\nexpand\r\nfor (i =0; i < N; i++) {\r\n if (topVal > b[i]) {\r\n *dst = a[i]; \r\n dst++;\r\n }\r\n}\r\nCMP %regMask, ops\r\n… \r\nADD %regA1, x1, y1\r\n…\r\nADD %regA2 = x2, y2\r\nBLEND %regA, %regMask, %regA1, %regA2\r\nPredication Scheme \r\nIf (condition) {\r\n A = ..\r\n} else {\r\n A = ..\r\n}\r\nSource code\r\nMachine code\r\n%Mask = cmp (condition)\r\n…\r\n%A1 = \r\n…\r\n%A2 =\r\n%A = SELECT %Mask, %A1, %A2\r\nLLVM IR\r\nMask = cmp (condition)\r\nNot-Mask = not(Mask) \r\n{Mask} C1 = \r\n{Mask} B1 = \r\n{Mask} A = B1+C1\r\n \r\n{Not-Mask} C2 = \r\n{Not-Mask} B2 = \r\n{Not-Mask} A = B2+C2\r\nGoal:\r\nTo set predicates for instructions that calculate A1 \r\nand A2 (Mask and Not-Mask)\r\nResult: \r\nIf the mask is all-zero, instruction will not be \r\nexecuted. \r\nMask Propagation Pass – design ideas \r\ntopVal = \r\nMask = cmp() \r\n \r\nC1 = topVal*2 \r\nB1 = \r\nA1 = B1 + C1 \r\nC2 = \r\nB2 = \r\nA2 = B2 + C2 \r\nA = BLEND(Mask, A1, A2) \r\nA new Machine Pass:\r\n• Before register allocation\r\n• Start from the “blend” operands and go up recursively till mask definition\r\n• Check all users of the destination operand before applying the mask\r\nPredicated memory accesses in LLVM IR \r\nwould be helpful !\r\n Mask Propagation Pass does not guarantee full mask propagation \r\nover the whole path from blend to compare\r\n Load/Store operations require exact masking\r\n FP operations require masking if exceptions are not suppressed\r\n– IR generators should use compiler intrinsics\r\ntopVal = \r\nMask = cmp() \r\n \r\n C1 = topVal*2 \r\n B1 = \r\n A1 = B1 + C1 \r\n C2 = \r\n B2 = \r\n A2 = B2 + C2 \r\nA = BLEND(Mask, A1, A2) \r\nMask\r\nMask\r\nMask\r\ntopVal = \r\nMask = cmp() \r\n!Mask = Not(Mask) \r\n C1 = topVal*2 \r\n B1 = \r\n A1 = B1 + C1 \r\n C2 = \r\n B2 = \r\n A2 = B2 + C2 \r\n A = BLEND(Mask, A1, A2) \r\nMask\r\nMask\r\n!Mask\r\n!Mask\r\n!Mask\r\nMask\r\ntopVal = \r\nMask = cmp() \r\n!Mask = Not(Mask) \r\n C1 = topVal*2 \r\n B1 = \r\n A = B1 + C1 \r\n C2 = \r\n B2 = \r\n A = B2 + C2 \r\nMask\r\nMask\r\nMask\r\n!Mask\r\n!Mask\r\n!Mask\r\nMasking Masking in LLVM\r\nUnmasked elements remain \r\nunchanged:\r\nVADDPD zmm1 {k1}, zmm2, zmm3\r\nOr zeroed:\r\nVADDPD zmm1 {k1} {z}, zmm2, zmm3\r\nfloat32 A[N], B[N], C[N];\r\nfor(i=0; i<16; i++)\r\n{\r\n if (B[i] != 0)\r\n A[i] = A[i] / B[i]; \r\n else\r\n A[i] = A[i] / C[i]; \r\n}\r\nVMOVUPS zmm2, A\r\nVCMPPS k1, zmm0, B\r\nVDIVPS zmm1 {k1}{z}, zmm2, B\r\nKNOT k2, k1\r\nVDIVPS zmm1 {k2}, zmm2, C\r\nVMOVUPS A, zmm1\r\nA source from memory is repeated across all the \r\nelements. \r\n vbroadcastss zmm3, [rax]\r\n vaddps zmm1, zmm2, zmm3\r\n \r\n vaddps zmm1, zmm2, [rax] {1to16}\r\nEmbedded Broadcast\r\n• Static (per instruction) rounding rode\r\n• No need to access MXCSR any more!\r\nvaddps zmm7 {k6}, zmm2, zmm4 {rd}\r\nvcvtdq2ps zmm1, zmm2, {ru}\r\nAll exceptions are always suspended by using \r\nembedded RC\r\nEmbedded Rounding Control\r\n Memory fault suppression\r\n Avoid FP exceptions\r\n Avoid extra blends\r\nzmm1 a7 a6 a5 a4 a3 a2 a1 a0\r\nzmm2 b7 b6 b5 b4 b3 b2 b1 b0\r\nzmm3\r\nk1\r\nzmm1 b7+c7 a6 b5+c5 b4+c4 b3+c3 b2+c2 a1 a0\r\n+ + + + + + + +\r\n1 0 1 1 1 1 0 0\r\nc7 c6 c5 c4 c3 c2 c1 c0\r\nXMM0-15 128-bits\r\nYMM0-15 256-bits\r\nZMM0-31 512-bits\r\n• INFORMATION IN THIS DOCUMENT IS PROVIDED IN CONNECTION WITH INTEL PRODUCTS. NO LICENSE, EXPRESS OR IMPLIED, BY ESTOPPEL OR OTHERWISE, TO ANY INTELLECTUAL PROPERTY RIGHTS IS GRANTED BY THIS DOCUMENT. EXCEPT AS PROVIDED IN INTEL'S TERMS AND CONDITIONS OF SALE FOR SUCH PRODUCTS, INTEL ASSUMES NO LIABILITY WHATSOEVER AND INTEL DISCLAIMS ANY EXPRESS OR IMPLIED WARRANTY, RELATING TO SALE AND/OR USE OF INTEL PRODUCTS INCLUDING LIABILITY OR WARRANTIES RELATING TO FITNESS FOR A PARTICULAR PURPOSE, MERCHANTABILITY, OR INFRINGEMENT OF ANY PATENT, COPYRIGHT OR OTHER INTELLECTUAL PROPERTY RIGHT. \r\n• A \"Mission Critical Application\" is any application in which failure of the Intel Product could result, directly or indirectly, in personal injury or death. SHOULD YOU PURCHASE OR USE INTEL'S PRODUCTS FOR ANY SUCH MISSION CRITICAL APPLICATION, YOU SHALL INDEMNIFY AND HOLD INTEL AND ITS SUBSIDIARIES, SUBCONTRACTORS AND AFFILIATES, AND THE DIRECTORS, OFFICERS, AND EMPLOYEES OF EACH, HARMLESS AGAINST ALL CLAIMS COSTS, DAMAGES, AND EXPENSES AND REASONABLE ATTORNEYS' FEES ARISING OUT OF, DIRECTLY OR INDIRECTLY, ANY CLAIM OF PRODUCT LIABILITY, PERSONAL INJURY, OR DEATH ARISING IN ANY WAY OUT OF SUCH MISSION CRITICAL APPLICATION, WHETHER OR NOT INTEL OR \r\nITS SUBCONTRACTOR WAS NEGLIGENT IN THE DESIGN, MANUFACTURE, OR WARNING OF THE INTEL PRODUCT OR ANY OF ITS PARTS. \r\n• Intel may make changes to specifications and product descriptions at any time, without notice. Designers must not rely on the absence or characteristics of any features or instructions marked \"reserved\" or \"undefined\". Intel reserves these for future definition and shall have no responsibility whatsoever for conflicts or incompatibilities arising from future changes to them. The information here is subject to change without notice. Do not finalize a design with this information. \r\n• The products described in this document may contain design defects or errors known as errata which may cause the product to deviate from published specifications. Current characterized errata are available on request. \r\n• Contact your local Intel sales office or your distributor to obtain the latest specifications and before placing your product order. \r\n• Copies of documents which have an order number and are referenced in this document, or other Intel literature, may be obtained by calling 1-800-548-4725, or go to: http://www.intel.com/design/literature.htm\r\n• Intel's compilers may or may not optimize to the same degree for non-Intel microprocessors for optimizations that are not unique to Intel microprocessors. These optimizations include SSE2, SSE3, and SSE3 instruction sets and other optimizations. Intel does not guarantee the availability, functionality, or effectiveness of any optimization on microprocessors not manufactured by Intel. \r\n• Microprocessor-dependent optimizations in this product are intended for use with Intel microprocessors. Certain optimizations not specific to Intel microarchitecture are reserved for Intel microprocessors. Please refer to the applicable product User and Reference Guides for more information regarding the specific instruction sets covered by this notice.\r\n• Copyright © 2013 Intel Corporation. All rights reserved. Intel and the Intel logo are trademarks of Intel Corporation in the U.S and other countries.\r\nElena Demikhovsky\r\nIntel® Software and Services Group\r\nIsrael",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/70b15ad8-069a-493a-83ef-34f70ac63255/images/a0a23555-e97c-4c3e-932c-cda7c24fa465.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T042310Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=020a5230dfb0ad6d8e2548164baf1019e0b9495d8563061ec9dceb0d720cf216",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 1324
      }
    ],
    "extracted_json": {
      "title": "Document Metadata",
      "schema_type": "object",
      "extracted_fields": [
        {
          "name": "title",
          "field_type": "string",
          "value": "Intel® AVX-512 Architecture\n"
        },
        {
          "name": "author",
          "field_type": "string",
          "value": "Elena Demikhovsky\n"
        },
        {
          "name": "date_published",
          "field_type": "string",
          "value": "2013\n"
        },
        {
          "name": "location",
          "field_type": "string",
          "value": "Israel\n"
        }
      ]
    }
  }
}