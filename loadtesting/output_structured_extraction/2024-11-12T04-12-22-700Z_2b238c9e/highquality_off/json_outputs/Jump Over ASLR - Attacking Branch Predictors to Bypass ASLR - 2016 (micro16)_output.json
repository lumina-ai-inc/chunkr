{
  "file_name": "Jump Over ASLR - Attacking Branch Predictors to Bypass ASLR - 2016 (micro16).pdf",
  "task_id": "a861ebc8-9a5a-43a8-98a1-3960693dbae4",
  "output": {
    "chunks": [
      {
        "segments": [
          {
            "segment_id": "ce5af76b-4cad-4cec-96eb-51d45f4bb10c",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 1,
            "page_width": 612,
            "page_height": 792,
            "content": "Jump Over ASLR:\r\nAttacking Branch Predictors to Bypass ASLR\r\nDmitry Evtyushkin\r\nDepartment of Computer Science\r\nState University of New York\r\nat Binghamton\r\ndevtyushkin@cs.binghamton.edu\r\nDmitry Ponomarev\r\nDepartment of Computer Science\r\nState University of New York\r\nat Binghamton\r\ndima@cs.binghamton.edu\r\nNael Abu-Ghazaleh\r\nComputer Science and\r\nEngineering Department\r\nUniversity of California, Riverside\r\nnaelag@ucr.edu\r\nAbstract—\r\nAddress Space Layout Randomization (ASLR) is a widely\u0002used technique that protects systems against a range of attacks.\r\nASLR works by randomizing the offset of key program segments\r\nin virtual memory, making it difficult for an attacker to derive\r\nthe addresses of specific code objects and consequently redirect\r\nthe control flow to this code. In this paper, we develop an attack\r\nto derive kernel and user-level ASLR offset using a side-channel\r\nattack on the branch target buffer (BTB). Our attack exploits the\r\nobservation that an adversary can create BTB collisions between\r\nthe branch instructions of the attacker process and either the\r\nuser-level victim process or on the kernel executing on its behalf.\r\nThese collisions, in turn, can impact the timing of the attacker’s\r\ncode, allowing the attacker to identify the locations of known\r\nbranch instructions in the address space of the victim process or\r\nthe kernel. We demonstrate that our attack can reliably recover\r\nkernel ASLR in about 60 milliseconds when performed on a real\r\nHaswell processor running a recent version of Linux. Finally, we\r\ndescribe several possible protection mechanisms, both in software\r\nand in hardware.\r\nIndex Terms—Address Space Layout Randomization, Bypass,\r\nSide Channel, Timing Channel, Timing Attacks, Kernel Vulner\u0002abilities, Exploit Mitigation.\r\nI. INTRODUCTION\r\nMemory corruption attacks such as stack and heap over\u0002flows [1], [2] and format string attacks [3] can lead to\r\ncontrol hijacking and arbitrary code execution by the attackers.\r\nDespite significant efforts to prevent such attacks [4], [5], [6],\r\n[7], [8], they remain a serious exploitable class of vulnera\u0002bilities present in many types of software. Since creating a\r\nbug-free environment is practically impossible, systems are\r\noften hardened using techniques that substantially reduce the\r\nprobability of a successful attack.\r\nOne such hardening technique is Address Space Layout\r\nRandomization (ASLR). ASLR provides protection by ran\u0002domizing positions of key program components in virtual\r\nmemory. The randomization targets code and data segments,\r\nstack, heap and libraries. The purpose of ASLR is to make it\r\ndifficult, if not impossible, for the attacker to know the location\r\nof specific code pages in the program’s address space. For\r\nexample, even if the attacker successfully hijacks the control\r\nflow, it would be difficult to perform a meaningful return\u0002oriented programming (ROP) [9], [10], [11] attack under\r\nASLR, because the addresses of ROP gadgets to inject on\r\nthe stack are not known due to randomization. Relying on\r\nbrute-force solutions to discover required gadget addresses\r\ncan cause the program to crash, or it can take prohibitively\r\nlong time [12], enabling detection by system software [13].\r\nDiscovering and exploiting other vulnerabilities that disclose\r\nthe randomization algorithm significantly complicates the at\u0002tack [14]. Non-control-data attacks [15] require the attacker\r\nto know locations of various data structures. Although our\r\nattack directly recovers ASLR for the code segment only,\r\ndata segments are typically not decoupled from code seg\u0002ments [16]; thus a successful attack on code ASLR reveals the\r\nlocations of data structures. Today, ASLR-based defenses are\r\nwidely adopted in all major Operating Systems (OS), including\r\nLinux [17], Windows [18] and OS X [19]. Smartphone system\r\nsoftware such as iOS [20] and Android [13] also use ASLR.\r\nASLR implementations across different operating systems\r\ndiffer by the amount of entropy used and by the frequency at\r\nwhich memory addresses are randomized. These characteris\u0002tics directly determine the resilience of ASLR implementations\r\nto possible attacks. For example, 32-bit systems have a much\r\nsmaller addressable space, limiting the amount of space that\r\ncan be dedicated to randomization, making it possible to build\r\nfast brute-force attacks [12]. The randomization frequency\r\ncan range from a single randomization at boot or compile\r\ntime to dynamic randomization during program execution.\r\nMore frequent re-randomization reduces the probability of a\r\nsuccessful attack.\r\nTraditionally, ASLR has only been considered as a protec\u0002tion mechanism against remote attacks. As a result, and also\r\nfor performance reasons [21], some ASLR implementations\r\nrandomize positions of libraries only one time during the\r\nsystem boot. Consequently, all processes executed on a ma\u0002978-1-5090-3508-3/16/$31.00 \rc 2016 IEEE chine receive the same mappings of the libraries, thus making",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/ce5af76b-4cad-4cec-96eb-51d45f4bb10c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=46e5ec36318ed796956de183a96e19d6ce1c26ff632297180c03526128007e17",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 713
      },
      {
        "segments": [
          {
            "segment_id": "ce5af76b-4cad-4cec-96eb-51d45f4bb10c",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 1,
            "page_width": 612,
            "page_height": 792,
            "content": "Jump Over ASLR:\r\nAttacking Branch Predictors to Bypass ASLR\r\nDmitry Evtyushkin\r\nDepartment of Computer Science\r\nState University of New York\r\nat Binghamton\r\ndevtyushkin@cs.binghamton.edu\r\nDmitry Ponomarev\r\nDepartment of Computer Science\r\nState University of New York\r\nat Binghamton\r\ndima@cs.binghamton.edu\r\nNael Abu-Ghazaleh\r\nComputer Science and\r\nEngineering Department\r\nUniversity of California, Riverside\r\nnaelag@ucr.edu\r\nAbstract—\r\nAddress Space Layout Randomization (ASLR) is a widely\u0002used technique that protects systems against a range of attacks.\r\nASLR works by randomizing the offset of key program segments\r\nin virtual memory, making it difficult for an attacker to derive\r\nthe addresses of specific code objects and consequently redirect\r\nthe control flow to this code. In this paper, we develop an attack\r\nto derive kernel and user-level ASLR offset using a side-channel\r\nattack on the branch target buffer (BTB). Our attack exploits the\r\nobservation that an adversary can create BTB collisions between\r\nthe branch instructions of the attacker process and either the\r\nuser-level victim process or on the kernel executing on its behalf.\r\nThese collisions, in turn, can impact the timing of the attacker’s\r\ncode, allowing the attacker to identify the locations of known\r\nbranch instructions in the address space of the victim process or\r\nthe kernel. We demonstrate that our attack can reliably recover\r\nkernel ASLR in about 60 milliseconds when performed on a real\r\nHaswell processor running a recent version of Linux. Finally, we\r\ndescribe several possible protection mechanisms, both in software\r\nand in hardware.\r\nIndex Terms—Address Space Layout Randomization, Bypass,\r\nSide Channel, Timing Channel, Timing Attacks, Kernel Vulner\u0002abilities, Exploit Mitigation.\r\nI. INTRODUCTION\r\nMemory corruption attacks such as stack and heap over\u0002flows [1], [2] and format string attacks [3] can lead to\r\ncontrol hijacking and arbitrary code execution by the attackers.\r\nDespite significant efforts to prevent such attacks [4], [5], [6],\r\n[7], [8], they remain a serious exploitable class of vulnera\u0002bilities present in many types of software. Since creating a\r\nbug-free environment is practically impossible, systems are\r\noften hardened using techniques that substantially reduce the\r\nprobability of a successful attack.\r\nOne such hardening technique is Address Space Layout\r\nRandomization (ASLR). ASLR provides protection by ran\u0002domizing positions of key program components in virtual\r\nmemory. The randomization targets code and data segments,\r\nstack, heap and libraries. The purpose of ASLR is to make it\r\ndifficult, if not impossible, for the attacker to know the location\r\nof specific code pages in the program’s address space. For\r\nexample, even if the attacker successfully hijacks the control\r\nflow, it would be difficult to perform a meaningful return\u0002oriented programming (ROP) [9], [10], [11] attack under\r\nASLR, because the addresses of ROP gadgets to inject on\r\nthe stack are not known due to randomization. Relying on\r\nbrute-force solutions to discover required gadget addresses\r\ncan cause the program to crash, or it can take prohibitively\r\nlong time [12], enabling detection by system software [13].\r\nDiscovering and exploiting other vulnerabilities that disclose\r\nthe randomization algorithm significantly complicates the at\u0002tack [14]. Non-control-data attacks [15] require the attacker\r\nto know locations of various data structures. Although our\r\nattack directly recovers ASLR for the code segment only,\r\ndata segments are typically not decoupled from code seg\u0002ments [16]; thus a successful attack on code ASLR reveals the\r\nlocations of data structures. Today, ASLR-based defenses are\r\nwidely adopted in all major Operating Systems (OS), including\r\nLinux [17], Windows [18] and OS X [19]. Smartphone system\r\nsoftware such as iOS [20] and Android [13] also use ASLR.\r\nASLR implementations across different operating systems\r\ndiffer by the amount of entropy used and by the frequency at\r\nwhich memory addresses are randomized. These characteris\u0002tics directly determine the resilience of ASLR implementations\r\nto possible attacks. For example, 32-bit systems have a much\r\nsmaller addressable space, limiting the amount of space that\r\ncan be dedicated to randomization, making it possible to build\r\nfast brute-force attacks [12]. The randomization frequency\r\ncan range from a single randomization at boot or compile\r\ntime to dynamic randomization during program execution.\r\nMore frequent re-randomization reduces the probability of a\r\nsuccessful attack.\r\nTraditionally, ASLR has only been considered as a protec\u0002tion mechanism against remote attacks. As a result, and also\r\nfor performance reasons [21], some ASLR implementations\r\nrandomize positions of libraries only one time during the\r\nsystem boot. Consequently, all processes executed on a ma\u0002978-1-5090-3508-3/16/$31.00 \rc 2016 IEEE chine receive the same mappings of the libraries, thus making",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/ce5af76b-4cad-4cec-96eb-51d45f4bb10c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=46e5ec36318ed796956de183a96e19d6ce1c26ff632297180c03526128007e17",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 713
      },
      {
        "segments": [
          {
            "segment_id": "26e86a2a-7e90-4487-9637-ba866f14d3fe",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 2,
            "page_width": 612,
            "page_height": 792,
            "content": "return-to-libc [22], [23] or other code reuse attacks possible\r\nwithin the same system. The presence of many high-privileged\r\nprocesses in the system makes the attack surface large. For\r\nexample, on our experimental machine, an OS with only basic\r\nservices executes 30 and 80 root background processes in\r\nUbuntu 14.04 LTS and OS X El Capitan 10.11.2 respectively.\r\nIf one of these processes is subverted by an attacker, the entire\r\nsystem becomes compromised with respect to ASLR.\r\nAll current operating systems supporting randomizations\r\nimplement variants of ASLR for both user and kernel-level ad\u0002dress spaces. Kernel-level ASLR (KASLR) randomizes kernel\r\ncode segments and can stop attacks that require knowledge of\r\nthe kernel address space layout (including ROP, jump-oriented\r\nprogramming (JOP), return-to-libc, ret-2-user [24] and other\r\nattacks). Unfortunately, current implementations of KASLR\r\nare often criticized for incompleteness and insufficient en\u0002tropy [25]. A small entropy is typically justified by the fact that\r\nit is infeasible for an adversary to mount a brute-force attack\r\nagainst KASLR. If the attacker guesses the randomization\r\nincorrectly, the kernel typically crashes and the attack fails.\r\nIn this paper, we demonstrate a new attack that can recover\r\nall random bits of the kernel addresses and reduce the entropy\r\nof user-level randomization by using side-channel information\r\nfrom the Branch Target Buffer (BTB). Our attack only requires\r\nthe control of a user-level process and does not rely on\r\nany explicit memory disclosures. The key insight that makes\r\nthe new BTB-based side-channel possible is that the BTB\r\ncollisions between two user-level processes, and between a\r\nuser process and the kernel, can be created by the attacker in\r\na controlled and robust manner. The collisions can be easily\r\ndetected by the attacker because they impact the timing of the\r\nattacker-controlled code. Identifying the BTB collisions allows\r\nthe attacker to determine the exact locations of known branch\r\ninstructions in the code segment of the kernel or of the victim\r\nprocess, thus disclosing the ASLR offset.\r\nOur attacks exploit two types of collisions in the BTB. The\r\nfirst collision type, exploited to bypass KASLR, is between a\r\nuser-level branch and a kernel-level branch - we call it cross\u0002domain collisions, or CDC. CDC occurs because these two\r\nbranches, located at different virtual addresses, can map to\r\nthe same entry in the BTB with the same target address. The\r\nreason is that the BTB addressing schemes in recent processors\r\nignore the upper-order bits of the address, thus trading off\r\nsome performance for lower design complexity. The second\r\ntype of BTB collisions is between two user-level branches that\r\nbelong to two different applications. We call these collisions\r\nsame-domain collisions, or SDC. SDCs are used to attack\r\nuser-level ASLR, allowing one process to identify the ASLR\r\noffset used in another. An SDC occurs when two branches,\r\none in each process, have the same virtual address and the\r\nsame target.\r\nWe demonstrate our attack on a real system with Haswell\r\nCPU and a recent version of Linux kernel equipped with\r\nASLR. Since this new attack adds to the arsenal of a potential\r\nadversary, we also discuss a number of possible software\r\nand hardware-supported mitigation mechanisms to thwart this\r\nattack. The solutions range from further hardening the ASLR\r\nimplementations to reconsidering the hardware designs of the\r\nBTB to avoid collisions.\r\nIn summary, this paper makes the following contributions:\r\n• We describe a new technique to bypass existing ASLR\r\nschemes by exploiting a side-channel created through\r\nshared BTB. We show how an adversary can create\r\na robust side-channel between a user process and the\r\nkernel, as well as between two user processes in a\r\ncontrolled manner.\r\n• We show how the details of the BTB addressing scheme,\r\nneeded for creating a reliable BTB side channel, can be\r\nreverse-engineered.\r\n• We show how the new BTB side-channel attack can be\r\nused to recover kernel and user-level ASLR in a fast\r\nand reliable fashion. We implement our attacks on a real\r\nsystem with Haswell CPU and recent Linux kernel and\r\nshow that kernel-level ASLR can be recovered in about\r\n60 milliseconds.\r\n• We propose several software and hardware countermea\u0002sures against the new attack and also place our attack in\r\nthe context of the related work.\r\nII. THREAT MODEL AND ASSUMPTIONS\r\nWe consider two distinct attacks/threat models: one on\r\nKASLR and one on user-level ASLR. In this section we\r\ndescribe our assumptions about the underlying system and the\r\ncapabilities of the attacker in each case.\r\nA. KASLR Attack\r\nWe assume that an attacker has control over a process\r\nrunning on the target system with normal user privileges. We\r\nrefer to this process as the spy process. We further assume\r\nthat the kernel implements some form of KASLR and that\r\nthe kernel’s code and module segments are randomly placed\r\nduring boot in accordance with the KASLR algorithm. The\r\nattacker knows which bits of the address are randomized and\r\nwhich bits are fixed. Beyond that, the attacker does not have\r\nany knowledge on how the random bits were generated. The\r\nspy process can only execute normal user-level instructions,\r\nincluding instructions for time measurement (such as rdtsc)\r\nand perform regular interactions with the kernel through\r\nsystem calls. We assume that the spy process cannot brute\u0002force the correct address. We do not assume any weaknesses\r\nin KASLR implementation: in other words, randomized offset\r\nvalues were generated using strong sources of entropy with\r\nno algorithmic weaknesses [26]. The goal of the attacker is to\r\nrecover the address of a kernel routine, such as a system call\r\nhandler in virtual memory.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/26e86a2a-7e90-4487-9637-ba866f14d3fe.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=b304e914276bed822ff38e3f308b821dfaa5d810e41f44c9dd555db0cf3b1b75",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 909
      },
      {
        "segments": [
          {
            "segment_id": "26e86a2a-7e90-4487-9637-ba866f14d3fe",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 2,
            "page_width": 612,
            "page_height": 792,
            "content": "return-to-libc [22], [23] or other code reuse attacks possible\r\nwithin the same system. The presence of many high-privileged\r\nprocesses in the system makes the attack surface large. For\r\nexample, on our experimental machine, an OS with only basic\r\nservices executes 30 and 80 root background processes in\r\nUbuntu 14.04 LTS and OS X El Capitan 10.11.2 respectively.\r\nIf one of these processes is subverted by an attacker, the entire\r\nsystem becomes compromised with respect to ASLR.\r\nAll current operating systems supporting randomizations\r\nimplement variants of ASLR for both user and kernel-level ad\u0002dress spaces. Kernel-level ASLR (KASLR) randomizes kernel\r\ncode segments and can stop attacks that require knowledge of\r\nthe kernel address space layout (including ROP, jump-oriented\r\nprogramming (JOP), return-to-libc, ret-2-user [24] and other\r\nattacks). Unfortunately, current implementations of KASLR\r\nare often criticized for incompleteness and insufficient en\u0002tropy [25]. A small entropy is typically justified by the fact that\r\nit is infeasible for an adversary to mount a brute-force attack\r\nagainst KASLR. If the attacker guesses the randomization\r\nincorrectly, the kernel typically crashes and the attack fails.\r\nIn this paper, we demonstrate a new attack that can recover\r\nall random bits of the kernel addresses and reduce the entropy\r\nof user-level randomization by using side-channel information\r\nfrom the Branch Target Buffer (BTB). Our attack only requires\r\nthe control of a user-level process and does not rely on\r\nany explicit memory disclosures. The key insight that makes\r\nthe new BTB-based side-channel possible is that the BTB\r\ncollisions between two user-level processes, and between a\r\nuser process and the kernel, can be created by the attacker in\r\na controlled and robust manner. The collisions can be easily\r\ndetected by the attacker because they impact the timing of the\r\nattacker-controlled code. Identifying the BTB collisions allows\r\nthe attacker to determine the exact locations of known branch\r\ninstructions in the code segment of the kernel or of the victim\r\nprocess, thus disclosing the ASLR offset.\r\nOur attacks exploit two types of collisions in the BTB. The\r\nfirst collision type, exploited to bypass KASLR, is between a\r\nuser-level branch and a kernel-level branch - we call it cross\u0002domain collisions, or CDC. CDC occurs because these two\r\nbranches, located at different virtual addresses, can map to\r\nthe same entry in the BTB with the same target address. The\r\nreason is that the BTB addressing schemes in recent processors\r\nignore the upper-order bits of the address, thus trading off\r\nsome performance for lower design complexity. The second\r\ntype of BTB collisions is between two user-level branches that\r\nbelong to two different applications. We call these collisions\r\nsame-domain collisions, or SDC. SDCs are used to attack\r\nuser-level ASLR, allowing one process to identify the ASLR\r\noffset used in another. An SDC occurs when two branches,\r\none in each process, have the same virtual address and the\r\nsame target.\r\nWe demonstrate our attack on a real system with Haswell\r\nCPU and a recent version of Linux kernel equipped with\r\nASLR. Since this new attack adds to the arsenal of a potential\r\nadversary, we also discuss a number of possible software\r\nand hardware-supported mitigation mechanisms to thwart this\r\nattack. The solutions range from further hardening the ASLR\r\nimplementations to reconsidering the hardware designs of the\r\nBTB to avoid collisions.\r\nIn summary, this paper makes the following contributions:\r\n• We describe a new technique to bypass existing ASLR\r\nschemes by exploiting a side-channel created through\r\nshared BTB. We show how an adversary can create\r\na robust side-channel between a user process and the\r\nkernel, as well as between two user processes in a\r\ncontrolled manner.\r\n• We show how the details of the BTB addressing scheme,\r\nneeded for creating a reliable BTB side channel, can be\r\nreverse-engineered.\r\n• We show how the new BTB side-channel attack can be\r\nused to recover kernel and user-level ASLR in a fast\r\nand reliable fashion. We implement our attacks on a real\r\nsystem with Haswell CPU and recent Linux kernel and\r\nshow that kernel-level ASLR can be recovered in about\r\n60 milliseconds.\r\n• We propose several software and hardware countermea\u0002sures against the new attack and also place our attack in\r\nthe context of the related work.\r\nII. THREAT MODEL AND ASSUMPTIONS\r\nWe consider two distinct attacks/threat models: one on\r\nKASLR and one on user-level ASLR. In this section we\r\ndescribe our assumptions about the underlying system and the\r\ncapabilities of the attacker in each case.\r\nA. KASLR Attack\r\nWe assume that an attacker has control over a process\r\nrunning on the target system with normal user privileges. We\r\nrefer to this process as the spy process. We further assume\r\nthat the kernel implements some form of KASLR and that\r\nthe kernel’s code and module segments are randomly placed\r\nduring boot in accordance with the KASLR algorithm. The\r\nattacker knows which bits of the address are randomized and\r\nwhich bits are fixed. Beyond that, the attacker does not have\r\nany knowledge on how the random bits were generated. The\r\nspy process can only execute normal user-level instructions,\r\nincluding instructions for time measurement (such as rdtsc)\r\nand perform regular interactions with the kernel through\r\nsystem calls. We assume that the spy process cannot brute\u0002force the correct address. We do not assume any weaknesses\r\nin KASLR implementation: in other words, randomized offset\r\nvalues were generated using strong sources of entropy with\r\nno algorithmic weaknesses [26]. The goal of the attacker is to\r\nrecover the address of a kernel routine, such as a system call\r\nhandler in virtual memory.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/26e86a2a-7e90-4487-9637-ba866f14d3fe.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=b304e914276bed822ff38e3f308b821dfaa5d810e41f44c9dd555db0cf3b1b75",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 909
      },
      {
        "segments": [
          {
            "segment_id": "2a57763f-f45a-4c8e-9a20-52967fd9f20d",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 3,
            "page_width": 612,
            "page_height": 792,
            "content": "B. Attack on User Process ASLR\r\nIn this case, we assume that two user processes are present\r\nin the system. The first process is a process that is the\r\ntarget of an attack typically because it runs as root or has\r\npermissions to access sensitive data. We refer to this process\r\nas the victim process. The other process is the spy process\r\nand it is controlled by the attacker who seeks to recover\r\nASLR of the victim as a first step of further attacks on it.\r\nWe assume that the system supports ASLR and the victim is\r\ncompiled as a position-independent executable to fully benefit\r\nfrom it. As a result, the segments in the process image are\r\nrandomly shifted in virtual memory. We assume that there are\r\nno weaknesses in the ASLR implementation and the spy does\r\nnot have any means to directly obtain the randomized ASLR\r\noffset, for example via a memory disclosure vulnerability. The\r\nspy can only execute normal user-level instructions, including\r\ninstructions for time measurement. The spy can also perform\r\nregular interactions with the victim via any interfaces it offers,\r\nfor example via initializing network connections.\r\nWe assume that the spy can achieve virtual core co\u0002residency with the victim process. This assumption is required\r\nbecause BTB collisions can only be achieved within the\r\nsame virtual core on Haswell CPU. This assumption is not\r\nunrealistic because, as we demonstrate in Section V-A, it is\r\npossible for the spy to control the cores on which the victim\r\nprocess is scheduled.\r\nIII. CREATING THE BTB SIDE-CHANNEL\r\nBranch predictors are critical to performance of modern pro\u0002cessors. One of the main components of the branch prediction\r\nhardware is the Branch Target Buffer (BTB). The BTB stores\r\ntarget addresses of recently executed branch instructions, so\r\nthat those addresses can be obtained directly from a BTB\r\nlookup to fetch instructions starting at the target in the next cy\u0002cle. Since the BTB is shared by several applications executing\r\non the same core, information leakage from one application\r\nto another through the BTB side-channel is possible. For\r\nexample, several previous works demonstrated the feasibility\r\nof recovering secret encryption key bits using branch predictor\r\nside channel [27], [28]. As another example, a recent study\r\nof [29], [30] demonstrated that a reliable and high speed covert\r\ncommunication channel can be created between two malicious\r\napplications that share the branch prediction logic.\r\nIn this paper we describe a new security threat associ\u0002ated with shared branch prediction hardware. Specifically, we\r\ndemonstrate how a user-level spy process can gain information\r\nabout the position of code blocks in the address space of either\r\na victim process or the kernel by aligning its code to intention\u0002ally create BTB collisions between these two address spaces.\r\nThe attacker performs a series of time measurements, each\r\nto test a hypothesis about the location of a specific branch.\r\nThese experiments allow the attacking process to discover the\r\nprecise location of a branch in the kernel address space, or\r\nthe address space of another process, thus bypassing kernel\u0002level ASLR and user level ASLR respectively. In principle,\r\nour approach has a potential to bypass even some recently\r\nproposed fine-grained ASLR solutions [31], [32], [33], [34].\r\nThe BTB side-channel that we exploit in this paper for\r\nattacking ASLR is based on creating BTB collisions between\r\nunconditional branch instructions belonging to two different\r\nexecution entities. We consider two types of collisions: col\u0002lisions between two user-level processes (to attack user-level\r\nASLR) and collisions between user-level and the kernel (to\r\nattack KASLR). While no specific BTB addressing details are\r\nneeded by the attacker to perform the attack on the user-level\r\nprocess, some reverse-engineering and understanding of the\r\nBTB addressing scheme is required for an attack on the kernel.\r\nA. Creating BTB Collisions in User Space\r\nTo create a BTB-based side-channel, three conditions must\r\nbe satisfied. First, one application has to fill a BTB entry by\r\nexecuting a branch instruction. Second, the execution time\r\nof another application running on the same core must be\r\naffected by the state of the BTB. This condition is satisfied\r\nwhen both applications use the same BTB entry, perhaps with\r\ndifferent targets stored. Third, the second application must be\r\nable to detect the impact on its execution by performing time\r\nmeasurements. We call the BTB collisions created between\r\ntwo processes executing in the same protection domain (e.g.\r\ntwo user-level processes) as Same-Domain Collisions (SDC).\r\nAn example of a SDC collision that can be exploited by our\r\nattack is shown in Figure 1.\r\nKernel space Kernel space\r\nUser space User space\r\nBTB\r\nAddress tag Target\r\njmp1 jmp2 0x7fefebe45a82\r\n0xebe45a82 0x7fefebe45ad6 0x7fefebe45ad6\r\nFig. 1: SDC Example\r\nTo verify the sufficiency of the above assumptions for\r\ncreating SDCs, we designed and conducted the following\r\nexperiment on a machine with an Intel Haswell processor.\r\nWe executed two processes on the system: the victim and the\r\nspy. The victim process writes some data into the BTB by\r\nexecuting branch instructions. The goal of the spy process is\r\nto use the branch instructions and time measurement tools\r\nto detect the information that was written to the BTB by\r\nthe victim process. Since the goal of this experiment is to\r\ndemonstrate the possibility of data transmission through the\r\nBTB side-channel, we allow the victim and the spy to coor\u0002dinate their actions by communicating with each other using",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/2a57763f-f45a-4c8e-9a20-52967fd9f20d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=1a1677f206724128b77db368dbca61e5f1b129bbacf5a025a7ac6377505c490a",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 881
      },
      {
        "segments": [
          {
            "segment_id": "2a57763f-f45a-4c8e-9a20-52967fd9f20d",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 3,
            "page_width": 612,
            "page_height": 792,
            "content": "B. Attack on User Process ASLR\r\nIn this case, we assume that two user processes are present\r\nin the system. The first process is a process that is the\r\ntarget of an attack typically because it runs as root or has\r\npermissions to access sensitive data. We refer to this process\r\nas the victim process. The other process is the spy process\r\nand it is controlled by the attacker who seeks to recover\r\nASLR of the victim as a first step of further attacks on it.\r\nWe assume that the system supports ASLR and the victim is\r\ncompiled as a position-independent executable to fully benefit\r\nfrom it. As a result, the segments in the process image are\r\nrandomly shifted in virtual memory. We assume that there are\r\nno weaknesses in the ASLR implementation and the spy does\r\nnot have any means to directly obtain the randomized ASLR\r\noffset, for example via a memory disclosure vulnerability. The\r\nspy can only execute normal user-level instructions, including\r\ninstructions for time measurement. The spy can also perform\r\nregular interactions with the victim via any interfaces it offers,\r\nfor example via initializing network connections.\r\nWe assume that the spy can achieve virtual core co\u0002residency with the victim process. This assumption is required\r\nbecause BTB collisions can only be achieved within the\r\nsame virtual core on Haswell CPU. This assumption is not\r\nunrealistic because, as we demonstrate in Section V-A, it is\r\npossible for the spy to control the cores on which the victim\r\nprocess is scheduled.\r\nIII. CREATING THE BTB SIDE-CHANNEL\r\nBranch predictors are critical to performance of modern pro\u0002cessors. One of the main components of the branch prediction\r\nhardware is the Branch Target Buffer (BTB). The BTB stores\r\ntarget addresses of recently executed branch instructions, so\r\nthat those addresses can be obtained directly from a BTB\r\nlookup to fetch instructions starting at the target in the next cy\u0002cle. Since the BTB is shared by several applications executing\r\non the same core, information leakage from one application\r\nto another through the BTB side-channel is possible. For\r\nexample, several previous works demonstrated the feasibility\r\nof recovering secret encryption key bits using branch predictor\r\nside channel [27], [28]. As another example, a recent study\r\nof [29], [30] demonstrated that a reliable and high speed covert\r\ncommunication channel can be created between two malicious\r\napplications that share the branch prediction logic.\r\nIn this paper we describe a new security threat associ\u0002ated with shared branch prediction hardware. Specifically, we\r\ndemonstrate how a user-level spy process can gain information\r\nabout the position of code blocks in the address space of either\r\na victim process or the kernel by aligning its code to intention\u0002ally create BTB collisions between these two address spaces.\r\nThe attacker performs a series of time measurements, each\r\nto test a hypothesis about the location of a specific branch.\r\nThese experiments allow the attacking process to discover the\r\nprecise location of a branch in the kernel address space, or\r\nthe address space of another process, thus bypassing kernel\u0002level ASLR and user level ASLR respectively. In principle,\r\nour approach has a potential to bypass even some recently\r\nproposed fine-grained ASLR solutions [31], [32], [33], [34].\r\nThe BTB side-channel that we exploit in this paper for\r\nattacking ASLR is based on creating BTB collisions between\r\nunconditional branch instructions belonging to two different\r\nexecution entities. We consider two types of collisions: col\u0002lisions between two user-level processes (to attack user-level\r\nASLR) and collisions between user-level and the kernel (to\r\nattack KASLR). While no specific BTB addressing details are\r\nneeded by the attacker to perform the attack on the user-level\r\nprocess, some reverse-engineering and understanding of the\r\nBTB addressing scheme is required for an attack on the kernel.\r\nA. Creating BTB Collisions in User Space\r\nTo create a BTB-based side-channel, three conditions must\r\nbe satisfied. First, one application has to fill a BTB entry by\r\nexecuting a branch instruction. Second, the execution time\r\nof another application running on the same core must be\r\naffected by the state of the BTB. This condition is satisfied\r\nwhen both applications use the same BTB entry, perhaps with\r\ndifferent targets stored. Third, the second application must be\r\nable to detect the impact on its execution by performing time\r\nmeasurements. We call the BTB collisions created between\r\ntwo processes executing in the same protection domain (e.g.\r\ntwo user-level processes) as Same-Domain Collisions (SDC).\r\nAn example of a SDC collision that can be exploited by our\r\nattack is shown in Figure 1.\r\nKernel space Kernel space\r\nUser space User space\r\nBTB\r\nAddress tag Target\r\njmp1 jmp2 0x7fefebe45a82\r\n0xebe45a82 0x7fefebe45ad6 0x7fefebe45ad6\r\nFig. 1: SDC Example\r\nTo verify the sufficiency of the above assumptions for\r\ncreating SDCs, we designed and conducted the following\r\nexperiment on a machine with an Intel Haswell processor.\r\nWe executed two processes on the system: the victim and the\r\nspy. The victim process writes some data into the BTB by\r\nexecuting branch instructions. The goal of the spy process is\r\nto use the branch instructions and time measurement tools\r\nto detect the information that was written to the BTB by\r\nthe victim process. Since the goal of this experiment is to\r\ndemonstrate the possibility of data transmission through the\r\nBTB side-channel, we allow the victim and the spy to coor\u0002dinate their actions by communicating with each other using",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/2a57763f-f45a-4c8e-9a20-52967fd9f20d.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=1a1677f206724128b77db368dbca61e5f1b129bbacf5a025a7ac6377505c490a",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 881
      },
      {
        "segments": [
          {
            "segment_id": "3dcd2e92-166e-44af-9ee1-87643cefd65c",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 4,
            "page_width": 612,
            "page_height": 792,
            "content": "signals. The BTB manipulations are performed by executing\r\nthe jmp instruction. Conditional branches can also be used,\r\nbut for the sake of simplicity we demonstrate our attack using\r\nunconditional jumps.\r\nThe key code block executed by both processes contains a\r\nsingle jmp instruction with additional nop instructions. The\r\noutline of this code is depicted in Listing 1. The code has\r\ntwo possible jump targets. However, when compiled, the target\r\nis statically set in the binary. We placed this code in both\r\nprocesses. The functions where this code was placed are called\r\nspy_func() and victim_func() accordingly.\r\nasm(\"jmp target2;\");\r\nasm(\"nop; nop; ... \");\r\nasm(\"Target1:\");\r\nasm(\"nop; nop; ... \");\r\nasm(\"Target2:\");\r\nasm(\"nop; nop; ... \");\r\nListing 1: Code example with jump instructions\r\nThe goal of this experiment is to record the execution\r\ntime of the spy process when the measured jmp instruction\r\naligns with a similar instruction in the victim process. Our\r\nexpectation is that the two branch instructions will map to the\r\nsame BTB entry if they are located at the same virtual address.\r\nAssuming BT B index() is the BTB indexing function, then\r\nBT B index(Avictim) = BT B index(Aspy) if Avictim and\r\nAspy are identical virtual addresses. As a result, the data\r\nplaced at this address by the victim will affect the execution\r\ntime of the spy due to the created SDC.\r\nThe victim and the spy processes are compiled and linked\r\nspecifically to align the jump instructions. The spy also\r\nmeasures the number of execution cycles required to execute\r\nthe jump block using the rdtscp instruction. We adjust the\r\nnumber of nop instructions in the spy in order to compensate\r\nfor the length of the rdtscp instruction and keep the ad\u0002dresses of the jump and both targets aligned with the victim’s\r\naddresses. The disassembly of the key functions is depicted in\r\nListing 2.\r\nWe executed the spy and the victim processes under two\r\nsettings. In the first setting, the targets of the spy and the victim\r\nare the same, as demonstrated in Listing 2. In the second\r\nsetting, the targets are different and the victim jumps to target\r\nT1. The use of different targets results in extra BTB misses\r\nand thus performance slowdown for the spy, as the spy’s BTB\r\nentry is overwritten by the victim, but with a different target\r\naddress. By running the spy under both settings, we obtain\r\nthe number of cycles required by the spy to execute the jump\r\ncode block.\r\nThe timing diagram depicting the stages of the experiment is\r\npresented in Figure 3. The affinity masks of the two processes\r\nare set to force them to execute on a single virtual core\r\ninterchangeably. First, the spy process sends a signal 1 to the\r\n3000 <victim_func>:\r\n3000 push %rbp\r\n3001 mov %rsp,%rbp\r\n3004 nop\r\n3005 nop\r\n. . .\r\n3021 jmp <T2>\r\n3023 nop\r\n. . .\r\n302d <T1>\r\n302d nop\r\n. . .\r\n3037 <T2>\r\n3037 nop\r\n. . .\r\n3041 pop %rbp\r\n3042 retq\r\n3000 <spy_func>:\r\n3000 push %rbp\r\n3001 mov %rsp,%rbp\r\n3004 rdtscp\r\n3005 nop\r\n. . .\r\n3021 jmp <T2>\r\n3023 nop\r\n. . .\r\n302d <T1>\r\n302d nop\r\n. . .\r\n3037 <T2>\r\n3037 nop\r\n. . .\r\n3041 rdtscp\r\n. . .\r\n306c pop %rbp\r\n306d retq\r\nListing 2: Disassembly of the functions containing the jump\r\nblock in the victim and the spy. Pictured an example with\r\naligned jump and target addresses.\r\nvictim process. To assure the delivery and the correct response\r\nbefore the spy continues, the spy process calls the sleep() 3\r\nfunction immediately after sending the signal. The victim\r\nhandles the signal by executing the victim_func() 2\r\nfunction. At this stage, an entry in the BTB will be created\r\nor updated. After a short sleep, the spy process executes\r\nthe spy_func() 4 and measures the number of cycles\r\nto execute its jump block. After this step, the measurement\r\nprocess is repeated again. When enough measurements are\r\nobtained, the same experiment is repeated with the victim\r\njumping to a different target. We ran this experiment to\r\ngenerate 100,000 measurements under each setting.\r\nSpy T2 Spy T1\r\nVictim T2 55.76 69.38 (+11.12)\r\nVictim T1 64.93 (+9.17) 58.26\r\nTABLE I: Averaged time of the jump code block (in cycles)\r\nas measured by the spy with different victim settings.\r\nThe results of this experiment are shown as a histogram in\r\nFigure 2. As can be observed from the graph, there are two\r\nseparate groups of time measurement values. The difference\r\nbetween the averages of these two groups is about 9 cycles.\r\nAccording to Intel developer’s manual, the frontend resteer\r\nfollowing an incorrect BTB prediction introduces an 8-cycle\r\nbubble into the instruction fetch pipeline. This value is similar\r\nto the observed slowdown.\r\nIn order to verify the consistency of our results, we also\r\nrepeated the experiment with the spy having the jump target",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/3dcd2e92-166e-44af-9ee1-87643cefd65c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2b2957bc103b6ed64e1026f9680d925cb88c0f64fbc264adf0fa01bff58d08cb",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 801
      },
      {
        "segments": [
          {
            "segment_id": "3dcd2e92-166e-44af-9ee1-87643cefd65c",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 4,
            "page_width": 612,
            "page_height": 792,
            "content": "signals. The BTB manipulations are performed by executing\r\nthe jmp instruction. Conditional branches can also be used,\r\nbut for the sake of simplicity we demonstrate our attack using\r\nunconditional jumps.\r\nThe key code block executed by both processes contains a\r\nsingle jmp instruction with additional nop instructions. The\r\noutline of this code is depicted in Listing 1. The code has\r\ntwo possible jump targets. However, when compiled, the target\r\nis statically set in the binary. We placed this code in both\r\nprocesses. The functions where this code was placed are called\r\nspy_func() and victim_func() accordingly.\r\nasm(\"jmp target2;\");\r\nasm(\"nop; nop; ... \");\r\nasm(\"Target1:\");\r\nasm(\"nop; nop; ... \");\r\nasm(\"Target2:\");\r\nasm(\"nop; nop; ... \");\r\nListing 1: Code example with jump instructions\r\nThe goal of this experiment is to record the execution\r\ntime of the spy process when the measured jmp instruction\r\naligns with a similar instruction in the victim process. Our\r\nexpectation is that the two branch instructions will map to the\r\nsame BTB entry if they are located at the same virtual address.\r\nAssuming BT B index() is the BTB indexing function, then\r\nBT B index(Avictim) = BT B index(Aspy) if Avictim and\r\nAspy are identical virtual addresses. As a result, the data\r\nplaced at this address by the victim will affect the execution\r\ntime of the spy due to the created SDC.\r\nThe victim and the spy processes are compiled and linked\r\nspecifically to align the jump instructions. The spy also\r\nmeasures the number of execution cycles required to execute\r\nthe jump block using the rdtscp instruction. We adjust the\r\nnumber of nop instructions in the spy in order to compensate\r\nfor the length of the rdtscp instruction and keep the ad\u0002dresses of the jump and both targets aligned with the victim’s\r\naddresses. The disassembly of the key functions is depicted in\r\nListing 2.\r\nWe executed the spy and the victim processes under two\r\nsettings. In the first setting, the targets of the spy and the victim\r\nare the same, as demonstrated in Listing 2. In the second\r\nsetting, the targets are different and the victim jumps to target\r\nT1. The use of different targets results in extra BTB misses\r\nand thus performance slowdown for the spy, as the spy’s BTB\r\nentry is overwritten by the victim, but with a different target\r\naddress. By running the spy under both settings, we obtain\r\nthe number of cycles required by the spy to execute the jump\r\ncode block.\r\nThe timing diagram depicting the stages of the experiment is\r\npresented in Figure 3. The affinity masks of the two processes\r\nare set to force them to execute on a single virtual core\r\ninterchangeably. First, the spy process sends a signal 1 to the\r\n3000 <victim_func>:\r\n3000 push %rbp\r\n3001 mov %rsp,%rbp\r\n3004 nop\r\n3005 nop\r\n. . .\r\n3021 jmp <T2>\r\n3023 nop\r\n. . .\r\n302d <T1>\r\n302d nop\r\n. . .\r\n3037 <T2>\r\n3037 nop\r\n. . .\r\n3041 pop %rbp\r\n3042 retq\r\n3000 <spy_func>:\r\n3000 push %rbp\r\n3001 mov %rsp,%rbp\r\n3004 rdtscp\r\n3005 nop\r\n. . .\r\n3021 jmp <T2>\r\n3023 nop\r\n. . .\r\n302d <T1>\r\n302d nop\r\n. . .\r\n3037 <T2>\r\n3037 nop\r\n. . .\r\n3041 rdtscp\r\n. . .\r\n306c pop %rbp\r\n306d retq\r\nListing 2: Disassembly of the functions containing the jump\r\nblock in the victim and the spy. Pictured an example with\r\naligned jump and target addresses.\r\nvictim process. To assure the delivery and the correct response\r\nbefore the spy continues, the spy process calls the sleep() 3\r\nfunction immediately after sending the signal. The victim\r\nhandles the signal by executing the victim_func() 2\r\nfunction. At this stage, an entry in the BTB will be created\r\nor updated. After a short sleep, the spy process executes\r\nthe spy_func() 4 and measures the number of cycles\r\nto execute its jump block. After this step, the measurement\r\nprocess is repeated again. When enough measurements are\r\nobtained, the same experiment is repeated with the victim\r\njumping to a different target. We ran this experiment to\r\ngenerate 100,000 measurements under each setting.\r\nSpy T2 Spy T1\r\nVictim T2 55.76 69.38 (+11.12)\r\nVictim T1 64.93 (+9.17) 58.26\r\nTABLE I: Averaged time of the jump code block (in cycles)\r\nas measured by the spy with different victim settings.\r\nThe results of this experiment are shown as a histogram in\r\nFigure 2. As can be observed from the graph, there are two\r\nseparate groups of time measurement values. The difference\r\nbetween the averages of these two groups is about 9 cycles.\r\nAccording to Intel developer’s manual, the frontend resteer\r\nfollowing an incorrect BTB prediction introduces an 8-cycle\r\nbubble into the instruction fetch pipeline. This value is similar\r\nto the observed slowdown.\r\nIn order to verify the consistency of our results, we also\r\nrepeated the experiment with the spy having the jump target",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/3dcd2e92-166e-44af-9ee1-87643cefd65c.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2b2957bc103b6ed64e1026f9680d925cb88c0f64fbc264adf0fa01bff58d08cb",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 801
      },
      {
        "segments": [
          {
            "segment_id": "058f1737-60b1-44fa-a668-f75da6b4ef81",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 5,
            "page_width": 612,
            "page_height": 792,
            "content": "45 50 55 60 65 70 75 80 85\r\n0.0\r\n0.1\r\n0.2\r\n0.3\r\n0.4\r\n0.5\r\n0.6\r\n0.7\r\nAverage matching\r\nAverage mismatching\r\nMatching\r\nMismatching\r\nFig. 2: Distribution of the execution time of the jump code\r\nblock (in cycles) when victim process jumps to matching and\r\nmismatching target addresses.\r\nset to T1. The results are summarized in Table I. Note that\r\nsince T1 is located closer to the jump instruction in the code\r\nsegment, the spy executes more instructions when jumping to\r\nT1. Consequently, T1’s measurements are higher comparing\r\nto T2’s with the victim performing jumps to the matching\r\ntarget. However, the relative difference between the matching\r\nand mismatching targets is similar in both cases.\r\nVictim Spy\r\nsignal\r\nvictim_func() sleep()\r\nkill(victim_pid)\r\nspy_func()\r\nn_cycles\r\n1\r\n3 2\r\n4\r\nrepeat\r\nFig. 3: Interactions between the spy and the victim\r\nThese results validate our hypotheses that the BTB access\r\nperformed by one process impact the execution time of another\r\nprocess. The stability of the results offers an opportunity to\r\nuse the BTB as a side-channel to monitor the branch activity\r\nof a victim process.\r\nB. Creating Cross-Domain BTB Collisions\r\nWe now describe how the BTB collisions can be created\r\nbetween a user-level process (the attacker) and the kernel\r\nas it executes on behalf of the user process. We call such\r\ncollisions Cross-Domain Collisions (CDC) because the spy\r\nand the victim belong to different protection domains. If the\r\nfull virtual address was used for BTB addressing, then CDCs\r\nwould not exist, because the kernel code and the user code are\r\nlocated at different virtual addresses. In this case, the BTB\r\ntags would be different and the user process would never\r\nexperience a BTB hit on a data placed in the BTB by the\r\nkernel.\r\nHowever, modern processors typically use long (48-bits in\r\ncurrent implementations) virtual addresses when they run in\r\nthe 64-bit mode [35]. Assuming that each BTB entry also\r\nneeds to store the absolute value of the target address, the\r\ntotal size of each BTB entry becomes large if the entire virtual\r\naddress is used for tagging and indexing. For example, for a\r\nBTB with 8K sets, 35 bits for the tag and 48 bits for the target\r\naddress will be needed, adding up to 83 bits of storage for each\r\nentry, which is expensive and power-consuming. Therefore,\r\ncurrent CPUs typically store only a part of the upper-order\r\naddress bits as tags, and some upper-order bits are ignored\r\nfor BTB addressing, possibly creating more collisions but\r\nsignificantly simplifying the design and the BTB area and\r\npower requirements.\r\nThe knowledge of the precise addressing scheme in the BTB\r\nhas significant implications on both types of attacks that we\r\nconsider in this paper. For the user-level attack that exploits\r\nSDCs, this information is important because the address bits\r\nthat are not used in BTB addressing cannot be recovered\r\nusing our attack. In other words, this knowledge gives the\r\nattacker information about the maximum possible benefits of\r\na successful attack. In terms of attacks against KASLR that\r\nexploits CDC, the knowledge of the addressing mechanism is\r\nessential even for creating the CDC collisions themselves.\r\nOn the Haswell processor used in our experiments, only a\r\nsubset of the virtual address bits is used for BTB addressing.\r\nWe used the following algorithm to discover which particular\r\nbits are used for addressing the BTB. First, we created a\r\ndetectable SDC between two jump instructions in two separate\r\nprocesses (as described in the previous section). Second, by\r\nchanging the address bits in the colliding instructions, we\r\ndetermined if the specific bits were used for BTB addressing.\r\nIn particular, when inverting a specific address bit eliminates\r\na previously observed collision, the conclusion is that this bit\r\nwas used in the BTB addressing; otherwise it was not used.\r\nTo determine the relevant bits for Haswell processor, we\r\nrepeated the experiment similar to the one described above in\r\nSection III-A under different settings. The main difference was\r\nthat while we kept the address of the jump instruction the same\r\nin the victim process, we changed the address bits of the jump\r\ninstruction in the spy process. We discovered that all lower bits\r\nof the address are used continuously and only the higher bits of\r\nthe address were cut off and not used in the BTB addressing.\r\nIn particular, bits 0 to 30 of the virtual address are used,\r\nand bits 31 to 47 are ignored. The reverse engineered BTB\r\naddressing scheme in the Haswell processor is depicted in\r\nFigure 4. Figure 5 shows how a kernel-level branch instruction\r\nand a user-level branch instruction can create a CDC in the\r\nBTB.\r\nEquipped with the understanding of the BTB addressing\r\nscheme, the attacker can now create CDCs in the BTB and\r\nexploit them for the kernel-level attack. The kernel-based",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/058f1737-60b1-44fa-a668-f75da6b4ef81.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d469f4ebf45097a7664816ba39ed1de33ce09541448cc871f403b730d272e75c",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 792
      },
      {
        "segments": [
          {
            "segment_id": "058f1737-60b1-44fa-a668-f75da6b4ef81",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 5,
            "page_width": 612,
            "page_height": 792,
            "content": "45 50 55 60 65 70 75 80 85\r\n0.0\r\n0.1\r\n0.2\r\n0.3\r\n0.4\r\n0.5\r\n0.6\r\n0.7\r\nAverage matching\r\nAverage mismatching\r\nMatching\r\nMismatching\r\nFig. 2: Distribution of the execution time of the jump code\r\nblock (in cycles) when victim process jumps to matching and\r\nmismatching target addresses.\r\nset to T1. The results are summarized in Table I. Note that\r\nsince T1 is located closer to the jump instruction in the code\r\nsegment, the spy executes more instructions when jumping to\r\nT1. Consequently, T1’s measurements are higher comparing\r\nto T2’s with the victim performing jumps to the matching\r\ntarget. However, the relative difference between the matching\r\nand mismatching targets is similar in both cases.\r\nVictim Spy\r\nsignal\r\nvictim_func() sleep()\r\nkill(victim_pid)\r\nspy_func()\r\nn_cycles\r\n1\r\n3 2\r\n4\r\nrepeat\r\nFig. 3: Interactions between the spy and the victim\r\nThese results validate our hypotheses that the BTB access\r\nperformed by one process impact the execution time of another\r\nprocess. The stability of the results offers an opportunity to\r\nuse the BTB as a side-channel to monitor the branch activity\r\nof a victim process.\r\nB. Creating Cross-Domain BTB Collisions\r\nWe now describe how the BTB collisions can be created\r\nbetween a user-level process (the attacker) and the kernel\r\nas it executes on behalf of the user process. We call such\r\ncollisions Cross-Domain Collisions (CDC) because the spy\r\nand the victim belong to different protection domains. If the\r\nfull virtual address was used for BTB addressing, then CDCs\r\nwould not exist, because the kernel code and the user code are\r\nlocated at different virtual addresses. In this case, the BTB\r\ntags would be different and the user process would never\r\nexperience a BTB hit on a data placed in the BTB by the\r\nkernel.\r\nHowever, modern processors typically use long (48-bits in\r\ncurrent implementations) virtual addresses when they run in\r\nthe 64-bit mode [35]. Assuming that each BTB entry also\r\nneeds to store the absolute value of the target address, the\r\ntotal size of each BTB entry becomes large if the entire virtual\r\naddress is used for tagging and indexing. For example, for a\r\nBTB with 8K sets, 35 bits for the tag and 48 bits for the target\r\naddress will be needed, adding up to 83 bits of storage for each\r\nentry, which is expensive and power-consuming. Therefore,\r\ncurrent CPUs typically store only a part of the upper-order\r\naddress bits as tags, and some upper-order bits are ignored\r\nfor BTB addressing, possibly creating more collisions but\r\nsignificantly simplifying the design and the BTB area and\r\npower requirements.\r\nThe knowledge of the precise addressing scheme in the BTB\r\nhas significant implications on both types of attacks that we\r\nconsider in this paper. For the user-level attack that exploits\r\nSDCs, this information is important because the address bits\r\nthat are not used in BTB addressing cannot be recovered\r\nusing our attack. In other words, this knowledge gives the\r\nattacker information about the maximum possible benefits of\r\na successful attack. In terms of attacks against KASLR that\r\nexploits CDC, the knowledge of the addressing mechanism is\r\nessential even for creating the CDC collisions themselves.\r\nOn the Haswell processor used in our experiments, only a\r\nsubset of the virtual address bits is used for BTB addressing.\r\nWe used the following algorithm to discover which particular\r\nbits are used for addressing the BTB. First, we created a\r\ndetectable SDC between two jump instructions in two separate\r\nprocesses (as described in the previous section). Second, by\r\nchanging the address bits in the colliding instructions, we\r\ndetermined if the specific bits were used for BTB addressing.\r\nIn particular, when inverting a specific address bit eliminates\r\na previously observed collision, the conclusion is that this bit\r\nwas used in the BTB addressing; otherwise it was not used.\r\nTo determine the relevant bits for Haswell processor, we\r\nrepeated the experiment similar to the one described above in\r\nSection III-A under different settings. The main difference was\r\nthat while we kept the address of the jump instruction the same\r\nin the victim process, we changed the address bits of the jump\r\ninstruction in the spy process. We discovered that all lower bits\r\nof the address are used continuously and only the higher bits of\r\nthe address were cut off and not used in the BTB addressing.\r\nIn particular, bits 0 to 30 of the virtual address are used,\r\nand bits 31 to 47 are ignored. The reverse engineered BTB\r\naddressing scheme in the Haswell processor is depicted in\r\nFigure 4. Figure 5 shows how a kernel-level branch instruction\r\nand a user-level branch instruction can create a CDC in the\r\nBTB.\r\nEquipped with the understanding of the BTB addressing\r\nscheme, the attacker can now create CDCs in the BTB and\r\nexploit them for the kernel-level attack. The kernel-based",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/058f1737-60b1-44fa-a668-f75da6b4ef81.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d469f4ebf45097a7664816ba39ed1de33ce09541448cc871f403b730d272e75c",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 792
      },
      {
        "segments": [
          {
            "segment_id": "cebcc29a-750d-4c5c-b1dd-00fa492fceec",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 6,
            "page_width": 612,
            "page_height": 792,
            "content": "Haswell\r\nVirtual Address: 0xAAAA AAAAAAAA\r\n30 0\r\nf(x)\r\nBranch Target Buffer\r\nIndexing \r\nfunction\r\nFig. 4: BTB addressing scheme in Haswell processor\r\nKernel space\r\nUser space\r\nBTB\r\nAddress tag Target\r\njmp1\r\njmp2\r\n0xffffa9fe8756\r\n0x000a9fe8756\r\n0xa9fe8756\r\nFig. 5: CDC Example\r\nattack flow is described in detail in the next section. After\r\npresenting the kernel-level attack, we show how a complete\r\nattack on user-level process can be realized using SDCs in the\r\nBTB.\r\nIV. RECOVERING ASLR BITS OF KERNEL CODE\r\nADDRESSES\r\nIn this section, we demonstrate how the BTB side-channel\r\ncan be used to effectively recover the randomized offset bits\r\nused in kernel ASLR in a short amount of time. We use a\r\nrecent Linux kernel (version 4.5) for our experiments.\r\nA. KASLR in Linux\r\nModern desktop and server operating systems implement\r\nkernel ASLR (KASLR). Starting from kernel version 3.14,\r\nKASLR is also included in the mainstream Linux kernel\r\ndistribution. To provide the necessary background, we first\r\nexplain the KASLR implementation in 64-bit mode Linux\r\nkernel.\r\nWhen KASLR is disabled, the kernel image is always\r\nplaced at the same physical address during system’s boot.\r\nThe address translation in kernel mode can be performed by\r\nsimply subtracting a predefined PAGE_OFFSET value (which\r\nis 0xffffffff80000000 for a 64-bit kernel) from the\r\nvirtual address. Thus, the location of the kernel image is fixed\r\nin both the virtual and physical address spaces.\r\nWhen KASLR is enabled, a sequence of random bits is\r\ngenerated during early boot process. These bits are used to\r\ncalculate the randomized offset at which the kernel image\r\nis placed in physical memory. The virtual-to-physical address\r\ntranslation for kernel addresses remains unchanged. The ran\u0002domized placement of kernel code in physical memory is\r\nmirrored by the same offset being applied to the virtual ad\u0002dresses in virtual memory. This leads to a critical observation:\r\nif an attacker discovers the position of the kernel code either\r\nin physical or virtual address space, the address layout is\r\ndisclosed, and the location of any address in the static kernel\r\nimage can be determined from there. Since our attack is built\r\naround virtually-addressed BTB, for the rest of this section\r\nwe focus on virtual addresses. Note that since the kernel is\r\nmapped into the address space of every process, deriving the\r\nKASLR offset on any process exposes KASLR for all.\r\nDue to the specifics of the Linux kernel memory layout, the\r\n64-bit kernel currently randomizes only 9 bits of the virtual\r\naddresses. In particular, the kernel code must be aligned at\r\n2MB boundaries. As a result, only the Page Directory Entry\r\n(PDE) bits of virtual addresses are randomized. While it would\r\nhave been possible to extend the relocation mechanism, this\r\nrequires significant reorganization of the physical memory lay\u0002out and will likely result in performance degradation. Figure 6\r\ndemonstrates the randomized bits as well as how the bits are\r\nused for page translation on x86 64 machines operating with\r\nlarge 2MB pages. The figure also shows possible range of\r\nkernel code addresses.\r\nPage Offset\r\n47 3839 2930 21 020\r\nPage Map\r\nLevel 4 Offset\r\nPage Dirrectory\r\nPointer Offset\r\nPage Directory\r\nOffset\r\nRandomized\r\nduring Load\r\nDetermined during\r\nCompilation\r\n47 2930 21 20 0\r\nAlways Fixed 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\r\n2MB page translation:\r\nKernel addresses randomization:\r\nExample of min and max randomized addresses:\r\nMin: \r\nMax:\r\n0xffffffff801e8756\r\n0xffffffffbffe8756\r\nFig. 6: KASLR used in 64-bit Linux kernel. Only the Page\r\nDirectory Entry (PDE) bits are randomized.\r\nB. Using the BTB Channel for KASLR Bits Recovery\r\nIn Section III we demonstrated how two independent jump\r\ninstructions can collide inside the BTB to create contention\r\nfor BTB entries, resulting in a measurable slowdown of the\r\ncolliding jump instructions. We now describe how this side\u0002channel can be used to discover the random address bits of\r\none kernel function. This, in turn, allows the discovery of a\r\nrandomized offset value generated during the boot process.\r\nTo prepare the attack, an adversary needs to locate a branch\r\ninstruction whose execution can be easily triggered by the spy\r\nprocess. One way to achieve this is to analyze the code of\r\nsystem calls available to a user process and locate a system\r\ncall that performs a branch instruction. In order to make the\r\nattack faster and to minimize noise, first consideration should\r\nbe given to system calls with a small number of instructions.\r\nNext, the attacker creates a list of all possible locations for\r\nthat branch taking into account the randomization scheme and\r\nthe location of that branch in the compiled kernel code. After\r\nthat, for each address A from that list, the attacker performs\r\nthe following steps:",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/cebcc29a-750d-4c5c-b1dd-00fa492fceec.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=436bddaaa310c429dfb888d6d8fa2ff96ca62bcf0161a7afb33e56b671b12a2d",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 770
      },
      {
        "segments": [
          {
            "segment_id": "cebcc29a-750d-4c5c-b1dd-00fa492fceec",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 6,
            "page_width": 612,
            "page_height": 792,
            "content": "Haswell\r\nVirtual Address: 0xAAAA AAAAAAAA\r\n30 0\r\nf(x)\r\nBranch Target Buffer\r\nIndexing \r\nfunction\r\nFig. 4: BTB addressing scheme in Haswell processor\r\nKernel space\r\nUser space\r\nBTB\r\nAddress tag Target\r\njmp1\r\njmp2\r\n0xffffa9fe8756\r\n0x000a9fe8756\r\n0xa9fe8756\r\nFig. 5: CDC Example\r\nattack flow is described in detail in the next section. After\r\npresenting the kernel-level attack, we show how a complete\r\nattack on user-level process can be realized using SDCs in the\r\nBTB.\r\nIV. RECOVERING ASLR BITS OF KERNEL CODE\r\nADDRESSES\r\nIn this section, we demonstrate how the BTB side-channel\r\ncan be used to effectively recover the randomized offset bits\r\nused in kernel ASLR in a short amount of time. We use a\r\nrecent Linux kernel (version 4.5) for our experiments.\r\nA. KASLR in Linux\r\nModern desktop and server operating systems implement\r\nkernel ASLR (KASLR). Starting from kernel version 3.14,\r\nKASLR is also included in the mainstream Linux kernel\r\ndistribution. To provide the necessary background, we first\r\nexplain the KASLR implementation in 64-bit mode Linux\r\nkernel.\r\nWhen KASLR is disabled, the kernel image is always\r\nplaced at the same physical address during system’s boot.\r\nThe address translation in kernel mode can be performed by\r\nsimply subtracting a predefined PAGE_OFFSET value (which\r\nis 0xffffffff80000000 for a 64-bit kernel) from the\r\nvirtual address. Thus, the location of the kernel image is fixed\r\nin both the virtual and physical address spaces.\r\nWhen KASLR is enabled, a sequence of random bits is\r\ngenerated during early boot process. These bits are used to\r\ncalculate the randomized offset at which the kernel image\r\nis placed in physical memory. The virtual-to-physical address\r\ntranslation for kernel addresses remains unchanged. The ran\u0002domized placement of kernel code in physical memory is\r\nmirrored by the same offset being applied to the virtual ad\u0002dresses in virtual memory. This leads to a critical observation:\r\nif an attacker discovers the position of the kernel code either\r\nin physical or virtual address space, the address layout is\r\ndisclosed, and the location of any address in the static kernel\r\nimage can be determined from there. Since our attack is built\r\naround virtually-addressed BTB, for the rest of this section\r\nwe focus on virtual addresses. Note that since the kernel is\r\nmapped into the address space of every process, deriving the\r\nKASLR offset on any process exposes KASLR for all.\r\nDue to the specifics of the Linux kernel memory layout, the\r\n64-bit kernel currently randomizes only 9 bits of the virtual\r\naddresses. In particular, the kernel code must be aligned at\r\n2MB boundaries. As a result, only the Page Directory Entry\r\n(PDE) bits of virtual addresses are randomized. While it would\r\nhave been possible to extend the relocation mechanism, this\r\nrequires significant reorganization of the physical memory lay\u0002out and will likely result in performance degradation. Figure 6\r\ndemonstrates the randomized bits as well as how the bits are\r\nused for page translation on x86 64 machines operating with\r\nlarge 2MB pages. The figure also shows possible range of\r\nkernel code addresses.\r\nPage Offset\r\n47 3839 2930 21 020\r\nPage Map\r\nLevel 4 Offset\r\nPage Dirrectory\r\nPointer Offset\r\nPage Directory\r\nOffset\r\nRandomized\r\nduring Load\r\nDetermined during\r\nCompilation\r\n47 2930 21 20 0\r\nAlways Fixed 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\r\n2MB page translation:\r\nKernel addresses randomization:\r\nExample of min and max randomized addresses:\r\nMin: \r\nMax:\r\n0xffffffff801e8756\r\n0xffffffffbffe8756\r\nFig. 6: KASLR used in 64-bit Linux kernel. Only the Page\r\nDirectory Entry (PDE) bits are randomized.\r\nB. Using the BTB Channel for KASLR Bits Recovery\r\nIn Section III we demonstrated how two independent jump\r\ninstructions can collide inside the BTB to create contention\r\nfor BTB entries, resulting in a measurable slowdown of the\r\ncolliding jump instructions. We now describe how this side\u0002channel can be used to discover the random address bits of\r\none kernel function. This, in turn, allows the discovery of a\r\nrandomized offset value generated during the boot process.\r\nTo prepare the attack, an adversary needs to locate a branch\r\ninstruction whose execution can be easily triggered by the spy\r\nprocess. One way to achieve this is to analyze the code of\r\nsystem calls available to a user process and locate a system\r\ncall that performs a branch instruction. In order to make the\r\nattack faster and to minimize noise, first consideration should\r\nbe given to system calls with a small number of instructions.\r\nNext, the attacker creates a list of all possible locations for\r\nthat branch taking into account the randomization scheme and\r\nthe location of that branch in the compiled kernel code. After\r\nthat, for each address A from that list, the attacker performs\r\nthe following steps:",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/cebcc29a-750d-4c5c-b1dd-00fa492fceec.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=436bddaaa310c429dfb888d6d8fa2ff96ca62bcf0161a7afb33e56b671b12a2d",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 770
      },
      {
        "segments": [
          {
            "segment_id": "128f4f8e-8300-4097-955e-d7d17d7d462a",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 7,
            "page_width": 612,
            "page_height": 792,
            "content": "1) It allocates a buffer at the required address in the spy\r\nprocess.\r\n2) It loads this buffer with a block of code containing a\r\nsingle jump instruction. The loading is done in a way\r\nthat creates collisions in the BTB with a possible kernel\r\nbranch instruction at address A. This block of code also\r\ncontains an instruction to measure the time to execute\r\nthe jump instruction.\r\n3) The target branch instruction in the kernel code is\r\nactivated by executing the identified system call.\r\n4) The block of code in the spy process is executed a\r\nnumber of times and the number of cycles taken to\r\nexecute it is recorded.\r\n5) Finally, the results are analyzed. The block with higher\r\naverage cycle measurement corresponds to the situation\r\nwhen the jump instruction in the spy’s code block\r\ncollides with the kernel branch at address A.\r\nC. Results of KASLR Bit Recovery\r\nWe implemented the attack discussed above and executed\r\nit on our test machine equipped with a Haswell CPU. In our\r\nexperiments, we used the open system call to locate a branch\r\ninstruction in the kernel code. This system call opens a file and\r\nreturns a file descriptor. However, prior to accessing the file\r\nsystem, the OS checks for any errors. This check involves a\r\ncomparison performed using a conditional branch instruction.\r\nThe branch instruction is located at a predictable address and\r\ntherefore can be used for the attack.\r\nOne of the possible errors that occurs during the system call\r\nis when the provided file name is larger than the maximum\r\nlength allowed by the system. In order to make the attack fast\r\nand to minimize noise, we intentionally provided the erroneous\r\nfilename. After the kernel detects the length violation, the\r\ncontrol flow is immediately returned to the user process that\r\nrequested this system call.\r\nThe results of this experiment are presented in Figure 7.\r\nThe nine random address bits correspond to 512 possible\r\nA addresses. For each such address A, we collected 50\r\nmeasurements. As seen from the graph, there is a single\r\npoint that has the average timing that is much higher than\r\nthe rest of the points on the graph. This point corresponds to\r\nthe colliding branch instruction. In particular, the user space\r\njump instruction at address 0xa9fe8756 collides with an\u0002other branch instruction at address 0xffffa9fe8756. This\r\ncollision results in a significant slowdown due to the wrong\u0002path instruction fetch after the BTB prediction. Therefore, the\r\nvalue of the KASLR bits is a9f in this case. The described\r\nattack takes a very short time: only 60 milliseconds are needed\r\nto collect the required number of samples.\r\nV. RECOVERING ASLR BITS IN USER APPLICATION CODE\r\nUser-level processes can also be the victims of attacks\r\nattempting to compromise ASLR. Privileged processes or\r\n7d0 834 898 8fc 960 9c4 a28 a8c af0 b54 bb8 c1c c80\r\nKASLR bits\r\n40\r\n50\r\n60\r\n70\r\n80\r\n90\r\n100\r\nCycles to execute spy's code block\r\n0xa9fe8756\r\nFig. 7: Results of the BTB-based Attack on KASLR\r\nprocesses that have access to specific data can be attacked by\r\nother processes running in the same system; as part of such\r\nan attack, reverse engineering the ASLR offset is necessary.\r\nWhile system security settings may only allow an attacker to\r\nremotely create a process with user privileges, the attacker can\r\nuse this user process as a starting point for discovering and\r\nattacking other processes with higher privileges.\r\nA typical system has many daemon processes executing\r\nwith administrative privileges and these daemons can have\r\ncommon exploitable vulnerabilities. For example, a recently\r\nreported vulnerability [36] in the cupsd printing scheduler\r\n(which is found on most Unix-like systems and is executing\r\nas root), allows a remote attacker to execute arbitrary code.\r\nTypically, ASLR interferes with the attacker’s ability to per\u0002form a subsequent attack, such as a code reuse attack, that\r\nfollows the exploitation of the vulnerability e.g. by means of\r\nbuffer overflow. To complete a successful attack, the adversary\r\nfirst needs to de-randomize the victim process prior to enabling\r\nthe correct exploitation of the vulnerability without crashing\r\nthe victim process.\r\nAnother relevant application of a user-level ASLR attack\r\nis to perform layout de-randomization in isolated execution\r\nenvironments, where application secrets are protected inside\r\nenclaves or compartments [37], [38], [39], [40]. The compart\u0002ment code layout is usually kept secret in such systems, and\r\nde-randomizing it opens avenue for side-channel attacks on\r\ncompartments, similar to the ones reported by Xu et al. [41].\r\nThe BTB side-channel presents one way of de-randomizing\r\nthe code segment of a running process in this scenario. Our\r\ncontribution is to demonstrate the principles of such user\u0002space attack. Similar to the attack on kernel ASLR described\r\nin previous section, the attack on user-level ASLR is based\r\non the ability of the spy process to trigger some activity in\r\nthe victim process. Such triggering can be accomplished in",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/128f4f8e-8300-4097-955e-d7d17d7d462a.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=45f71e706a6d72b826b3485c5354db0d339760d1d4d3d895c51f9a6b9e29d174",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 806
      },
      {
        "segments": [
          {
            "segment_id": "128f4f8e-8300-4097-955e-d7d17d7d462a",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 7,
            "page_width": 612,
            "page_height": 792,
            "content": "1) It allocates a buffer at the required address in the spy\r\nprocess.\r\n2) It loads this buffer with a block of code containing a\r\nsingle jump instruction. The loading is done in a way\r\nthat creates collisions in the BTB with a possible kernel\r\nbranch instruction at address A. This block of code also\r\ncontains an instruction to measure the time to execute\r\nthe jump instruction.\r\n3) The target branch instruction in the kernel code is\r\nactivated by executing the identified system call.\r\n4) The block of code in the spy process is executed a\r\nnumber of times and the number of cycles taken to\r\nexecute it is recorded.\r\n5) Finally, the results are analyzed. The block with higher\r\naverage cycle measurement corresponds to the situation\r\nwhen the jump instruction in the spy’s code block\r\ncollides with the kernel branch at address A.\r\nC. Results of KASLR Bit Recovery\r\nWe implemented the attack discussed above and executed\r\nit on our test machine equipped with a Haswell CPU. In our\r\nexperiments, we used the open system call to locate a branch\r\ninstruction in the kernel code. This system call opens a file and\r\nreturns a file descriptor. However, prior to accessing the file\r\nsystem, the OS checks for any errors. This check involves a\r\ncomparison performed using a conditional branch instruction.\r\nThe branch instruction is located at a predictable address and\r\ntherefore can be used for the attack.\r\nOne of the possible errors that occurs during the system call\r\nis when the provided file name is larger than the maximum\r\nlength allowed by the system. In order to make the attack fast\r\nand to minimize noise, we intentionally provided the erroneous\r\nfilename. After the kernel detects the length violation, the\r\ncontrol flow is immediately returned to the user process that\r\nrequested this system call.\r\nThe results of this experiment are presented in Figure 7.\r\nThe nine random address bits correspond to 512 possible\r\nA addresses. For each such address A, we collected 50\r\nmeasurements. As seen from the graph, there is a single\r\npoint that has the average timing that is much higher than\r\nthe rest of the points on the graph. This point corresponds to\r\nthe colliding branch instruction. In particular, the user space\r\njump instruction at address 0xa9fe8756 collides with an\u0002other branch instruction at address 0xffffa9fe8756. This\r\ncollision results in a significant slowdown due to the wrong\u0002path instruction fetch after the BTB prediction. Therefore, the\r\nvalue of the KASLR bits is a9f in this case. The described\r\nattack takes a very short time: only 60 milliseconds are needed\r\nto collect the required number of samples.\r\nV. RECOVERING ASLR BITS IN USER APPLICATION CODE\r\nUser-level processes can also be the victims of attacks\r\nattempting to compromise ASLR. Privileged processes or\r\n7d0 834 898 8fc 960 9c4 a28 a8c af0 b54 bb8 c1c c80\r\nKASLR bits\r\n40\r\n50\r\n60\r\n70\r\n80\r\n90\r\n100\r\nCycles to execute spy's code block\r\n0xa9fe8756\r\nFig. 7: Results of the BTB-based Attack on KASLR\r\nprocesses that have access to specific data can be attacked by\r\nother processes running in the same system; as part of such\r\nan attack, reverse engineering the ASLR offset is necessary.\r\nWhile system security settings may only allow an attacker to\r\nremotely create a process with user privileges, the attacker can\r\nuse this user process as a starting point for discovering and\r\nattacking other processes with higher privileges.\r\nA typical system has many daemon processes executing\r\nwith administrative privileges and these daemons can have\r\ncommon exploitable vulnerabilities. For example, a recently\r\nreported vulnerability [36] in the cupsd printing scheduler\r\n(which is found on most Unix-like systems and is executing\r\nas root), allows a remote attacker to execute arbitrary code.\r\nTypically, ASLR interferes with the attacker’s ability to per\u0002form a subsequent attack, such as a code reuse attack, that\r\nfollows the exploitation of the vulnerability e.g. by means of\r\nbuffer overflow. To complete a successful attack, the adversary\r\nfirst needs to de-randomize the victim process prior to enabling\r\nthe correct exploitation of the vulnerability without crashing\r\nthe victim process.\r\nAnother relevant application of a user-level ASLR attack\r\nis to perform layout de-randomization in isolated execution\r\nenvironments, where application secrets are protected inside\r\nenclaves or compartments [37], [38], [39], [40]. The compart\u0002ment code layout is usually kept secret in such systems, and\r\nde-randomizing it opens avenue for side-channel attacks on\r\ncompartments, similar to the ones reported by Xu et al. [41].\r\nThe BTB side-channel presents one way of de-randomizing\r\nthe code segment of a running process in this scenario. Our\r\ncontribution is to demonstrate the principles of such user\u0002space attack. Similar to the attack on kernel ASLR described\r\nin previous section, the attack on user-level ASLR is based\r\non the ability of the spy process to trigger some activity in\r\nthe victim process. Such triggering can be accomplished in",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/128f4f8e-8300-4097-955e-d7d17d7d462a.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=45f71e706a6d72b826b3485c5354db0d339760d1d4d3d895c51f9a6b9e29d174",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 806
      },
      {
        "segments": [
          {
            "segment_id": "6f0d7e60-7066-45d3-af66-d1febf8c0bd2",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 8,
            "page_width": 612,
            "page_height": 792,
            "content": "several different ways depending on the interfaces offered by\r\nthe victim process. For example, with the cupsd daemon,\r\nthe spy can send some requests via the network to force some\r\ncode to be executed as needed. In the attack preparation stage,\r\nthe attacker analyzes the victim’s executable to find functions\r\nthat can be triggered and also locates jump instructions in such\r\nfunctions. The stages of the attack are presented in Figure 8.\r\nSpecifically, the spy process performs the following steps for\r\neach possible address A where the victim’s branch instruction\r\ncan reside:\r\n1) It allocates a buffer at the required address.\r\n2) It fills the buffer with the code containing a single jump\r\ninstruction at address A.\r\n3) It triggers 1 an activity in the victim process 2 in order\r\nto force the victim to create a BTB entry.\r\n4) It waits 3 for the activity to complete.\r\n5) It executes the jump block several times and measures\r\nthe execution time 4 .\r\n6) It changes the target of the jump instruction 5 and\r\nrepeats the measurement stages.\r\n7) Finally, the spy discovers the address at which the\r\nbehavior of the jump is similar to what we described\r\nin Section IV.\r\nWe now discuss the requirements for this attack and mech\u0002anisms that allow the attacker to fulfill these requirements.\r\nVictim Spy\r\nrequest\r\nrequest\r\nvictim_activity sleep()\r\nTrigger victim\r\nChange jmp target\r\nsleep()\r\nspy_func()\r\nn_cycles\r\nspy_func()\r\nn_cycles\r\n1\r\n5\r\n3 2\r\n4\r\nvictim_activity\r\nTrigger victim\r\nFig. 8: Stages of the user ASLR attack\r\nA. Achieving Co-residency of the Victim and the Spy\r\nThe attack on kernel ASLR described in previous section\r\ndoes not have to be tied to a specific core. When a process\r\nperforms a system call, the process switches to kernel mode\r\nand executes the kernel code which is mapped into its address\r\nspace; i.e., the kernel code executes on the same core without\r\ncausing a context switch. After that, the kernel returns to the\r\nprocess and allows it to continue.\r\nThe situation is quite different for the user-level attack. Our\r\nexperiments with the BTB side-channel on both Sandy Bridge\r\nand Haswell CPUs revealed that a BTB collision between two\r\nuser-level processes can only happen when both processes are\r\n— Dummy — Victim\r\n— Spy — Conext swith\r\nPhys Core 0 Phys Core 1\r\nPhys Core 2 Phys Core 3\r\n0 14 5\r\n2 6 3 7\r\n(a) Dummy processes force the OS to schedule the\r\nvictim on a desired virtual core (prior the spy)\r\nPhys Core 0\r\n0 14 5\r\n2 6 3 7\r\nPhys Core 1\r\nPhys Core 2 Phys Core 3\r\n(b) A copy of the spy process is executed on each\r\ncore\r\nFig. 9: Two types of spy scheduling. Both produce context\r\nswitches from the victim to the spy allowing leakage of\r\nsensitive data.\r\nscheduled consecutively on the same virtual core (or hardware\r\nthread context) of a hyper-threaded processor. The collision\r\ndoes not happen when the two processes are executed on\r\nparallel hardware contexts. This observation implies that either\r\neach virtual core has a dedicated area in the BTB, or every\r\nBTB entry is marked with a virtual core ID. Consequently, the\r\nfirst goal of the user-level attack is to ensure co-residency of\r\nthe victim and the spy on the same virtual core.\r\nThe virtual core co-residency requirement can be met in\r\nseveral ways. One method is to inject dummy processes in the\r\nsystem on all other virtual cores in order to alter the scheduling\r\nmechanism and force the spy to be placed on the same virtual\r\ncore as the victim. Another option is to execute the spy on all\r\nvirtual cores. These two schemes are summarized in Figure 9\r\nand are described below.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/6f0d7e60-7066-45d3-af66-d1febf8c0bd2.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=161c430a766abafe20257ec6469af6593f2838e4354cb4327029bd6f5008709e",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 618
      },
      {
        "segments": [
          {
            "segment_id": "6f0d7e60-7066-45d3-af66-d1febf8c0bd2",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 8,
            "page_width": 612,
            "page_height": 792,
            "content": "several different ways depending on the interfaces offered by\r\nthe victim process. For example, with the cupsd daemon,\r\nthe spy can send some requests via the network to force some\r\ncode to be executed as needed. In the attack preparation stage,\r\nthe attacker analyzes the victim’s executable to find functions\r\nthat can be triggered and also locates jump instructions in such\r\nfunctions. The stages of the attack are presented in Figure 8.\r\nSpecifically, the spy process performs the following steps for\r\neach possible address A where the victim’s branch instruction\r\ncan reside:\r\n1) It allocates a buffer at the required address.\r\n2) It fills the buffer with the code containing a single jump\r\ninstruction at address A.\r\n3) It triggers 1 an activity in the victim process 2 in order\r\nto force the victim to create a BTB entry.\r\n4) It waits 3 for the activity to complete.\r\n5) It executes the jump block several times and measures\r\nthe execution time 4 .\r\n6) It changes the target of the jump instruction 5 and\r\nrepeats the measurement stages.\r\n7) Finally, the spy discovers the address at which the\r\nbehavior of the jump is similar to what we described\r\nin Section IV.\r\nWe now discuss the requirements for this attack and mech\u0002anisms that allow the attacker to fulfill these requirements.\r\nVictim Spy\r\nrequest\r\nrequest\r\nvictim_activity sleep()\r\nTrigger victim\r\nChange jmp target\r\nsleep()\r\nspy_func()\r\nn_cycles\r\nspy_func()\r\nn_cycles\r\n1\r\n5\r\n3 2\r\n4\r\nvictim_activity\r\nTrigger victim\r\nFig. 8: Stages of the user ASLR attack\r\nA. Achieving Co-residency of the Victim and the Spy\r\nThe attack on kernel ASLR described in previous section\r\ndoes not have to be tied to a specific core. When a process\r\nperforms a system call, the process switches to kernel mode\r\nand executes the kernel code which is mapped into its address\r\nspace; i.e., the kernel code executes on the same core without\r\ncausing a context switch. After that, the kernel returns to the\r\nprocess and allows it to continue.\r\nThe situation is quite different for the user-level attack. Our\r\nexperiments with the BTB side-channel on both Sandy Bridge\r\nand Haswell CPUs revealed that a BTB collision between two\r\nuser-level processes can only happen when both processes are\r\n— Dummy — Victim\r\n— Spy — Conext swith\r\nPhys Core 0 Phys Core 1\r\nPhys Core 2 Phys Core 3\r\n0 14 5\r\n2 6 3 7\r\n(a) Dummy processes force the OS to schedule the\r\nvictim on a desired virtual core (prior the spy)\r\nPhys Core 0\r\n0 14 5\r\n2 6 3 7\r\nPhys Core 1\r\nPhys Core 2 Phys Core 3\r\n(b) A copy of the spy process is executed on each\r\ncore\r\nFig. 9: Two types of spy scheduling. Both produce context\r\nswitches from the victim to the spy allowing leakage of\r\nsensitive data.\r\nscheduled consecutively on the same virtual core (or hardware\r\nthread context) of a hyper-threaded processor. The collision\r\ndoes not happen when the two processes are executed on\r\nparallel hardware contexts. This observation implies that either\r\neach virtual core has a dedicated area in the BTB, or every\r\nBTB entry is marked with a virtual core ID. Consequently, the\r\nfirst goal of the user-level attack is to ensure co-residency of\r\nthe victim and the spy on the same virtual core.\r\nThe virtual core co-residency requirement can be met in\r\nseveral ways. One method is to inject dummy processes in the\r\nsystem on all other virtual cores in order to alter the scheduling\r\nmechanism and force the spy to be placed on the same virtual\r\ncore as the victim. Another option is to execute the spy on all\r\nvirtual cores. These two schemes are summarized in Figure 9\r\nand are described below.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/6f0d7e60-7066-45d3-af66-d1febf8c0bd2.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=161c430a766abafe20257ec6469af6593f2838e4354cb4327029bd6f5008709e",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 618
      },
      {
        "segments": [
          {
            "segment_id": "20422b34-1f15-4488-aa0f-a75f987eb9ab",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 9,
            "page_width": 612,
            "page_height": 792,
            "content": "1) Manipulating the OS Scheduler: One way to achieve co\u0002residency is to manipulate process scheduling by the kernel.\r\nWe assume that it is possible for a user process to schedule\r\nitself on an arbitrary core. In Linux, such capability is available\r\nthrough a call to sched_setaffinity() [42]. Scheduling\r\nmanipulation is possible because of predictability of the task\r\nplacement algorithm. In order to efficiently and equally utilize\r\nthe CPU computational and power resources, the OS attempts\r\nto spread the load equally among all cores. With that con\u0002straint, the OS is more likely to schedule a process on a core\r\nwith a lower utilization level. To exploit this algorithm, the\r\nattacker can substantially load all cores in the system with\r\ndummy tasks, except for the core on which it wishes to place\r\nthe victim process.\r\nTo validate that it is possible for a user-level process to\r\ncontrol the placement of other processes (including privileged\r\nones) in the system, we examined the scheduling of the\r\nsshd daemon process (OpenSSH server) that was executed\r\nas root. First, we did not introduce any dummy processes\r\nin the background and allowed the OS to freely choose any\r\ncores to schedule this process on. We performed a series of\r\nobservations recording which core the process was scheduled\r\non. During each observation, we initialized a new ssh con\u0002nection in order to force the OS to wake up the process\r\nand place it on one of the cores. For the second part of the\r\nexperiment, we executed dummy CPU-bound processes (as\r\nshown in Figure 9a), loading all but a single virtual core to\r\nthe maximum. We repeated the same series of observations,\r\nrecording the cores on which the sshd process was placed.\r\nWe executed the above experiment to capture 1 million data\r\npoints for each case. For this experiment, we used a machine\r\nwith Intel Core i7-4800MQ quad-core processor. Note that\r\nalthough the CPU has 4 physical cores, the hyper-threading\r\ntechnology makes the OS recognize 8 virtual cores with 2\r\nthreads per physical core. Our machine was running Ubuntu\r\n14.04 LTS with the generic Linux kernel version 3.16.0-48.\r\nThe results of these experiments are presented in Figure 10.\r\nAs seen from the graphs, when there are no dummy processes\r\nrunning on the CPU, the OS spreads the load among the\r\ncores equally. However, when there is a core with much lower\r\nutilization level, the OS would typically schedule the sshd\r\ndaemon on that core. Another interesting observation is that\r\nthe OS is more likely to choose virtual cores 0 – 3 (thus\r\nspreading the load among all four physical cores) before using\r\nvirtual cores 4 – 7, which add another process on the same\r\nphysical core via hyper-threading.\r\n2) Executing Multiple Spies: An alternative method of\r\nachieving context switches from the victim to the spy on\r\nthe same virtual core is to execute multiple copies of the\r\nspy process and allowing the OS to freely choose any core\r\nto schedule the victim process on. Figure 9b illustrates this\r\napproach. Even if a task migration happens, the victim process\r\nwill be placed on a core with a copy of the spy process\r\nrunning. This method requires a slightly more complex spy\r\norganization. In order to achieve a continuous side-channel,\r\nthe scheduled group of spy processes needs to detect which\r\none of the spies is co-located with the victim process at the\r\nmoment. They also need to communicate this information\r\nto each other. Detecting co-residency can be done either by\r\ndirectly obtaining such information from the OS or by relying\r\non side-channel analysis [43].\r\nIn our experimental system, which was configured with the\r\ndefault parameters, the OS allows all user processes to obtain\r\nthe placement information on any other process, including\r\nprivileged processes. This information includes the status of\r\nthe process (active, sleeping, etc.) and the core number on\r\nwhich the target process is/was executing. Such information\r\nis provided through the /proc [44] virtual file system. This\r\nmakes the detection of core co-residency straightforward.\r\nMoreover, the OS is more likely to reschedule a process to\r\nthe same core due to scheduling policies favoring cache affin\u0002ity [45], [46]. This scheduling approach reduces the number of\r\ntimes the process is migrated between the cores and promotes\r\nuninterrupted collection of side-channel data.\r\nB. Experimental results\r\nWe implemented a prototype of the attack on user-level\r\nASLR by modifying the experiment described in Section IV.\r\nFirst, we compiled the victim process with full ASLR support.\r\nSecond, we equipped the spy process with the capability to\r\ncheck possible locations of the victim branch. The victim has a\r\njump with target T2, while the spy repeatedly tries two targets:\r\nthe matching target T2 and the mismatching target T1. The\r\nresults are presented in Figure 11. For demonstration purposes,\r\nwe only show the recovery of 8 bits of the address.\r\nThe results are obtained following the methodology of\r\nSection 3.1. The victim and the spy code is the same as shown\r\nin Listing 2. The spy executes more instructions when jumping\r\nto target T1, therefore the blue points are higher than the green\r\npoints on Figure 11. The vertical line in the middle of the\r\ngraph shows the situation when the victim’s branch and the\r\nspy’s branch hash to the same BTB entry, causing a collision\r\nand additional delay at the spy. While the latency increase\r\nin T1 is expected, the slight increase in T2 (matching target)\r\nis due to collisions and contention on other shared virtually\u0002addressed resources, such as the uop cache. The collisions are\r\nnot through BTB in this case because both victim and spy will\r\nget the BTB hits for the same virtual address and the same\r\ntarget address (T2).\r\nOur prototype code tests 100 addresses in a second. Further\r\noptimizations can make the throughput even higher. Please\r\nnote that current BTB addressing scheme (as used in Haswell\r\nprocessor used for our experiments) allows us to recover only\r\na limited number of ASLR bits. The number of bits that are",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/20422b34-1f15-4488-aa0f-a75f987eb9ab.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5ca6738d829fecbbf01c9ba75378e721744b1e59721d9795040810bd624331b0",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 994
      },
      {
        "segments": [
          {
            "segment_id": "20422b34-1f15-4488-aa0f-a75f987eb9ab",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 9,
            "page_width": 612,
            "page_height": 792,
            "content": "1) Manipulating the OS Scheduler: One way to achieve co\u0002residency is to manipulate process scheduling by the kernel.\r\nWe assume that it is possible for a user process to schedule\r\nitself on an arbitrary core. In Linux, such capability is available\r\nthrough a call to sched_setaffinity() [42]. Scheduling\r\nmanipulation is possible because of predictability of the task\r\nplacement algorithm. In order to efficiently and equally utilize\r\nthe CPU computational and power resources, the OS attempts\r\nto spread the load equally among all cores. With that con\u0002straint, the OS is more likely to schedule a process on a core\r\nwith a lower utilization level. To exploit this algorithm, the\r\nattacker can substantially load all cores in the system with\r\ndummy tasks, except for the core on which it wishes to place\r\nthe victim process.\r\nTo validate that it is possible for a user-level process to\r\ncontrol the placement of other processes (including privileged\r\nones) in the system, we examined the scheduling of the\r\nsshd daemon process (OpenSSH server) that was executed\r\nas root. First, we did not introduce any dummy processes\r\nin the background and allowed the OS to freely choose any\r\ncores to schedule this process on. We performed a series of\r\nobservations recording which core the process was scheduled\r\non. During each observation, we initialized a new ssh con\u0002nection in order to force the OS to wake up the process\r\nand place it on one of the cores. For the second part of the\r\nexperiment, we executed dummy CPU-bound processes (as\r\nshown in Figure 9a), loading all but a single virtual core to\r\nthe maximum. We repeated the same series of observations,\r\nrecording the cores on which the sshd process was placed.\r\nWe executed the above experiment to capture 1 million data\r\npoints for each case. For this experiment, we used a machine\r\nwith Intel Core i7-4800MQ quad-core processor. Note that\r\nalthough the CPU has 4 physical cores, the hyper-threading\r\ntechnology makes the OS recognize 8 virtual cores with 2\r\nthreads per physical core. Our machine was running Ubuntu\r\n14.04 LTS with the generic Linux kernel version 3.16.0-48.\r\nThe results of these experiments are presented in Figure 10.\r\nAs seen from the graphs, when there are no dummy processes\r\nrunning on the CPU, the OS spreads the load among the\r\ncores equally. However, when there is a core with much lower\r\nutilization level, the OS would typically schedule the sshd\r\ndaemon on that core. Another interesting observation is that\r\nthe OS is more likely to choose virtual cores 0 – 3 (thus\r\nspreading the load among all four physical cores) before using\r\nvirtual cores 4 – 7, which add another process on the same\r\nphysical core via hyper-threading.\r\n2) Executing Multiple Spies: An alternative method of\r\nachieving context switches from the victim to the spy on\r\nthe same virtual core is to execute multiple copies of the\r\nspy process and allowing the OS to freely choose any core\r\nto schedule the victim process on. Figure 9b illustrates this\r\napproach. Even if a task migration happens, the victim process\r\nwill be placed on a core with a copy of the spy process\r\nrunning. This method requires a slightly more complex spy\r\norganization. In order to achieve a continuous side-channel,\r\nthe scheduled group of spy processes needs to detect which\r\none of the spies is co-located with the victim process at the\r\nmoment. They also need to communicate this information\r\nto each other. Detecting co-residency can be done either by\r\ndirectly obtaining such information from the OS or by relying\r\non side-channel analysis [43].\r\nIn our experimental system, which was configured with the\r\ndefault parameters, the OS allows all user processes to obtain\r\nthe placement information on any other process, including\r\nprivileged processes. This information includes the status of\r\nthe process (active, sleeping, etc.) and the core number on\r\nwhich the target process is/was executing. Such information\r\nis provided through the /proc [44] virtual file system. This\r\nmakes the detection of core co-residency straightforward.\r\nMoreover, the OS is more likely to reschedule a process to\r\nthe same core due to scheduling policies favoring cache affin\u0002ity [45], [46]. This scheduling approach reduces the number of\r\ntimes the process is migrated between the cores and promotes\r\nuninterrupted collection of side-channel data.\r\nB. Experimental results\r\nWe implemented a prototype of the attack on user-level\r\nASLR by modifying the experiment described in Section IV.\r\nFirst, we compiled the victim process with full ASLR support.\r\nSecond, we equipped the spy process with the capability to\r\ncheck possible locations of the victim branch. The victim has a\r\njump with target T2, while the spy repeatedly tries two targets:\r\nthe matching target T2 and the mismatching target T1. The\r\nresults are presented in Figure 11. For demonstration purposes,\r\nwe only show the recovery of 8 bits of the address.\r\nThe results are obtained following the methodology of\r\nSection 3.1. The victim and the spy code is the same as shown\r\nin Listing 2. The spy executes more instructions when jumping\r\nto target T1, therefore the blue points are higher than the green\r\npoints on Figure 11. The vertical line in the middle of the\r\ngraph shows the situation when the victim’s branch and the\r\nspy’s branch hash to the same BTB entry, causing a collision\r\nand additional delay at the spy. While the latency increase\r\nin T1 is expected, the slight increase in T2 (matching target)\r\nis due to collisions and contention on other shared virtually\u0002addressed resources, such as the uop cache. The collisions are\r\nnot through BTB in this case because both victim and spy will\r\nget the BTB hits for the same virtual address and the same\r\ntarget address (T2).\r\nOur prototype code tests 100 addresses in a second. Further\r\noptimizations can make the throughput even higher. Please\r\nnote that current BTB addressing scheme (as used in Haswell\r\nprocessor used for our experiments) allows us to recover only\r\na limited number of ASLR bits. The number of bits that are",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/20422b34-1f15-4488-aa0f-a75f987eb9ab.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5ca6738d829fecbbf01c9ba75378e721744b1e59721d9795040810bd624331b0",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 994
      },
      {
        "segments": [
          {
            "segment_id": "945e735a-326d-4573-9911-84a8a9f92a93",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 10,
            "page_width": 612,
            "page_height": 792,
            "content": "0 1 2 3 4 5 6 7\r\nSchedule Frequency by Core\r\n0.0%\r\n5.0%\r\n10.0%\r\n15.0%\r\n20.0%\r\n25.0%\r\nFrequency\r\n24.80%\r\n23.46%\r\n21.19%\r\n22.32%\r\n2.07% 2.54% 2.18%\r\n1.44%\r\n(a) No scheduling manipulation\r\n0 1 2 3 4 5 6 7\r\nSchedule Frequency by Core\r\n0.0%\r\n20.0%\r\n40.0%\r\n60.0%\r\n80.0%\r\n100.0%\r\nFrequency\r\n0.07% 0.06% 0.06%\r\n99.59%\r\n0.03% 0.02% 0.02% 0.17%\r\n(b) The spy forces scheduling at core number 3\r\nFig. 10: Scheduling of the victim process to virtual cores.\r\nrandomizes is implementation specific. However, according\r\nto [47], the full ASLR in Linux randomizes 12th to 40th bits\r\nof the virtual address. Since 30th and higher bits are not used\r\nin BTB addressing, only 18 bits can be recovered using the\r\nBTB attack on Haswell. However, this significantly reduces\r\nthe entropy, making the brute force of the remaining 11 bits\r\nmore feasible.\r\n7efebe3e8 7efebe44c 7efebe4b0 7efebe514\r\nRandomized part of the instruction address\r\n75\r\n80\r\n85\r\n90\r\n95\r\n100\r\n105\r\n110\r\n115\r\n120\r\nCycles to execute spy's code block\r\nT1\r\nT2\r\n0x7fefebe45a82\r\nFig. 11: Results of the BTB-based Attack on User-level ASLR\r\nVI. MITIGATING BTB-BASED ATTACKS\r\nIn this section we describe several possible countermeasures\r\nthat can either make the ASLR schemes less vulnerable to\r\nthe BTB side-channel attacks presented above, or completely\r\nsuppress the side-channel. We categorize possible solutions\r\ninto two groups: purely software solutions and hardware\u0002supported solutions.\r\nA. Software Mitigations\r\nSoftware countermeasures are limited because they are not\r\nable to control how branches are mapped to the BTB entries,\r\nthus they do not address the root cause of the side channel.\r\nHowever, several software countermeasures are possible that\r\ncan make the recovery of the ASLR bits difficult or even\r\nimpossible.\r\nTraditional ASLR schemes randomize only the offset of the\r\nsegments within the program address space. However, recent\r\nresearch efforts suggested finer-grained ASLR schemes that\r\ncan randomize code at the granularity of functions [31], basic\r\nblocks [48] or instructions [49], [50]. While most of these\r\nsolutions focus on user-level ASLR, fine-grained KASLR is\r\nalso possible. Reconstructing the code layout in memory is\r\nmuch harder when such fine-grained protection schemes are\r\napplied. The BTB attack described in this paper has a potential\r\nto bypass even these fine-grained techniques, provided that\r\nthey preserve the basic block structure, because it discovers\r\nthe position of individual branch instructions in memory.\r\nHowever, such an attack on fine-grain ASLR would require\r\nsignificantly more effort from the attacker. In addition, if an\r\nASLR technique randomizes the sizes of basic blocks, the spy\r\nprocess will not be able to distinguish basic blocks from one\r\nanother, thus closing the BTB side-channel.\r\nAnother approach to mitigating the BTB side channel (as\r\nwell as many others) is to make the accurate execution\r\ntime readings difficult by fuzzing the time stamp counter, or\r\ndisabling it completely [51], [52]. However, such a solution\r\ncould interfere with many legitimate applications that need\r\nto have precise time measurement capability. Moreover, some\r\nimplementations have been shown to be insecure [53].\r\n1) Kernel ASLR Reinforcement: As was demonstrated in\r\nSection IV-A using the example of Linux, today’s operating\r\nsystems rely on limited entropy for KASLR. A small number",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/945e735a-326d-4573-9911-84a8a9f92a93.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=9f263d78874e6a357f92f801df6c2cb9379e90de190e04f323b413486749370b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 517
      },
      {
        "segments": [
          {
            "segment_id": "945e735a-326d-4573-9911-84a8a9f92a93",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 10,
            "page_width": 612,
            "page_height": 792,
            "content": "0 1 2 3 4 5 6 7\r\nSchedule Frequency by Core\r\n0.0%\r\n5.0%\r\n10.0%\r\n15.0%\r\n20.0%\r\n25.0%\r\nFrequency\r\n24.80%\r\n23.46%\r\n21.19%\r\n22.32%\r\n2.07% 2.54% 2.18%\r\n1.44%\r\n(a) No scheduling manipulation\r\n0 1 2 3 4 5 6 7\r\nSchedule Frequency by Core\r\n0.0%\r\n20.0%\r\n40.0%\r\n60.0%\r\n80.0%\r\n100.0%\r\nFrequency\r\n0.07% 0.06% 0.06%\r\n99.59%\r\n0.03% 0.02% 0.02% 0.17%\r\n(b) The spy forces scheduling at core number 3\r\nFig. 10: Scheduling of the victim process to virtual cores.\r\nrandomizes is implementation specific. However, according\r\nto [47], the full ASLR in Linux randomizes 12th to 40th bits\r\nof the virtual address. Since 30th and higher bits are not used\r\nin BTB addressing, only 18 bits can be recovered using the\r\nBTB attack on Haswell. However, this significantly reduces\r\nthe entropy, making the brute force of the remaining 11 bits\r\nmore feasible.\r\n7efebe3e8 7efebe44c 7efebe4b0 7efebe514\r\nRandomized part of the instruction address\r\n75\r\n80\r\n85\r\n90\r\n95\r\n100\r\n105\r\n110\r\n115\r\n120\r\nCycles to execute spy's code block\r\nT1\r\nT2\r\n0x7fefebe45a82\r\nFig. 11: Results of the BTB-based Attack on User-level ASLR\r\nVI. MITIGATING BTB-BASED ATTACKS\r\nIn this section we describe several possible countermeasures\r\nthat can either make the ASLR schemes less vulnerable to\r\nthe BTB side-channel attacks presented above, or completely\r\nsuppress the side-channel. We categorize possible solutions\r\ninto two groups: purely software solutions and hardware\u0002supported solutions.\r\nA. Software Mitigations\r\nSoftware countermeasures are limited because they are not\r\nable to control how branches are mapped to the BTB entries,\r\nthus they do not address the root cause of the side channel.\r\nHowever, several software countermeasures are possible that\r\ncan make the recovery of the ASLR bits difficult or even\r\nimpossible.\r\nTraditional ASLR schemes randomize only the offset of the\r\nsegments within the program address space. However, recent\r\nresearch efforts suggested finer-grained ASLR schemes that\r\ncan randomize code at the granularity of functions [31], basic\r\nblocks [48] or instructions [49], [50]. While most of these\r\nsolutions focus on user-level ASLR, fine-grained KASLR is\r\nalso possible. Reconstructing the code layout in memory is\r\nmuch harder when such fine-grained protection schemes are\r\napplied. The BTB attack described in this paper has a potential\r\nto bypass even these fine-grained techniques, provided that\r\nthey preserve the basic block structure, because it discovers\r\nthe position of individual branch instructions in memory.\r\nHowever, such an attack on fine-grain ASLR would require\r\nsignificantly more effort from the attacker. In addition, if an\r\nASLR technique randomizes the sizes of basic blocks, the spy\r\nprocess will not be able to distinguish basic blocks from one\r\nanother, thus closing the BTB side-channel.\r\nAnother approach to mitigating the BTB side channel (as\r\nwell as many others) is to make the accurate execution\r\ntime readings difficult by fuzzing the time stamp counter, or\r\ndisabling it completely [51], [52]. However, such a solution\r\ncould interfere with many legitimate applications that need\r\nto have precise time measurement capability. Moreover, some\r\nimplementations have been shown to be insecure [53].\r\n1) Kernel ASLR Reinforcement: As was demonstrated in\r\nSection IV-A using the example of Linux, today’s operating\r\nsystems rely on limited entropy for KASLR. A small number",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/945e735a-326d-4573-9911-84a8a9f92a93.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=9f263d78874e6a357f92f801df6c2cb9379e90de190e04f323b413486749370b",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 517
      },
      {
        "segments": [
          {
            "segment_id": "5335fcb1-fa0f-4040-8d9c-6e70cd7979ba",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 11,
            "page_width": 612,
            "page_height": 792,
            "content": "of randomized bits makes the KASLR side-channel attack\r\npossible. In addition, the bits being randomized fall into the\r\nlower 30 bits of the virtual address1, making the BTB-based\r\nattack possible. A simple solution which does not require\r\nany hardware changes is to ensure that more higher-order\r\nbits are randomized during every system load. The memory\r\norganization on x86 64 machines allows the use of 48 bits of\r\nvirtual address with the most significant bit used to distinguish\r\nbetween the lower half and the upper half of virtual memory.\r\nThus, assuming 2MB pages for kernel code (and thus 21\r\nbits in the page offset), the maximum number of bits that\r\ncan be theoretically randomized is 26 (48-1-21). Since 17 of\r\nthese bits (the upper order bits of the address) are not used\r\nfor BTB addressing, the BTB side-channel will not provide\r\nsufficient information to derive ASLR. The 17 bits correspond\r\nto approximately 131,000 possible kernel positions. Since\r\nbrute-force attacks in kernel space are infeasible, this level\r\nof entropy is likely to provide sufficient security.\r\nRandomization schemes interfere with the way the kernel\r\nnormally organizes its memory layout. In current implementa\u0002tions, large memory areas are fixed and reserved for devices,\r\nthe hypervisor and other service structures. Therefore, im\u0002plementing such a scheme would require significant memory\r\nreorganization in order to benefit from high levels of entropy.\r\nB. Hardware Mitigations\r\nThe BTB side channel attack is possible because of two\r\ntypes of BTB collisions. The first type of collision occurs when\r\ntwo branches residing in different protection rings and located\r\nat different addresses are mapped to the same BTB entry -\r\nthis opens the door for BTB-based attack against KASLR.\r\nThe second type of BTB collision occurs when two different\r\nbranch instructions are located at identical virtual addresses\r\nbut belong to different processes - this collision is the basis\r\nfor an attack on user-level ASLR.\r\nA hardware solution that would fundamentally mitigate\r\nthe BTB-based attacks is to change the BTB addressing\r\nmechanism in a way that prevents exploitable collisions in the\r\nBTB. The attack against KASLR can be mitigated by using\r\nfull virtual address for accessing the BTB, thus eliminating\r\ncollisions between the user code and the kernel code. This\r\nwould require adding extra bits in the BTB, as the tag size\r\nwill increase significantly (by 17 bits compared to Haswell\r\nimplementation for 48-bit virtual addresses).\r\nAlternatively, the BTB can use different indexing functions\r\nfor user and kernel-level code. For example, a secret value can\r\nbe added to the existing BTB hash function when the CPU\r\nis executing in the kernel mode. To prevent the user process\r\nfrom discovering this value and reverse-engineering the hash\r\nfunction, this value can be randomized during each system’s\r\nboot.\r\n1The number of bits can be different on other microarchitectures\r\nIn order to apply the same protection technique to mitigate\r\nuser-level ASLR attack, each process needs to have a unique\r\nvalue that will be used in the BTB hashing function. This\r\ncan be the hardware Address Space Identifier (ASID) [54],\r\nor the values of the CR3 register, which are unique for each\r\nprocess. Of course, these values must be kept secret from other\r\nprocesses.\r\nOther possible hardware-supported mitigation techniques\r\ninclude flushing the BTB on context switches or marking each\r\nBTB entry with unique process ID to distinguish the entries\r\nset up by different processes.\r\nVII. RELATED WORK\r\nHardware side channels are well-known threats to security\r\nof sensitive data. A large number of prior works studied differ\u0002ent aspects of side channels in instruction and data caches [55],\r\n[56], [57], [58], [59]. Aciicmez et al [27], [28]. were the first to\r\ndemonstrate side channel attacks on branch prediction units to\r\nrecover secret keys. In another recent work [30], [29], branch\r\npredictor’s pattern history tables were used to build a covert\r\nchannel and to pass information from one process to another.\r\nIn this paper, we show how the specially-constructed new BTB\r\nside channel can be used to discover the memory layout of\r\nanother process or the kernel, thus bypassing existing KASLR\r\nschemes and reducing the entropy of user-level ASLR.\r\nSeveral works have demonstrated how ASLR can be de\u0002feated through brute-force approach [12], and by using mem\u0002ory disclosure attacks [60]. Some studies also showed how to\r\nbypass ASLR on mobile platforms [61] and novel shielded\r\nsystems [41]. In [62], Gu et al. addressed the problem of\r\nde-randomizing kernel address space based on signatures\r\ngenerated from kernel memory snapshots.\r\nHund et al [63] demonstrated an attack on kernel ASLR\r\nusing cache-based timing side channel analysis. In that work,\r\nthree different attacks were demonstrated. The first attack\r\nrelied on the collision of kernel and user objects in the last\r\nlevel caches. This attack requires the attacker to know the\r\nphysical address of data that he places in the cache. In addition,\r\nthe attack is hard to perform in realistic scenario because of\r\nexcessive amount of noise in the last-level caches from other\r\nprocessor cores. The second attack described in [63] exploits\r\na particular property of Intel’s CPUs. In particular, when a\r\nuser process tries to access a location in the kernel memory\r\nspace, an exception is generated. Even though the access is\r\ndenied, the TLB entry is still created, which can be detected\r\nlater by the user process. This attack allows the spy process to\r\ndiscover which memory pages are allocated in kernel space.\r\nThe third attack of [63] is based on observing the time needed\r\nfor a page walk. To perform the cache-based attack, the spy\r\nprocess first flushes all cache levels and then invokes some\r\nsystem service. After that, it performs a memory access, times\r\nit, and uses this information to determine what kernel code",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/5335fcb1-fa0f-4040-8d9c-6e70cd7979ba.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=707580d5a2469abacc283efe0323c18161b81ed59bdb06ad36daab4d58e0bc83",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 942
      },
      {
        "segments": [
          {
            "segment_id": "5335fcb1-fa0f-4040-8d9c-6e70cd7979ba",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 11,
            "page_width": 612,
            "page_height": 792,
            "content": "of randomized bits makes the KASLR side-channel attack\r\npossible. In addition, the bits being randomized fall into the\r\nlower 30 bits of the virtual address1, making the BTB-based\r\nattack possible. A simple solution which does not require\r\nany hardware changes is to ensure that more higher-order\r\nbits are randomized during every system load. The memory\r\norganization on x86 64 machines allows the use of 48 bits of\r\nvirtual address with the most significant bit used to distinguish\r\nbetween the lower half and the upper half of virtual memory.\r\nThus, assuming 2MB pages for kernel code (and thus 21\r\nbits in the page offset), the maximum number of bits that\r\ncan be theoretically randomized is 26 (48-1-21). Since 17 of\r\nthese bits (the upper order bits of the address) are not used\r\nfor BTB addressing, the BTB side-channel will not provide\r\nsufficient information to derive ASLR. The 17 bits correspond\r\nto approximately 131,000 possible kernel positions. Since\r\nbrute-force attacks in kernel space are infeasible, this level\r\nof entropy is likely to provide sufficient security.\r\nRandomization schemes interfere with the way the kernel\r\nnormally organizes its memory layout. In current implementa\u0002tions, large memory areas are fixed and reserved for devices,\r\nthe hypervisor and other service structures. Therefore, im\u0002plementing such a scheme would require significant memory\r\nreorganization in order to benefit from high levels of entropy.\r\nB. Hardware Mitigations\r\nThe BTB side channel attack is possible because of two\r\ntypes of BTB collisions. The first type of collision occurs when\r\ntwo branches residing in different protection rings and located\r\nat different addresses are mapped to the same BTB entry -\r\nthis opens the door for BTB-based attack against KASLR.\r\nThe second type of BTB collision occurs when two different\r\nbranch instructions are located at identical virtual addresses\r\nbut belong to different processes - this collision is the basis\r\nfor an attack on user-level ASLR.\r\nA hardware solution that would fundamentally mitigate\r\nthe BTB-based attacks is to change the BTB addressing\r\nmechanism in a way that prevents exploitable collisions in the\r\nBTB. The attack against KASLR can be mitigated by using\r\nfull virtual address for accessing the BTB, thus eliminating\r\ncollisions between the user code and the kernel code. This\r\nwould require adding extra bits in the BTB, as the tag size\r\nwill increase significantly (by 17 bits compared to Haswell\r\nimplementation for 48-bit virtual addresses).\r\nAlternatively, the BTB can use different indexing functions\r\nfor user and kernel-level code. For example, a secret value can\r\nbe added to the existing BTB hash function when the CPU\r\nis executing in the kernel mode. To prevent the user process\r\nfrom discovering this value and reverse-engineering the hash\r\nfunction, this value can be randomized during each system’s\r\nboot.\r\n1The number of bits can be different on other microarchitectures\r\nIn order to apply the same protection technique to mitigate\r\nuser-level ASLR attack, each process needs to have a unique\r\nvalue that will be used in the BTB hashing function. This\r\ncan be the hardware Address Space Identifier (ASID) [54],\r\nor the values of the CR3 register, which are unique for each\r\nprocess. Of course, these values must be kept secret from other\r\nprocesses.\r\nOther possible hardware-supported mitigation techniques\r\ninclude flushing the BTB on context switches or marking each\r\nBTB entry with unique process ID to distinguish the entries\r\nset up by different processes.\r\nVII. RELATED WORK\r\nHardware side channels are well-known threats to security\r\nof sensitive data. A large number of prior works studied differ\u0002ent aspects of side channels in instruction and data caches [55],\r\n[56], [57], [58], [59]. Aciicmez et al [27], [28]. were the first to\r\ndemonstrate side channel attacks on branch prediction units to\r\nrecover secret keys. In another recent work [30], [29], branch\r\npredictor’s pattern history tables were used to build a covert\r\nchannel and to pass information from one process to another.\r\nIn this paper, we show how the specially-constructed new BTB\r\nside channel can be used to discover the memory layout of\r\nanother process or the kernel, thus bypassing existing KASLR\r\nschemes and reducing the entropy of user-level ASLR.\r\nSeveral works have demonstrated how ASLR can be de\u0002feated through brute-force approach [12], and by using mem\u0002ory disclosure attacks [60]. Some studies also showed how to\r\nbypass ASLR on mobile platforms [61] and novel shielded\r\nsystems [41]. In [62], Gu et al. addressed the problem of\r\nde-randomizing kernel address space based on signatures\r\ngenerated from kernel memory snapshots.\r\nHund et al [63] demonstrated an attack on kernel ASLR\r\nusing cache-based timing side channel analysis. In that work,\r\nthree different attacks were demonstrated. The first attack\r\nrelied on the collision of kernel and user objects in the last\r\nlevel caches. This attack requires the attacker to know the\r\nphysical address of data that he places in the cache. In addition,\r\nthe attack is hard to perform in realistic scenario because of\r\nexcessive amount of noise in the last-level caches from other\r\nprocessor cores. The second attack described in [63] exploits\r\na particular property of Intel’s CPUs. In particular, when a\r\nuser process tries to access a location in the kernel memory\r\nspace, an exception is generated. Even though the access is\r\ndenied, the TLB entry is still created, which can be detected\r\nlater by the user process. This attack allows the spy process to\r\ndiscover which memory pages are allocated in kernel space.\r\nThe third attack of [63] is based on observing the time needed\r\nfor a page walk. To perform the cache-based attack, the spy\r\nprocess first flushes all cache levels and then invokes some\r\nsystem service. After that, it performs a memory access, times\r\nit, and uses this information to determine what kernel code",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/5335fcb1-fa0f-4040-8d9c-6e70cd7979ba.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=707580d5a2469abacc283efe0323c18161b81ed59bdb06ad36daab4d58e0bc83",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 942
      },
      {
        "segments": [
          {
            "segment_id": "357678cd-d923-4852-9ddb-0e58d8816115",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 12,
            "page_width": 612,
            "page_height": 792,
            "content": "resides on what page. Compared to the cache-based attacks,\r\nthe BTB-based attacks proposed in this paper are significantly\r\nsimpler and allow the adversary to perform the attack under a\r\nmuch more controlled setting. Indeed, the attacker no longer\r\nneeds to deal with noisy measurements from the last-level\r\ncache and does not require any knowledge about the physical\r\naddressing. All our attacks are based on virtual addressing and\r\nthe exploitation of simple BTB collisions. While the attacks\r\non KASLR using side-channel information were previously\r\nconsidered, as described above, to the best of our knowledge\r\nthis paper is the first to consider side-channel analysis to\r\nrecover user-level ASLR.\r\nTo harden the security properties of ASLR schemes against\r\nemerging attacks, researchers have proposed various fine\u0002grain ASLR techniques. These schemes enforce the enhanced\r\nrandomization at different levels, such as at the level of func\u0002tions [31], basic blocks [48] or instructions [49], [50]. While\r\nsome of fine-grain ASLR solutions can thwart our BTB attack\r\nby randomizing the relative positions of branch instructions in\r\nmemory, they usually have significant performance overhead\r\nand are not widely adopted. In addition, our attack can still be\r\nused to locate the position of individual branch instructions\r\nin memory. This information can potentially lead to the\r\ndevelopment of other techniques to eventually reconstruct the\r\ncode layout in memory despite deep randomization.\r\nSnow et al. [64] presented just-in-time code reuse attack as\r\nan effective technique against sophisticated fine-grained ran\u0002domization schemes. The attack is based by scanning and con\u0002structing the Return-Oriented-Programming (ROP) payload at\r\nthe runtime exploiting memory disclosures. A system called\r\nHeisenbyte [65] has been proposed to protect against such\r\njust-in-time attacks by addressing memory disclosure attacks.\r\nHeisenbyte defeats memory disclosure attacks by introducing\r\nthe concept of destructive code reads. Since our BTB attack\r\ndoes not rely on code reads from memory, it can still be used in\r\nan arsenal of tools to create memory disclosures and eventually\r\nreconstruct the address randomization schemes.\r\nVIII. CONCLUDING REMARKS\r\nAddress Space Layout Randomization (ASLR) is a widely\u0002adopted security mechanism, both in kernel and application\r\nlevels, to protect systems from code reuse attacks. In this\r\npaper, we exploited collisions in shared BTBs to create BTB\r\nside-channels and allow the attacker process to recover the\r\nmemory layout of both the kernel and user-level applications.\r\nWe demonstrated a successful attack on a system with Haswell\r\nCPU and a recent version of Linux kernel. We showed that\r\nour attack is robust and can bypass KASLR in a very short\r\namount time. In addition, the attack can reduce the entropy of\r\nthe user-level ASLR. Since this BTB attack adds to the arsenal\r\nof tools available to the attackers, we also described possible\r\nsoftware and hardware countermeasures to mitigate this new\r\nsecurity threat.\r\nIX. ACKNOWLEDGMENT\r\nThis material is based on research sponsored by the National\r\nScience Foundation grant CNS-1422401.\r\nREFERENCES\r\n[1] A. One, “Smashing the stack for fun and profit,” Phrack magazine,\r\nvol. 7, no. 49, pp. 14–16, 1996.\r\n[2] C. Cowan, P. Wagle, C. Pu, S. Beattie, and J. Walpole, “Buffer overflows:\r\nAttacks and defenses for the vulnerability of the decade,” in DARPA\r\nInformation Survivability Conference and Exposition, 2000. DISCEX’00.\r\nProceedings, vol. 2. IEEE, 2000, pp. 119–129.\r\n[3] T. Newsham, “Format string attacks,” 2000.\r\n[4] F. Qin, S. Lu, and Y. Zhou, “SafeMem: Exploiting ECC-memory for\r\ndetecting memory leaks and memory corruption during production runs,”\r\nin High-Performance Computer Architecture, 2005. HPCA-11. 11th\r\nInternational Symposium on. IEEE, 2005, pp. 291–302.\r\n[5] S. Chen, J. Xu, N. Nakka, Z. Kalbarczyk, and R. K. Iyer, “Defeating\r\nmemory corruption attacks via pointer taintedness detection,” in Depend\u0002able Systems and Networks, 2005. DSN 2005. Proceedings. International\r\nConference on. IEEE, 2005, pp. 378–387.\r\n[6] J. Xu, P. Ning, C. Kil, Y. Zhai, and C. Bookholt, “Automatic diagnosis\r\nand response to memory corruption vulnerabilities,” in Proceedings of\r\nthe 12th ACM conference on Computer and communications security.\r\nACM, 2005, pp. 223–234.\r\n[7] D. Jang, Z. Tatlock, and S. Lerner, “SafeDispatch: Securing C++ Virtual\r\nCalls from Memory Corruption Attacks.” in NDSS, 2014.\r\n[8] E. C. Sezer, P. Ning, C. Kil, and J. Xu, “Memsherlock: an automated de\u0002bugger for unknown memory corruption vulnerabilities,” in Proceedings\r\nof the 14th ACM conference on Computer and communications security.\r\nACM, 2007, pp. 562–572.\r\n[9] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi, H. Shacham,\r\nand M. Winandy, “Return-oriented programming without returns,” in\r\nProceedings of the 17th ACM conference on Computer and communi\u0002cations security. ACM, 2010, pp. 559–572.\r\n[10] M. Kayaalp, M. Ozsoy, N. Abu-Ghazaleh, and D. Ponomarev, “Branch\r\nregulation: Low-overhead protection from code reuse attacks,” in Com\u0002puter Architecture (ISCA), 2012 39th Annual International Symposium\r\non. IEEE, 2012, pp. 94–105.\r\n[11] M. Kayaalp, T. Schmitt, J. Nomani, D. Ponomarev, and N. Abu\u0002Ghazaleh, “SCRAP: Architecture for signature-based protection from\r\ncode reuse attacks,” in High Performance Computer Architecture\r\n(HPCA2013), 2013 IEEE 19th International Symposium on. IEEE,\r\n2013, pp. 258–269.\r\n[12] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu, and D. Boneh,\r\n“On the effectiveness of address-space randomization,” in Proceedings\r\nof the 11th ACM conference on Computer and communications security.\r\nACM, 2004, pp. 298–307.\r\n[13] H. Bojinov, D. Boneh, R. Cannings, and I. Malchev, “Address space\r\nrandomization for mobile devices,” in Proceedings of the fourth ACM\r\nconference on Wireless network security. ACM, 2011, pp. 127–138.\r\n[14] “CVE-2015-3108.” Available from NVD, CVE-ID CVE-2015-3108,\r\nSep. 6 2015, [Online; accessed Feb. 2 2016 https://web.nvd.nist.gov/\r\nview/vuln/detail?vulnId=CVE-2015-3108].\r\n[15] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K. Iyer, “Non-control-data\r\nattacks are realistic threats.” in Usenix Security, vol. 5, 2005.\r\n[16] K. Lu, C. Song, B. Lee, S. P. Chung, T. Kim, and W. Lee, “ASLR\u0002Guard: Stopping address space leakage for code reuse attacks,” in\r\nProceedings of the 22nd ACM SIGSAC Conference on Computer and\r\nCommunications Security. ACM, 2015, pp. 280–291.\r\n[17] PaX Team, “Address space layout randomization,” Phrack, March, 2003.\r\n[18] M. Howard, “Address space layout randomization in Windows Vista,”\r\nMicrosoft Corporation, vol. 26, 2006.\r\n[19] D. Keuper, “XNU: A security evaluation,” December 2012.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/357678cd-d923-4852-9ddb-0e58d8816115.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=9c3bd87b1a5d98b2b94cacc07aef68a41c26dfce32f02ecc03ae1b756bd3bb47",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 985
      },
      {
        "segments": [
          {
            "segment_id": "357678cd-d923-4852-9ddb-0e58d8816115",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 12,
            "page_width": 612,
            "page_height": 792,
            "content": "resides on what page. Compared to the cache-based attacks,\r\nthe BTB-based attacks proposed in this paper are significantly\r\nsimpler and allow the adversary to perform the attack under a\r\nmuch more controlled setting. Indeed, the attacker no longer\r\nneeds to deal with noisy measurements from the last-level\r\ncache and does not require any knowledge about the physical\r\naddressing. All our attacks are based on virtual addressing and\r\nthe exploitation of simple BTB collisions. While the attacks\r\non KASLR using side-channel information were previously\r\nconsidered, as described above, to the best of our knowledge\r\nthis paper is the first to consider side-channel analysis to\r\nrecover user-level ASLR.\r\nTo harden the security properties of ASLR schemes against\r\nemerging attacks, researchers have proposed various fine\u0002grain ASLR techniques. These schemes enforce the enhanced\r\nrandomization at different levels, such as at the level of func\u0002tions [31], basic blocks [48] or instructions [49], [50]. While\r\nsome of fine-grain ASLR solutions can thwart our BTB attack\r\nby randomizing the relative positions of branch instructions in\r\nmemory, they usually have significant performance overhead\r\nand are not widely adopted. In addition, our attack can still be\r\nused to locate the position of individual branch instructions\r\nin memory. This information can potentially lead to the\r\ndevelopment of other techniques to eventually reconstruct the\r\ncode layout in memory despite deep randomization.\r\nSnow et al. [64] presented just-in-time code reuse attack as\r\nan effective technique against sophisticated fine-grained ran\u0002domization schemes. The attack is based by scanning and con\u0002structing the Return-Oriented-Programming (ROP) payload at\r\nthe runtime exploiting memory disclosures. A system called\r\nHeisenbyte [65] has been proposed to protect against such\r\njust-in-time attacks by addressing memory disclosure attacks.\r\nHeisenbyte defeats memory disclosure attacks by introducing\r\nthe concept of destructive code reads. Since our BTB attack\r\ndoes not rely on code reads from memory, it can still be used in\r\nan arsenal of tools to create memory disclosures and eventually\r\nreconstruct the address randomization schemes.\r\nVIII. CONCLUDING REMARKS\r\nAddress Space Layout Randomization (ASLR) is a widely\u0002adopted security mechanism, both in kernel and application\r\nlevels, to protect systems from code reuse attacks. In this\r\npaper, we exploited collisions in shared BTBs to create BTB\r\nside-channels and allow the attacker process to recover the\r\nmemory layout of both the kernel and user-level applications.\r\nWe demonstrated a successful attack on a system with Haswell\r\nCPU and a recent version of Linux kernel. We showed that\r\nour attack is robust and can bypass KASLR in a very short\r\namount time. In addition, the attack can reduce the entropy of\r\nthe user-level ASLR. Since this BTB attack adds to the arsenal\r\nof tools available to the attackers, we also described possible\r\nsoftware and hardware countermeasures to mitigate this new\r\nsecurity threat.\r\nIX. ACKNOWLEDGMENT\r\nThis material is based on research sponsored by the National\r\nScience Foundation grant CNS-1422401.\r\nREFERENCES\r\n[1] A. One, “Smashing the stack for fun and profit,” Phrack magazine,\r\nvol. 7, no. 49, pp. 14–16, 1996.\r\n[2] C. Cowan, P. Wagle, C. Pu, S. Beattie, and J. Walpole, “Buffer overflows:\r\nAttacks and defenses for the vulnerability of the decade,” in DARPA\r\nInformation Survivability Conference and Exposition, 2000. DISCEX’00.\r\nProceedings, vol. 2. IEEE, 2000, pp. 119–129.\r\n[3] T. Newsham, “Format string attacks,” 2000.\r\n[4] F. Qin, S. Lu, and Y. Zhou, “SafeMem: Exploiting ECC-memory for\r\ndetecting memory leaks and memory corruption during production runs,”\r\nin High-Performance Computer Architecture, 2005. HPCA-11. 11th\r\nInternational Symposium on. IEEE, 2005, pp. 291–302.\r\n[5] S. Chen, J. Xu, N. Nakka, Z. Kalbarczyk, and R. K. Iyer, “Defeating\r\nmemory corruption attacks via pointer taintedness detection,” in Depend\u0002able Systems and Networks, 2005. DSN 2005. Proceedings. International\r\nConference on. IEEE, 2005, pp. 378–387.\r\n[6] J. Xu, P. Ning, C. Kil, Y. Zhai, and C. Bookholt, “Automatic diagnosis\r\nand response to memory corruption vulnerabilities,” in Proceedings of\r\nthe 12th ACM conference on Computer and communications security.\r\nACM, 2005, pp. 223–234.\r\n[7] D. Jang, Z. Tatlock, and S. Lerner, “SafeDispatch: Securing C++ Virtual\r\nCalls from Memory Corruption Attacks.” in NDSS, 2014.\r\n[8] E. C. Sezer, P. Ning, C. Kil, and J. Xu, “Memsherlock: an automated de\u0002bugger for unknown memory corruption vulnerabilities,” in Proceedings\r\nof the 14th ACM conference on Computer and communications security.\r\nACM, 2007, pp. 562–572.\r\n[9] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi, H. Shacham,\r\nand M. Winandy, “Return-oriented programming without returns,” in\r\nProceedings of the 17th ACM conference on Computer and communi\u0002cations security. ACM, 2010, pp. 559–572.\r\n[10] M. Kayaalp, M. Ozsoy, N. Abu-Ghazaleh, and D. Ponomarev, “Branch\r\nregulation: Low-overhead protection from code reuse attacks,” in Com\u0002puter Architecture (ISCA), 2012 39th Annual International Symposium\r\non. IEEE, 2012, pp. 94–105.\r\n[11] M. Kayaalp, T. Schmitt, J. Nomani, D. Ponomarev, and N. Abu\u0002Ghazaleh, “SCRAP: Architecture for signature-based protection from\r\ncode reuse attacks,” in High Performance Computer Architecture\r\n(HPCA2013), 2013 IEEE 19th International Symposium on. IEEE,\r\n2013, pp. 258–269.\r\n[12] H. Shacham, M. Page, B. Pfaff, E.-J. Goh, N. Modadugu, and D. Boneh,\r\n“On the effectiveness of address-space randomization,” in Proceedings\r\nof the 11th ACM conference on Computer and communications security.\r\nACM, 2004, pp. 298–307.\r\n[13] H. Bojinov, D. Boneh, R. Cannings, and I. Malchev, “Address space\r\nrandomization for mobile devices,” in Proceedings of the fourth ACM\r\nconference on Wireless network security. ACM, 2011, pp. 127–138.\r\n[14] “CVE-2015-3108.” Available from NVD, CVE-ID CVE-2015-3108,\r\nSep. 6 2015, [Online; accessed Feb. 2 2016 https://web.nvd.nist.gov/\r\nview/vuln/detail?vulnId=CVE-2015-3108].\r\n[15] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K. Iyer, “Non-control-data\r\nattacks are realistic threats.” in Usenix Security, vol. 5, 2005.\r\n[16] K. Lu, C. Song, B. Lee, S. P. Chung, T. Kim, and W. Lee, “ASLR\u0002Guard: Stopping address space leakage for code reuse attacks,” in\r\nProceedings of the 22nd ACM SIGSAC Conference on Computer and\r\nCommunications Security. ACM, 2015, pp. 280–291.\r\n[17] PaX Team, “Address space layout randomization,” Phrack, March, 2003.\r\n[18] M. Howard, “Address space layout randomization in Windows Vista,”\r\nMicrosoft Corporation, vol. 26, 2006.\r\n[19] D. Keuper, “XNU: A security evaluation,” December 2012.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/357678cd-d923-4852-9ddb-0e58d8816115.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=9c3bd87b1a5d98b2b94cacc07aef68a41c26dfce32f02ecc03ae1b756bd3bb47",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 985
      },
      {
        "segments": [
          {
            "segment_id": "33aecf44-3021-4ed5-a48a-e4dda43019c0",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 13,
            "page_width": 612,
            "page_height": 792,
            "content": "[20] D. A. Dai Zovi, “Apple iOS 4 security evaluation,” Black Hat USA, pp.\r\n1–29, 2011.\r\n[21] M. Payer, “Too much PIE is bad for performance,” 2012.\r\n[22] S. Designer, “return-to-libc attack,” Bugtraq, Aug, 1997.\r\n[23] H. Shacham, “The geometry of innocent flesh on the bone: Return-into\u0002libc without function calls (on the x86),” in Proceedings of the 14th\r\nACM conference on Computer and communications security. ACM,\r\n2007, pp. 552–561.\r\n[24] V. P. Kemerlis, G. Portokalidis, and A. D. Keromytis, “kGuard:\r\nlightweight kernel protection against return-to-user attacks,” in Presented\r\nas part of the 21st USENIX Security Symposium (USENIX Security 12),\r\n2012, pp. 459–474.\r\n[25] B. Spengler and PaX Team, “KASLR: An Exercise in Cargo Cult\r\nSecurity,” Available online, Mar. 20 2013, [Online; accessed Feb. 2 2016\r\nhttp://forums.grsecurity.net/viewtopic.php?f=7&t=3367#p12726/].\r\n[26] T. Mandt, “Revisiting iOS Kernel (In) Security: Attacking the\r\nearly random() PRNG.”\r\n[27] O. Aciicmez, K. Koc, and J. Seifert, “On the power of simple branch\r\nprediction analysis,” in Symposium on Information, Computer and\r\nCommunication Security (ASIACCS). IEEE, 2007.\r\n[28] ——, “Predicting secret keys via branch prediction,” in The cryptogra\u0002phers’ track at the RSA conference, 2007.\r\n[29] D. Evtyushkin, D. Ponomarev, and N. Abu-Ghazaleh, “Understanding\r\nand mitigating covert channels through branch predictors,” ACM Trans\u0002actions on Architecture and Code Optimization (TACO), vol. 13, no. 1,\r\np. 10, 2016.\r\n[30] ——, “Covert channels through branch predictors: a feasibility study,”\r\nin Proceedings of the Fourth Workshop on Hardware and Architectural\r\nSupport for Security and Privacy (HASP). ACM, 2015, p. 5.\r\n[31] C. Kil, J. Jun, C. Bookholt, J. Xu, and P. Ning, “Address space layout\r\npermutation (ASLP): Towards fine-grained randomization of commodity\r\nsoftware,” in null. IEEE, 2006, pp. 339–348.\r\n[32] C. Giuffrida, A. Kuijsten, and A. S. Tanenbaum, “Enhanced operating\r\nsystem security through efficient and fine-grained address space random\u0002ization,” in Presented as part of the 21st USENIX Security Symposium\r\n(USENIX Security 12), 2012, pp. 475–490.\r\n[33] H. Xu and S. J. Chapin, “Improving address space randomization with\r\na dynamic offset randomization technique,” in Proceedings of the 2006\r\nACM symposium on Applied computing. ACM, 2006, pp. 384–391.\r\n[34] S. Bhatkar, D. C. DuVarney, and R. Sekar, “Efficient techniques for com\u0002prehensive protection from memory error exploits.” in Usenix Security,\r\n2005.\r\n[35] C. N. Keltcher, K. J. McGrath, A. Ahmed, and P. Conway, “The AMD\r\nOpteron processor for multiprocessor servers,” IEEE Micro, no. 2, pp.\r\n66–76, 2003.\r\n[36] “CVE-2015-1158.” Available from NVD, CVE-ID CVE-2015-1158,\r\nSep. 6 2015, [Online; accessed Feb. 2 2016 https://web.nvd.nist.gov/\r\nview/vuln/detail?vulnId=CVE-2015-1158].\r\n[37] I. Anati, S. Gueron, S. Johnson, and V. Scarlata, “Innovative technology\r\nfor CPU based attestation and sealing,” in Proceedings of the 2nd\r\ninternational workshop on hardware and architectural support for\r\nsecurity and privacy, vol. 13, 2013.\r\n[38] D. Evtyushkin, J. Elwell, M. Ozsoy, D. Ponomarev, N. A. Ghazaleh,\r\nand R. Riley, “Iso-x: A flexible architecture for hardware-managed\r\nisolated execution,” in Microarchitecture (MICRO), 2014 47th Annual\r\nIEEE/ACM International Symposium on. IEEE, 2014, pp. 190–202.\r\n[39] ——, “Flexible hardware-managed isolated execution: Architecture,\r\nsoftware support and applications,” IEEE Transactions on Dependable\r\nand Secure Computing (TDSC), 2016.\r\n[40] V. Costan, I. Lebedev, and S. Devadas, “Sanctum: Minimal hardware\r\nextensions for strong software isolation,” in 25th USENIX Security\r\nSymposium (USENIX Security 16). Austin, TX: USENIX Association,\r\nAug. 2016. [Online]. Available: https://www.usenix.org/conference/\r\nusenixsecurity16/technical-sessions/presentation/costan\r\n[41] Y. Xu, W. Cui, and M. Peinado, “Controlled-channel attacks: Determin\u0002istic side channels for untrusted operating systems,” 2015.\r\n[42] M. Kerrisk et al., “SCHED SETAFFINITY(2) linux programme’s man\u0002ual,” Dec 2015.\r\n[43] Y. Zhang, A. Juels, A. Oprea, and M. K. Reiter, “Homealone: Co\u0002residency detection in the cloud via side-channel analysis,” in security\r\nand Privacy (SP), 2011 IEEE Symposium on. IEEE, 2011, pp. 313–328.\r\n[44] M. Kerrisk et al., “proc(5) Linux Programmer’s Manual,” Dec 2015.\r\n[45] V. Kazempour, A. Fedorova, and P. Alagheband, “Performance impli\u0002cations of cache affinity on multicore processors,” in Euro-Par 2008–\r\nParallel Processing. Springer, 2008, pp. 151–161.\r\n[46] J. Torrellas, A. Tucker, and A. Gupta, “Evaluating the performance of\r\ncache-affinity scheduling in shared-memory multiprocessors,” Journal of\r\nParallel and Distributed Computing, vol. 24, no. 2, pp. 139–151, 1995.\r\n[47] H. Marco-Gisbert and I. Ripoll, “On the Effectiveness of Full-ASLR on\r\n64-bit Linux,” 2014.\r\n[48] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin, “Binary stirring:\r\nSelf-randomizing instruction addresses of legacy x86 binary code,” in\r\nProceedings of the 2012 ACM conference on Computer and communi\u0002cations security. ACM, 2012, pp. 157–168.\r\n[49] V. Pappas, M. Polychronakis, and A. D. Keromytis, “Smashing the\r\ngadgets: Hindering return-oriented programming using in-place code\r\nrandomization,” in Security and Privacy (SP), 2012 IEEE Symposium\r\non. IEEE, 2012, pp. 601–615.\r\n[50] S. Shamasunder, “On the Effectiveness of Heterogeneous-ISA Program\r\nState Relocation against Return-Oriented Programming,” Ph.D. disser\u0002tation, UNIVERSITY OF CALIFORNIA, SAN DIEGO, 2015.\r\n[51] R. Martin, J. Demme, and S. Sethumadhavan, “TimeWarp: rethinking\r\ntimekeeping and performance monitoring mechanisms to mitigate side\u0002channel attacks,” ACM SIGARCH Computer Architecture News, vol. 40,\r\nno. 3, pp. 118–129, 2012.\r\n[52] D. Gullasch, E. Bangerter, and S. Krenn, “Cache games–bringing access\u0002based cache attacks on AES to practice,” in Security and Privacy (SP),\r\n2011 IEEE Symposium on. IEEE, 2011, pp. 490–505.\r\n[53] S. Bhattacharya, C. Rebeiro, and D. Mukhopadhyay, “Unraveling time\u0002warp: What all the fuzz is about?” in Workshop on Hardware and\r\nArchitectural Support for Security and Privacy (HASP), 2013.\r\n[54] B. Jacob and T. Mudge, “Virtual memory in contemporary micropro\u0002cessors,” Micro, IEEE, vol. 18, no. 4, pp. 60–75, 1998.\r\n[55] D. Gruss, C. Maurice, and K. Wagner, “Flush+ Flush: A Stealthier Last\u0002Level Cache Attack,” arXiv preprint arXiv:1511.04594, 2015.\r\n[56] Z. Wang and R. B. Lee, “Covert and side channels due to processor\r\narchitecture,” in null. IEEE, 2006, pp. 473–482.\r\n[57] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee, “Last-level cache\r\nside-channel attacks are practical,” in IEEE Symposium on Security and\r\nPrivacy, 2015, pp. 605–622.\r\n[58] Y. Yarom and K. Falkner, “Flush+ reload: a high resolution, low noise,\r\nL3 cache side-channel attack,” in 23rd USENIX Security Symposium\r\n(USENIX Security 14), 2014, pp. 719–732.\r\n[59] M. Kayaalp, N. Abu-Ghazaleh, D. Ponomarev, and A. Jaleel, “A high\u0002resolution side-channel attack on last-level cache,” in Proceedings of the\r\n53rd Annual Design Automation Conference. ACM, 2016, p. 72.\r\n[60] G. F. Roglia, L. Martignoni, R. Paleari, and D. Bruschi, “Surgically\r\nreturning to randomized libc,” in Computer Security Applications Con\u0002ference, 2009. ACSAC’09. Annual. IEEE, 2009, pp. 60–69.\r\n[61] B. Lee, L. Lu, T. Wang, T. Kim, and W. Lee, “From zygote to morula:\r\nFortifying weakened ASLR on Android,” in Security and Privacy (SP),\r\n2014 IEEE Symposium on. IEEE, 2014, pp. 424–439.\r\n[62] Y. Gu and Z. Lin, “Derandomizing kernel address space layout for\r\nmemory introspection and forensics,” in Proceedings of the Sixth ACM\r\non Conference on Data and Application Security and Privacy. ACM,\r\n2016, pp. 62–72.\r\n[63] R. Hund, C. Willems, and T. Holz, “Practical timing side channel attacks\r\nagainst kernel space ASLR,” in Security and Privacy (SP), 2013 IEEE\r\nSymposium on. IEEE, 2013, pp. 191–205.\r\n[64] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko, C. Liebchen, and A.-R.\r\nSadeghi, “Just-in-time code reuse: On the effectiveness of fine-grained\r\naddress space layout randomization,” in Security and Privacy (SP), 2013\r\nIEEE Symposium on. IEEE, 2013, pp. 574–588.\r\n[65] A. Tang, S. Sethumadhavan, and S. Stolfo, “Heisenbyte: Thwarting\r\nmemory disclosure attacks using destructive code reads,” in Proceedings\r\nof the 22nd ACM SIGSAC Conference on Computer and Communica\u0002tions Security. ACM, 2015, pp. 256–267.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/33aecf44-3021-4ed5-a48a-e4dda43019c0.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=6389fd55d9d0276364b6181fef758c834e90424562baf13a9ca7a32562e2b223",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 1206
      },
      {
        "segments": [
          {
            "segment_id": "33aecf44-3021-4ed5-a48a-e4dda43019c0",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 13,
            "page_width": 612,
            "page_height": 792,
            "content": "[20] D. A. Dai Zovi, “Apple iOS 4 security evaluation,” Black Hat USA, pp.\r\n1–29, 2011.\r\n[21] M. Payer, “Too much PIE is bad for performance,” 2012.\r\n[22] S. Designer, “return-to-libc attack,” Bugtraq, Aug, 1997.\r\n[23] H. Shacham, “The geometry of innocent flesh on the bone: Return-into\u0002libc without function calls (on the x86),” in Proceedings of the 14th\r\nACM conference on Computer and communications security. ACM,\r\n2007, pp. 552–561.\r\n[24] V. P. Kemerlis, G. Portokalidis, and A. D. Keromytis, “kGuard:\r\nlightweight kernel protection against return-to-user attacks,” in Presented\r\nas part of the 21st USENIX Security Symposium (USENIX Security 12),\r\n2012, pp. 459–474.\r\n[25] B. Spengler and PaX Team, “KASLR: An Exercise in Cargo Cult\r\nSecurity,” Available online, Mar. 20 2013, [Online; accessed Feb. 2 2016\r\nhttp://forums.grsecurity.net/viewtopic.php?f=7&t=3367#p12726/].\r\n[26] T. Mandt, “Revisiting iOS Kernel (In) Security: Attacking the\r\nearly random() PRNG.”\r\n[27] O. Aciicmez, K. Koc, and J. Seifert, “On the power of simple branch\r\nprediction analysis,” in Symposium on Information, Computer and\r\nCommunication Security (ASIACCS). IEEE, 2007.\r\n[28] ——, “Predicting secret keys via branch prediction,” in The cryptogra\u0002phers’ track at the RSA conference, 2007.\r\n[29] D. Evtyushkin, D. Ponomarev, and N. Abu-Ghazaleh, “Understanding\r\nand mitigating covert channels through branch predictors,” ACM Trans\u0002actions on Architecture and Code Optimization (TACO), vol. 13, no. 1,\r\np. 10, 2016.\r\n[30] ——, “Covert channels through branch predictors: a feasibility study,”\r\nin Proceedings of the Fourth Workshop on Hardware and Architectural\r\nSupport for Security and Privacy (HASP). ACM, 2015, p. 5.\r\n[31] C. Kil, J. Jun, C. Bookholt, J. Xu, and P. Ning, “Address space layout\r\npermutation (ASLP): Towards fine-grained randomization of commodity\r\nsoftware,” in null. IEEE, 2006, pp. 339–348.\r\n[32] C. Giuffrida, A. Kuijsten, and A. S. Tanenbaum, “Enhanced operating\r\nsystem security through efficient and fine-grained address space random\u0002ization,” in Presented as part of the 21st USENIX Security Symposium\r\n(USENIX Security 12), 2012, pp. 475–490.\r\n[33] H. Xu and S. J. Chapin, “Improving address space randomization with\r\na dynamic offset randomization technique,” in Proceedings of the 2006\r\nACM symposium on Applied computing. ACM, 2006, pp. 384–391.\r\n[34] S. Bhatkar, D. C. DuVarney, and R. Sekar, “Efficient techniques for com\u0002prehensive protection from memory error exploits.” in Usenix Security,\r\n2005.\r\n[35] C. N. Keltcher, K. J. McGrath, A. Ahmed, and P. Conway, “The AMD\r\nOpteron processor for multiprocessor servers,” IEEE Micro, no. 2, pp.\r\n66–76, 2003.\r\n[36] “CVE-2015-1158.” Available from NVD, CVE-ID CVE-2015-1158,\r\nSep. 6 2015, [Online; accessed Feb. 2 2016 https://web.nvd.nist.gov/\r\nview/vuln/detail?vulnId=CVE-2015-1158].\r\n[37] I. Anati, S. Gueron, S. Johnson, and V. Scarlata, “Innovative technology\r\nfor CPU based attestation and sealing,” in Proceedings of the 2nd\r\ninternational workshop on hardware and architectural support for\r\nsecurity and privacy, vol. 13, 2013.\r\n[38] D. Evtyushkin, J. Elwell, M. Ozsoy, D. Ponomarev, N. A. Ghazaleh,\r\nand R. Riley, “Iso-x: A flexible architecture for hardware-managed\r\nisolated execution,” in Microarchitecture (MICRO), 2014 47th Annual\r\nIEEE/ACM International Symposium on. IEEE, 2014, pp. 190–202.\r\n[39] ——, “Flexible hardware-managed isolated execution: Architecture,\r\nsoftware support and applications,” IEEE Transactions on Dependable\r\nand Secure Computing (TDSC), 2016.\r\n[40] V. Costan, I. Lebedev, and S. Devadas, “Sanctum: Minimal hardware\r\nextensions for strong software isolation,” in 25th USENIX Security\r\nSymposium (USENIX Security 16). Austin, TX: USENIX Association,\r\nAug. 2016. [Online]. Available: https://www.usenix.org/conference/\r\nusenixsecurity16/technical-sessions/presentation/costan\r\n[41] Y. Xu, W. Cui, and M. Peinado, “Controlled-channel attacks: Determin\u0002istic side channels for untrusted operating systems,” 2015.\r\n[42] M. Kerrisk et al., “SCHED SETAFFINITY(2) linux programme’s man\u0002ual,” Dec 2015.\r\n[43] Y. Zhang, A. Juels, A. Oprea, and M. K. Reiter, “Homealone: Co\u0002residency detection in the cloud via side-channel analysis,” in security\r\nand Privacy (SP), 2011 IEEE Symposium on. IEEE, 2011, pp. 313–328.\r\n[44] M. Kerrisk et al., “proc(5) Linux Programmer’s Manual,” Dec 2015.\r\n[45] V. Kazempour, A. Fedorova, and P. Alagheband, “Performance impli\u0002cations of cache affinity on multicore processors,” in Euro-Par 2008–\r\nParallel Processing. Springer, 2008, pp. 151–161.\r\n[46] J. Torrellas, A. Tucker, and A. Gupta, “Evaluating the performance of\r\ncache-affinity scheduling in shared-memory multiprocessors,” Journal of\r\nParallel and Distributed Computing, vol. 24, no. 2, pp. 139–151, 1995.\r\n[47] H. Marco-Gisbert and I. Ripoll, “On the Effectiveness of Full-ASLR on\r\n64-bit Linux,” 2014.\r\n[48] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin, “Binary stirring:\r\nSelf-randomizing instruction addresses of legacy x86 binary code,” in\r\nProceedings of the 2012 ACM conference on Computer and communi\u0002cations security. ACM, 2012, pp. 157–168.\r\n[49] V. Pappas, M. Polychronakis, and A. D. Keromytis, “Smashing the\r\ngadgets: Hindering return-oriented programming using in-place code\r\nrandomization,” in Security and Privacy (SP), 2012 IEEE Symposium\r\non. IEEE, 2012, pp. 601–615.\r\n[50] S. Shamasunder, “On the Effectiveness of Heterogeneous-ISA Program\r\nState Relocation against Return-Oriented Programming,” Ph.D. disser\u0002tation, UNIVERSITY OF CALIFORNIA, SAN DIEGO, 2015.\r\n[51] R. Martin, J. Demme, and S. Sethumadhavan, “TimeWarp: rethinking\r\ntimekeeping and performance monitoring mechanisms to mitigate side\u0002channel attacks,” ACM SIGARCH Computer Architecture News, vol. 40,\r\nno. 3, pp. 118–129, 2012.\r\n[52] D. Gullasch, E. Bangerter, and S. Krenn, “Cache games–bringing access\u0002based cache attacks on AES to practice,” in Security and Privacy (SP),\r\n2011 IEEE Symposium on. IEEE, 2011, pp. 490–505.\r\n[53] S. Bhattacharya, C. Rebeiro, and D. Mukhopadhyay, “Unraveling time\u0002warp: What all the fuzz is about?” in Workshop on Hardware and\r\nArchitectural Support for Security and Privacy (HASP), 2013.\r\n[54] B. Jacob and T. Mudge, “Virtual memory in contemporary micropro\u0002cessors,” Micro, IEEE, vol. 18, no. 4, pp. 60–75, 1998.\r\n[55] D. Gruss, C. Maurice, and K. Wagner, “Flush+ Flush: A Stealthier Last\u0002Level Cache Attack,” arXiv preprint arXiv:1511.04594, 2015.\r\n[56] Z. Wang and R. B. Lee, “Covert and side channels due to processor\r\narchitecture,” in null. IEEE, 2006, pp. 473–482.\r\n[57] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee, “Last-level cache\r\nside-channel attacks are practical,” in IEEE Symposium on Security and\r\nPrivacy, 2015, pp. 605–622.\r\n[58] Y. Yarom and K. Falkner, “Flush+ reload: a high resolution, low noise,\r\nL3 cache side-channel attack,” in 23rd USENIX Security Symposium\r\n(USENIX Security 14), 2014, pp. 719–732.\r\n[59] M. Kayaalp, N. Abu-Ghazaleh, D. Ponomarev, and A. Jaleel, “A high\u0002resolution side-channel attack on last-level cache,” in Proceedings of the\r\n53rd Annual Design Automation Conference. ACM, 2016, p. 72.\r\n[60] G. F. Roglia, L. Martignoni, R. Paleari, and D. Bruschi, “Surgically\r\nreturning to randomized libc,” in Computer Security Applications Con\u0002ference, 2009. ACSAC’09. Annual. IEEE, 2009, pp. 60–69.\r\n[61] B. Lee, L. Lu, T. Wang, T. Kim, and W. Lee, “From zygote to morula:\r\nFortifying weakened ASLR on Android,” in Security and Privacy (SP),\r\n2014 IEEE Symposium on. IEEE, 2014, pp. 424–439.\r\n[62] Y. Gu and Z. Lin, “Derandomizing kernel address space layout for\r\nmemory introspection and forensics,” in Proceedings of the Sixth ACM\r\non Conference on Data and Application Security and Privacy. ACM,\r\n2016, pp. 62–72.\r\n[63] R. Hund, C. Willems, and T. Holz, “Practical timing side channel attacks\r\nagainst kernel space ASLR,” in Security and Privacy (SP), 2013 IEEE\r\nSymposium on. IEEE, 2013, pp. 191–205.\r\n[64] K. Z. Snow, F. Monrose, L. Davi, A. Dmitrienko, C. Liebchen, and A.-R.\r\nSadeghi, “Just-in-time code reuse: On the effectiveness of fine-grained\r\naddress space layout randomization,” in Security and Privacy (SP), 2013\r\nIEEE Symposium on. IEEE, 2013, pp. 574–588.\r\n[65] A. Tang, S. Sethumadhavan, and S. Stolfo, “Heisenbyte: Thwarting\r\nmemory disclosure attacks using destructive code reads,” in Proceedings\r\nof the 22nd ACM SIGSAC Conference on Computer and Communica\u0002tions Security. ACM, 2015, pp. 256–267.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/a861ebc8-9a5a-43a8-98a1-3960693dbae4/images/33aecf44-3021-4ed5-a48a-e4dda43019c0.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041338Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=6389fd55d9d0276364b6181fef758c834e90424562baf13a9ca7a32562e2b223",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 1206
      }
    ],
    "extracted_json": {
      "title": "Document Metadata",
      "schema_type": "object",
      "extracted_fields": [
        {
          "name": "title",
          "field_type": "string",
          "value": "```json\n{\"title\": \"Jump Over ASLR: Attacking Branch Predictors to Bypass ASLR\"}\n```"
        },
        {
          "name": "author",
          "field_type": "string",
          "value": "No response"
        },
        {
          "name": "date_published",
          "field_type": "string",
          "value": "No response"
        },
        {
          "name": "location",
          "field_type": "string",
          "value": "No response"
        }
      ]
    }
  }
}