{
  "file_name": "Learning a Hidden Hypergraph - 2006 (angluin06a).pdf",
  "task_id": "43455c86-72e3-46ce-bc37-21547ff3dfb4",
  "output": {
    "chunks": [
      {
        "segments": [
          {
            "segment_id": "00088747-ed9a-40d3-a4b1-5e598f80537a",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 1,
            "page_width": 612,
            "page_height": 792,
            "content": "Journal of Machine Learning Research 7 (2006) 2215-2236 Submitted 12/05; Revised 8/06; Published 10/06\r\nLearning a Hidden Hypergraph\r\nDana Angluin ANGLUIN@CS.YALE.EDU\r\nDepartment of Computer Science\r\nYale University\r\nP.O. Box 208285\r\nNew Haven, CT 06520, USA\r\nJiang Chen CRIVER@CS.COLUMBIA.EDU\r\nCenter for Computational Learning Systems\r\nColumbia University\r\n475 Riverside Drive\r\n850 Interchurch MC 7717\r\nNew York, NY 10115, USA\r\nEditor: Manfred Warmuth\r\nAbstract\r\nWe consider the problem of learning a hypergraph using edge-detecting queries. In this model,\r\nthe learner may query whether a set of vertices induces an edge of the hidden hypergraph or not.\r\nWe show that an r-uniform hypergraph with m edges and n vertices is learnable with O(2\r\n4rm ·\r\npoly(r,logn)) queries with high probability. The queries can be made in O(min(2\r\nr\r\n(logm + r)\r\n2\r\n,\r\n(logm + r)\r\n3\r\n)) rounds. We also give an algorithm that learns an almost uniform hypergraph of\r\ndimension r using O(2\r\nO((1+\r\n∆\r\n2\r\n)r)\r\n· m\r\n1+\r\n∆\r\n2 · poly(logn)) queries with high probability, where ∆ is the\r\ndifference between the maximum and the minimum edge sizes. This upper bound matches our\r\nlower bound of Ω(( m\r\n1+\r\n∆\r\n2\r\n)\r\n1+\r\n∆\r\n2 ) for this class of hypergraphs in terms of dependence on m. The\r\nqueries can also be made in O((1+∆)·min(2\r\nr\r\n(logm+r)\r\n2\r\n,(logm+r)\r\n3\r\n)) rounds.\r\nKeywords: query learning, hypergraph, multiple round algorithm, sampling, chemical reaction\r\nnetwork\r\n1. Introduction\r\nA hypergraph H = (V,E) is given by a set of vertices V and a set of edges E, which is a subset of\r\nthe power set of V (E ⊆ 2\r\nV\r\n). The dimension of a hypergraph H is the cardinality of the largest set\r\nin E. H is said to be r-uniform if E contains only sets of size r. In this paper, we are interested in\r\nlearning a hidden hypergraph using edge-detecting queries of the following form\r\nQH(S) : does S include at least one edge of H?\r\nwhere S ⊆ V. The query QH(S) is answered 1 or 0, indicating whether S contains all vertices of at\r\nleast one edge of H or not. We abbreviate QH(S) to Q(S) whenever the choice of H is clear from\r\nthe context. This type of query may be motivated by the following scenarios. We are given a set of\r\nchemicals, in which some groups of chemicals react and others don’t. When multiple chemicals are\r\n\rc 2006 Dana Angluin and Jiang Chen.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/00088747-ed9a-40d3-a4b1-5e598f80537a.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5c3d1052fbfe7975b3bda33888b3d621be8180ff9cb7c1d2e30fad42c52bad87",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 409
      },
      {
        "segments": [
          {
            "segment_id": "9cc5d7eb-57f4-4a53-a45f-e203d5ef80aa",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 2,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\ncombined in one test tube, a reaction is detectable if and only if at least one group of chemicals in\r\nthe tube react.\r\nConsiderable effort, for example, Grebinski and Kucherov (1998), Beigel et al. (2001), Alon\r\net al. (2004), Angluin and Chen (2004), and Alon and Asodi (2005), has been devoted to the case\r\nwhen the underlying reaction network is a graph, that is, chemicals react in pairs. Among them,\r\nGrebinski and Kucherov (1998), Beigel et al. (2001) and Alon et al. (2004) study the case when\r\nthe underlying networks are Hamiltonian cycles or matchings, which have specific applications to\r\ngenome sequencing. In this application, DNA sequences are aligned according to the reactions that\r\ninvolve the two ends of pairs of DNA sequences in certain experimental settings. The reaction graph\r\ncan be characterized as either a Hamiltonian cycle or path (if you consider each DNA sequence as a\r\nvertex) or a matching (if you consider each end of a DNA sequence as a vertex). Implementations of\r\nsome of these algorithms are in practical use. Grebinski and Kucherov (2000) also study a somewhat\r\ndifferent and interesting query model, which they call the additive model, where instead of giving a\r\n1 or 0 answer, a query tells you the total number of edges contained in a certain vertex set.\r\nAngluin and Chen (2004) generalize the problem of learning with edge-detecting queries to\r\ngeneral reaction graphs and show that general graphs are efficiently learnable. In this work, we\r\nconsider a more general problem when the chemicals react in groups of size more than two, that\r\nis, the underlying reaction network is a hypergraph. In Angluin and Chen (2004), they give an\r\nadaptive algorithm which takes O(logn) queries per edge, where n is the number of vertices. This\r\nis nearly optimal as we can easily show using an information-theoretic argument. For the problem\r\nof learning hypergraphs of bounded dimension and a given number of edges, a similar information\u0002theoretic argument gives a lower bound that is linear in the number of edges. However, the lower\r\nbound is not achievable. It is shown in Angluin and Chen (2004) that Ω((2m/r)\r\nr/2\r\n) edge-detecting\r\nqueries are required to learn a general hypergraph of dimension r with m edges. In the heart of the\r\nconstruction of Angluin and Chen (2004), edges of size 2 are deliberately arranged to hide an edge\r\nof size r. The discrepancy in sizes of different coexisting edges is the main barrier for the learner.\r\nHowever, this lower bound does not preclude efficient algorithms for classes of hypergraphs whose\r\nedges sizes are close. In particular, the question whether there is a learning algorithm for uniform\r\nhypergraphs using a number of queries that is linear in the number of edges is still left open, which\r\nis the main subject of this paper.\r\nIn this paper, we are able to answer this question affirmatively. Let n be the number of vertices\r\nand m be the number of edges in the hypergraph. We show that an r-uniform hypergraph is learnable\r\nwith O(2\r\n4rm· poly(r,logn,log 1\r\nδ\r\n)) queries with probability at least 1−δ.\r\nWe also obtain results for learning the class of hypergraphs that is almost uniform. Formally\r\nspeaking,\r\nDefinition 1 A hypergraph is (r,∆)-uniform, where ∆ < r, if its dimension is r and the difference\r\nbetween its maximum and minimum edge sizes is ∆, or equivalently, the maximum and the minimum\r\nedge sizes are r and r −∆ respectively.\r\nThe class of hypergraphs used in the construction of the lower bound in Angluin and Chen (2004)\r\nis in fact (r,r − 2)-uniform. Therefore, they show that Ω((2m/r)\r\nr/2\r\n) edge-detecting queries are\r\nrequired to learn a (r,r − 2)-uniform hypergraph. Based on this result, we show by a simple re\u0002duction that Ω(( m\r\n1+\r\n∆\r\n2\r\n)\r\n1+\r\n∆\r\n2 ) queries are required to learn the class of (r,∆)-uniform hypergraphs. On\r\nthe other hand, we extend the algorithm that learns uniform hypergraphs to learning the class of\r\n2216",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/9cc5d7eb-57f4-4a53-a45f-e203d5ef80aa.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=761fac8d690192895785d307a10da0a3751c2e96a445894ccf6917f486f83ea8",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 667
      },
      {
        "segments": [
          {
            "segment_id": "9cc5d7eb-57f4-4a53-a45f-e203d5ef80aa",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 2,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\ncombined in one test tube, a reaction is detectable if and only if at least one group of chemicals in\r\nthe tube react.\r\nConsiderable effort, for example, Grebinski and Kucherov (1998), Beigel et al. (2001), Alon\r\net al. (2004), Angluin and Chen (2004), and Alon and Asodi (2005), has been devoted to the case\r\nwhen the underlying reaction network is a graph, that is, chemicals react in pairs. Among them,\r\nGrebinski and Kucherov (1998), Beigel et al. (2001) and Alon et al. (2004) study the case when\r\nthe underlying networks are Hamiltonian cycles or matchings, which have specific applications to\r\ngenome sequencing. In this application, DNA sequences are aligned according to the reactions that\r\ninvolve the two ends of pairs of DNA sequences in certain experimental settings. The reaction graph\r\ncan be characterized as either a Hamiltonian cycle or path (if you consider each DNA sequence as a\r\nvertex) or a matching (if you consider each end of a DNA sequence as a vertex). Implementations of\r\nsome of these algorithms are in practical use. Grebinski and Kucherov (2000) also study a somewhat\r\ndifferent and interesting query model, which they call the additive model, where instead of giving a\r\n1 or 0 answer, a query tells you the total number of edges contained in a certain vertex set.\r\nAngluin and Chen (2004) generalize the problem of learning with edge-detecting queries to\r\ngeneral reaction graphs and show that general graphs are efficiently learnable. In this work, we\r\nconsider a more general problem when the chemicals react in groups of size more than two, that\r\nis, the underlying reaction network is a hypergraph. In Angluin and Chen (2004), they give an\r\nadaptive algorithm which takes O(logn) queries per edge, where n is the number of vertices. This\r\nis nearly optimal as we can easily show using an information-theoretic argument. For the problem\r\nof learning hypergraphs of bounded dimension and a given number of edges, a similar information\u0002theoretic argument gives a lower bound that is linear in the number of edges. However, the lower\r\nbound is not achievable. It is shown in Angluin and Chen (2004) that Ω((2m/r)\r\nr/2\r\n) edge-detecting\r\nqueries are required to learn a general hypergraph of dimension r with m edges. In the heart of the\r\nconstruction of Angluin and Chen (2004), edges of size 2 are deliberately arranged to hide an edge\r\nof size r. The discrepancy in sizes of different coexisting edges is the main barrier for the learner.\r\nHowever, this lower bound does not preclude efficient algorithms for classes of hypergraphs whose\r\nedges sizes are close. In particular, the question whether there is a learning algorithm for uniform\r\nhypergraphs using a number of queries that is linear in the number of edges is still left open, which\r\nis the main subject of this paper.\r\nIn this paper, we are able to answer this question affirmatively. Let n be the number of vertices\r\nand m be the number of edges in the hypergraph. We show that an r-uniform hypergraph is learnable\r\nwith O(2\r\n4rm· poly(r,logn,log 1\r\nδ\r\n)) queries with probability at least 1−δ.\r\nWe also obtain results for learning the class of hypergraphs that is almost uniform. Formally\r\nspeaking,\r\nDefinition 1 A hypergraph is (r,∆)-uniform, where ∆ < r, if its dimension is r and the difference\r\nbetween its maximum and minimum edge sizes is ∆, or equivalently, the maximum and the minimum\r\nedge sizes are r and r −∆ respectively.\r\nThe class of hypergraphs used in the construction of the lower bound in Angluin and Chen (2004)\r\nis in fact (r,r − 2)-uniform. Therefore, they show that Ω((2m/r)\r\nr/2\r\n) edge-detecting queries are\r\nrequired to learn a (r,r − 2)-uniform hypergraph. Based on this result, we show by a simple re\u0002duction that Ω(( m\r\n1+\r\n∆\r\n2\r\n)\r\n1+\r\n∆\r\n2 ) queries are required to learn the class of (r,∆)-uniform hypergraphs. On\r\nthe other hand, we extend the algorithm that learns uniform hypergraphs to learning the class of\r\n2216",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/9cc5d7eb-57f4-4a53-a45f-e203d5ef80aa.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=761fac8d690192895785d307a10da0a3751c2e96a445894ccf6917f486f83ea8",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 667
      },
      {
        "segments": [
          {
            "segment_id": "18c7d9be-9287-4def-b10e-ffc134b3b8ed",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 3,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\n(r,∆)-uniform hypergraphs with O(2\r\nO((1+\r\n∆\r\n2\r\n)r)\r\n·m\r\n1+\r\n∆\r\n2 · poly(logn,log 1\r\nδ\r\n)) queries with probability at\r\nleast 1−δ. The upper bound and lower bound have the same dependence on m.\r\nAnother important issue studied in the literature is the parallelism of algorithms. Since the\r\nqueries are motivated by an experiment design scenario, it is desirable that experiments can be\r\nconducted in parallel. Alon et al. (2004) and Alon and Asodi (2005) give lower and upper bounds for\r\n1-round algorithms for certain types of graphs. Beigel et al. (2001) describe an 8-round algorithm\r\nfor learning a matching. Angluin and Chen (2004) give a 5-round algorithm for learning a general\r\ngraph. In this paper, we show that in our algorithm for r-uniform hypergraphs, queries can be made\r\nin O(min(2\r\nr\r\n(logm+r)\r\n2\r\n,(logm+r)\r\n3\r\n)) rounds, and in our algorithm for (r,∆)-uniform hypergraphs,\r\nqueries can be made in O((1+∆)·min(2\r\nr\r\n(logm+r)\r\n2\r\n,(logm+r)\r\n3\r\n)) rounds.\r\nIn the paper, we also introduce an interesting combinatorial object, which we call an indepen\u0002dent covering family. Basically, an independent covering family of a hypergraph is a collection\r\nof independent sets that cover all non-edges. An interesting observation is that the set of negative\r\nqueries of any algorithm that learns a hypergraph drawn from a class of hypergraphs that is closed\r\nunder the operation of adding an edge is an independent covering family of that hypergraph. Note\r\nboth the class of r-uniform hypergraphs and the class of (r,∆)-uniform hypergraphs are closed un\u0002der the operation of adding an edge. This implies that the query complexity of learning such a\r\nhypergraph is bounded below by the minimum size of its independent covering families. In the\r\nopposite direction, we give subroutines to find one arbitrary edge from a hypergraph. With the help\r\nof the subroutines, we show that if we can construct small-sized independent covering families for\r\nsome class of hypergraphs, we are able to obtain an efficient learning algorithm for it. In this paper,\r\nwe give a randomized construction of an independent covering family of size O(r2\r\n2rmlogn) for\r\nr-uniform hypergraphs with m edges. This yields a learning algorithm using a number of queries\r\nthat is quadratic in m, which is further improved to give an algorithm using a number of queries that\r\nis linear in m.\r\nAs mentioned in Angluin and Chen (2004) and some other papers, the hypergraph learning\r\nproblem may also be viewed as the problem of learning a monotone disjunctive normal form (DNF)\r\nboolean formula using membership queries only. Each vertex of H is represented by a variable and\r\neach edge by a term containing all variables associated with the vertices of the edge. A membership\r\nquery assigns 1 or 0 to each variable, and is answered 1 if the assignment satisfies at least one term,\r\nand 0 otherwise, that is, if the set of vertices corresponding to the variables assigned 1 contains all\r\nvertices of at least one edge of H. An r-uniform hypergraph corresponds to a monotone r-DNF. An\r\n(r,∆)-uniform hypergraph corresponds to a monotone DNF whose terms are of sizes in the range\r\nof [r − ∆,r]. Thus, our results apply also to learning the corresponding classes of monotone DNF\r\nformulas using membership queries.\r\nThe paper is organized as follows. In Section 3, we formally define the concept of an inde\u0002pendent covering family and give a randomized construction of independent covering families for\r\ngeneral r-uniform hypergraphs. In Section 4, we show how to efficiently find an arbitrary edge in\r\na hypergraph and give a simple learning algorithm using a number of queries that is quadratic in\r\nthe number of edges. In Section 5, we give an algorithm that learns r-uniform hypergraphs using\r\na number of queries that is linear in the number of edges. Then we derive a lower bound for al\u0002most uniform hypergraphs in Section 6. Finally, we show how to learn the class of (r,∆)-uniform\r\nhypergraphs in Section 7.\r\n2217",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/18c7d9be-9287-4def-b10e-ffc134b3b8ed.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5621f86117fc93aa2b6fb8e451d965f4ce87e8d9117b55e0749cfc127d3eaeac",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 660
      },
      {
        "segments": [
          {
            "segment_id": "18c7d9be-9287-4def-b10e-ffc134b3b8ed",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 3,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\n(r,∆)-uniform hypergraphs with O(2\r\nO((1+\r\n∆\r\n2\r\n)r)\r\n·m\r\n1+\r\n∆\r\n2 · poly(logn,log 1\r\nδ\r\n)) queries with probability at\r\nleast 1−δ. The upper bound and lower bound have the same dependence on m.\r\nAnother important issue studied in the literature is the parallelism of algorithms. Since the\r\nqueries are motivated by an experiment design scenario, it is desirable that experiments can be\r\nconducted in parallel. Alon et al. (2004) and Alon and Asodi (2005) give lower and upper bounds for\r\n1-round algorithms for certain types of graphs. Beigel et al. (2001) describe an 8-round algorithm\r\nfor learning a matching. Angluin and Chen (2004) give a 5-round algorithm for learning a general\r\ngraph. In this paper, we show that in our algorithm for r-uniform hypergraphs, queries can be made\r\nin O(min(2\r\nr\r\n(logm+r)\r\n2\r\n,(logm+r)\r\n3\r\n)) rounds, and in our algorithm for (r,∆)-uniform hypergraphs,\r\nqueries can be made in O((1+∆)·min(2\r\nr\r\n(logm+r)\r\n2\r\n,(logm+r)\r\n3\r\n)) rounds.\r\nIn the paper, we also introduce an interesting combinatorial object, which we call an indepen\u0002dent covering family. Basically, an independent covering family of a hypergraph is a collection\r\nof independent sets that cover all non-edges. An interesting observation is that the set of negative\r\nqueries of any algorithm that learns a hypergraph drawn from a class of hypergraphs that is closed\r\nunder the operation of adding an edge is an independent covering family of that hypergraph. Note\r\nboth the class of r-uniform hypergraphs and the class of (r,∆)-uniform hypergraphs are closed un\u0002der the operation of adding an edge. This implies that the query complexity of learning such a\r\nhypergraph is bounded below by the minimum size of its independent covering families. In the\r\nopposite direction, we give subroutines to find one arbitrary edge from a hypergraph. With the help\r\nof the subroutines, we show that if we can construct small-sized independent covering families for\r\nsome class of hypergraphs, we are able to obtain an efficient learning algorithm for it. In this paper,\r\nwe give a randomized construction of an independent covering family of size O(r2\r\n2rmlogn) for\r\nr-uniform hypergraphs with m edges. This yields a learning algorithm using a number of queries\r\nthat is quadratic in m, which is further improved to give an algorithm using a number of queries that\r\nis linear in m.\r\nAs mentioned in Angluin and Chen (2004) and some other papers, the hypergraph learning\r\nproblem may also be viewed as the problem of learning a monotone disjunctive normal form (DNF)\r\nboolean formula using membership queries only. Each vertex of H is represented by a variable and\r\neach edge by a term containing all variables associated with the vertices of the edge. A membership\r\nquery assigns 1 or 0 to each variable, and is answered 1 if the assignment satisfies at least one term,\r\nand 0 otherwise, that is, if the set of vertices corresponding to the variables assigned 1 contains all\r\nvertices of at least one edge of H. An r-uniform hypergraph corresponds to a monotone r-DNF. An\r\n(r,∆)-uniform hypergraph corresponds to a monotone DNF whose terms are of sizes in the range\r\nof [r − ∆,r]. Thus, our results apply also to learning the corresponding classes of monotone DNF\r\nformulas using membership queries.\r\nThe paper is organized as follows. In Section 3, we formally define the concept of an inde\u0002pendent covering family and give a randomized construction of independent covering families for\r\ngeneral r-uniform hypergraphs. In Section 4, we show how to efficiently find an arbitrary edge in\r\na hypergraph and give a simple learning algorithm using a number of queries that is quadratic in\r\nthe number of edges. In Section 5, we give an algorithm that learns r-uniform hypergraphs using\r\na number of queries that is linear in the number of edges. Then we derive a lower bound for al\u0002most uniform hypergraphs in Section 6. Finally, we show how to learn the class of (r,∆)-uniform\r\nhypergraphs in Section 7.\r\n2217",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/18c7d9be-9287-4def-b10e-ffc134b3b8ed.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=5621f86117fc93aa2b6fb8e451d965f4ce87e8d9117b55e0749cfc127d3eaeac",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 660
      },
      {
        "segments": [
          {
            "segment_id": "b9847c0b-a8d2-4992-b817-5c8a5e0a9748",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 4,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\n2. Preliminaries\r\nLet H = (V,E) be a hypergraph. In this paper, we assume that edges do not contain each other,\r\nas there is no way to detect the existence of edges that contain other edges using edge-detecting\r\nqueries. A subset of V is an independent set of H if it contains no edge of H. We use the term\r\nnon-edge to denote any set that is a candidate edge in some class of hypergraphs but is not an edge\r\nin the target hypergraph. For example, in an r-uniform hypergraph, any r-set that is not an edge is\r\na non-edge. In an (r,∆)-uniform hypergraph, any set of size in the range of [r −∆,r] that is not an\r\nedge is a non-edge. The degree of a set χ ⊆ V in a hypergraph H denoted as dH(χ) is the number of\r\nedges of H that contain χ. In particular, dH(0/) = |E| is the number of all edges in H.\r\nThroughout the paper, we omit the ceiling and floor signs whenever they are not crucial.\r\n3. An Independent Covering Family\r\nDefinition 2 An independent covering family of a hypergraph H is a collection of independent sets\r\nof H such that every non-edge not containing an edge is contained in one of these independent sets.\r\nWhen H is a uniform hypergraph, the above only requires that every non-edge is contained in\r\none of the independent sets in the independent covering family. An example is shown below.\r\nExample 1 Let V = [1,6]. Let H = (V, {{1,2,3},{4,5,6},{2,4,5}}) be a 3-uniform hypergraph.\r\nF = {{1,2,4,6},{1,2,5,6},{1,3,4,5},{1,3,4,6},{2,3,4,6},{2,3,5,6}}\r\nis an independent covering family of H. As we can easily verify, all sets in F are independent sets,\r\nand every triple except {1,2,3},{4,5,6},{2,4,5} is contained in some set in F .\r\nThe concept of independent covering families is central in this paper. This can be appreciated\r\nfrom two aspects.\r\nFirst, we observe that if the target hypergraph is drawn from a class of hypergraphs that is\r\nclosed under the operation of adding an edge (e.g., the class of all r-uniform hypergraphs), the\r\nset of negative queries of any algorithm that learns it is an independent covering family of this\r\nhypergraph. This is because if there is a non-edge not contained in any of the sets on which these\r\nnegative queries are made, we will not be able to distinguish between the target hypergraph and the\r\nhypergraph with this non-edge being an extra edge. Therefore, the minimum size of independent\r\ncovering families bounds the query complexity from below. Furthermore, any learning algorithm\r\ngives a construction of an independent covering family of the target hypergraph. Therefore, in order\r\nto learn the hypergraph, we have to be able to construct an independent covering family for it.\r\nSecond, although the task of constructing an independent covering family seems substantially\r\neasier than that of learning, since the hypergraph is known in the construction task, we show that\r\nefficient construction of small-sized independent covering families yields an efficient learning algo\u0002rithm. In Section 4, we will show how to find an arbitrary edge out of a hypergraph of dimension\r\nr using O(rlogn) queries. Imagine a simple algorithm in which at each iteration we maintain a\r\nsub-hypergraph of the target hypergraph which contains edges that we have found, and construct\r\nan independent covering family for it and ask queries on all the sets in the family. If there is a set\r\nwhose query is answered positively, we can find at least one edge out of this set. The edge must\r\n2218",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/b9847c0b-a8d2-4992-b817-5c8a5e0a9748.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d97d70838372404c153be1390123b30be24ee9d55bb64681db7d4df2f0ed0633",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 590
      },
      {
        "segments": [
          {
            "segment_id": "b9847c0b-a8d2-4992-b817-5c8a5e0a9748",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 4,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\n2. Preliminaries\r\nLet H = (V,E) be a hypergraph. In this paper, we assume that edges do not contain each other,\r\nas there is no way to detect the existence of edges that contain other edges using edge-detecting\r\nqueries. A subset of V is an independent set of H if it contains no edge of H. We use the term\r\nnon-edge to denote any set that is a candidate edge in some class of hypergraphs but is not an edge\r\nin the target hypergraph. For example, in an r-uniform hypergraph, any r-set that is not an edge is\r\na non-edge. In an (r,∆)-uniform hypergraph, any set of size in the range of [r −∆,r] that is not an\r\nedge is a non-edge. The degree of a set χ ⊆ V in a hypergraph H denoted as dH(χ) is the number of\r\nedges of H that contain χ. In particular, dH(0/) = |E| is the number of all edges in H.\r\nThroughout the paper, we omit the ceiling and floor signs whenever they are not crucial.\r\n3. An Independent Covering Family\r\nDefinition 2 An independent covering family of a hypergraph H is a collection of independent sets\r\nof H such that every non-edge not containing an edge is contained in one of these independent sets.\r\nWhen H is a uniform hypergraph, the above only requires that every non-edge is contained in\r\none of the independent sets in the independent covering family. An example is shown below.\r\nExample 1 Let V = [1,6]. Let H = (V, {{1,2,3},{4,5,6},{2,4,5}}) be a 3-uniform hypergraph.\r\nF = {{1,2,4,6},{1,2,5,6},{1,3,4,5},{1,3,4,6},{2,3,4,6},{2,3,5,6}}\r\nis an independent covering family of H. As we can easily verify, all sets in F are independent sets,\r\nand every triple except {1,2,3},{4,5,6},{2,4,5} is contained in some set in F .\r\nThe concept of independent covering families is central in this paper. This can be appreciated\r\nfrom two aspects.\r\nFirst, we observe that if the target hypergraph is drawn from a class of hypergraphs that is\r\nclosed under the operation of adding an edge (e.g., the class of all r-uniform hypergraphs), the\r\nset of negative queries of any algorithm that learns it is an independent covering family of this\r\nhypergraph. This is because if there is a non-edge not contained in any of the sets on which these\r\nnegative queries are made, we will not be able to distinguish between the target hypergraph and the\r\nhypergraph with this non-edge being an extra edge. Therefore, the minimum size of independent\r\ncovering families bounds the query complexity from below. Furthermore, any learning algorithm\r\ngives a construction of an independent covering family of the target hypergraph. Therefore, in order\r\nto learn the hypergraph, we have to be able to construct an independent covering family for it.\r\nSecond, although the task of constructing an independent covering family seems substantially\r\neasier than that of learning, since the hypergraph is known in the construction task, we show that\r\nefficient construction of small-sized independent covering families yields an efficient learning algo\u0002rithm. In Section 4, we will show how to find an arbitrary edge out of a hypergraph of dimension\r\nr using O(rlogn) queries. Imagine a simple algorithm in which at each iteration we maintain a\r\nsub-hypergraph of the target hypergraph which contains edges that we have found, and construct\r\nan independent covering family for it and ask queries on all the sets in the family. If there is a set\r\nwhose query is answered positively, we can find at least one edge out of this set. The edge must\r\n2218",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/b9847c0b-a8d2-4992-b817-5c8a5e0a9748.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d97d70838372404c153be1390123b30be24ee9d55bb64681db7d4df2f0ed0633",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 590
      },
      {
        "segments": [
          {
            "segment_id": "8c3f2368-823f-4765-ba02-a91c8ef29f28",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 5,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\nbe a new edge as the set is an independent set of the sub-hypergraph that we have found. We re\u0002peat this process until we have collected all the edges in the target hypergraph, in which case the\r\nindependent covering family we construct is a proof of this fact. Suppose that we can construct an\r\nindependent covering family of size at most f(m) for any hypergraph with at most m edges drawn\r\nfrom certain class of hypergraphs. The above algorithm learns this class of hypergraphs using only\r\nO(f(m)·m·rlogn) queries.\r\nIn the rest of this section, we give a randomized construction of a linear-sized (linear in the\r\nnumber of edges) independent covering family of an r-uniform hypergraph which succeeds with\r\nprobability at least 1/2. By the standard probabilistic argument, the construction provesthe existence\r\nof an independent covering family of size linear in the number of edges for any uniform hypergraph.\r\nThis construction leads to a quadratic algorithm described in Section 4, and is also a central part of\r\nour main algorithm given in Section 5.\r\nOur main theorem in this section is as follows.\r\nTheorem 3 Any r-uniform hypergraph with m edges has an independent covering family of size\r\nO(r2\r\n2rmlogn).\r\nBefore giving the construction, we introduce some notation and definitions. We call a vertex set\r\nχ ⊆V relevant if it is contained in at least one edge in the hypergraph. Similarly, a vertex is relevant\r\nif it is contained in at least one edge in the hypergraph. Let pH(χ) = 1/(2\r\nr+1dH(χ))1/(r−|χ|)\r\n, where\r\nχ is a relevant vertex set. We will call pH(χ) the discovery probability of χ, as this is a probability\r\nthat will help in discovering edges containing χ in our learning algorithms.\r\nDefinition 4 A (χ, p)-sample is a random set of vertices that contains χ and contains each other\r\nvertex independently with probability p.\r\nWe will abbreviate (χ, p)-sample as χ-sample when the choice of p is clear or not important in the\r\ncontext.\r\nIn the construction, we draw (χ, pH(χ))-samples independently for each relevant set χ. Each\r\n(χ, pH(χ))-sample deals only with non-edges that contain χ. Let us take a look at the probability\r\nthat a (χ, pH(χ))-sample Pχ covers some non-edge z ⊇ χ while excluding all edges. Due to our\r\nchoice of pH(χ),\r\nPr[z ⊆ Pχ] = pH(χ)\r\nr−|χ| =\r\n1\r\n2\r\nr+1dH(χ)\r\n.\r\nTherefore, if we draw 2\r\nr+1dH(χ) many χ-samples, the probability that z is contained in at least one\r\nχ-sample is Ω(1). However, such a χ-sample is not necessarily an independent set. Especially when\r\nz contains a high degree subset χ\r\n0\r\n, it is likely that such a χ-sample contains an edges that contains χ\r\n0\r\n.\r\nBut since we will also draw (χ\r\n0\r\n, pH(χ\r\n0\r\n))-samples, it is reasonable to hope that a (χ\r\n0\r\n, pH(χ\r\n0\r\n))-sample\r\nhas better chance of success in dealing with z. In fact, in our construction, we show that the set of\r\nχ-samples, where χ ⊆ z has the minimum discovery probability among all relevant subsets of z, has\r\nan independent set that contains z with probability at least 1/2.\r\nA construction of an independent covering family is given in Algorithm 1, which succeeds with\r\nprobability at least 1/2 as shown by Lemma 5.\r\nLemma 5 FH (constructed in Algorithm 1) contains an independent covering family of H with\r\nprobability at least 1/2.\r\n2219",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/8c3f2368-823f-4765-ba02-a91c8ef29f28.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=658c0832865181fe12fe9bd33de8debd8be8bd723d84092c4a413fb70cc15db3",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 569
      },
      {
        "segments": [
          {
            "segment_id": "8c3f2368-823f-4765-ba02-a91c8ef29f28",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 5,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\nbe a new edge as the set is an independent set of the sub-hypergraph that we have found. We re\u0002peat this process until we have collected all the edges in the target hypergraph, in which case the\r\nindependent covering family we construct is a proof of this fact. Suppose that we can construct an\r\nindependent covering family of size at most f(m) for any hypergraph with at most m edges drawn\r\nfrom certain class of hypergraphs. The above algorithm learns this class of hypergraphs using only\r\nO(f(m)·m·rlogn) queries.\r\nIn the rest of this section, we give a randomized construction of a linear-sized (linear in the\r\nnumber of edges) independent covering family of an r-uniform hypergraph which succeeds with\r\nprobability at least 1/2. By the standard probabilistic argument, the construction provesthe existence\r\nof an independent covering family of size linear in the number of edges for any uniform hypergraph.\r\nThis construction leads to a quadratic algorithm described in Section 4, and is also a central part of\r\nour main algorithm given in Section 5.\r\nOur main theorem in this section is as follows.\r\nTheorem 3 Any r-uniform hypergraph with m edges has an independent covering family of size\r\nO(r2\r\n2rmlogn).\r\nBefore giving the construction, we introduce some notation and definitions. We call a vertex set\r\nχ ⊆V relevant if it is contained in at least one edge in the hypergraph. Similarly, a vertex is relevant\r\nif it is contained in at least one edge in the hypergraph. Let pH(χ) = 1/(2\r\nr+1dH(χ))1/(r−|χ|)\r\n, where\r\nχ is a relevant vertex set. We will call pH(χ) the discovery probability of χ, as this is a probability\r\nthat will help in discovering edges containing χ in our learning algorithms.\r\nDefinition 4 A (χ, p)-sample is a random set of vertices that contains χ and contains each other\r\nvertex independently with probability p.\r\nWe will abbreviate (χ, p)-sample as χ-sample when the choice of p is clear or not important in the\r\ncontext.\r\nIn the construction, we draw (χ, pH(χ))-samples independently for each relevant set χ. Each\r\n(χ, pH(χ))-sample deals only with non-edges that contain χ. Let us take a look at the probability\r\nthat a (χ, pH(χ))-sample Pχ covers some non-edge z ⊇ χ while excluding all edges. Due to our\r\nchoice of pH(χ),\r\nPr[z ⊆ Pχ] = pH(χ)\r\nr−|χ| =\r\n1\r\n2\r\nr+1dH(χ)\r\n.\r\nTherefore, if we draw 2\r\nr+1dH(χ) many χ-samples, the probability that z is contained in at least one\r\nχ-sample is Ω(1). However, such a χ-sample is not necessarily an independent set. Especially when\r\nz contains a high degree subset χ\r\n0\r\n, it is likely that such a χ-sample contains an edges that contains χ\r\n0\r\n.\r\nBut since we will also draw (χ\r\n0\r\n, pH(χ\r\n0\r\n))-samples, it is reasonable to hope that a (χ\r\n0\r\n, pH(χ\r\n0\r\n))-sample\r\nhas better chance of success in dealing with z. In fact, in our construction, we show that the set of\r\nχ-samples, where χ ⊆ z has the minimum discovery probability among all relevant subsets of z, has\r\nan independent set that contains z with probability at least 1/2.\r\nA construction of an independent covering family is given in Algorithm 1, which succeeds with\r\nprobability at least 1/2 as shown by Lemma 5.\r\nLemma 5 FH (constructed in Algorithm 1) contains an independent covering family of H with\r\nprobability at least 1/2.\r\n2219",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/8c3f2368-823f-4765-ba02-a91c8ef29f28.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=658c0832865181fe12fe9bd33de8debd8be8bd723d84092c4a413fb70cc15db3",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 569
      },
      {
        "segments": [
          {
            "segment_id": "d43f72b2-01e7-40c4-85e7-3ce5a3e7abcf",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 6,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\nAlgorithm 1 Construction of an independent covering family\r\n1: FH ← a set containing 4(ln2 + rlnn)· 2\r\nrdH(χ) (χ, pH(χ))-samples drawn independently for\r\nevery relevant set χ.\r\n2: Output the independent sets contained in FH as an independent covering family.\r\nProof Suppose z is a non-edge and χ is a subset of z with the minimum discovery probability. Let\r\nPχ be a χ-sample. As argued before,\r\nPr[z ⊆ Pχ] =\r\n1\r\n2\r\nr+1dH(χ)\r\n.\r\nSince χ has the minimum discovery probability, the degree of any subset χ\r\n0 ⊆ z is at most\r\n1/(2\r\nr+1 pH(χ)r−|χ\r\n0\r\n|\r\n). By the union bound,\r\nPr[Pχ is independent|z ⊆ Pχ] ≥ 1− ∑\r\nχ\r\n0⊆z\r\ndH(χ\r\n0\r\n)pH(χ)\r\nr−|χ\r\n0\r\n|\r\n≥ 1− ∑\r\nχ\r\n0⊆z\r\n1\r\n2\r\nr+1 pH(χ)\r\nr−|χ\r\n0\r\n|\r\npH(χ)\r\nr−|χ\r\n0\r\n|\r\n= 1/2.\r\nThe probability that a χ-sample contains z and is independent is at least 1/(2\r\nr+2dH(χ)). Therefore,\r\nthe probability that such a χ-sample exists in FH is at least\r\n1−(1−\r\n1\r\n2\r\nr+2dH(χ)\r\n)\r\n4(ln2+rlnn)·2\r\nrdH (χ)\r\n≥1−e\r\n−(rlnn+ln2)\r\n=1−\r\n1\r\n2n\r\n−r\r\n.\r\nThus, the probability that every non-edge is contained in some negative sample in FH is at least\r\n1−\r\n\r\nn\r\nr\r\n\u0001\r\n/(2n\r\nr\r\n) ≥ 1/2.\r\nTheorem 3 is then established by the fact that the size of FH is bounded by ∑χ 4(ln2+rlnn)·\r\n2\r\nrdH(χ) = O(r22rmlogn).\r\n4. A Simple Quadratic Algorithm\r\nIn this section, we first give an algorithm that finds an arbitrary edge in a hypergraph of dimension\r\nr using only rlogn edge-detecting queries. The algorithm is adaptive and takes rlogn rounds. The\r\nsuccess probability in the construction of independent covering families in the previous section can\r\nbe easily improved by drawing more samples. Using the high-probability version of the construc\u0002tion, we obtain an algorithm using a number of queries that is quadratic in m that learns an r-uniform\r\nhypergraph with m edges with high probability. Although the first algorithm for finding one edge is\r\ndeterministic and simple, the round complexity rlogn might be too high when n is much larger than\r\nm. We then improve the round complexity to O(logm+r) using only O(logmlogn) more queries.\r\nThe improved algorithm is randomized and succeeds with high probability.\r\n2220",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/d43f72b2-01e7-40c4-85e7-3ce5a3e7abcf.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=9de0ad28aba7b77ec25a2d3c30d19d93265618c19df94969fea9839becf75ff4",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 374
      },
      {
        "segments": [
          {
            "segment_id": "5aefe5f8-286e-4d6b-8dac-ab7bd9bd0919",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 7,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\n4.1 Find One Edge\r\nWe start with a simpler task, finding just one relevant vertex in the hypergraph. The algorithm\r\nFIND-ONE-VERTEX is shown in Algorithm 2.\r\nAlgorithm 2 FIND-ONE-VERTEX\r\n1: S ← V,A ← V.\r\n2: while |A| > 1 do\r\n3: Divide A arbitrarily into A0 and A1, such that |A0| = d|A|/2e, |A1| = b|A|/2c.\r\n4: if Q(S\\A0) = 0 then\r\n5: A ← A0.\r\n6: else\r\n7: A ← A1, S ← S\\A0.\r\n8: end if\r\n9: end while\r\n10: Output the element in A.\r\nLemma 6 FIND-ONE-VERTEX finds one relevant vertex in a non-empty hypergraph with n ver\u0002tices using at most logn edge-detecting queries.\r\nProof First we show that the following equalities hold for each iteration (see Figure 1).\r\nQ(S) = 1,Q(S\\A) = 0.\r\nV\r\nS\r\nA0 A1\r\nA\r\nQ(S\\A) = 0 Q(S) = 1\r\nFigure 1: An illustration of FIND-ONE-VERTEX\r\nThese equalities guarantee that A contains at least one relevant vertex. Since we assume that\r\nthe hypergraph is non-empty, the above equalities clearly hold for our initial assignment of S and A.\r\nLet’s assume Q(S) = 1 and Q(S\\A) = 0 at the beginning of an iteration. There are two cases:\r\n1. Q(S\\A0) = 0, clearly the equalities hold for S and A0.\r\n2. Q(S\\A0) = 1, since Q((S\\A0)\\A1) = Q(S\\(A0 ∪A1)) = Q(S\\A) = 0, the equalities hold for\r\nS\\A0 and A1.\r\nSince the size of A halves at each iteration, after at most logn iterations, A has exactly one rele\u0002vant vertex. The algorithm takes at most logn edge-detecting queries in total, as it makes one query\r\nin each iteration.\r\n2221",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/5aefe5f8-286e-4d6b-8dac-ab7bd9bd0919.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2bdf92f9812d5fadc5d17b94d9ee98702d268f9c98c3b12f0e95b4f52f308839",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 271
      },
      {
        "segments": [
          {
            "segment_id": "fa6e4c53-fb44-4628-9b9d-78e85e1087de",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 8,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\nUsing FIND-ONE-VERTEX as a subroutine, FIND-ONE-EDGE (Algorithm 3) is a recursive\r\nalgorithm that finds one edge from a non-empty hypergraph, which is not necessarily uniform.\r\nNote knowledge of r is not required in FIND-ONE-EDGE. It is included in the description of the\r\nalgorithm for the purpose of explanation.\r\nAlgorithm 3 FIND-ONE-EDGE\r\n1: Let r > 0 be the dimension of the hypergraph.\r\n2: Call FIND-ONE-VERTEX and let v be the found vertex.\r\n3: Make a query on {v}.\r\n4: if the query is answered 1 then\r\n5: Output {v}.\r\n6: else\r\n7: FIND-ONE-VERTEX also computes a set S such that Q(S) = 1 and Q(S\\{v}) = 0. That is,\r\nS contains only edges incident with v.\r\n8: Call FIND-ONE-EDGE on the hypergraph induced on S with the vertex v removed. The\r\nhypergraph is of dimension at most r −1. Let e be the found edge.\r\n9: Output the edge e∪{v}.\r\n10: end if\r\nEdge-detecting queries for recursive calls of FIND-ONE-EDGE can be simulated recursively.\r\nTo make an edge-detecting query for a next-level recursive call of FIND-ONE-EDGE, we just need\r\nto make an edge-detecting query at the current level on the union of a subset of S and {v}. In fact,\r\neach time, we make edge-detecting queries on the union of a subset of S and the set of vertices\r\nalready found.\r\nIn FIND-ONE-EDGE, because S contains only edges incident with v, e∪ {v} is an edge in the\r\nhypergraph. This establishes its correctness. The following lemma shows that it uses only rlogn\r\nqueries.\r\nLemma 7 FIND-ONE-EDGE finds one edge in a non-empty hypergraph of dimension r with n\r\nvertices using rlogn edge-detecting queries.\r\nProof When r = 1, the problem is exactly that of finding one relevant vertex and hence solvable us\u0002ing logn queries. It is evident that if FIND-ONE-EDGE uses (r −1)logn queries for a hypergraph\r\nwith dimension r −1. then it only uses (r −1)logn+logn = rlogn queries for a hypergraph with\r\ndimension r.\r\n4.2 A Quadratic Algorithm\r\nWith the help of FIND-ONE-EDGE, we give the first learning algorithm for r-uniform hypergraphs.\r\nA sketch of the algorithm has been described in Section 3. Let H = (V,E) be the sub-hypergraph\r\nthe algorithm has found so far. Algorithm 4 learns a uniform hypergraph with probability at least\r\n1−δ. We will specify δ\r\n0\r\nlater.\r\nIn the algorithm we draw 4(ln(\r\n1\r\nδ\r\n0) + rlnn)· 2\r\nrdH(χ) χ-samples. Using essentially the same\r\nargument as in Section 3, we can guarantee that FH contains an independent covering family with\r\n2222",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/fa6e4c53-fb44-4628-9b9d-78e85e1087de.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=592b0753598e21445ceb5e3620544156eefdebfe0f82bf77dc426b74a9c04402",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 423
      },
      {
        "segments": [
          {
            "segment_id": "672bde08-7364-4637-a5f6-c6fddb9d7982",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 9,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\nAlgorithm 4 The quadratic algorithm\r\n1: e ← FIND-ONE-EDGE(V). E ← {e}.\r\n2: repeat\r\n3: FH ← 4(ln 1\r\nδ\r\n0 + rlnn)· 2\r\nrdH(χ) (χ, pH(χ))-samples drawn independently for every relevant\r\nset χ in H.\r\n4: Make queries on sets of FH that are independent in H.\r\n5: Call FIND-ONE-EDGE on one positive sample if there exists any. Let e be the edge found.\r\nE ← E ∪{e}.\r\n6: until no new edge found\r\nprobability at least 1 − δ\r\n0\r\n. Algorithm 4 finds one new edge at each iteration because FH is an\r\nindependent covering family of the already found sub-hypergraph H. Thus, it ends after at most m\r\niterations. If we we choose δ\r\n0 = δ/m, it will succeed with probability at least 1−δ. As knowledge\r\nof m is not assumed, we will choose δ\r\n0 = δ/\r\n\r\nn\r\nr\r\n\u0001\r\n≤ δ/m. The query complexity will be O(2\r\n2rm2\r\n·\r\npoly(r,logn)·log 1\r\nδ\r\n), which is quadratic in m.\r\n4.3 An Improved FIND-ONE-EDGE\r\nDespite the simplicity of FIND-ONE-EDGE, its queries have to be made in rlogn rounds. When\r\nirrelevant vertices abound, that is, when n is much larger than m, we would like to arrange queries in\r\na smaller number of rounds. In the following, we use a technique developed in Damaschke (1998)\r\n(for learning monotone boolean functions) to find one edge from a non-empty hypergraph with high\r\nprobability using only O(logm+r) rounds and O((logm+r)logn) queries. However, the algorithm\r\nis more involved.\r\nThe new algorithm is also based on FIND-ONE-VERTEX. The process of FIND-ONE-VERTEX\r\ncan be viewed as a binary decision tree. At each internal node, a set A is split and a decision on\r\nwhich branch to follow is made based on query results. The FIND-ONE-VERTEX algorithm does\r\nnot restrict how we split the set A as long as we divide it into halves. In the new algorithm, we will\r\npre-determine the way A’s will be divided at the very beginning of the algorithm.\r\nLet us index each vertex by a distinct binary number b1b2 ...blogn. Each split is based on a\r\ncertain bit. We say that we split a set A according to its i\r\nth\r\n(i ∈ [1,logn]) bit, we will divide A into\r\ntwo sets, one containing vertices whose i\r\nth bits are 0 and the other containing vertices whose ith\r\nbits are 1. We will denote these two sets A|bi=0 and A|bi=1 respectively. If we split A|bi=0 further\r\naccording to the j\r\nth bit, we get another two sets (A|bi=0)|bj=0 and (A|bi=0)|bj=1. We will abbreviate\r\nthese two sets as A|bi=0,bj=0 and A|bi=0,bj=1. In general, let s be a partial assignment that assigns\r\nsome bits to 0 or 1, we use A|sto denote the set of vertices in A that match the assignments of bits\r\nin s.\r\nUsing this notation and our splitting scheme, at each iteration of FIND-ONE-VERTEX, A is\r\nequal to V|s for some partial assignment s, and A0 and A1 are equal to A|bi=0 and A|bi=1 if we\r\nsplit A according to the i\r\nth bit. One of the key ideas in Damaschke (1998) is that because the\r\nsplits are pre-determined, and the queries are monotone in terms of subset relation, we can make\r\nqueries on pre-determined splits to make predictions. The idea will be made clear in the rest of\r\nthe section. PARA-FIND-ONE-VERTEX (Algorithm 5) improves the round complexity of FIND\u0002ONE-VERTEX.\r\n2223",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/672bde08-7364-4637-a5f6-c6fddb9d7982.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=112aab15e979da7ad6205c1a2b7a8c7c35cb9c5cdd968545b22ebf9c65b98eac",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 570
      },
      {
        "segments": [
          {
            "segment_id": "672bde08-7364-4637-a5f6-c6fddb9d7982",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 9,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\nAlgorithm 4 The quadratic algorithm\r\n1: e ← FIND-ONE-EDGE(V). E ← {e}.\r\n2: repeat\r\n3: FH ← 4(ln 1\r\nδ\r\n0 + rlnn)· 2\r\nrdH(χ) (χ, pH(χ))-samples drawn independently for every relevant\r\nset χ in H.\r\n4: Make queries on sets of FH that are independent in H.\r\n5: Call FIND-ONE-EDGE on one positive sample if there exists any. Let e be the edge found.\r\nE ← E ∪{e}.\r\n6: until no new edge found\r\nprobability at least 1 − δ\r\n0\r\n. Algorithm 4 finds one new edge at each iteration because FH is an\r\nindependent covering family of the already found sub-hypergraph H. Thus, it ends after at most m\r\niterations. If we we choose δ\r\n0 = δ/m, it will succeed with probability at least 1−δ. As knowledge\r\nof m is not assumed, we will choose δ\r\n0 = δ/\r\n\r\nn\r\nr\r\n\u0001\r\n≤ δ/m. The query complexity will be O(2\r\n2rm2\r\n·\r\npoly(r,logn)·log 1\r\nδ\r\n), which is quadratic in m.\r\n4.3 An Improved FIND-ONE-EDGE\r\nDespite the simplicity of FIND-ONE-EDGE, its queries have to be made in rlogn rounds. When\r\nirrelevant vertices abound, that is, when n is much larger than m, we would like to arrange queries in\r\na smaller number of rounds. In the following, we use a technique developed in Damaschke (1998)\r\n(for learning monotone boolean functions) to find one edge from a non-empty hypergraph with high\r\nprobability using only O(logm+r) rounds and O((logm+r)logn) queries. However, the algorithm\r\nis more involved.\r\nThe new algorithm is also based on FIND-ONE-VERTEX. The process of FIND-ONE-VERTEX\r\ncan be viewed as a binary decision tree. At each internal node, a set A is split and a decision on\r\nwhich branch to follow is made based on query results. The FIND-ONE-VERTEX algorithm does\r\nnot restrict how we split the set A as long as we divide it into halves. In the new algorithm, we will\r\npre-determine the way A’s will be divided at the very beginning of the algorithm.\r\nLet us index each vertex by a distinct binary number b1b2 ...blogn. Each split is based on a\r\ncertain bit. We say that we split a set A according to its i\r\nth\r\n(i ∈ [1,logn]) bit, we will divide A into\r\ntwo sets, one containing vertices whose i\r\nth bits are 0 and the other containing vertices whose ith\r\nbits are 1. We will denote these two sets A|bi=0 and A|bi=1 respectively. If we split A|bi=0 further\r\naccording to the j\r\nth bit, we get another two sets (A|bi=0)|bj=0 and (A|bi=0)|bj=1. We will abbreviate\r\nthese two sets as A|bi=0,bj=0 and A|bi=0,bj=1. In general, let s be a partial assignment that assigns\r\nsome bits to 0 or 1, we use A|sto denote the set of vertices in A that match the assignments of bits\r\nin s.\r\nUsing this notation and our splitting scheme, at each iteration of FIND-ONE-VERTEX, A is\r\nequal to V|s for some partial assignment s, and A0 and A1 are equal to A|bi=0 and A|bi=1 if we\r\nsplit A according to the i\r\nth bit. One of the key ideas in Damaschke (1998) is that because the\r\nsplits are pre-determined, and the queries are monotone in terms of subset relation, we can make\r\nqueries on pre-determined splits to make predictions. The idea will be made clear in the rest of\r\nthe section. PARA-FIND-ONE-VERTEX (Algorithm 5) improves the round complexity of FIND\u0002ONE-VERTEX.\r\n2223",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/672bde08-7364-4637-a5f6-c6fddb9d7982.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=112aab15e979da7ad6205c1a2b7a8c7c35cb9c5cdd968545b22ebf9c65b98eac",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 570
      },
      {
        "segments": [
          {
            "segment_id": "1674429f-39b0-4969-a613-6d95c7ada8a8",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 10,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\nAlgorithm 5 PARA-FIND-ONE-VERTEX\r\n1: S ← V,A ← V,I ← [1,logn].\r\n2: while |A| > 1 do\r\n3: ∀i ∈ I, make queries on (S\\A)∪A|bi=0 and (S\\A)∪A|bi=1.\r\n4: Let Ri = (Q((S\\A)∪A|bi=0),Q((S\\A)∪A|bi=1)) be the query results for i ∈ I.\r\n5: case 1: ∃i ∈ I such that Ri = (0,0)\r\n6: A ← A|bi=0,I ← I\\{i}.\r\n7: case 2: ∃i ∈ I such that Ri = (1,1)\r\n8: Choose a from {0,1} uniformly at random.\r\n9: A ← A|bi=a, S ← (S\\A)∪A|bi=a,I ← I\\{i}.\r\n10: case 3: ∀i ∈ I, Ri = (1,0) or Ri = (0,1)\r\n11: Swap the indices of vertices so that Ri = (1,0) for every i ∈ I. (If Ri = (0,1), we flip the\r\ni\r\nth bit of all the indices, that is, for every vertex, if the ith bit of its index is 0, we set the ith\r\nbit to 1 and vice versa.)\r\n12: ∀i ∈ I, let A\r\ni = A|∀ j∈I, j≤i,bj=0 and make a query on Si = (S\\A)∪Ai\r\n.\r\n13: Let i\r\n∗ = min\b\r\ni|Q(S\r\ni\r\n) = 0\r\n\t\r\nif it exists and the largest index in I otherwise. Let j\r\n∗ =\r\nmax{ j| j < i\r\n∗\r\n, j ∈ I}.\r\n14: I ← {i|i > i\r\n∗\r\n,i ∈ I}.\r\n15: if all queries are answered 1 then\r\n16: A ← A\r\ni\r\n∗\r\n,S ← S\r\ni\r\n∗\r\n(i\r\n∗\r\nis the largest index in I in this case).\r\n17: else\r\n18: A ← A\r\ni\r\n∗\r\n,S ← S\r\nj\r\n∗\r\n.\r\n19: end if\r\n20: end while\r\n21: Output the element in A.\r\nIn PARA-FIND-ONE-VERTEX, the equalities Q(S) = 1,Q(S\\A) = 0 are also preserved at all\r\ntimes, which establishes the correctness. We first make queries on (S\\A)∪A|bi=0 (= S\\A|bi=1) and\r\n(S\\A)∪A|bi=1 (= S\\A|bi=0) for every i. There are 3 possible query outcomes.\r\ncase 1: If there exists i such that Ri = (0,0), that is, both queries are answered 0, all edges contained\r\nin S are split between A|bi=0 and A|bi=1, that is, the intersections of each edge with these two\r\nsets are a partition of the edge. We call this case an edge-splitting event. The iterations at\r\nwhich an edge-splitting event happens are edge-splitting iterations. Since we then set A to be\r\nA|bi=0, the intersection of A with any edge contained in S becomes strictly smaller. Because\r\nwe will only shrink A in other cases, the intersections will never increase. Thus, there are at\r\nmost r −1 edge-splitting iterations as each edge is of size at most r.\r\ncase 2: If there exists i such that Ri = (1,1), that is, both queries are answered 1, we can set S to\r\nbe either of the two sets (S\\A)∪A|bi=0 and (S\\A)∪A|bi=1 as they both contain edges, and\r\nset A to be A|bi=0 or A|bi=1 respectively. The equalities Q(S) = 1,Q(S\\A) = 0 are preserved\r\nin this case. However, we would like to choose whichever of the two sets (S\\A) ∪ A|bi=0\r\nand (S\\A)∪A|bi=1 contains fewer edges. Because they do not share a common edge as their\r\nintersection S\\A does not contain an edge, the sum of the numbers of edges contained in\r\nthese two sets is at most the number of edges contained in S. If we choose the set with fewer\r\n2224",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/1674429f-39b0-4969-a613-6d95c7ada8a8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2164c0b776117abf0c9bdc3865128d44ab52069ad48186c53daeac4c0faf865e",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 557
      },
      {
        "segments": [
          {
            "segment_id": "1674429f-39b0-4969-a613-6d95c7ada8a8",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 10,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\nAlgorithm 5 PARA-FIND-ONE-VERTEX\r\n1: S ← V,A ← V,I ← [1,logn].\r\n2: while |A| > 1 do\r\n3: ∀i ∈ I, make queries on (S\\A)∪A|bi=0 and (S\\A)∪A|bi=1.\r\n4: Let Ri = (Q((S\\A)∪A|bi=0),Q((S\\A)∪A|bi=1)) be the query results for i ∈ I.\r\n5: case 1: ∃i ∈ I such that Ri = (0,0)\r\n6: A ← A|bi=0,I ← I\\{i}.\r\n7: case 2: ∃i ∈ I such that Ri = (1,1)\r\n8: Choose a from {0,1} uniformly at random.\r\n9: A ← A|bi=a, S ← (S\\A)∪A|bi=a,I ← I\\{i}.\r\n10: case 3: ∀i ∈ I, Ri = (1,0) or Ri = (0,1)\r\n11: Swap the indices of vertices so that Ri = (1,0) for every i ∈ I. (If Ri = (0,1), we flip the\r\ni\r\nth bit of all the indices, that is, for every vertex, if the ith bit of its index is 0, we set the ith\r\nbit to 1 and vice versa.)\r\n12: ∀i ∈ I, let A\r\ni = A|∀ j∈I, j≤i,bj=0 and make a query on Si = (S\\A)∪Ai\r\n.\r\n13: Let i\r\n∗ = min\b\r\ni|Q(S\r\ni\r\n) = 0\r\n\t\r\nif it exists and the largest index in I otherwise. Let j\r\n∗ =\r\nmax{ j| j < i\r\n∗\r\n, j ∈ I}.\r\n14: I ← {i|i > i\r\n∗\r\n,i ∈ I}.\r\n15: if all queries are answered 1 then\r\n16: A ← A\r\ni\r\n∗\r\n,S ← S\r\ni\r\n∗\r\n(i\r\n∗\r\nis the largest index in I in this case).\r\n17: else\r\n18: A ← A\r\ni\r\n∗\r\n,S ← S\r\nj\r\n∗\r\n.\r\n19: end if\r\n20: end while\r\n21: Output the element in A.\r\nIn PARA-FIND-ONE-VERTEX, the equalities Q(S) = 1,Q(S\\A) = 0 are also preserved at all\r\ntimes, which establishes the correctness. We first make queries on (S\\A)∪A|bi=0 (= S\\A|bi=1) and\r\n(S\\A)∪A|bi=1 (= S\\A|bi=0) for every i. There are 3 possible query outcomes.\r\ncase 1: If there exists i such that Ri = (0,0), that is, both queries are answered 0, all edges contained\r\nin S are split between A|bi=0 and A|bi=1, that is, the intersections of each edge with these two\r\nsets are a partition of the edge. We call this case an edge-splitting event. The iterations at\r\nwhich an edge-splitting event happens are edge-splitting iterations. Since we then set A to be\r\nA|bi=0, the intersection of A with any edge contained in S becomes strictly smaller. Because\r\nwe will only shrink A in other cases, the intersections will never increase. Thus, there are at\r\nmost r −1 edge-splitting iterations as each edge is of size at most r.\r\ncase 2: If there exists i such that Ri = (1,1), that is, both queries are answered 1, we can set S to\r\nbe either of the two sets (S\\A)∪A|bi=0 and (S\\A)∪A|bi=1 as they both contain edges, and\r\nset A to be A|bi=0 or A|bi=1 respectively. The equalities Q(S) = 1,Q(S\\A) = 0 are preserved\r\nin this case. However, we would like to choose whichever of the two sets (S\\A) ∪ A|bi=0\r\nand (S\\A)∪A|bi=1 contains fewer edges. Because they do not share a common edge as their\r\nintersection S\\A does not contain an edge, the sum of the numbers of edges contained in\r\nthese two sets is at most the number of edges contained in S. If we choose the set with fewer\r\n2224",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/1674429f-39b0-4969-a613-6d95c7ada8a8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2164c0b776117abf0c9bdc3865128d44ab52069ad48186c53daeac4c0faf865e",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 557
      },
      {
        "segments": [
          {
            "segment_id": "6fa8ba17-a5d2-4b1c-b919-0aeb38730a99",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 11,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\nedges, we will cut the number of edges contained in S in half. With a random choice, this\r\nhappens with probability 1/2. We will call this case an edge-separating event and call the\r\ncorresponding iteration an edge-separating iteration.\r\ncase 3: If neither of the two events happens, we need to deal with the third case where ∀i ∈ I, one\r\nof the queries is answered 0 and the other is answered 1. In this case, for convenience of\r\nexposition, we will flip the indices of all vertices, so that Ri = (1,0) for every i ∈ I. Thus,\r\n∀i ∈ I,Q((S\\A) ∪ A|bi=0) = 1. In this case, we can set A to A|bi=0 for some i ∈ I, and the\r\nequalities Q(S) = 1,Q(S\\A) = 0 are preserved. However, this won’t help us to reduce the\r\nround complexity as it only cuts A in half.\r\nConsider the next split. We shall divide A|bi=0 further into A|bi=0,bj=0 and A|bi=0,bj=1 for\r\nsome j ∈ I, j 6= i. Since we already know that Q((S\\A)∪A|bj=1) = 0, the fact that A|bi=0,bj=1\r\nis a subset of A|bj=1 implies Q((S\\A)∪A|bi=0,bj=1) = 0. Therefore, we only need to know\r\nQ((S\\A)∪A|bi=0,bj=0).\r\n(a) If it is 1, we can set A to be A|bi=0,bj=0 and continue.\r\n(b) Otherwise, it is 0, an edge-splitting event takes place.\r\nIn PARA-FIND-ONE-VERTEX, we choose the indices we use to split A in the increasing\r\norder of indices in I and make queries on S\r\ni = (S\\A)∪Ai\r\nfor every i ∈ I all in parallel (recall\r\nthat A\r\ni = A|∀ j∈I, j≤i,bj=0). If all queries are answered 1, i∗\r\nis the largest index in I and A\r\ni\r\n∗\r\nis\r\na singleton set containing a relevant vertex. Otherwise, we get an edge-splitting event, since\r\nS\r\nj\r\n∗\r\n= (S\\A)∪A\r\nj\r\n∗\r\ncontains edges, but both (S\\A)∪A\r\nj\r\n∗\r\n|bi\r\n∗=0 and (S\\A)∪A\r\nj\r\n∗\r\n|bi\r\n∗=1 don’t (note\r\nthat j\r\n∗\r\nis the index right before i\r\n∗\r\nin the increasing order of indices in I and A\r\ni\r\n∗\r\n= A\r\nj\r\n∗\r\n|bi\r\n∗=0). In\r\nthis case, it can be verified that our updates to A and S in the third case preserve the equalities\r\nQ(S) = 1,Q(S\\A) = 0.\r\nBy the above analysis, the first case and the third case both result in an edge-splitting event or\r\nsucceed in finding a relevant vertex. There are at most r such iterations. The second case results in\r\nan edge-separating event, in which with probability 1/2 we will cut the number of edges contained\r\nin S in half. We can show that in expectation there are logm edge-separating events. Therefore,\r\nthere are logm+r iterations in expectation. At each iteration, we use at most 3logn queries which\r\nare made in at most 2 rounds. Therefore,\r\nLemma 8 In expectation, PARA-FIND-ONE-VERTEX finds one relevant vertex using O((logm +\r\nr)logn) queries, and the queries can be made in 2(logm+r) rounds.\r\nPARA-FIND-ONE-VERTEX can work with FIND-ONE-EDGE to find an edge using expected\r\nO(r(logm + r)logn) queries in expected 2r(logm + r) rounds. In fact, we can improve the round\r\ncomplexity further to 2(logm+r) based on two observations, both of which use the fact that in the\r\nwhole process we only shrink S.\r\nThe first observation is that edges removed from S in the edge-separating events will not be\r\nconsidered again. Therefore, the logm bounds not only the expected number of edge-separating\r\niterations of PARA-FIND-ONE-VERTEX, but also that of the whole process.\r\nThe second observation is that the edge-splitting events can be remembered and reused when\r\nwe try to find the next relevant vertex. Since we only shrink S, the bits that split all edges in S will\r\ncontinue to do so. Let I\r\n∗ be the set of edge-splitting indices. In the new vertex finding process,\r\n2225",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/6fa8ba17-a5d2-4b1c-b919-0aeb38730a99.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=eae5c86c8b69744a51e2e6b7c449d2230300410ee2c0c6693a19c1a6c2be54e5",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 637
      },
      {
        "segments": [
          {
            "segment_id": "6fa8ba17-a5d2-4b1c-b919-0aeb38730a99",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 11,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\nedges, we will cut the number of edges contained in S in half. With a random choice, this\r\nhappens with probability 1/2. We will call this case an edge-separating event and call the\r\ncorresponding iteration an edge-separating iteration.\r\ncase 3: If neither of the two events happens, we need to deal with the third case where ∀i ∈ I, one\r\nof the queries is answered 0 and the other is answered 1. In this case, for convenience of\r\nexposition, we will flip the indices of all vertices, so that Ri = (1,0) for every i ∈ I. Thus,\r\n∀i ∈ I,Q((S\\A) ∪ A|bi=0) = 1. In this case, we can set A to A|bi=0 for some i ∈ I, and the\r\nequalities Q(S) = 1,Q(S\\A) = 0 are preserved. However, this won’t help us to reduce the\r\nround complexity as it only cuts A in half.\r\nConsider the next split. We shall divide A|bi=0 further into A|bi=0,bj=0 and A|bi=0,bj=1 for\r\nsome j ∈ I, j 6= i. Since we already know that Q((S\\A)∪A|bj=1) = 0, the fact that A|bi=0,bj=1\r\nis a subset of A|bj=1 implies Q((S\\A)∪A|bi=0,bj=1) = 0. Therefore, we only need to know\r\nQ((S\\A)∪A|bi=0,bj=0).\r\n(a) If it is 1, we can set A to be A|bi=0,bj=0 and continue.\r\n(b) Otherwise, it is 0, an edge-splitting event takes place.\r\nIn PARA-FIND-ONE-VERTEX, we choose the indices we use to split A in the increasing\r\norder of indices in I and make queries on S\r\ni = (S\\A)∪Ai\r\nfor every i ∈ I all in parallel (recall\r\nthat A\r\ni = A|∀ j∈I, j≤i,bj=0). If all queries are answered 1, i∗\r\nis the largest index in I and A\r\ni\r\n∗\r\nis\r\na singleton set containing a relevant vertex. Otherwise, we get an edge-splitting event, since\r\nS\r\nj\r\n∗\r\n= (S\\A)∪A\r\nj\r\n∗\r\ncontains edges, but both (S\\A)∪A\r\nj\r\n∗\r\n|bi\r\n∗=0 and (S\\A)∪A\r\nj\r\n∗\r\n|bi\r\n∗=1 don’t (note\r\nthat j\r\n∗\r\nis the index right before i\r\n∗\r\nin the increasing order of indices in I and A\r\ni\r\n∗\r\n= A\r\nj\r\n∗\r\n|bi\r\n∗=0). In\r\nthis case, it can be verified that our updates to A and S in the third case preserve the equalities\r\nQ(S) = 1,Q(S\\A) = 0.\r\nBy the above analysis, the first case and the third case both result in an edge-splitting event or\r\nsucceed in finding a relevant vertex. There are at most r such iterations. The second case results in\r\nan edge-separating event, in which with probability 1/2 we will cut the number of edges contained\r\nin S in half. We can show that in expectation there are logm edge-separating events. Therefore,\r\nthere are logm+r iterations in expectation. At each iteration, we use at most 3logn queries which\r\nare made in at most 2 rounds. Therefore,\r\nLemma 8 In expectation, PARA-FIND-ONE-VERTEX finds one relevant vertex using O((logm +\r\nr)logn) queries, and the queries can be made in 2(logm+r) rounds.\r\nPARA-FIND-ONE-VERTEX can work with FIND-ONE-EDGE to find an edge using expected\r\nO(r(logm + r)logn) queries in expected 2r(logm + r) rounds. In fact, we can improve the round\r\ncomplexity further to 2(logm+r) based on two observations, both of which use the fact that in the\r\nwhole process we only shrink S.\r\nThe first observation is that edges removed from S in the edge-separating events will not be\r\nconsidered again. Therefore, the logm bounds not only the expected number of edge-separating\r\niterations of PARA-FIND-ONE-VERTEX, but also that of the whole process.\r\nThe second observation is that the edge-splitting events can be remembered and reused when\r\nwe try to find the next relevant vertex. Since we only shrink S, the bits that split all edges in S will\r\ncontinue to do so. Let I\r\n∗ be the set of edge-splitting indices. In the new vertex finding process,\r\n2225",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/6fa8ba17-a5d2-4b1c-b919-0aeb38730a99.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=eae5c86c8b69744a51e2e6b7c449d2230300410ee2c0c6693a19c1a6c2be54e5",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 637
      },
      {
        "segments": [
          {
            "segment_id": "080bd60c-1091-441b-8d99-f821cd84e4f5",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 12,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\ninstead of starting with A = V = S (recall in a recursive call of FIND-ONE-EDGE, we look for a\r\nrelevant edge contained in the S. Therefore, in the recursive call, V is equal to the S we obtain in\r\nthe previous call), we start with A = S|i∈I\r\n∗\r\n,bi=0. Note that the equalities Q(S) = 1,Q(S\\A) = 0 are\r\npreserved. This helps us to bound the number of edge-splitting iterations by r − 1 for the whole\r\nprocess.\r\nThus, we have the following lemma.\r\nLemma 9 There is an algorithm that finds an edge in a non-empty hypergraph using expected\r\nO((logm+r)logn) edge-detecting queries. Moreover, the queries can be made in expected 2(logm+\r\nr) rounds.\r\nSince the algorithm terminates in expected logm+r iterations, according to Markov’s Inequal\u0002ity, with probability at least 1/2, the algorithm terminates in 2(logm + r) iterations. We convert\r\nit to one that succeeds with high probability by running log 1\r\nδ\r\ncopies, each of which has its own\r\nindependent random choices. All copies are synchronized at each iteration and the algorithm ends\r\nwhen one of them succeeds. This leads to an algorithm that succeeds with high probability. We will\r\nrefer to this algorithm as PARA-FIND-ONE-EDGE.\r\nCorollary 10 With probability at least 1−δ, PARA-FIND-ONE-EDGE finds an edge using O((logm+\r\nr)lognlog 1\r\nδ\r\n) edge-detecting queries, and the queries can be made in 4(logm+r) rounds.\r\n5. A Linear-Query Algorithm\r\nReconstructing an independent covering family at the discovery of every new edge is indeed waste\u0002ful. In this section we show how to modify the quadratic algorithm to obtain an algorithm using\r\na number of queries that is linear in the number of edges. Our algorithm is optimal in terms of\r\nthe dependence on m. Moreover, the queries can be made in O(min(2\r\nr\r\n(logm + r)\r\n2\r\n,(logm + r)\r\n3\r\n))\r\nrounds.\r\nBefore we begin to describe our algorithm, we introduce some notation and make some defini\u0002tions. First we reduce the discovery probabilities. Let\r\npH(χ) = 1/(2\r\nr+|χ|+2\r\ndH(χ))1/(r−|χ|),\r\nwhere χ is a relevant vertex set. Let the best discovery probability of χ be the minimum discovery\r\nprobability among all its subsets. That is,\r\np\r\n∗\r\nH(χ) = min\r\nχ\r\n0⊆χ\r\npH(χ\r\n0\r\n).\r\nDefinition 11 Let ρχ(p) be the probability that a (χ, p)-sample is positive, where χ is a relevant\r\nvertex set.\r\nRemark 12 ρχ(p) is continuous and monotonically increasing.\r\nAngluin and Chen (2004) contains a proof of this fact.\r\nDefinition 13 Let pχ = min\b\r\np|ρχ(p) = 1/2\r\nr+1\r\n\t\r\nbe the threshold probability of a relevant vertex\r\nset χ.\r\n2226",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/080bd60c-1091-441b-8d99-f821cd84e4f5.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=9571e615e68e45ff13b9dc3888b2b85adfec6a1abb8f861d74a27cb95775278a",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 429
      },
      {
        "segments": [
          {
            "segment_id": "52c9ca71-7784-4d89-924d-bcba8e664c71",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 13,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\nRemark 14 Due to the fact that ρχ(0) = 0, ρχ(1) = 1 and that ρχ(p) is continuous and monotoni\u0002cally increasing, the threshold probability uniquely exists.\r\nNote that both threshold probabilities and discovery probabilities reflect the degree of set χ\r\nor the degrees of its subsets. The difference is that discovery probabilities reflect degrees in the\r\nhypergraph we have found, while threshold probabilities reflect degrees in the target hypergraph.\r\nThreshold probabilities are only used in analysis.\r\n5.1 Overview Of The Algorithm\r\nAn “obvious” improvement to the quadratic algorithm is that instead of calling FIND-ONE-EDGE\r\non one positive sample at each iteration, we can call it on all positive samples. It is plausible that this\r\nwill yield more edges. However, there is no guarantee that different calls to FIND-ONE-EDGE will\r\noutput different edges. For instance, calls to FIND-ONE-EDGE on two sets that share a common\r\nedge will produce the same edge in the worst case. We use several standard tricks to circumvent\r\nthis obstacle. In fact, the family of samples constructed here is more complex than that used in\r\nSection 4, so as to ensure with high probability that the algorithm will make a certain amount of\r\nprogress at each iteration. By doing so, we are able to reduce the number of iterations from m to\r\nO(min(2\r\nr\r\n(logm+r),(logm+r)\r\n2\r\n)). The number of queries will also be reduced.\r\nFirst of all, the sampling probabilities are halved in order to accommodate more edges. More\r\nprecisely, imagine that we draw (χ,\r\n1\r\n2\r\npH(χ))-samples instead of (χ, pH(χ))-samples in the quadratic\r\nalgorithm. Take a look at a sample drawn several iterations ago, which the quadratic algorithm did\r\nnot call FIND-ONE-EDGE on. Such a sample will still have reasonable probability of excluding\r\nall the edges that have been found, as long as the degree of χ has not been increased by a factor of\r\n2\r\nr−|χ| or equivalently the discovery probability of χ has not been decreased by half.\r\nSecond, the algorithm uses the best discovery probability for each relevant set. We call a relevant\r\nvertex set minimal if it has the minimum discovery probability among its subsets. In the quadratic\r\nalgorithm, the goal is that one of the samples will produce an edge. According to the proof of\r\nLemma 5, in the quadratic algorithm, we actually only need to draw samples for minimal relevant\r\nsets. In this algorithm, we hope that samples drawn for every relevant set will produce edges. But\r\ndrawing samples for non-minimal relevant sets with discovery probabilities is not sufficient to avoid\r\nedges we have already found. Therefore, the best discovery probabilities are used.\r\nFinally, besides samples drawn proportional to degrees, the algorithm also draws samples pro\u0002portional to the contribution of each relevant set. The idea is simple. Draw more samples for those\r\nrelevant sets that are more likely to produce a new edge. The algorithm maintains a contribution\r\ncounter c(χ) for each relevant set χ, which records the number of new edges that χ-samples have\r\nproduced. As we have already said, different calls to FIND-ONE-EDGE at each iteration may\r\noutput the same edge. As all calls to FIND-ONE-EDGE at each iteration are made in parallel, it\r\nis not clear which sample each new edge should be attributed to. To solve this problem, calls to\r\nFIND-ONE-EDGE are processed sequentially in an arbitrary order.\r\nIn the algorithm, FH consists of two parts: F\r\n1\r\nH\r\nand F\r\n2\r\nH\r\n. In F\r\n1\r\nH\r\n, the algorithm draws samples\r\nproportional to the contribution of each relevant set. F\r\n2\r\nH\r\nis closer to FH in Section 4. Intuitively, a\r\nhigh-degree relevant set in the target hypergraph (not necessarily a high-degree relevant set in H),\r\nor a relevant set with small threshold probability is important, because an edge or a non-edge may\r\nnot be found if its important relevant subsets are not found. The smaller the threshold probability\r\na relevant set is, the more important it is. The algorithm uses samples in F\r\n1\r\nH\r\nto find edges while\r\n2227",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/52c9ca71-7784-4d89-924d-bcba8e664c71.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=acea218dda4930d7eb2934d2757ada515c4c5489bfb3e50999bb89799b8157f1",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 673
      },
      {
        "segments": [
          {
            "segment_id": "52c9ca71-7784-4d89-924d-bcba8e664c71",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 13,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\nRemark 14 Due to the fact that ρχ(0) = 0, ρχ(1) = 1 and that ρχ(p) is continuous and monotoni\u0002cally increasing, the threshold probability uniquely exists.\r\nNote that both threshold probabilities and discovery probabilities reflect the degree of set χ\r\nor the degrees of its subsets. The difference is that discovery probabilities reflect degrees in the\r\nhypergraph we have found, while threshold probabilities reflect degrees in the target hypergraph.\r\nThreshold probabilities are only used in analysis.\r\n5.1 Overview Of The Algorithm\r\nAn “obvious” improvement to the quadratic algorithm is that instead of calling FIND-ONE-EDGE\r\non one positive sample at each iteration, we can call it on all positive samples. It is plausible that this\r\nwill yield more edges. However, there is no guarantee that different calls to FIND-ONE-EDGE will\r\noutput different edges. For instance, calls to FIND-ONE-EDGE on two sets that share a common\r\nedge will produce the same edge in the worst case. We use several standard tricks to circumvent\r\nthis obstacle. In fact, the family of samples constructed here is more complex than that used in\r\nSection 4, so as to ensure with high probability that the algorithm will make a certain amount of\r\nprogress at each iteration. By doing so, we are able to reduce the number of iterations from m to\r\nO(min(2\r\nr\r\n(logm+r),(logm+r)\r\n2\r\n)). The number of queries will also be reduced.\r\nFirst of all, the sampling probabilities are halved in order to accommodate more edges. More\r\nprecisely, imagine that we draw (χ,\r\n1\r\n2\r\npH(χ))-samples instead of (χ, pH(χ))-samples in the quadratic\r\nalgorithm. Take a look at a sample drawn several iterations ago, which the quadratic algorithm did\r\nnot call FIND-ONE-EDGE on. Such a sample will still have reasonable probability of excluding\r\nall the edges that have been found, as long as the degree of χ has not been increased by a factor of\r\n2\r\nr−|χ| or equivalently the discovery probability of χ has not been decreased by half.\r\nSecond, the algorithm uses the best discovery probability for each relevant set. We call a relevant\r\nvertex set minimal if it has the minimum discovery probability among its subsets. In the quadratic\r\nalgorithm, the goal is that one of the samples will produce an edge. According to the proof of\r\nLemma 5, in the quadratic algorithm, we actually only need to draw samples for minimal relevant\r\nsets. In this algorithm, we hope that samples drawn for every relevant set will produce edges. But\r\ndrawing samples for non-minimal relevant sets with discovery probabilities is not sufficient to avoid\r\nedges we have already found. Therefore, the best discovery probabilities are used.\r\nFinally, besides samples drawn proportional to degrees, the algorithm also draws samples pro\u0002portional to the contribution of each relevant set. The idea is simple. Draw more samples for those\r\nrelevant sets that are more likely to produce a new edge. The algorithm maintains a contribution\r\ncounter c(χ) for each relevant set χ, which records the number of new edges that χ-samples have\r\nproduced. As we have already said, different calls to FIND-ONE-EDGE at each iteration may\r\noutput the same edge. As all calls to FIND-ONE-EDGE at each iteration are made in parallel, it\r\nis not clear which sample each new edge should be attributed to. To solve this problem, calls to\r\nFIND-ONE-EDGE are processed sequentially in an arbitrary order.\r\nIn the algorithm, FH consists of two parts: F\r\n1\r\nH\r\nand F\r\n2\r\nH\r\n. In F\r\n1\r\nH\r\n, the algorithm draws samples\r\nproportional to the contribution of each relevant set. F\r\n2\r\nH\r\nis closer to FH in Section 4. Intuitively, a\r\nhigh-degree relevant set in the target hypergraph (not necessarily a high-degree relevant set in H),\r\nor a relevant set with small threshold probability is important, because an edge or a non-edge may\r\nnot be found if its important relevant subsets are not found. The smaller the threshold probability\r\na relevant set is, the more important it is. The algorithm uses samples in F\r\n1\r\nH\r\nto find edges while\r\n2227",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/52c9ca71-7784-4d89-924d-bcba8e664c71.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=acea218dda4930d7eb2934d2757ada515c4c5489bfb3e50999bb89799b8157f1",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 673
      },
      {
        "segments": [
          {
            "segment_id": "70c57b11-62ed-4150-9936-8b069873b2bc",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 14,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\nsamples in F\r\n2\r\nH\r\nare mainly used to cover non-edges of H. F\r\n2\r\nH\r\nnot only gives a short proof when\r\nH is indeed the target hypergraph, but also finds important relevant sets quickly. The design of\r\nF\r\n2\r\nH\r\nguarantees that if the contribution of the most important subset of an edge or a non-edge stops\r\ndoubling, a more important relevant subset will be discovered with high probability.\r\n5.2 The Algorithm\r\nLet H = (V,E) be the hypergraph the algorithm has found so far. δ\r\n0\r\nis a parameter we will specify\r\nlater. The algorithm is shown in Algorithm 6. At each iteration, the algorithm operates in two\r\nphases, the query phase and the computation phase. In the query phase, the algorithm draws random\r\nsamples and make queries. The queries can be made in O(logm+r) rounds, as queries of each call\r\nto PARA-FIND-ONE-EDGE can be made in O(logm + r) rounds. In the computation phase, the\r\nalgorithm processes the query results to update the contribution counter of each relevant set and also\r\nadds newly found relevant sets.\r\nAlgorithm 6 The linear-query algorithm\r\nAll PARA-FIND-ONE-EDGE’s are called with parameter δ\r\n0\r\n.\r\n1: e ← PARA-FIND-ONE-EDGE(V).\r\n2: E ← {e}. c(0/) ← 1.\r\n3: repeat\r\nQUERY PHASE\r\n4: Let F\r\n1\r\nH\r\nbe a family that for every known relevant set χ contains c(χ)· 2\r\nr+2\r\nln 1\r\nδ\r\n0 (χ,\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ))-\r\nsamples.\r\n5: Let F\r\n2\r\nH\r\nbe a family that for every known relevant set χ contains 2\r\n3r+3dH(χ)ln 1\r\nδ\r\n0 (χ,\r\n1\r\n4\r\np\r\n∗\r\nH\r\n(χ))-\r\nsamples.\r\n6: Let FH = F\r\n1\r\nH ∪F\r\n2\r\nH\r\n. Make queries on sets in FH that are independent in H.\r\n7: Call PARA-FIND-ONE-EDGE on all positive samples.\r\nCOMPUTATION PHASE\r\n8: For each known relevant set χ, divide χ-samples in F\r\n1\r\nH\r\ninto c(χ) groups of size 2\r\nr+2\r\nln 1\r\nδ\r\n0\r\n.\r\n9: Process the samples in F\r\n1\r\nH\r\ngroup by group in an arbitrary order. Increase c(χ) by the number\r\nof new edges that χ-samples produce. Add newly found edges to E.\r\n10: Process the samples in F\r\n2\r\nH\r\n. Add newly found edges to E.\r\n11: For every newly found relevant set χ, c(χ) ← 1.\r\n12: until no new edge is found\r\nWe will show that the algorithm terminates in O(min(2\r\nr\r\n(logm+r),(logm+r)\r\n2\r\n)) iterations with\r\nhigh probability. Since ∑χ dH(χ) ≤ 2\r\nrm and ∑χ c(χ) ≤ (2r +1)m (note that c(χ) is one more than the\r\nnumber of new edges that χ-samples in F\r\n1\r\nH\r\nproduce), the number of queries made at each iteration\r\nis at most O(2\r\n4rm· poly(r,logn,log 1\r\nδ\r\n0)). Therefore, the total number of queries will be linear in the\r\nnumber of edges with high probability, as desired.\r\n5.3 Analysis\r\nConsider some iteration of the algorithm. Let H be the hypergraph the algorithm has found at the\r\nbeginning of the iteration. Let e be an edge that has not yet been found. Let χ be a known subset of\r\n2228",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/70c57b11-62ed-4150-9936-8b069873b2bc.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a17322f55351020a25b388fec7a18bb83aff416fbc60d5f602a3220c21d71b52",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 519
      },
      {
        "segments": [
          {
            "segment_id": "70c57b11-62ed-4150-9936-8b069873b2bc",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 14,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\nsamples in F\r\n2\r\nH\r\nare mainly used to cover non-edges of H. F\r\n2\r\nH\r\nnot only gives a short proof when\r\nH is indeed the target hypergraph, but also finds important relevant sets quickly. The design of\r\nF\r\n2\r\nH\r\nguarantees that if the contribution of the most important subset of an edge or a non-edge stops\r\ndoubling, a more important relevant subset will be discovered with high probability.\r\n5.2 The Algorithm\r\nLet H = (V,E) be the hypergraph the algorithm has found so far. δ\r\n0\r\nis a parameter we will specify\r\nlater. The algorithm is shown in Algorithm 6. At each iteration, the algorithm operates in two\r\nphases, the query phase and the computation phase. In the query phase, the algorithm draws random\r\nsamples and make queries. The queries can be made in O(logm+r) rounds, as queries of each call\r\nto PARA-FIND-ONE-EDGE can be made in O(logm + r) rounds. In the computation phase, the\r\nalgorithm processes the query results to update the contribution counter of each relevant set and also\r\nadds newly found relevant sets.\r\nAlgorithm 6 The linear-query algorithm\r\nAll PARA-FIND-ONE-EDGE’s are called with parameter δ\r\n0\r\n.\r\n1: e ← PARA-FIND-ONE-EDGE(V).\r\n2: E ← {e}. c(0/) ← 1.\r\n3: repeat\r\nQUERY PHASE\r\n4: Let F\r\n1\r\nH\r\nbe a family that for every known relevant set χ contains c(χ)· 2\r\nr+2\r\nln 1\r\nδ\r\n0 (χ,\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ))-\r\nsamples.\r\n5: Let F\r\n2\r\nH\r\nbe a family that for every known relevant set χ contains 2\r\n3r+3dH(χ)ln 1\r\nδ\r\n0 (χ,\r\n1\r\n4\r\np\r\n∗\r\nH\r\n(χ))-\r\nsamples.\r\n6: Let FH = F\r\n1\r\nH ∪F\r\n2\r\nH\r\n. Make queries on sets in FH that are independent in H.\r\n7: Call PARA-FIND-ONE-EDGE on all positive samples.\r\nCOMPUTATION PHASE\r\n8: For each known relevant set χ, divide χ-samples in F\r\n1\r\nH\r\ninto c(χ) groups of size 2\r\nr+2\r\nln 1\r\nδ\r\n0\r\n.\r\n9: Process the samples in F\r\n1\r\nH\r\ngroup by group in an arbitrary order. Increase c(χ) by the number\r\nof new edges that χ-samples produce. Add newly found edges to E.\r\n10: Process the samples in F\r\n2\r\nH\r\n. Add newly found edges to E.\r\n11: For every newly found relevant set χ, c(χ) ← 1.\r\n12: until no new edge is found\r\nWe will show that the algorithm terminates in O(min(2\r\nr\r\n(logm+r),(logm+r)\r\n2\r\n)) iterations with\r\nhigh probability. Since ∑χ dH(χ) ≤ 2\r\nrm and ∑χ c(χ) ≤ (2r +1)m (note that c(χ) is one more than the\r\nnumber of new edges that χ-samples in F\r\n1\r\nH\r\nproduce), the number of queries made at each iteration\r\nis at most O(2\r\n4rm· poly(r,logn,log 1\r\nδ\r\n0)). Therefore, the total number of queries will be linear in the\r\nnumber of edges with high probability, as desired.\r\n5.3 Analysis\r\nConsider some iteration of the algorithm. Let H be the hypergraph the algorithm has found at the\r\nbeginning of the iteration. Let e be an edge that has not yet been found. Let χ be a known subset of\r\n2228",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/70c57b11-62ed-4150-9936-8b069873b2bc.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a17322f55351020a25b388fec7a18bb83aff416fbc60d5f602a3220c21d71b52",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 519
      },
      {
        "segments": [
          {
            "segment_id": "b06b0a44-ae15-45a2-8482-76446325ade6",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 15,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\ne. χ can be either active, in which case a χ-sample is likely to contain an edge or inactive otherwise.\r\nFormally speaking,\r\nDefinition 15 We say that χ is active if ρχ(\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ)) ≥ 1/2\r\nr+1 or, equivalently,\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ) ≥ pχ, and\r\ninactive otherwise.\r\nThe following two assertions serve as the goals for each iteration.\r\nAssertion 16 Consider one group of χ-samples G in F\r\n1\r\nH\r\n. Let H\r\n0 be the hypergraph the algorithm\r\nhas found before this group is processed. If χ is active, either p\r\n∗\r\nH0(χ) <\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ) or G will produce\r\na new edge.\r\nAssertion 17 If χ is inactive, then at the end of this iteration, either e has been found or a subset\r\nof e whose threshold probability is at most 1\r\n2\r\npχ has been found (a relevant subset is found when an\r\nedge that contains it is found).\r\nThe following two lemmas show that both assertions hold with high probability.\r\nLemma 18 Assertion 16 is true with probability at least 1−δ\r\n0\r\n.\r\nProof If p\r\n∗\r\nH0(χ) ≥\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ), the probability that a χ-sample contains an edge in H\r\n0\r\nis at most\r\n∑\r\nχ\r\n0⊆χ\r\ndH0(χ\r\n0\r\n)(1\r\n2\r\np\r\n∗\r\nH(χ))r−|χ\r\n0\r\n| ≤ ∑\r\nχ\r\n0⊆χ\r\ndH0(χ\r\n0\r\n)p\r\n∗\r\nH0(χ)\r\nr−|χ\r\n0\r\n| ≤\r\n2\r\n|χ|\r\n2\r\nr+|χ|+2\r\n=\r\n1\r\n2\r\nr+2\r\n.\r\nOn the other hand, since χ is active, we have ρχ(\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ)) ≥ 1/2\r\nr+1\r\n. That is, with probability at least\r\n1/2\r\nr+1\r\na χ-sample will contain an edge. Therefore the probability that a χ-sample contains a new\r\nedge is at least 1/2\r\nr+1 −1/2r+2 = 1/2r+2\r\n. Recall that G contains 2\r\nr+2\r\nln 1\r\nδ\r\n0 χ-samples. Therefore,\r\nwith probability at least 1−δ\r\n0\r\nthere exists at least one sample in G that will produce a new edge.\r\nLemma 19 Assertion 17 is true with probability at least 1−δ\r\n0\r\n.\r\nProof Let χ\r\n∗ ⊆ χ have the minimum discovery probability among all subsets of χ at the beginning\r\nof the iteration. Thus, pH(χ\r\n∗\r\n) = p\r\n∗\r\nH\r\n(χ) by the definition. Let us consider a χ\r\n∗\r\n-sample Pχ\r\n∗ in F\r\n2\r\nH\r\n.\r\nLet A be the collection of all subsets of e whose threshold probabilities are not less than 1\r\n2\r\npχ. We\r\ndo not want Pχ\r\n∗ to contain any edge that contains χ\r\n0\r\nfor any χ\r\n0 ∈ A because they prevent us from\r\ndiscovering relevant sets with low threshold probabilities (<\r\n1\r\n2\r\npχ).\r\nWe observe that 1\r\n2\r\npH(χ\r\n∗\r\n) =\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ) < pχ because χ is inactive. Thus, we have that ∀χ\r\n0 ∈ A,\r\nρχ\r\n0(\r\n1\r\n4\r\npH(χ\r\n∗\r\n)) < ρχ\r\n0(\r\n1\r\n2\r\npχ) ≤ ρχ\r\n0(pχ0) = 1/2\r\nr+1\r\n.\r\nTherefore,\r\nPr[∃ an edge e\r\n0 ⊆ Pχ\r\n∗ , e\r\n0 ∩e ∈ A|e ⊆ Pχ\r\n∗ ] ≤ ∑\r\nχ\r\n0∈A\r\nρχ\r\n0(\r\n1\r\n4\r\npH(χ\r\n∗\r\n)) ≤ 1/2.\r\n2229",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/b06b0a44-ae15-45a2-8482-76446325ade6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e83d0e0dd16b953c01d23b76cff9c898e3f89d00bd84e30441c4d5da98464cca",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 537
      },
      {
        "segments": [
          {
            "segment_id": "b06b0a44-ae15-45a2-8482-76446325ade6",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 15,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\ne. χ can be either active, in which case a χ-sample is likely to contain an edge or inactive otherwise.\r\nFormally speaking,\r\nDefinition 15 We say that χ is active if ρχ(\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ)) ≥ 1/2\r\nr+1 or, equivalently,\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ) ≥ pχ, and\r\ninactive otherwise.\r\nThe following two assertions serve as the goals for each iteration.\r\nAssertion 16 Consider one group of χ-samples G in F\r\n1\r\nH\r\n. Let H\r\n0 be the hypergraph the algorithm\r\nhas found before this group is processed. If χ is active, either p\r\n∗\r\nH0(χ) <\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ) or G will produce\r\na new edge.\r\nAssertion 17 If χ is inactive, then at the end of this iteration, either e has been found or a subset\r\nof e whose threshold probability is at most 1\r\n2\r\npχ has been found (a relevant subset is found when an\r\nedge that contains it is found).\r\nThe following two lemmas show that both assertions hold with high probability.\r\nLemma 18 Assertion 16 is true with probability at least 1−δ\r\n0\r\n.\r\nProof If p\r\n∗\r\nH0(χ) ≥\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ), the probability that a χ-sample contains an edge in H\r\n0\r\nis at most\r\n∑\r\nχ\r\n0⊆χ\r\ndH0(χ\r\n0\r\n)(1\r\n2\r\np\r\n∗\r\nH(χ))r−|χ\r\n0\r\n| ≤ ∑\r\nχ\r\n0⊆χ\r\ndH0(χ\r\n0\r\n)p\r\n∗\r\nH0(χ)\r\nr−|χ\r\n0\r\n| ≤\r\n2\r\n|χ|\r\n2\r\nr+|χ|+2\r\n=\r\n1\r\n2\r\nr+2\r\n.\r\nOn the other hand, since χ is active, we have ρχ(\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ)) ≥ 1/2\r\nr+1\r\n. That is, with probability at least\r\n1/2\r\nr+1\r\na χ-sample will contain an edge. Therefore the probability that a χ-sample contains a new\r\nedge is at least 1/2\r\nr+1 −1/2r+2 = 1/2r+2\r\n. Recall that G contains 2\r\nr+2\r\nln 1\r\nδ\r\n0 χ-samples. Therefore,\r\nwith probability at least 1−δ\r\n0\r\nthere exists at least one sample in G that will produce a new edge.\r\nLemma 19 Assertion 17 is true with probability at least 1−δ\r\n0\r\n.\r\nProof Let χ\r\n∗ ⊆ χ have the minimum discovery probability among all subsets of χ at the beginning\r\nof the iteration. Thus, pH(χ\r\n∗\r\n) = p\r\n∗\r\nH\r\n(χ) by the definition. Let us consider a χ\r\n∗\r\n-sample Pχ\r\n∗ in F\r\n2\r\nH\r\n.\r\nLet A be the collection of all subsets of e whose threshold probabilities are not less than 1\r\n2\r\npχ. We\r\ndo not want Pχ\r\n∗ to contain any edge that contains χ\r\n0\r\nfor any χ\r\n0 ∈ A because they prevent us from\r\ndiscovering relevant sets with low threshold probabilities (<\r\n1\r\n2\r\npχ).\r\nWe observe that 1\r\n2\r\npH(χ\r\n∗\r\n) =\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ) < pχ because χ is inactive. Thus, we have that ∀χ\r\n0 ∈ A,\r\nρχ\r\n0(\r\n1\r\n4\r\npH(χ\r\n∗\r\n)) < ρχ\r\n0(\r\n1\r\n2\r\npχ) ≤ ρχ\r\n0(pχ0) = 1/2\r\nr+1\r\n.\r\nTherefore,\r\nPr[∃ an edge e\r\n0 ⊆ Pχ\r\n∗ , e\r\n0 ∩e ∈ A|e ⊆ Pχ\r\n∗ ] ≤ ∑\r\nχ\r\n0∈A\r\nρχ\r\n0(\r\n1\r\n4\r\npH(χ\r\n∗\r\n)) ≤ 1/2.\r\n2229",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/b06b0a44-ae15-45a2-8482-76446325ade6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e83d0e0dd16b953c01d23b76cff9c898e3f89d00bd84e30441c4d5da98464cca",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 537
      },
      {
        "segments": [
          {
            "segment_id": "fcf445b2-fc48-48da-a7cc-359e49c3fada",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 16,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\nCombining with the fact that\r\nPr[e ⊆ Pχ\r\n∗ ] = (\r\n1\r\n4\r\npH(χ\r\n∗\r\n))r−|χ\r\n∗\r\n| =\r\n1\r\n2\r\nr+|χ\r\n∗\r\n|+2+2r−2|χ\r\n∗\r\n|dH(χ\r\n∗)\r\n≥\r\n1\r\n2\r\n3r+2dH(χ∗)\r\n,\r\nwe have that with probability at least 1/(2\r\n3r+3dH(χ∗\r\n)), Pχ\r\n∗ contains e but does not contain any edge\r\nwhose intersection with e is in A, in which case PARA-FIND-ONE-EDGE(Pχ\r\n∗ ) either outputs e or\r\noutputs an edge whose intersection with e has threshold probability at most 1\r\n2\r\npχ. The probability\r\nthat such a Pχ\r\n∗ exists in F\r\n2\r\nH\r\nis at least 1 − δ\r\n0\r\n, as we draw at least 2\r\n3r+3dH(χ∗\r\n)ln 1\r\nδ\r\n0 (χ\r\n∗\r\n,\r\n1\r\n4\r\npH(χ\r\n∗\r\n))-\r\nsamples.\r\nLet H\r\n0 be the hypergraph that has been found at the end of the iteration. Let cH\r\n(χ) and cH0(χ)\r\nbe the values of c(χ) at the beginning and end of the iteration respectively. At each iteration, if no\r\nassertion is violated, one of the following two events happens.\r\n1. Either cH0(χ) ≥ 2cH\r\n(χ) or p\r\n∗\r\nH0(χ) <\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ). (cH(χ) doubles when each of the cH(χ) groups\r\nof χ-samples in F\r\n1\r\nH\r\nsucceeds in producing a new edge.)\r\n2. Either e has been found or a subset of e whose threshold probability is at most 1\r\n2\r\npχ has been\r\nfound.\r\nThat is, the two assertions guarantee that the algorithm makes definite progress at each iteration.\r\nThe following lemma gives bound on the number of iterations of the algorithm.\r\nLemma 20 Assuming no assertion is violated, the algorithm terminates in O(min(2\r\nr\r\n(logm + r),\r\n(logm+r)\r\n2\r\n)) iterations.\r\nProof First we remark that the minimum and maximum possible values for both discovery prob\u0002abilities and threshold probabilities are 1/(2\r\n2r+1m) and 1/2 respectively, and the minimum and\r\nmaximum possible values for c(χ) are 1 and m+1.\r\nFor each edge e, we divide the iterations into phases until e is found. Each phase is associated\r\nwith a known relevant subset χ of e which has the minimum threshold probability at the beginning\r\nof the phase. A χ-phase ends when χ becomes inactive and then either e will be found or another\r\nrelevant subset of e with at most half of χ’s threshold probability will be found. Let us associate\r\nχ’s threshold probability with a χ-phase. There are certainly at most 2\r\nr phases because this is a\r\nbound on the number of subsets of e. Moreover, there are at most O(logm+r) phases as the asso\u0002ciated threshold probability halves at the end of each phase. Furthermore, each phase takes at most\r\nO(logm + r) iterations, since either c(χ) doubles or the best discovery probability halves at each\r\niteration. Therefore the algorithm terminates in O(min(2\r\nr\r\n(logm+r),(logm+r)\r\n2\r\n)) iterations.\r\nIt is not hard to see that total number of assertions we need to satisfy before the algorithm\r\nsucceeds is bounded by poly(2\r\nr\r\n,m), including the assertions that each PARA-FIND-ONE-EDGE\r\nwill succeed. Choose δ\r\n0 = Θ(δ/poly(2r\r\n,m)) and the algorithm will succeed with probability at\r\nleast 1−δ. Although the choice of δ\r\n0\r\nrequires knowledge of m, it is sufficient to use an upper bound\r\nof \r\nn\r\nr\r\n\u0001\r\n, and we have that log 1\r\nδ\r\n0 ≤ poly(r,logn)· log 1\r\nδ\r\n. Since queries at each iteration are made in\r\nO(logm+r) rounds, it follows that\r\n2230",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/fcf445b2-fc48-48da-a7cc-359e49c3fada.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=00326c5f4be10e73f430dfa5084836bc7d2341fc0d7c1840d5fc4bc10b8973bd",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 574
      },
      {
        "segments": [
          {
            "segment_id": "fcf445b2-fc48-48da-a7cc-359e49c3fada",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 16,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\nCombining with the fact that\r\nPr[e ⊆ Pχ\r\n∗ ] = (\r\n1\r\n4\r\npH(χ\r\n∗\r\n))r−|χ\r\n∗\r\n| =\r\n1\r\n2\r\nr+|χ\r\n∗\r\n|+2+2r−2|χ\r\n∗\r\n|dH(χ\r\n∗)\r\n≥\r\n1\r\n2\r\n3r+2dH(χ∗)\r\n,\r\nwe have that with probability at least 1/(2\r\n3r+3dH(χ∗\r\n)), Pχ\r\n∗ contains e but does not contain any edge\r\nwhose intersection with e is in A, in which case PARA-FIND-ONE-EDGE(Pχ\r\n∗ ) either outputs e or\r\noutputs an edge whose intersection with e has threshold probability at most 1\r\n2\r\npχ. The probability\r\nthat such a Pχ\r\n∗ exists in F\r\n2\r\nH\r\nis at least 1 − δ\r\n0\r\n, as we draw at least 2\r\n3r+3dH(χ∗\r\n)ln 1\r\nδ\r\n0 (χ\r\n∗\r\n,\r\n1\r\n4\r\npH(χ\r\n∗\r\n))-\r\nsamples.\r\nLet H\r\n0 be the hypergraph that has been found at the end of the iteration. Let cH\r\n(χ) and cH0(χ)\r\nbe the values of c(χ) at the beginning and end of the iteration respectively. At each iteration, if no\r\nassertion is violated, one of the following two events happens.\r\n1. Either cH0(χ) ≥ 2cH\r\n(χ) or p\r\n∗\r\nH0(χ) <\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ). (cH(χ) doubles when each of the cH(χ) groups\r\nof χ-samples in F\r\n1\r\nH\r\nsucceeds in producing a new edge.)\r\n2. Either e has been found or a subset of e whose threshold probability is at most 1\r\n2\r\npχ has been\r\nfound.\r\nThat is, the two assertions guarantee that the algorithm makes definite progress at each iteration.\r\nThe following lemma gives bound on the number of iterations of the algorithm.\r\nLemma 20 Assuming no assertion is violated, the algorithm terminates in O(min(2\r\nr\r\n(logm + r),\r\n(logm+r)\r\n2\r\n)) iterations.\r\nProof First we remark that the minimum and maximum possible values for both discovery prob\u0002abilities and threshold probabilities are 1/(2\r\n2r+1m) and 1/2 respectively, and the minimum and\r\nmaximum possible values for c(χ) are 1 and m+1.\r\nFor each edge e, we divide the iterations into phases until e is found. Each phase is associated\r\nwith a known relevant subset χ of e which has the minimum threshold probability at the beginning\r\nof the phase. A χ-phase ends when χ becomes inactive and then either e will be found or another\r\nrelevant subset of e with at most half of χ’s threshold probability will be found. Let us associate\r\nχ’s threshold probability with a χ-phase. There are certainly at most 2\r\nr phases because this is a\r\nbound on the number of subsets of e. Moreover, there are at most O(logm+r) phases as the asso\u0002ciated threshold probability halves at the end of each phase. Furthermore, each phase takes at most\r\nO(logm + r) iterations, since either c(χ) doubles or the best discovery probability halves at each\r\niteration. Therefore the algorithm terminates in O(min(2\r\nr\r\n(logm+r),(logm+r)\r\n2\r\n)) iterations.\r\nIt is not hard to see that total number of assertions we need to satisfy before the algorithm\r\nsucceeds is bounded by poly(2\r\nr\r\n,m), including the assertions that each PARA-FIND-ONE-EDGE\r\nwill succeed. Choose δ\r\n0 = Θ(δ/poly(2r\r\n,m)) and the algorithm will succeed with probability at\r\nleast 1−δ. Although the choice of δ\r\n0\r\nrequires knowledge of m, it is sufficient to use an upper bound\r\nof \r\nn\r\nr\r\n\u0001\r\n, and we have that log 1\r\nδ\r\n0 ≤ poly(r,logn)· log 1\r\nδ\r\n. Since queries at each iteration are made in\r\nO(logm+r) rounds, it follows that\r\n2230",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/fcf445b2-fc48-48da-a7cc-359e49c3fada.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=00326c5f4be10e73f430dfa5084836bc7d2341fc0d7c1840d5fc4bc10b8973bd",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 574
      },
      {
        "segments": [
          {
            "segment_id": "40a1e959-5a18-4981-824d-00e9ab86f026",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 17,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\nTheorem 21 With probability at least 1 − δ, Algorithm 6 learns an r-uniform hypergraph with m\r\nedges and n vertices, using O(2\r\n4rm· poly(r,logn,log 1\r\nδ\r\n)) queries, in O(min(2\r\nr\r\n(logm+r)\r\n2\r\n,(logm+\r\nr)\r\n3\r\n)) rounds.\r\n6. Lower Bounds For Almost Uniform Hypergraphs\r\nIn this section, we derive a lower bound for the class of (r,∆)-uniform hypergraphs. The following\r\ntheorem is proved in Angluin and Chen (2004).\r\nTheorem 22 Ω((2m/r)\r\nr/2\r\n) edge-detecting queries are required to identify a hypergraph drawn\r\nfrom the class of all (r,r −2)-uniform hypergraphs with n vertices and m edges.\r\nWe show that by a simple reduction this gives us a lower bound for general (r,∆)-uniform hyper\u0002graphs.\r\nTheorem 23 Ω((2m/(∆ + 2))1+\r\n∆\r\n2 ) edge-detecting queries are required to identify a hypergraph\r\ndrawn from the class of all (r,∆)-uniform hypergraphs with n vertices and m edges.\r\nProof Given a (∆+2,∆)-uniform hypergraph H = (V,E), let H\r\n0 = (V ∪V0\r\n,E\r\n0\r\n) be an (r,∆)-uniform\r\nhypergraph, where |V\r\n0\r\n| = r −∆−2, V\r\n0 ∩V = φ and E0 = {e∪V0\r\n|e ∈ E}. Any algorithm that learns\r\nH\r\n0\r\ncan be converted to learn H with the same number of queries.\r\n7. Learning Almost Uniform Hypergraphs\r\nIn this section, we extend our results to learning (r,∆)-uniform hypergraphs. The query upper bound\r\nstated in the following theorem matches the lower bound of Theorem 23 in terms of dependence on\r\nm. The round upper bound is only 1+∆ times more than that of Algorithm 6.\r\nTheorem 24 There is a randomized algorithm that learns an (r,∆)-uniform hypergraph with m\r\nedges and n vertices with probability at least 1−δ, using O(2\r\nO((1+\r\n∆\r\n2\r\n)r)\r\n· m\r\n1+\r\n∆\r\n2 · poly(logn,log 1\r\nδ\r\n)))\r\nqueries. Furthermore, the queries can be made in O((1 + ∆)· min(2\r\nr\r\n(logm + r)\r\n2\r\n,(logm + r)\r\n3\r\n))\r\nrounds.\r\n7.1 The Algorithm\r\nOne of the main modifications is the use of new discovery probabilities. We first provide some\r\nintuition for the new discovery probabilities. We have been choosing the discovery probability for\r\na relevant set χ to be inversely proportional to the (r−|χ|)\r\nth\r\nroot of its degree. It is so chosen that a\r\nχ-sample has good chance of excluding edges that contain χ. In an almost uniform hypergraph, we\r\nchoose the discovery probabilities for the same purpose. In other words, we would like to choose p\r\nsuch that ∑e∈E,e⊇χ p\r\n|e\\χ| ≤ 1/2r+2\r\n. Similarly, we should set p to be inversely proportional to the w\r\nth\r\nroot of dH(χ), where w = mine⊇χ |e\\χ| is the minimum difference in cardinalities between edges\r\ncontaining χ and χ. However, w is no longer equal to r −|χ| as in uniform hypergraphs. There are\r\ntwo cases. When |χ| < r − ∆, we have w ≥ r − ∆ − |χ| because the minimum edge size is r − ∆;\r\nwhen |χ| ≥ r −∆, w can be as small as 1.\r\n2231",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/40a1e959-5a18-4981-824d-00e9ab86f026.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=ec67e7b4630e2226cff716c2f6bb3b160c8c9b01af072000de88a89c1ad08285",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 504
      },
      {
        "segments": [
          {
            "segment_id": "9d075ed0-679a-4ffa-ac64-42f201ff99f3",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 18,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\nThe case when w = 1 is special, as it implies that there exists an edge e such that |e\\χ| = 1 or e\r\nhas only one vertex v that χ does not have. We will call e a 1-edge of χ. On one hand, any χ-sample\r\ncontaining v contains e, and hence is not an independent set; on the other hand, by excluding every\r\nvertex whose union with χ contains an edge, we can easily exclude all corresponding edges. Thus\r\nwe remove these vertices from each χ-sample and the resulting sample, which we call a modified\r\nχ-sample, is an improvement over the original one. (We remark that this improvement is available\r\nfor the uniform hypergraph problem in the case when |χ| = r − 1, but is not as important.) More\r\nspecifically, let νH(χ) be the set of all vertices v such that χ∪{v} contains an edge in H. A modified\r\n(χ, p)-sample is a (χ,νH(χ), p)-sample defined as follows.\r\nDefinition 25 A (χ,ν, p)-sample (χ∩ν = 0/) is a random set of vertices that contains χ and does\r\nnot contain any vertex in ν and contains each other vertex independently with probability p.\r\nAlgorithm 7 Learning an (r,∆)-uniform hypergraph\r\nAll PARA-FIND-ONE-EDGE’s are called with parameter δ\r\n0\r\n.\r\n1: e ← PARA-FIND-ONE-EDGE(V).\r\n2: E ← {e}. c(0/) ← 1.\r\n3: repeat\r\nQUERY PHASE\r\n4: Let F\r\n1\r\nH\r\nbe a family that for every known relevant set χ contains c(χ)· 2\r\nr+2\r\nln 1\r\nδ\r\n0 modified\r\n(χ,\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ))-samples and the same number of modified (χ,\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n)-samples.\r\n5: Let F\r\n2\r\nH\r\nbe a family that for every known relevantset χ contains 2(4/pH(χ))r−|χ|ln 1\r\nδ\r\n0 modified\r\n(χ,\r\n1\r\n4\r\np\r\n∗\r\nH\r\n(χ))-samples and 2\r\nr+4+|χ|dH(χ)ln 1\r\nδ\r\n0 modified (χ,\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n)-samples.\r\n6: Let FH = F\r\n1\r\nH ∪F\r\n2\r\nH\r\n. Make queries on sets in FH that are independent in H.\r\n7: Call PARA-FIND-ONE-EDGE on all positive samples.\r\nCOMPUTATION PHASE\r\n8: For each relevant set χ, divide χ-samples in F\r\n1\r\nH\r\nin c(χ) groups of 2\r\nr+2\r\nln 1\r\nδ\r\n0 modified\r\n(χ,\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ))-samples and the same number of modified (χ,\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n)-samples.\r\n9: Process the samples in F\r\n1\r\nH\r\ngroup by group in an arbitrary order. Increase c(χ) by the number\r\nof new edges that χ-samples produce. Add newly found edges to E.\r\n10: Process the samples in F\r\n2\r\nH\r\n. Add newly found edges to E.\r\n11: 1-edge-finder: For any χ-sample Pχ ∈ F\r\n2\r\nH\r\n, let e be the output of PARA-FIND-ONE\u0002EDGE(Pχ). ∀v ∈ e, make a query on χ ∪ {v} to test whether it is an edge. Add newly\r\nfound edges to E.\r\n12: For every newly found relevant set χ, c(χ) ← 1.\r\n13: until no new edge is found\r\nWe remark that we can use original χ-samples and obtain a much simpler algorithm than Algo\u0002rithm 7. However, the query complexity will be roughly m\r\n∆+2\r\ninstead of m\r\n1+\r\n∆\r\n2 . The reduction of\r\nthe complexity in the exponent of m is due to the fact that each modified χ-sample only needs to\r\ndeal with edges that have at least 2 vertices that χ does not have. This leads to the definition of the\r\n2232",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/9d075ed0-679a-4ffa-ac64-42f201ff99f3.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d3957f3f981bd607b92f9160e622a730ec07ee341d4d4f4bfa5f7ecc059088ab",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 567
      },
      {
        "segments": [
          {
            "segment_id": "9d075ed0-679a-4ffa-ac64-42f201ff99f3",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 18,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\nThe case when w = 1 is special, as it implies that there exists an edge e such that |e\\χ| = 1 or e\r\nhas only one vertex v that χ does not have. We will call e a 1-edge of χ. On one hand, any χ-sample\r\ncontaining v contains e, and hence is not an independent set; on the other hand, by excluding every\r\nvertex whose union with χ contains an edge, we can easily exclude all corresponding edges. Thus\r\nwe remove these vertices from each χ-sample and the resulting sample, which we call a modified\r\nχ-sample, is an improvement over the original one. (We remark that this improvement is available\r\nfor the uniform hypergraph problem in the case when |χ| = r − 1, but is not as important.) More\r\nspecifically, let νH(χ) be the set of all vertices v such that χ∪{v} contains an edge in H. A modified\r\n(χ, p)-sample is a (χ,νH(χ), p)-sample defined as follows.\r\nDefinition 25 A (χ,ν, p)-sample (χ∩ν = 0/) is a random set of vertices that contains χ and does\r\nnot contain any vertex in ν and contains each other vertex independently with probability p.\r\nAlgorithm 7 Learning an (r,∆)-uniform hypergraph\r\nAll PARA-FIND-ONE-EDGE’s are called with parameter δ\r\n0\r\n.\r\n1: e ← PARA-FIND-ONE-EDGE(V).\r\n2: E ← {e}. c(0/) ← 1.\r\n3: repeat\r\nQUERY PHASE\r\n4: Let F\r\n1\r\nH\r\nbe a family that for every known relevant set χ contains c(χ)· 2\r\nr+2\r\nln 1\r\nδ\r\n0 modified\r\n(χ,\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ))-samples and the same number of modified (χ,\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n)-samples.\r\n5: Let F\r\n2\r\nH\r\nbe a family that for every known relevantset χ contains 2(4/pH(χ))r−|χ|ln 1\r\nδ\r\n0 modified\r\n(χ,\r\n1\r\n4\r\np\r\n∗\r\nH\r\n(χ))-samples and 2\r\nr+4+|χ|dH(χ)ln 1\r\nδ\r\n0 modified (χ,\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n)-samples.\r\n6: Let FH = F\r\n1\r\nH ∪F\r\n2\r\nH\r\n. Make queries on sets in FH that are independent in H.\r\n7: Call PARA-FIND-ONE-EDGE on all positive samples.\r\nCOMPUTATION PHASE\r\n8: For each relevant set χ, divide χ-samples in F\r\n1\r\nH\r\nin c(χ) groups of 2\r\nr+2\r\nln 1\r\nδ\r\n0 modified\r\n(χ,\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ))-samples and the same number of modified (χ,\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n)-samples.\r\n9: Process the samples in F\r\n1\r\nH\r\ngroup by group in an arbitrary order. Increase c(χ) by the number\r\nof new edges that χ-samples produce. Add newly found edges to E.\r\n10: Process the samples in F\r\n2\r\nH\r\n. Add newly found edges to E.\r\n11: 1-edge-finder: For any χ-sample Pχ ∈ F\r\n2\r\nH\r\n, let e be the output of PARA-FIND-ONE\u0002EDGE(Pχ). ∀v ∈ e, make a query on χ ∪ {v} to test whether it is an edge. Add newly\r\nfound edges to E.\r\n12: For every newly found relevant set χ, c(χ) ← 1.\r\n13: until no new edge is found\r\nWe remark that we can use original χ-samples and obtain a much simpler algorithm than Algo\u0002rithm 7. However, the query complexity will be roughly m\r\n∆+2\r\ninstead of m\r\n1+\r\n∆\r\n2 . The reduction of\r\nthe complexity in the exponent of m is due to the fact that each modified χ-sample only needs to\r\ndeal with edges that have at least 2 vertices that χ does not have. This leads to the definition of the\r\n2232",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/9d075ed0-679a-4ffa-ac64-42f201ff99f3.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d3957f3f981bd607b92f9160e622a730ec07ee341d4d4f4bfa5f7ecc059088ab",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 567
      },
      {
        "segments": [
          {
            "segment_id": "bd7f362d-61c2-4bc7-890b-a064c3383347",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 19,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\nnew discovery probability as follows.\r\npH(χ) =\r\n(\r\n1/(2\r\nr+|χ|+2\r\ndH(χ))1/(r−∆−|χ|), if |χ| ≤ r −∆−2\r\n1/(2\r\nr+|χ|+2\r\ndH(χ))1/2, otherwise.\r\nWe use the new discovery probabilities in Algorithm 7. Although we use modified samples,\r\nspecial care is still needed for 1-edges in order to parallelize the edge finding process. In fact, the\r\nmajority of effort in developing Algorithm 7 is devoted to dealing with 1-edges.\r\nIn both F\r\n1\r\nH\r\nand F\r\n2\r\nH\r\n, we draw (χ,\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n)-samples in addition. The reason for the design will\r\nbe made clear in the analysis section. A group of χ-samples in F\r\n1\r\nH will consist of both (χ,\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ))-\r\nsamples and (χ,\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n)-samples. F\r\n2\r\nH\r\ncontains (χ,\r\n1\r\n4\r\np\r\n∗\r\nH\r\n(χ))-samples as in Algorithm 6. Al\u0002though, the number of (χ,\r\n1\r\n4\r\np\r\n∗\r\nH\r\n(χ))-samples appears to be different from that of Algorithm 6, we\r\nremark that 2(4/pH(χ))r−|χ|ln 1\r\nδ\r\n0\r\nis bounded by 2\r\n3r+3dH(χ)ln 1\r\nδ\r\n0 under the definition of discovery\r\nprobabilities in Section 5 and this group of samples are designed for essentially the same purpose\r\nas those for Algorithm 6. We also use a subroutine called 1-edge-finder, specified in Algorithm 7.\r\n7.2 Analysis\r\nRound complexity\r\nThe following two definitions are analogous to those in Section 5. The extra subscript indi\u0002cates that the new definitions depend on the already found sub-hypergraph H, while the previous\r\ndefinitions don’t.\r\nDefinition 26 Let ρχ,H(p) be the probability that a (χ,νH(χ), p)-sample is positive, where χ is a\r\nvertex set that does not contain an edge.\r\nDefinition 27 Let pχ,H = min\bp|ρχ,H(p) = 1/2\r\nr+1\r\n\t\r\nbe the threshold probability of χ.\r\nNow we bound the number of iterations of Algorithm 7. We divide the process of the algorithm\r\ninto (1+∆) phases, each of which is indexed by a number in [r−∆,r]. The phase l begins when all\r\nedges of size less than l have been found. Phase r −∆ is the first phase because there is no edge of\r\nsize less than r −∆.\r\nLet e be an edge of size l and χ be a known relevant subset of e. We need to deal with two cases\r\n: |χ| = l −1 and |χ| ≤ l −2, the latter of which is simpler as every 1-edge of χ has been discovered.\r\nWe make the following definition.\r\nDefinition 28 χ is active if it satisfies either of the following two conditions.\r\n1. |χ| ≤ l −2 and ρχ,H(\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ)) ≥ 1/2\r\nr+1\r\n.\r\n2. |χ| = l −1 and ρχ,H(\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ)) ≥ 1/2\r\nr+1 and ρχ,H(\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n) ≥ 1/2\r\nr+1\r\n.\r\nIt is inactive otherwise.\r\nThe definition is analogous to that in Section 5, and so are the following assertions. The assertions\r\nare made at phase l.\r\nAssertion 29 Consider one group of χ-samples G in F\r\n1\r\nH\r\n. Let H\r\n0 be the hypergraph the algorithm\r\nhas found before the group is processed. If χ is active, one of the following three events happens.\r\n2233",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/bd7f362d-61c2-4bc7-890b-a064c3383347.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2e244a75d68239e20c001fdf93c66558e9e235411bb08cf8bd8f9fd33efebcdb",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 531
      },
      {
        "segments": [
          {
            "segment_id": "bd7f362d-61c2-4bc7-890b-a064c3383347",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 19,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\nnew discovery probability as follows.\r\npH(χ) =\r\n(\r\n1/(2\r\nr+|χ|+2\r\ndH(χ))1/(r−∆−|χ|), if |χ| ≤ r −∆−2\r\n1/(2\r\nr+|χ|+2\r\ndH(χ))1/2, otherwise.\r\nWe use the new discovery probabilities in Algorithm 7. Although we use modified samples,\r\nspecial care is still needed for 1-edges in order to parallelize the edge finding process. In fact, the\r\nmajority of effort in developing Algorithm 7 is devoted to dealing with 1-edges.\r\nIn both F\r\n1\r\nH\r\nand F\r\n2\r\nH\r\n, we draw (χ,\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n)-samples in addition. The reason for the design will\r\nbe made clear in the analysis section. A group of χ-samples in F\r\n1\r\nH will consist of both (χ,\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ))-\r\nsamples and (χ,\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n)-samples. F\r\n2\r\nH\r\ncontains (χ,\r\n1\r\n4\r\np\r\n∗\r\nH\r\n(χ))-samples as in Algorithm 6. Al\u0002though, the number of (χ,\r\n1\r\n4\r\np\r\n∗\r\nH\r\n(χ))-samples appears to be different from that of Algorithm 6, we\r\nremark that 2(4/pH(χ))r−|χ|ln 1\r\nδ\r\n0\r\nis bounded by 2\r\n3r+3dH(χ)ln 1\r\nδ\r\n0 under the definition of discovery\r\nprobabilities in Section 5 and this group of samples are designed for essentially the same purpose\r\nas those for Algorithm 6. We also use a subroutine called 1-edge-finder, specified in Algorithm 7.\r\n7.2 Analysis\r\nRound complexity\r\nThe following two definitions are analogous to those in Section 5. The extra subscript indi\u0002cates that the new definitions depend on the already found sub-hypergraph H, while the previous\r\ndefinitions don’t.\r\nDefinition 26 Let ρχ,H(p) be the probability that a (χ,νH(χ), p)-sample is positive, where χ is a\r\nvertex set that does not contain an edge.\r\nDefinition 27 Let pχ,H = min\bp|ρχ,H(p) = 1/2\r\nr+1\r\n\t\r\nbe the threshold probability of χ.\r\nNow we bound the number of iterations of Algorithm 7. We divide the process of the algorithm\r\ninto (1+∆) phases, each of which is indexed by a number in [r−∆,r]. The phase l begins when all\r\nedges of size less than l have been found. Phase r −∆ is the first phase because there is no edge of\r\nsize less than r −∆.\r\nLet e be an edge of size l and χ be a known relevant subset of e. We need to deal with two cases\r\n: |χ| = l −1 and |χ| ≤ l −2, the latter of which is simpler as every 1-edge of χ has been discovered.\r\nWe make the following definition.\r\nDefinition 28 χ is active if it satisfies either of the following two conditions.\r\n1. |χ| ≤ l −2 and ρχ,H(\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ)) ≥ 1/2\r\nr+1\r\n.\r\n2. |χ| = l −1 and ρχ,H(\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ)) ≥ 1/2\r\nr+1 and ρχ,H(\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n) ≥ 1/2\r\nr+1\r\n.\r\nIt is inactive otherwise.\r\nThe definition is analogous to that in Section 5, and so are the following assertions. The assertions\r\nare made at phase l.\r\nAssertion 29 Consider one group of χ-samples G in F\r\n1\r\nH\r\n. Let H\r\n0 be the hypergraph the algorithm\r\nhas found before the group is processed. If χ is active, one of the following three events happens.\r\n2233",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/bd7f362d-61c2-4bc7-890b-a064c3383347.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2e244a75d68239e20c001fdf93c66558e9e235411bb08cf8bd8f9fd33efebcdb",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 531
      },
      {
        "segments": [
          {
            "segment_id": "f17b56b7-6b55-4209-93ef-227e1f7e9168",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 20,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\n1. p\r\n∗\r\nH0(χ) <\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ) ,\r\n2. dH0(χ) > 2dH(χ) , or\r\n3. G will produce a new edge.\r\nAssertion 30 If χ is inactive, at the end of this iteration, e has been found or a subset of e whose\r\nthreshold probability is at most 1\r\n2\r\npχ,H has been found.\r\nThe two assertions guarantee that Algorithm 7 makes a certain progress at each iteration.\r\nLemma 31 If no assertion is violated, phase l terminates in O(min(2\r\nr\r\n(logm + r),(logm + r)\r\n2\r\n))\r\niterations.\r\nProof We need to prove that every edge of size l can be found in the specified number iterations. Let\r\ne be an edge of size l. The proof proceeds similarly to that of Lemma 20. We divide the iterations\r\ninto sub-phases, each of which is associated with a subset of e (we use sub-phases here to avoid\r\nconfusion). Using an argument similar to that used in the proof of Lemma 20, we can show that\r\neach sub-phase takes O(logm+r) iterations. The only exception is that in this proof, the threshold\r\nprobability of a set χ might not be fixed (it depends on the already found sub-hypergraph H). When\r\nmore 1-edges of χ are found, ρχ,H(p) will decrease as more vertices are excluded from the sample.\r\nTherefore, pχ,H might increase. After such a sub-phase, the associated threshold probability might\r\nnot halve. However, this exception only happens when the subset associated with the sub-phase is\r\nof size l −1 and only happens l ≤ r times as there are at most l such subsets and causes at most l\r\nadditional sub-phases. Therefore, we get the same asymptotic bound on the number of sub-phases,\r\nwhich is O(min(2\r\nr\r\n,logm+r)). This establishes the lemma.\r\nNow we show the two assertions are true with high probability.\r\nLemma 32 Assertion 29 is true for Algorithm 7 with probability at least 1−δ\r\n0\r\n.\r\nProof G consists of two subgroups of samples with different sampling probabilities. In the analysis\r\nwe will only consider one subgroup. In the case that |χ| ≤ l −2, we use only (χ,\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ))-samples.\r\nIn the case that |χ| = l −1, we will use the subgroup with the smaller sampling probability. Let η\r\nbe the sampling probability of the subgroup we consider. We have η =\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ) when |χ| ≤ l − 2\r\nand η = min(\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ),\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n) when |χ| = l − 1. By our definition of active, in both cases\r\nρχ,H(η) ≥ 1/2\r\nr+1\r\n. The probability that a modified (χ,η)-sample contains an edge in H\r\n0\r\nis at most\r\n∑\r\nχ\r\n0⊆χ\r\ndH0(χ\r\n0\r\n)·η\r\nmax(r−∆−|χ\r\n0\r\n|,2) +|νH0(χ)\\νH(χ)|·η. (1)\r\n• When |χ| = l −2, |νH0(χ)\\νH(χ)| = 0. Therefore, if η =\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ) ≤ p\r\n∗\r\nH0(χ), Equation (1) is\r\nat most 1/2\r\nr+2\r\n.\r\n• When |χ| = l −1, since every 1-edge of χ must contain χ in phase l, Equation (1) is bounded\r\nby\r\n∑\r\nχ\r\n0⊂χ\r\ndH0(χ\r\n0\r\n)·η\r\nmax(r−∆−|χ\r\n0\r\n|,2) +dH0(χ)·η.\r\nIf 1\r\n2\r\np\r\n∗\r\nH\r\n(χ) ≤ p\r\n∗\r\nH0(χ) and dH0(χ) ≤ 2dH(χ), the above is bounded by 1/2\r\nr+2\r\n.\r\n2234",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/f17b56b7-6b55-4209-93ef-227e1f7e9168.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=19c076cf08466582b83eae56991108dddcc5bae7f119fd9b3f6f4fc68cdfb8c0",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 555
      },
      {
        "segments": [
          {
            "segment_id": "f17b56b7-6b55-4209-93ef-227e1f7e9168",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 20,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\n1. p\r\n∗\r\nH0(χ) <\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ) ,\r\n2. dH0(χ) > 2dH(χ) , or\r\n3. G will produce a new edge.\r\nAssertion 30 If χ is inactive, at the end of this iteration, e has been found or a subset of e whose\r\nthreshold probability is at most 1\r\n2\r\npχ,H has been found.\r\nThe two assertions guarantee that Algorithm 7 makes a certain progress at each iteration.\r\nLemma 31 If no assertion is violated, phase l terminates in O(min(2\r\nr\r\n(logm + r),(logm + r)\r\n2\r\n))\r\niterations.\r\nProof We need to prove that every edge of size l can be found in the specified number iterations. Let\r\ne be an edge of size l. The proof proceeds similarly to that of Lemma 20. We divide the iterations\r\ninto sub-phases, each of which is associated with a subset of e (we use sub-phases here to avoid\r\nconfusion). Using an argument similar to that used in the proof of Lemma 20, we can show that\r\neach sub-phase takes O(logm+r) iterations. The only exception is that in this proof, the threshold\r\nprobability of a set χ might not be fixed (it depends on the already found sub-hypergraph H). When\r\nmore 1-edges of χ are found, ρχ,H(p) will decrease as more vertices are excluded from the sample.\r\nTherefore, pχ,H might increase. After such a sub-phase, the associated threshold probability might\r\nnot halve. However, this exception only happens when the subset associated with the sub-phase is\r\nof size l −1 and only happens l ≤ r times as there are at most l such subsets and causes at most l\r\nadditional sub-phases. Therefore, we get the same asymptotic bound on the number of sub-phases,\r\nwhich is O(min(2\r\nr\r\n,logm+r)). This establishes the lemma.\r\nNow we show the two assertions are true with high probability.\r\nLemma 32 Assertion 29 is true for Algorithm 7 with probability at least 1−δ\r\n0\r\n.\r\nProof G consists of two subgroups of samples with different sampling probabilities. In the analysis\r\nwe will only consider one subgroup. In the case that |χ| ≤ l −2, we use only (χ,\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ))-samples.\r\nIn the case that |χ| = l −1, we will use the subgroup with the smaller sampling probability. Let η\r\nbe the sampling probability of the subgroup we consider. We have η =\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ) when |χ| ≤ l − 2\r\nand η = min(\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ),\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n) when |χ| = l − 1. By our definition of active, in both cases\r\nρχ,H(η) ≥ 1/2\r\nr+1\r\n. The probability that a modified (χ,η)-sample contains an edge in H\r\n0\r\nis at most\r\n∑\r\nχ\r\n0⊆χ\r\ndH0(χ\r\n0\r\n)·η\r\nmax(r−∆−|χ\r\n0\r\n|,2) +|νH0(χ)\\νH(χ)|·η. (1)\r\n• When |χ| = l −2, |νH0(χ)\\νH(χ)| = 0. Therefore, if η =\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ) ≤ p\r\n∗\r\nH0(χ), Equation (1) is\r\nat most 1/2\r\nr+2\r\n.\r\n• When |χ| = l −1, since every 1-edge of χ must contain χ in phase l, Equation (1) is bounded\r\nby\r\n∑\r\nχ\r\n0⊂χ\r\ndH0(χ\r\n0\r\n)·η\r\nmax(r−∆−|χ\r\n0\r\n|,2) +dH0(χ)·η.\r\nIf 1\r\n2\r\np\r\n∗\r\nH\r\n(χ) ≤ p\r\n∗\r\nH0(χ) and dH0(χ) ≤ 2dH(χ), the above is bounded by 1/2\r\nr+2\r\n.\r\n2234",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/f17b56b7-6b55-4209-93ef-227e1f7e9168.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=19c076cf08466582b83eae56991108dddcc5bae7f119fd9b3f6f4fc68cdfb8c0",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 555
      },
      {
        "segments": [
          {
            "segment_id": "f915f2a4-b61a-4de4-b75b-8117e60aa048",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 21,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\nWith probability at least 1/2\r\nr+2\r\n, a (χ,η)-sample contains an edge that is not contained in H\r\n0\r\n.\r\nThus, with probability at least 1−δ\r\n0\r\n, G will produce a new edge.\r\nLemma 33 Assertion 30 is true for Algorithm 7 with probability at least 1−δ\r\n0\r\n.\r\nProof First we remark that if e has not been found, the probability that e is contained in a modified\r\nχ-sample is the same as for an unmodified one. This is because e does not contain any vertex in\r\nνH(χ). Otherwise, e contains an edge in H, which violates our assumption that edges do not contain\r\neach other.\r\nIf ρχ,H(\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ)) < 1/2\r\nr+1\r\n, the proof proceeds similarly to that of Lemma 19. We remark that\r\nthe differences are that ρχ,H and pχ,H are used instead of ρχ and pχ and we draw more samples in\r\nF\r\n2\r\nH\r\nin Algorithm 7.\r\nThe remaining case is when |χ| = l − 1 and ρχ,H(\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n) < 1/2\r\nr+1\r\n. Consider a\r\n(χ,\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n)-sample Pχ in F\r\n2\r\nH\r\n. Since e is of size l, we have |e\\χ| = 1. Let {v} = e\\χ. We\r\nhave that\r\nPr[v ∈ Pχ] =\r\n1\r\n2\r\nr+3+|χ|dH(χ)\r\nand\r\nPr[∃ an edge e\r\n0 ⊆ Pχ such that v ∈/ e0\r\n| v ∈ Pχ] ≤ ρχ,H(\r\n1\r\n2\r\nr+3+|χ|dH(χ)\r\n) < 1/2\r\nr+1\r\n.\r\nTherefore, with probability at least 1\r\n2\r\nr+3+|χ|dH (χ)\r\n·(1 − 1/2\r\nr+1\r\n), Pχ contains v and contains only\r\nedges that are incident with v. Our 1-edge-finder will find e in this case. As we draw 2\r\nr+4+|χ|dH(χ)\r\nln 1\r\nδ\r\n0 samples, e will be found with probability at least 1−δ\r\n0\r\n.\r\nSince the algorithm has only 1+∆ phases, the algorithm ends after O((1+∆)·min(2\r\nr\r\n(logm+\r\nr),(logm+r)\r\n2\r\n)) iterations. If no assertion is violated, the round complexity of Algorithm 7 is\r\nO((1+∆)·min(2\r\nr\r\n(logm+r)\r\n2\r\n,(logm+r)\r\n3\r\n))\r\nWe can choose δ\r\n0\r\nso that the algorithm succeeds with probability 1−δ and log 1\r\nδ\r\n0 ≤ poly(r,logn)·\r\nlog 1\r\nδ\r\n.\r\nQuery complexity\r\nThe main discrepancy of the performance of this algorithm is due to the fact that in F\r\n2\r\nH\r\n, the\r\ndiscovery probabilities are chosen as if all the edges were of minimum possible size, while the\r\nnumbers of samples drawn are chosen as if all the non-edges (or potential edges) of H were of\r\nthe maximum possible size. This causes the super-linear query complexity. At each iteration, the\r\nnumber of χ-samples in F\r\n2\r\nH\r\nis at most\r\n2(4/pH(χ))r−|χ|ln 1\r\nδ\r\n0\r\n=\r\n\r\n\r\n\r\nO((2\r\nO(r)\r\n· dH(χ))\r\nr−|χ|\r\nr−∆−|χ|\r\n·log 1\r\nδ\r\n0\r\n) if |χ| ≤ r −∆−2\r\nO((2\r\nO(r)\r\n· dH(χ))1+\r\n∆\r\n2 ·log 1\r\nδ\r\n0\r\n) otherwise.\r\nNote that (r − |χ|)/(r − ∆ − |χ|) is at most 1 +\r\n∆\r\n2 when |χ| ≤ r − ∆ − 2. Therefore, the number\r\nof modified χ-samples in F\r\n2\r\nH\r\nis at most O((2\r\nO(r)\r\n· dH(χ))1+\r\n∆\r\n2 · log 1\r\nδ\r\n0). Because ∑χ dH(χ) ≤ 2\r\nrm\r\n2235",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/f915f2a4-b61a-4de4-b75b-8117e60aa048.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=65a9d9c7650860371e969ee3d7ae634622f404c542c7e0db00d61e28e4016275",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 537
      },
      {
        "segments": [
          {
            "segment_id": "f915f2a4-b61a-4de4-b75b-8117e60aa048",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 21,
            "page_width": 612,
            "page_height": 792,
            "content": "LEARNING A HIDDEN HYPERGRAPH\r\nWith probability at least 1/2\r\nr+2\r\n, a (χ,η)-sample contains an edge that is not contained in H\r\n0\r\n.\r\nThus, with probability at least 1−δ\r\n0\r\n, G will produce a new edge.\r\nLemma 33 Assertion 30 is true for Algorithm 7 with probability at least 1−δ\r\n0\r\n.\r\nProof First we remark that if e has not been found, the probability that e is contained in a modified\r\nχ-sample is the same as for an unmodified one. This is because e does not contain any vertex in\r\nνH(χ). Otherwise, e contains an edge in H, which violates our assumption that edges do not contain\r\neach other.\r\nIf ρχ,H(\r\n1\r\n2\r\np\r\n∗\r\nH\r\n(χ)) < 1/2\r\nr+1\r\n, the proof proceeds similarly to that of Lemma 19. We remark that\r\nthe differences are that ρχ,H and pχ,H are used instead of ρχ and pχ and we draw more samples in\r\nF\r\n2\r\nH\r\nin Algorithm 7.\r\nThe remaining case is when |χ| = l − 1 and ρχ,H(\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n) < 1/2\r\nr+1\r\n. Consider a\r\n(χ,\r\n1\r\n2\r\nr+3+|χ|dH (χ)\r\n)-sample Pχ in F\r\n2\r\nH\r\n. Since e is of size l, we have |e\\χ| = 1. Let {v} = e\\χ. We\r\nhave that\r\nPr[v ∈ Pχ] =\r\n1\r\n2\r\nr+3+|χ|dH(χ)\r\nand\r\nPr[∃ an edge e\r\n0 ⊆ Pχ such that v ∈/ e0\r\n| v ∈ Pχ] ≤ ρχ,H(\r\n1\r\n2\r\nr+3+|χ|dH(χ)\r\n) < 1/2\r\nr+1\r\n.\r\nTherefore, with probability at least 1\r\n2\r\nr+3+|χ|dH (χ)\r\n·(1 − 1/2\r\nr+1\r\n), Pχ contains v and contains only\r\nedges that are incident with v. Our 1-edge-finder will find e in this case. As we draw 2\r\nr+4+|χ|dH(χ)\r\nln 1\r\nδ\r\n0 samples, e will be found with probability at least 1−δ\r\n0\r\n.\r\nSince the algorithm has only 1+∆ phases, the algorithm ends after O((1+∆)·min(2\r\nr\r\n(logm+\r\nr),(logm+r)\r\n2\r\n)) iterations. If no assertion is violated, the round complexity of Algorithm 7 is\r\nO((1+∆)·min(2\r\nr\r\n(logm+r)\r\n2\r\n,(logm+r)\r\n3\r\n))\r\nWe can choose δ\r\n0\r\nso that the algorithm succeeds with probability 1−δ and log 1\r\nδ\r\n0 ≤ poly(r,logn)·\r\nlog 1\r\nδ\r\n.\r\nQuery complexity\r\nThe main discrepancy of the performance of this algorithm is due to the fact that in F\r\n2\r\nH\r\n, the\r\ndiscovery probabilities are chosen as if all the edges were of minimum possible size, while the\r\nnumbers of samples drawn are chosen as if all the non-edges (or potential edges) of H were of\r\nthe maximum possible size. This causes the super-linear query complexity. At each iteration, the\r\nnumber of χ-samples in F\r\n2\r\nH\r\nis at most\r\n2(4/pH(χ))r−|χ|ln 1\r\nδ\r\n0\r\n=\r\n\r\n\r\n\r\nO((2\r\nO(r)\r\n· dH(χ))\r\nr−|χ|\r\nr−∆−|χ|\r\n·log 1\r\nδ\r\n0\r\n) if |χ| ≤ r −∆−2\r\nO((2\r\nO(r)\r\n· dH(χ))1+\r\n∆\r\n2 ·log 1\r\nδ\r\n0\r\n) otherwise.\r\nNote that (r − |χ|)/(r − ∆ − |χ|) is at most 1 +\r\n∆\r\n2 when |χ| ≤ r − ∆ − 2. Therefore, the number\r\nof modified χ-samples in F\r\n2\r\nH\r\nis at most O((2\r\nO(r)\r\n· dH(χ))1+\r\n∆\r\n2 · log 1\r\nδ\r\n0). Because ∑χ dH(χ) ≤ 2\r\nrm\r\n2235",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/f915f2a4-b61a-4de4-b75b-8117e60aa048.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=65a9d9c7650860371e969ee3d7ae634622f404c542c7e0db00d61e28e4016275",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 537
      },
      {
        "segments": [
          {
            "segment_id": "df048056-5400-4339-b34e-23042f553c59",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 22,
            "page_width": 612,
            "page_height": 792,
            "content": "ANGLUIN AND CHEN\r\nand ∀χ,dH(χ) ≤ m, we have ∑χ dH(χ)\r\n1+\r\n∆\r\n2 ≤ (2\r\nrm)1+\r\n∆\r\n2 . Therefore, the total number of queries the\r\nalgorithm makes is bounded by\r\nO(2\r\nO((1+\r\n∆\r\n2\r\n)r)\r\n·m\r\n1+\r\n∆\r\n2 · poly(logn,log 1\r\nδ\r\n)).\r\nThis finishes the proof of Theorem 24.\r\nAcknowledgments\r\nThe conference version of this paper appears in Angluin and Chen (2005). The authors would like\r\nto thank the referees for helpful comments.\r\nReferences\r\nNoga Alon and Vera Asodi. Learning a hidden subgraph. SIAM Journal on Discrete Mathematics,\r\n18(4):697–712, 2005.\r\nNoga Alon, Richard Beigel, Simon Kasif, Steven Rudich, and Benny Sudakov. Learning a hidden\r\nmatching. SIAM Journal of Computing, 33(2):487–501, 2004.\r\nDana Angluin and Jiang Chen. Learning a hidden graph using O(log n) queries per edge. In\r\nConference on Learning Theory, pages 210–223. Springer, 2004.\r\nDana Angluin and Jiang Chen. Learning a hidden hypergraph. In Conference on Learning Theory,\r\npages 561–575. Springer, 2005.\r\nRichard Beigel, Noga Alon, Simon Kasif, Mehmet Serkan Apaydin, and Lance Fortnow. An optimal\r\nprocedure for gap closing in whole genome shotgun sequencing. In RECOMB, pages 22–30,\r\n2001.\r\nPeter Damaschke. Adaptive versus nonadaptive attribute-efficient learning. In Proceedings of the\r\nThirtieth Annual ACM Symposium on Theory of Computing, pages 590–596. ACM Press, 1998.\r\nVladimir Grebinski and Gregory Kucherov. Reconstructing a Hamiltonian cycle by querying the\r\ngraph: Application to DNA physical mapping. Discrete Applied Mathematics, 88(1-3):147–165,\r\n1998.\r\nVladimir Grebinski and Gregory Kucherov. Optimal reconstruction of graphs under the additive\r\nmodel. Algorithmica, 28(1):104–124, 2000.\r\n2236",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/43455c86-72e3-46ce-bc37-21547ff3dfb4/images/df048056-5400-4339-b34e-23042f553c59.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041852Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c470bd35aa8c7e26645e0d2882070cbd4c5ac270d59d9e2078ef554da10a37cb",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 249
      }
    ],
    "extracted_json": {
      "title": "Document Metadata",
      "schema_type": "object",
      "extracted_fields": [
        {
          "name": "title",
          "field_type": "string",
          "value": "No response"
        },
        {
          "name": "author",
          "field_type": "string",
          "value": "No response"
        },
        {
          "name": "date_published",
          "field_type": "string",
          "value": "No response"
        },
        {
          "name": "location",
          "field_type": "string",
          "value": "No response"
        }
      ]
    }
  }
}