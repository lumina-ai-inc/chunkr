{
  "file_name": "Kerncraft - A Tool for Analytic Performance Modeling of Loop Kernels - 2018 (1702.04653).pdf",
  "task_id": "38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a",
  "output": {
    "chunks": [
      {
        "segments": [
          {
            "segment_id": "50640c97-8642-45c3-9375-37aa9309255e",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 1,
            "page_width": 612,
            "page_height": 792,
            "content": "Kerncraft: A Tool for Analytic Performance\r\nModeling of Loop Kernels\r\nJulian Hammer, Jan Eitzinger, Georg Hager, and Gerhard Wellein\r\nAbstract Achieving optimal program performance requires deep insight into the\r\ninteraction between hardware and software. For software developers without an in\u0002depth background in computer architecture, understanding and fully utilizing mod\u0002ern architectures is close to impossible. Analytic loop performance modeling is a\r\nuseful way to understand the relevant bottlenecks of code execution based on sim\u0002ple machine models. The Roofline Model and the Execution-Cache-Memory (ECM)\r\nmodel are proven approaches to performance modeling of loop nests. In comparison\r\nto the Roofline model, the ECM model can also describes the single-core perfor\u0002mance and saturation behavior on a multicore chip.\r\nWe give an introduction to the Roofline and ECM models, and to stencil perfor\u0002mance modeling using layer conditions (LC). We then present Kerncraft, a tool that\r\ncan automatically construct Roofline and ECM models for loop nests by performing\r\nthe required code, data transfer, and LC analysis. The layer condition analysis allows\r\nto predict optimal spatial blocking factors for loop nests. Together with the models it\r\nenables an ab-initio estimate of the potential benefits of loop blocking optimizations\r\nand of useful block sizes. In cases where LC analysis is not easily possible, Kern\u0002craft supports a cache simulator as a fallback option. Using a 25-point long-range\r\nstencil we demonstrate the usefulness and predictive power of the Kerncraft tool.\r\nJulian Hammer\r\nErlangen Regional Computing Center, Germany, e-mail: julian.hammer@fau.de\r\nJan Eitzinger\r\nErlangen Regional Computing Center, Germany, e-mail: jan.eitzinger@fau.de\r\nGeorg Hager\r\nErlangen Regional Computing Center, Germany, e-mail: georg.hager@fau.de\r\nGerhard Wellein\r\nErlangen Regional Computing Center, Germany, e-mail: gerhard.wellein@fau.de\r\n1\r\narXiv:1702.04653v1 [cs.PF] 13 Jan 2017",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/50640c97-8642-45c3-9375-37aa9309255e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=937ebec305025a1a2d5054d2991323b9968d3013f5b648754bedfe4eaf022d75",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 272
      },
      {
        "segments": [
          {
            "segment_id": "df2ccc9f-6c31-4041-aa99-1afc0559b285",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 2,
            "page_width": 612,
            "page_height": 792,
            "content": "2 J. Hammer, J. Eitzinger, G. Hager, and G. Wellein\r\n1 Introduction\r\nExpensive, large-scale supercomputers consisting of thousands of nodes make per\u0002formance a major issue for efficient resource utilization. A lot of research in this\r\narea concentrates on massive scalability, but there is just as much potential for op\u0002timization at the core and chip levels. If performance fails to be acceptable at small\r\nscales, scaling up will waste resources even if the parallel efficiency is good. There\u0002fore, performance engineering should always start with solid insight at the smallest\r\nscale: the core. Using this approach will give the performance engineer a profound\r\nunderstanding of performance behavior, guide optimization attempts and, finally,\r\ndrive scaling at the relevant hardware bottlenecks.\r\nModeling techniques are essential to understand performance on a single core\r\ndue to the complexities hidden in modern CPU and node architectures. Without a\r\nmodel it is hardly possible to navigate through the multitude of potential perfor\u0002mance bottlenecks such as memory bandwidth, execution unit throughput, decoder\r\nthroughput, cache latency, TLB misses or even OS jitter, which may or may not be\r\nrelevant to the specific application at hand. Analytic models, if applied correctly,\r\nhelp us focus on the most relevant factors and allow validation of the gained in\u0002sights. With “analytic” we mean models that were derived not by automated fitting\r\nof parameters of a highly generic predictor function, but by consciously selecting\r\nkey factors that can be explained and understood by experts and then constructing a\r\nsimplified machine and execution model from them.\r\nWe understand that the application of analytic performance modeling techniques\r\noften poses challenges or tends to be tedious, even for experienced software de\u0002velopers with a deep understanding of computer architecture and performance en\u0002gineering. Kerncraft [7], our tool for automatic performance modeling, addresses\r\nthese issues. Since its first publication, Kerncraft has been throughly extended with\r\nthe layer condition model, an independent and more versatile cache simulation, as\r\nwell as more flexible support for data accesses and kernel codes. These enhance\u0002ments will be detailed in the following sections. Kerncraft is available for download\r\nunder GPLv3 [1].\r\n1.1 Related Work\r\nOut of the many performance modeling tools that rely on hardware metrics, statis\u0002tical methods, curve fitting, and machine learning, there are only four projects in\r\nthe area of automatic and analytic modeling that we know of: PBound, ExaSAT,\r\nRoofline Model Toolkit and MAQAO.\r\nNarayanan et al. [13] describe a tool (PBound) for automatically extracting rele\u0002vant information about execution resources (arithmetic operations, loads and stores)\r\nfrom source code. They do not, however, consider cache effects and parallel exe\u0002cution, and their machine model is rather idealized. Unat et al. [20] introduce the\r\nExaSAT tool, which uses compiler technology for source code analysis and also em-",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/df2ccc9f-6c31-4041-aa99-1afc0559b285.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e5046d4c7f95f2374d53f7e3129e04858c1aac15a6f2855ea847a9be3cd4ad00",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 450
      },
      {
        "segments": [
          {
            "segment_id": "e062ffbd-34ab-4edc-98e1-608fd374d6b7",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 3,
            "page_width": 612,
            "page_height": 792,
            "content": "Kerncraft: A Tool for Analytic Performance Modeling of Loop Kernels 3\r\nploys “layer conditions” [17] to assess the real data traffic for every memory hierar\u0002chy level based on cache and problem sizes. They use an abstract simplified machine\r\nmodel, whereas our Kerncraft tool employs Intel IACA to generate more accurate\r\nin-core predictions. On the one hand this (currently) restricts Kerncraft’s in-core\r\npredictions to Intel CPUs, but on the other hand provides predictions from the ac\u0002tual machine code containing all compiler optimizationsr. Furthermore, ExaSAT is\r\nrestricted to the Roofline model for performance prediction. Being compiler-based,\r\nExaSAT supports full-application modeling and code optimizations, which is work\r\nin progress for Kerncraft. It can also incorporate communication (i.e., message pass\u0002ing) overhead, which is not the scope of our research. Lo et al. [14] introduced in\r\n2014 the “Empirical Roofline Toolkit,” (ERT) which aims at automatically gener\u0002ating hardware descriptions for Roofline analysis. They do not support automatic\r\ntopology detection and their use of compiler-generated loops introduces an element\r\nof uncertainty. Djoudi et al. [2] started the MAQAO Project in 2005, which uses\r\nstatic analysis to predict in-core execution time and combines it with dynamic anal\u0002ysis to assess the overall code quality. It was originally developed for the Itanium 2\r\nprocessor but has since been adapted for recent Intel64 architectures and the Xeon\r\nPhi. As with Kerncraft, MAQAO currently supports only Intel architectures. The\r\nmemory access analysis is based on dynamic run-time data, i.e., it requires the code\r\nto be run on the target architecture.\r\n1.2 Performance Models\r\nPerformance modeling, historically done by pen, paper and brain, has a long tradi\u0002tion in computer science. For instance, the well-known Roofline model has its ori\u0002gins in the 1980s [8]. In this paper, we make use of the Roofline and the Execution\u0002Cache-Memory (ECM) models, both of which are based on a bottleneck analysis\r\nunder a throughput assumption. Detailed explanations of the models can be found\r\nin previous publications; we will limit ourselves to a short overview.\r\n1.2.1 Roofline\r\nThe Roofline model yields an absolute upper performance bound for a loop. It is\r\nbased on the assumption that either the data transfers to and from a single level in\r\nthe memory hierarchy or the computational work dictates the runtime. This implies\r\nthat all data transfers to all memory hierarchy levels perfectly overlap with each\r\nother and with the execution of instructions in the core, which is too optimistic\r\nin the general case. The Roofline model in the current form was popularized and\r\nnamed by Williams et al. in 2009 [21].\r\nFor the types of analysis Kerncraft supports it is useful to reformulate the\r\nRoofline model in terms of execution time instead of performance, and to use a\r\nbasic unit of work that spans the length of a cache line (typically eight iterations):",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/e062ffbd-34ab-4edc-98e1-608fd374d6b7.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=a95c75891c45cbf6bb8e918f4e4459a2b8b7cec84a1c3e11b76d22ffc22d00b4",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 462
      },
      {
        "segments": [
          {
            "segment_id": "430a89cb-3248-4e11-bcd1-2e41e0512569",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 4,
            "page_width": 612,
            "page_height": 792,
            "content": "4 J. Hammer, J. Eitzinger, G. Hager, and G. Wellein\r\nTable 1 Overview of data transfers and bandwidths necessary to model a 3D seven-point stencil\r\nkernel using the Roofline model.\r\nLevel Data Volume per 8 It. STREAM copy Bandwidth Time for 8 It.\r\nk βk Bk Tk\r\nL1 448B (only LOAD) 137.1GB/s 9.8 cy\r\nL2 7CL or 384B 68.4GB/s 16.6 cy\r\nL3 5CL or 256B 38.8GB/s 24.7 cy\r\nMEM 3CL or 128B 17.9GB/s 32.2 cy\r\nTroof = maxk (Tcore,Tk). The ratio Tk = βk/Bk, with the achievable peak bandwidth\r\nBk and data transfer volume βk, is the data transfer time for memory hierarchy level\r\nk. Tcore = φ/Pmax is the in-core execution time for computations with the amount\r\nof work φ. The latter is usually given in flops, but any other well-defined metric\r\nwill do. Pmax is the applicable computational peak performance (in flops per cy) of\r\nthe code at hand. It may be smaller than the absolute peak performance because of\r\nunbalanced multiply and add operations, because SIMD cannot be applied, etc.\r\nApplying the Roofline model to a loop kernel which loads 448 bytes from the\r\nfirst level cache (L1), 6 cache lines (CL) from the second level cache (L2), 4 CLs\r\nfrom the last level cache (L3), and two CLs from main memory, to produce one\r\ncache line of results (8 iterations), gives us the data volumes in Table 1. This is\r\nwhat we would expect with a 3D seven-point stencil (see Listing 1) for a certain\r\nproblem size that leads to a 3D-layer condition fulfilled in L3 and a 2D-layer condi\u0002tion fulfilled in L2 (see below for more on layer conditions). For the computational\r\nwork, we assume 5 additions and 7 multiplications per iteration, thus 96 FLOPs for\r\neight iterations, i.e., φ = 96flop. Combining this with measured bandwidths from\r\na STREAM [15] copy kernel on an Ivy Bridge EP processor in all memory hierar\u0002chy levels, we can derive the throughput time per eight iterations shown in the last\r\ncolumn of Table 1. The achievable peak bandwidth Bkis obtained via a streaming\r\nbenchmark since theoretical bandwidths published by vendors cannot be obtained in\r\npractice. The ECM model provides a partial explanation for this effect, so it requires\r\nless measured input data (see below).\r\nThe double precision maximum applicable performance of a code with 5/7\r\naddition-multiplication ratio on an Ivy Bridge core is\r\nPmax =\r\n40flop\r\n7 cy\r\nwhich yields an in-core prediction of\r\nTcore =\r\n96flop\r\n40flop/7 cy\r\n= 16.8 cy\r\nThe dominating bottleneck is therefore the transfer from main memory TMEM with\r\n32.2 cy for eight iterations or updates, which corresponds to a maximum expected\r\n(“lightspeed”) performance of 8.94Gflop/s.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/430a89cb-3248-4e11-bcd1-2e41e0512569.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=575d9f3540ad486cad7b231fb32d49290987c7077fe8bfb315bf446994bb8d7f",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 443
      },
      {
        "segments": [
          {
            "segment_id": "4ee5702d-0e16-4350-b22d-a81eadca3ceb",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 5,
            "page_width": 612,
            "page_height": 792,
            "content": "Kerncraft: A Tool for Analytic Performance Modeling of Loop Kernels 5\r\nPredicting the L1 time and performance with the measured bandwidth can only\r\nbe precise if the microbenchmark mimics exactly the load/store ratio as found in the\r\nmodeled code. To circumvent this issue it is advisable to use a static analyzer with\r\nknowledge of the architecture, like the Intel Architecture Core Analyzer (IACA)\r\n[10]. It also allows a more accurate prediction of Tcore.\r\n1.2.2 Execution-Cache-Memory\r\nThe Execution-Memory-Cache (ECM) model is based on the same fundamental\r\nidea as the Roofline model, i.e., that data transfer time or execution of instructions,\r\nwhichever takes longer, determine the runtime of a loop. Unlike in the Roofline\r\nmodel, all memory hierarchy levels contribute to a single bottleneck. Depending on\r\nthe microarchitecture, data transfer times to different memory hierarchy levels may\r\noverlap (as in the Roofline model) or they may add up. This latter assumption was\r\nshown to fit measurements quite well on x86-based processors [17, 22]; on Power8,\r\nfor instance, the cache hierarchy shows considerable overlap [9]. In the following\r\nwe will concentrate on Intel architectures, since the current version of Kerncraft\r\nimplements a strict non-overlapping ECM model.\r\nWe also need to know the data volumes transferred to and from each memory\r\nhierarchy level and the amount of work performed in the core. To calculate the time\r\ncontributions per cache level we use documented inter-cache throughputs (e.g., two\r\ncycles per cache line from L3 to L2 on Intel Ivy Bridge). The ECM prediction on\r\nan Intel core for data in memory is then given by\r\nTECM,Mem = max(TOL,TnOL +TL1−L2 +TL2−L3 +TL3−MEM) .\r\nTOL is the overlapping time for computations and stores, TnOL is the time for the\r\nloads from registers into L1, TL1L2 the loads from L2 into L1, and so on. The model\r\nis written in the following compact notation:\r\n{TOL kTnOL |TL1−L2 |TL2−L3 |TL3−MEM} .\r\nSee [17] for more details on the model and the notation.\r\nApplying the ECM model to the 3D seven-point stencil (see Listing 1) on an Ivy\r\nBridge EP processor, we get the in-core contributions from IACA:\r\nTOL = 13.2 cy and TnOL = βL1 · 1\r\ncy\r\n64B\r\n= 7 cy .\r\nThe data transfers through the memory hierarchy are obtained from cache simula\u0002tion in combination with hardware performance characteristics:\r\nTL1−L2 = βL2 · 2\r\ncy\r\nCL\r\n= 14 cy\r\nTL2−L3 = βL3 · 2\r\ncy\r\nCL\r\n= 10 cy",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/4ee5702d-0e16-4350-b22d-a81eadca3ceb.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=addfb41ed43cafdb03b3078caeaf552159c6aca07774083fb4da2f7cceeca809",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 402
      },
      {
        "segments": [
          {
            "segment_id": "166aaeed-1507-43d0-9e80-45a8c006e1f8",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 6,
            "page_width": 612,
            "page_height": 792,
            "content": "6 J. Hammer, J. Eitzinger, G. Hager, and G. Wellein\r\nOrigin of hardware limits\r\nOrigin of software limits\r\nIntel Architecture Core\r\nAnalyzer (IACA) and static\r\nassembly code analysis\r\nData volumes gained\r\nby cache simulation or\r\nlayer condition analysis\r\nDocumentation\r\nBandwidths gained from\r\nmicrobenchmarks (e.g.,\r\nlikwid-bench or STREAM)\r\nL1\r\nL2\r\nL3\r\nMEM\r\nTOL\r\nTnOL\r\nTL1-L2\r\nTL2-L3\r\nTL3-MEM\r\nRegisters\r\nExecution\r\nECM\r\nL1\r\nL2\r\nL3\r\nMEM\r\nTL1\r\nTL2\r\nTL3\r\nTMEM\r\nTcore\r\nRegisters\r\nExecution\r\nRoo\u001fine\r\nFig. 1 Side-by-side comparison of the (x86) ECM model and the Roofline model, including the\r\norigin of information needed as input for both, such as bandwidth and execution bottlenecks.\r\nTL3−MEM =\r\nβMEM · 3.0\r\nGcy\r\ns\r\n· 64 B\r\nCL\r\n63.4\r\nGB\r\ns\r\n= 9.1 cy\r\nThe ECM notation for eight iterations of the 3D seven-point stencil code is then:\r\n{13.2k7|14|10|9.1} cy .\r\nA comparison of the data that goes into the ECM and Roofline analysis (manual\r\nand automatic) is shown in Figure 1. It also illustrates the fundamental differences\r\nin the bottleneck assumption.\r\n2 Kerncraft\r\nIn this section we give an overview of the architecture and analysis modes avail\u0002able in Kerncraft. The recent additions, which have not been covered in our 2015\r\npublication [7], will be explained in due detail.\r\nThe core of Kerncraft is responsible for parsing and extracting information from\r\na given kernel code, abstracting information about the machine, and providing a\r\nhomogenous user interface. The modules responsible for the modeling will be de\u0002scribed in Section 2.3. A visualization of the overall structure is shown in Figure 2.\r\nThe user has to provide a kernel code (described in Sec. 2.1) and a machine descrip\u0002tion (described in Sec. 2.2), and they have to select a performance model to apply\r\n(options are described in Sec.2.3). Optionally, parameters can be passed to the ker-",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/166aaeed-1507-43d0-9e80-45a8c006e1f8.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=677d3137ce0c01f7ddea38ec5fc2a5edf240024084bf7540ac811261643b8f1e",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 295
      },
      {
        "segments": [
          {
            "segment_id": "e4ea8ffb-2cdd-476e-9f01-10aa07066228",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 7,
            "page_width": 612,
            "page_height": 792,
            "content": "Kerncraft: A Tool for Analytic Performance Modeling of Loop Kernels 7\r\n | offsets ...\r\n---+------------...\r\n a | ('rel', 'j', 0),('rel', 'i', -1)\r\n | ('rel', 'j', 0), ('rel', 'i', 1)\r\n | ('rel', 'j', -1), ('rel', 'i', 0)\r\n | ('rel', 'j', 1), ('rel', 'i', 0)\r\n s | ('dir',)\r\nthroughput/latency\r\nwith IACA\r\npycparser compiler\r\nvmovsd (%rsi,%rbx,8), %xmm1\r\nvaddsd 16(%rsi,%rbx,8), %xmm1, %xmm2\r\nvaddsd 8(%rdx,%rbx,8), %xmm2, %xmm3\r\nvaddsd 8(%rcx,%rbx,8), %xmm3, %xmm4\r\nvaddsd 8(%r8,%rbx,8), %xmm4, %xmm5\r\nvaddsd 8(%r9,%rbx,8), %xmm5, %xmm6\r\nvmulsd %xmm6, %xmm0, %xmm7\r\nInput\r\nIntermediate\r\nOutput\r\ndata pattern\r\nmarked for IACA\r\nbinary\r\nT_L1L2, T_L2L3, T_L3MEM\r\ndata transfers\r\nT_OL, T_nOL\r\nin-core\r\nLayer condition model ECM/Roo\u001fine model\r\nabstract syntax tree\r\nAST\r\n#define N 1000\r\n#define M 2000\r\nfor (j=1 ; j < N-1; ++j)\r\nfor(i=1; i < M -1; ++i)\r\nb[j][i] = (a[ j ][i -1] + a[ j ][i+1]\r\n+ a[j -1][ i ] + a[j+1][ i ] )* s;\r\nkernel code constants\r\nKernel\r\nclock: 2.7 GHz\r\ncacheline size: 64 B\r\nmemory hierarchy:\r\n- {cores per group: 1, cycles per cacheline: 2,\r\n level: L1, size per group: 32 kB}\r\n- {cores per group: 1, cycles per cacheline: 2,\r\n level: L2, size per group: 256 kB}\r\n- {cores per group: 8, bandwidth: 40 GB/s,\r\n level: L3, size per group: 20 MB}\r\n[...]\r\nmachine description\r\nTiling Suggestions\r\ncache simulation\r\nwith pycachesim\r\nlayer condition\r\nanalysis OR\r\nFig. 2 Overview of the Kerncraft pipeline. The user provides kernel code, constants, and a machine\r\ndescription. IACA, pycachesim, and a compiler are employed to build the ECM, Roofline, and\r\nlayer condition models.\r\nnel code, similar to constants defined by macros or -D compiler flags. For models\r\nthat rely on prediction of caching, either the layer condition prediction or the cache\r\nsimulation (using the pycachesim module) can be employed. Both predictors will\r\nbe described in Section 2.4.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/e4ea8ffb-2cdd-476e-9f01-10aa07066228.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=2e3c6751cde3d9ec141ca7214d0d5869143fe5b7e11e8bcc9564a5111b76e23f",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 294
      },
      {
        "segments": [
          {
            "segment_id": "01f9534a-abb8-4598-9d1b-0fd3029a6e2f",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 8,
            "page_width": 612,
            "page_height": 792,
            "content": "8 J. Hammer, J. Eitzinger, G. Hager, and G. Wellein\r\nListing 1 Input kernel code for a three-dimensional 7-point star stencil (3D-7pt).\r\ndouble a[M][N][N];\r\ndouble b[M][N][N];\r\ndouble coeffs_N, coeffs_S, coeffs_W, coeffs_E,\r\ncoeffs_F, coeffs_B, s;\r\nfor(int k=1; k<M-1; ++k)\r\nfor(int j=1; j<N-1; ++j)\r\nfor(int i=1; i<N-1; ++i)\r\nb[k][j][i] = ( coeffs_W*a[k][j][i-1]\r\n+ coeffs_E*a[k][j][i+1]\r\n+ coeffs_N*a[k][j-1][i]\r\n+ coeffs_S*a[k][j+1][i]\r\n+ coeffs_B*a[k-1][j][i]\r\n+ coeffs_F*a[k+1][j][i]) * s;\r\n2.1 Kernel Code\r\nKerncraft is based on the analysis of standard-compliant C99 [11] code, which must\r\nbe provided as shown in Listing 1. Example files for several stencils are distributed\r\nwith the Kerncraft repository1. The first lines are dedicated to variable and array\r\ndefinitions. While large arrays would in practice be allocated on the heap, Kerncraft\r\nrequires arrays to be declared as local varaibles. The multidimensional syntax (e.g.,\r\na[M][N] and a[j][i]) is optional, since Kerncraft now also supports flattened\r\nindices (e.g., a[M*N] and a[j*N+i]).\r\nN and M in Listing 1, are constants which can be passed to the code through the\r\ncommand line. During analysis they are treated as symbols, which may be replaced\r\nby constant positive integers.\r\nFollowing the variable definitions is the loop nest, which may only contain one\r\nloop per level and only the innermost loop may contain variable assignments and\r\narithmetic operations. The loop indices must be local to that loop and the bounds\r\nmay only depend on constant integers and simple arithmetic operations (addition,\r\nsubtraction, and multiplication) of constant integers. The step size can be any con\u0002stant length; in Listing 1 we have a step size of one, but k+=2 would for instance\r\nalso work.\r\nAny number of statements are allowed in the loop body, as long as they are as\u0002signments and arithmetic operations based on constants, integers, variables, and ar\u0002ray references. Array references may contain arithmetic expressions in their indices\r\n(e.g., a[j*N+i+1]). Such an expression may only be composed of constants, in\u0002tegers, and loop index variables (i, j, and k in Listing 1).\r\nFunction calls, ifs, pointer arithmetic, and irregular data accesses are not al\u0002lowed, since they could not be analyzed with the algorithms used in the current\r\n1 https://github.com/RRZE-HPC/kerncraft/tree/master/examples/\r\nkernels",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/01f9534a-abb8-4598-9d1b-0fd3029a6e2f.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=59e87f95d065955480781907bd36cb7db59b8efa62e10187a45ecb1ef6ef5a7d",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 349
      },
      {
        "segments": [
          {
            "segment_id": "09f502f0-d862-4119-9924-bf5905057e72",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 9,
            "page_width": 612,
            "page_height": 792,
            "content": "Kerncraft: A Tool for Analytic Performance Modeling of Loop Kernels 9\r\nversion of Kerncraft. Moreover, the underlying models do not yet have a canonical\r\nway of dealing with the effects arising in such cases.\r\n2.2 Machine Description\r\nTo select the targeted machine architecture, Kerncraft needs a machine description\r\nfile in the YAML file format [3]. Example machines description files are distributed\r\nthrough the Kerncraft repository2. A machine description file always consists of\r\nthree parts: the execution architecture description, the cache and memory hierarchy\r\ndescription, and benchmark results of typical streaming kernels. In the following,\r\nwe will go into some settings found in Listing 2 that are not self-explanatory.\r\nCompute Architecture\r\nThe first section is the execution architecture description (the actual order of ele\u0002ments does not matter in the YAML file format). This section describes the com\u0002pute capabilities of the machine, such as clock speed, number of cores, or com\u0002piler flags to use for benchmarks. micro-architecture is the abbreviation for\r\nthe Intel microarchitecture codename as used by IACA (e.g., HSW for Haswell),\r\noverlapping-ports are the execution ports corresponding to the overlapping\r\nportion in the ECM model as reported by IACA, non-overlapping-ports are\r\nall other ports as reported by IACA.\r\nThe machine description file with the benchmark section and partial information\r\nabout the memory hierarchy and compute architecture can be generated automat\u0002ically by the script likwid bench auto.py, which comes with Kerncraft. It\r\nemploys likwid-topology and likwid-bench [19] to gather accurate in\u0002formation about the machine it is executed on.\r\nMemory Hierarchy\r\nEach level of the memory hierarchy has an entry in the memory hierarchy sec\u0002tion. cores per group is the number of physical cores that share one resource\r\non this level (e.g., if every core has its own private cache, cores per group\r\nis 1). threads per group is the number of virtual threads that share one re\u0002source on this level. groups is the total number of resources of this type (e.g., an\r\nL1 cache) that exist on all sockets. cycles per cacheline transfer is\r\nonly needed for caches, except for the last level cache (LLC). It denotes the number\r\nof cycles it takes to load one cache line from the adjacent “lower” (closer to main\r\n2 https://github.com/RRZE-HPC/kerncraft/tree/master/examples/\r\nmachine-files",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/09f502f0-d862-4119-9924-bf5905057e72.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=802527ec1260726a58032e1af5863a26658a8a7966dcc2d6c0c2aa3593d9a505",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 367
      },
      {
        "segments": [
          {
            "segment_id": "9f5c394d-fe41-4400-b5a8-5fc1d3a55490",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 10,
            "page_width": 612,
            "page_height": 792,
            "content": "10 J. Hammer, J. Eitzinger, G. Hager, and G. Wellein\r\nListing 2 Shortened machine description for Haswell (skipped sections are marked by ...).\r\n# Execution Architecture:\r\nmodel name: Intel(R) Xeon(R) CPU E5-2695 v3 @ 2.30GHz\r\nmicro-architecture: HSW\r\nnon-overlapping ports: [2D, 3D]\r\noverlapping ports: [’0’, 0DV, ’1’, ’2’, ’3’, ’4’, ’5’, ’6’, ’7’]\r\nFLOPs per cycle:\r\nDP: {ADD: 8, FMA: 8, MUL: 8, total: 16}\r\nSP: {ADD: 16, FMA: 16, MUL: 16, total: 32}\r\ncompiler: icc\r\ncompiler flags: [-O3, -xAVX, -fno-alias]\r\n...\r\n# Memory and Cache Hierarchy:\r\nmemory hierarchy:\r\n- level: L1\r\ncache per group: {\r\n’sets’: 64, ’ways’: 8, ’cl_size’: 64, # 32 kB\r\n’replacement_policy’: ’LRU’,\r\n’write_allocate’: True, ’write_back’: True,\r\n’load_from’: ’L2’, ’store_to’: ’L2’}\r\ncores per group: 1\r\nthreads per group: 2\r\ngroups: 28\r\ncycles per cacheline transfer: 2\r\n...\r\n# Benchmark Description and Results:\r\nbenchmarks:\r\nkernels:\r\ncopy:\r\nFLOPs per iteration: 0\r\nread streams: {bytes: 8.00 B, streams: 1}\r\nread+write streams: {bytes: 0.00 B, streams: 0}\r\nwrite streams: {bytes: 8.00 B, streams: 1}\r\n...\r\nmeasurements:\r\nL1:\r\n1:\r\ncores: [1, 2, 3, ...]\r\nresults:\r\ncopy: [36.15 GB/s, 72.32 GB/s, 108.48 GB/s, ...]\r\n...\r\nsize per core: [21.12 kB, 21.12 kB, 21.12 kB, ...]\r\nsize per thread: [21.12 kB, 21.12 kB, 21.12 kB, ...]\r\nthreads: [1, 2, 3, ...]\r\nthreads per core: 1\r\ntotal size: [21.12 kB, 42.24 kB, 63.36 kB, ...]\r\n...",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/9f5c394d-fe41-4400-b5a8-5fc1d3a55490.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f05a69489db0c4baeb0a5667603f539358a49b2857be20f46c1e3eee9ecd8588",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 221
      },
      {
        "segments": [
          {
            "segment_id": "cfeaa2e9-eaf5-4885-adb6-b7aa8ceaff35",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 11,
            "page_width": 612,
            "page_height": 792,
            "content": "Kerncraft: A Tool for Analytic Performance Modeling of Loop Kernels 11\r\nmemory) cache. For the last level cache this number is calculated from the measured\r\nsaturated memory bandwidth.\r\nThe cache per group dictionary contains the cache description as required\r\nby pycachesim [6]. write back makes sure that a modified cache line is trans\u0002ferred to the store to cache in case of its replacement. write allocate en\u0002forces a load of the cache line if some part of it is updated. The product of sets,\r\nways, and cl size is the size of one cache resource in bytes.\r\nBenchmarks\r\nStreaming benchmark results are required input for the Roofline model with all\r\ncore counts and in all memory hierarchy levels. The ECM model only needs the\r\nmeasured saturated main memory bandwidth. In order to cover the whole memory\r\nhierarchy and typical effects and configurations, many tests are performed and their\r\nresults stored in the machine description file. First, all benchmark kernels need to be\r\nspecified in the kernels dictionary. For each kernel, FLOPs per iteration\r\nis the number of floating-point operations per iteration of the underlying kernel.\r\nread streams is the number of bytes and different streams read at each itera\u0002tion. The ratio bytes/streams is the size of one element in the processed array.\r\nread+write streams are accesses that are both read and written to (e.g., a in\r\na[i] = a[i] + 1). write streams complements read streams. The\r\ndifferentiation into these three metrics is important to handle write-allocate trans\u0002fers correctly.\r\nThe benchmark results are then grouped into memory hierarchy levels and SMT\r\nthreads. Each such block has the configuration per physical core, with measured\r\nbandwidth (without write-allocate), used memory size (total, per thread and per\r\ncore), and the number of cores and threads used.\r\n2.3 Models\r\nThe models offered in Kerncraft are: Roofline, ECM, Layer Conditions,\r\nand Benchmark. Although not all are, strictly speaking, performance models, each\r\none allows some unique and valuable insight into the performance, or some aspect\r\nof expected behavior, of the kernel at hand.\r\nRoofline\r\nThe Roofline model is implemented in the two variants Roofline and Roof\u0002lineIACA. The former counts flops in the high level code and matches them to the\r\nFLOPs per cycle configuration in the machine description file. It also models\r\nthe first level cache to register transfers using the corresponding measured band-",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/cfeaa2e9-eaf5-4885-adb6-b7aa8ceaff35.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=91ec4a90df7f3f5fb2b2b7317550873f22cff9cd35cd68195e8585e8b748b7a0",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 387
      },
      {
        "segments": [
          {
            "segment_id": "a6ceb8b3-133d-4a5b-a21f-e8d6391bcdc9",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 12,
            "page_width": 612,
            "page_height": 792,
            "content": "12 J. Hammer, J. Eitzinger, G. Hager, and G. Wellein\r\nwidth result. RooflineIACA, on the other hand, uses the IACA analysis to pre\u0002dict in-core or compute performance and first level cache to register throughput.\r\nThis analysis will be explained in detail in the ECM section below.\r\nApart from the differences in the in-core and first level cache to registers bottle\u0002necks, both variants use the same approach for analysis throughout the rest of the\r\nmemory hierarchy: take the cache miss prediction (explained in Section 2.4) and\r\npredict the required data volume (βk) coming out of each memory hierarchy level\r\nper iteration. Take these volumes and divide them by the measured achievable band\u0002widths (Bk) out of the corresponding hierarchy level, which yields a throughput time\r\nfor that data amount (Tk = βk/Bk). Out of the numerous benchmarks (as described\r\nin Section 2.2), Kerncraft tries to find the one matching the kernel under examina\u0002tion as closely as possible with regard to the number of read and write streams into\r\nmemory.\r\nIf IACA is available and a supported Intel architecture is analyzed, the Roof\u0002lineIACA model is to be preferred over the regular Roofline model, as it will\r\nyield a much better accuracy.\r\nECM\r\nThree versions of the Execution-Cache-Memory (ECM) model are supported: ECM\u0002Data (modeling only the first level cache to main memory data transfers), ECMCPU\r\n(modeling only the in-core performance and first level cache to registers) and ECM\r\n(combining the data and in-core predictions). ECMPCPU relies on a suitable com\u0002piler and IACA to be available, which is why the rest of the ECM model can be run\r\nseparately.\r\nECMData uses either the layer conditions or cache simulation (both explained in\r\nSection 2.2) to predict the data volumes out of each memory hierarchy level. Then\r\nit applies the documented bandwidths for inter-cache transfers and the measured\r\nfull-socket main memory bandwidth for the memory to LLC transfers. By taking\r\nthe ratio of data volume and bandwidth, TL1L2, TL2L3, and TL3Mem are calculated (on\r\nmachines with three cache levels). The benchmark kernel used for the main memory\r\nbandwidth is chosen according to the read and write stream counts best matching\r\nthe analyzed kernel.\r\nECMCPU requires that the kernel is analyzed by IACA, which in turn requires a\r\ncompilable version of the kernel. The kernel code is therefore wrapped in a main\r\nfunction that takes care of initializing all arrays and variables. Dummy function calls\r\nare inserted to prevent the compiler from removing seemingly useless data accesses.\r\nOnce compiled to assembly language using appropriate optimizing flags, the inner\u0002most kernel loop is extracted and the unrolling factor is determined from it. Both are\r\ndone using heuristics and may fail; if they do, interaction by the user is requested.\r\nUsing the unrolling factor, the IACA predictions can be scaled to iterations in the\r\nhigh-level kernel code. IACA reports throughput cycle counts per port, which are\r\nthen accumulated into TnOL and TOL based on the machine description configuration.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/a6ceb8b3-133d-4a5b-a21f-e8d6391bcdc9.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=3614c448062240fb86feb2296ec708979e4ea4e2e4feae828dcf5218d28857d4",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 487
      },
      {
        "segments": [
          {
            "segment_id": "55a8b7f5-eb75-4050-9a94-d159e590f85b",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 13,
            "page_width": 612,
            "page_height": 792,
            "content": "Kerncraft: A Tool for Analytic Performance Modeling of Loop Kernels 13\r\nLayer Conditions\r\nTo predict optimal blocking sizes, layer conditions can be formulated in an algebraic\r\nway and solved for block sizes. The details are explained in [5], while the concept\r\nof layer conditions and our generic formulation is described in Section 2.4.2.\r\nBenchmark\r\nTo allow validation of the previously explained models, the benchmark model com\u0002piles and runs the code and measures performance. The code is prepared in basically\r\nthe same way as for an IACA analysis, but arrays are initialized and LIKWID marker\r\ncalls are inserted to enable precise measurements using hardware performance coun\u0002ters. The output of likwid-perfctr is used to derive familiar metrics (Gflop/s,\r\nMLUP/s, etc.), which in turn are used for validations. It is important to note that this\r\nmodel must be executed on the same machine as the one in the machine description\r\nfile passed to Kerncraft, otherwise results will not be conclusive.\r\n2.4 Cache Miss Prediction\r\nOne of the core capabilities of Kerncraft is the prediction of the origin of data within\r\nthe memory hierarchy, which can currently be done via two methods: a partial cache\r\nsimulation using pycachesim, or a layer condition analysis. Both prediction methods\r\nhave their strong points and drawbacks. Cache simulation can capture some irreg\u0002ularities arising from the cache structure and implementation in hardware (such as\r\nassociativity conflicts) and at the same time is more generic and versatile in terms\r\nof architectural features and the kernels it can be used for. Layer conditions, on the\r\nother hand, yield very clean and stable results without disturbance from hardware\u0002specific issues. They can be evaluated very quickly and almost independently of the\r\ncode and domain size, but they only work for least-recently-used (LRU) replacement\r\npolicies and currently only handle sequential traversal patterns.\r\nIn summary, if the layer condition prediction can be applied to the kernel and\r\narchitecture of interest, it is usually the better choice.\r\n2.4.1 Cache Simulation with pycachesim\r\nThe open source pycachesim library is a spin-off from Kerncraft. It is designed to ef\u0002ficiently model all the common cache architectures found in Intel, AMD, and Nvidia\r\nproducts.3 The cache architecture is described in the machine description file and\r\nthen modeled in pycachesim. It supports inclusive and exclusive caching, multiple\r\n3 Kerncraft currently only supports Intel Xeon and Core architectures, but pycachesim has been\r\ndeveloped with other architectures in mind.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/55a8b7f5-eb75-4050-9a94-d159e590f85b.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=b045979f9486c8ce7443d03fa7913d2c0a82b38011241d86f84bc477b29b8561",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 396
      },
      {
        "segments": [
          {
            "segment_id": "2df5f3be-b1d9-4166-b9f8-25c1a0c34ec6",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 14,
            "page_width": 612,
            "page_height": 792,
            "content": "14 J. Hammer, J. Eitzinger, G. Hager, and G. Wellein\r\nreplacement policies (LRU, RR, Random and FIFO) as well as victim caches. For\r\nthe Intel architectures covered in this paper, inclusive write-back caches with LRU\r\nare assumed. The simulator, once initialized with the cache structure, gets passed ac\u0002cessed data locations (loads and stores), which are followed through the simulated\r\nmemory hierarchy. It also keeps a statistic about accumulated load, store, hit, and\r\nmiss counts. After a warm-up phase, the statistic is reset, data accesses from a pre\u0002cise number of loop iterations are passed to the simulator, and the updated statistic\r\nis read out. The gained information reflects the steady state behavior.\r\nIt is very important to align the end of the warm-up period with cache line bound\u0002aries, as well as with edges of the arrays to skip over boundary handling (e.g., loops\r\nthat go from 2 to N −3). If these cases are not considered, imprecise and oscillating\r\nperformance predictions are likely.\r\n2.4.2 Layer Conditions\r\nAnother approach to predicting the cache traffic are the Layer Conditions [16, 17].\r\nIn order to utilize them for our purposes, we have generalized and reformulated them\r\nto allow symbolic evaluation. The symbolic evaluation heavily relies on sympy [18],\r\na computer algebra system for python.\r\nThe basis of layer conditions is the least-recently-used replacement policy, which\r\n(although typically not perfectly implemented in large, real caches) mimics ob\u0002served behavior quite well. By taking the relative data access offsets and assuming\r\nsequential increments during the subsequent iterations, we can predict very pre\u0002cisely which access will hit or miss depending on given cache sizes.\r\nFor demonstration we assume a double precision 2D 5-point stencil on M × N\r\narrays a[M][N] and b[M][N], with accesses in the jth and ith iteration to\r\na[j-1][i], a[j][i-1] a[j][i+1], a[j+1][i] and b[j][i]. The inner\r\nloop index is i. Now we compute the offsets between all accesses after sorting them\r\nin increasing order (as already shown), e.g., &a[j][i-1] - &a[j-1][i] or\r\n(N −1) elements. We store them in the list L and insert, per array, another ∞, since\r\nwe do not know the offsets between the arrays:\r\nL = { ∞|{z}\r\nfirst access\r\nto a\r\n, N −1\r\n| {z }\r\n&a[j][i-1]\r\n- &a[j-1][i]\r\n, 2\r\n|{z}\r\n&a[j][i+1]\r\n- &a[j][i-1]\r\n, N −1\r\n| {z }\r\n&a[j+1][i]\r\n- &a[j][i+1]\r\n, ∞|{z}\r\nfirst access\r\nto b\r\n}\r\nFor each reuse distance t in L we can derive the required cache size Creq, hits Chits,\r\nand misses Cmisses:\r\nCreq = ∑(L≤t) +t ∗ count(L>t)\r\nChits = count(L≤t)\r\nCmisses = count(L>t) .\r\nHere, Lcondition is a sublist of L that contains only entries that fulfill the given condi\u0002tion (e.g., L<t contains all elements out of L which are smaller than t). Applying this",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/2df5f3be-b1d9-4166-b9f8-25c1a0c34ec6.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=467e8b24d326b351f4288f9464ff5f14a4f96ae657f1a100d4b19033c1562d1a",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 456
      },
      {
        "segments": [
          {
            "segment_id": "8f8135ba-635b-4cb4-a470-40cf8785d93e",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 15,
            "page_width": 612,
            "page_height": 792,
            "content": "Kerncraft: A Tool for Analytic Performance Modeling of Loop Kernels 15\r\nmethod to the described kernel, we have the interesting case t = N −1, for which we\r\nget Creq = 2(N −1)+2+2(N −1) = 4N −2 elements, or 32N −16 bytes, Chits = 3,\r\nand Cmisses = 2.\r\nThis means that if an LRU-based cache can hold more than 32N −16 bytes, three\r\nhits will be observed in each iteration and two misses will need to be passed to the\r\nnext level in the memory hierarchy, which is to leading order exactly the result from\r\na manual LC analysis (where the 16 bytes are typically neglected so that four layers,\r\ni.e., rows, must fit into the cache). Since caches in modern CPUs do not operate on\r\nbytes but on cache lines, the computed hits and misses are averaged. Once a cache\r\nline was loaded due to a miss, subsequent accesses will be hits, which averages out\r\nto the misses and hits per iteration yielded by the layer condition analysis.\r\n2.5 Underlying In-Core Execution Prediction\r\nTo predict the in-core execution behavior, we employ the Intel Architecture Core\r\nAnalyzer (IACA) [10], which predicts the throughput and latency for a sequence\r\nof assembly instructions under the assumption that all loads can be served by the\r\nfirst level cache. IACA presupposes steady-state execution, i.e., the loop body is\r\nassumed to be executed often enough to amortize any start-up effects.\r\nKerncraft operates on high level C code, which can not be analyzed by IACA\r\ndirectly. Therefore it first needs to be transformed into a compilable version by\r\nwrapping the kernel in a main function. It is then passed through a compiler and\r\nconverted to assembly. The assembly sequence of the inner loop body needs to be\r\nmarked to be recognized by IACA. The marked assembly is then fed into the as\u0002sembler to produce an object file as input to IACA. IACA reports the throughput\r\nand latency analysis itemized by execution ports. We are interested in the overall\r\nand load-related throughput and latency. Which execution ports are associated with\r\nloads is defined in the machine description file (see Section 2.2 above). The compiler\r\nmight have unrolled the inner-most loop a number of times (e.g., to allow vector\u0002ization), so this factor needs to be extracted from the assembly to scale the IACA\r\nresults to a single high-level kernel code loop iteration. The IACA output is parsed\r\nand the data is presented by Kerncraft as part of the analysis.\r\n3 Kerncraft Usage\r\nKerncraft guides performance engineering efforts by allowing developers to pre\u0002dict and validate performance. In the following sections we will use an instructive\r\nexample to demonstrate the single-core performance prediction, the scaling from\r\nsingle-core to the full socket, and the analytic layer conditions. The analysis will\r\nbe based on the long-range 3D kernel (3d-long-range) in Listing 3. Predictions and",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/8f8135ba-635b-4cb4-a470-40cf8785d93e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=f6ae842c9b614fabc2c57e9233bd8dbd0d3079c001aba93d67e5ad98c561ef37",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 473
      },
      {
        "segments": [
          {
            "segment_id": "ff4706d9-3f0f-4120-9024-a354c69c9efb",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 16,
            "page_width": 612,
            "page_height": 792,
            "content": "16 J. Hammer, J. Eitzinger, G. Hager, and G. Wellein\r\nListing 3 Kernel code for a three dimensional long-range star stencil with constant coefficients.\r\ndouble U[M][N][N];\r\ndouble V[M][N][N];\r\ndouble ROC[M][N][N];\r\ndouble c0, c1, c2, c3, c4, lap;\r\nfor(int k=4; k < M-4; k++) {\r\nfor(int j=4; j < N-4; j++) {\r\nfor(int i=4; i < N-4; i++) {\r\nlap = c0 * V[k][j][i]\r\n+ c1 * ( V[ k ][ j ][i+1] + V[ k ][ j ][i-1])\r\n+ c1 * ( V[ k ][j+1][ i ] + V[ k ][j-1][ i ])\r\n+ c1 * ( V[k+1][ j ][ i ] + V[k-1][ j ][ i ])\r\n+ c2 * ( V[ k ][ j ][i+2] + V[ k ][ j ][i-2])\r\n+ c2 * ( V[ k ][j+2][ i ] + V[ k ][j-2][ i ])\r\n+ c2 * ( V[k+2][ j ][ i ] + V[k-2][ j ][ i ])\r\n+ c3 * ( V[ k ][ j ][i+3] + V[ k ][ j ][i-3])\r\n+ c3 * ( V[ k ][j+3][ i ] + V[ k ][j-3][ i ])\r\n+ c3 * ( V[k+3][ j ][ i ] + V[k-3][ j ][ i ])\r\n+ c4 * ( V[ k ][ j ][i+4] + V[ k ][ j ][i-4])\r\n+ c4 * ( V[ k ][j+4][ i ] + V[ k ][j-4][ i ])\r\n+ c4 * ( V[k+4][ j ][ i ] + V[k-4][ j ][ i ]);\r\nU[k][j][i] = 2.f * V[k][j][i] - U[k][j][i]\r\n+ ROC[k][j][i] * lap;\r\n}}}\r\nTable 2 Technical data of the Ivy Bridge-based node used for the long-range stencil case study.\r\nMicroarchitecture Ivy Bridge EP\r\nAbbreviation IVY\r\nModel Name E5-2690v2\r\nClock (fixed, no turbo) 3.0 GHz\r\nCores per socket 10\r\nCacheline size 64B\r\nTheoretical L1-L2 bandwidth 0.5CL/cy\r\nTheoretical L2-L3 bandwidth per core 0.5CL/cy\r\nAchievable single-socket memory 47.2GB/s (7 cores) bandwidth (copy kernel)\r\nCompiler version Intel ICC 16.0.3\r\nIACA version 2.1\r\nKerncraft version 0.4.3\r\nmeasurements will be done for the Intel Ivy Bridge EP (IVY) microarchitecture.\r\nThe details of the machine are described in Table 3.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/ff4706d9-3f0f-4120-9024-a354c69c9efb.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=e9dad35ef2dcd0845bba746c7bfc0ae1a8f20773be3a74acf9b8648e4b7f07e0",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 345
      },
      {
        "segments": [
          {
            "segment_id": "cbbfd216-b485-40bd-beee-bf549f90152e",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 17,
            "page_width": 612,
            "page_height": 792,
            "content": "Kerncraft: A Tool for Analytic Performance Modeling of Loop Kernels 17\r\nListing 4 Excerpt from the kerncraft CLI (reformatted for brevity) for the analysis of the long\u0002range stencil\r\n$ kerncraft -p ECM -p RooflineIACA --cache-predictor=SIM \\\r\n3d-long-range.c -m IVY.yaml -D M 130 -D N 1015;\r\n=========================== kerncraft ===========================\r\n3d-long-range-stencil.c -m IVY.yaml\r\n-D M 130 -D N 1015\r\n----------------------------- ECM -------------------------------\r\n{ 52.0 || 54.0 | 40.0 | 24.0 | 48.5 } cy/CL\r\n{ 54.0 \\ 94.0 \\ 118.0 \\ 166.5 } cy/CL\r\nsaturating at 4 cores\r\n------------------------- RooflineIACA --------------------------\r\nBottlenecks:\r\nlevel | a. intensity | performance | bandwidth | bw kernel\r\n-------+--------------+---------------+------------+----------\r\nCPU | | 18.22 GFLOP/s | |\r\nL2 | 0.26 FLOP/B | 17.52 GFLOP/s | 68.37 GB/s | copy\r\nL3 | 0.43 FLOP/B | 16.57 GFLOP/s | 38.79 GB/s | copy\r\nMEM | 0.43 FLOP/B | 7.65 GFLOP/s | 17.91 GB/s | copy\r\nCache or mem bound with 1 core(s)\r\n7.65 GFLOP/s due to MEM bottleneck (bw with from copy benchmark)\r\nArithmetic Intensity: 0.43 FLOP/B\r\n3.1 Single-Core Performance\r\nUsing Kerncraft for a single-core performance analysis involves choosing an over\u0002all prediction model (ECM or Roofline) and a cache predictor model (pycachesim\r\nsimulation [SIM] or layer conditions [LC]). An example using RooflineIACA,\r\nECM, and SIM is shown in Listing 4. It is easy to do parameter studies via simple\r\nscripting, and scanning a range of problem sizes often leads to valuable insights.\r\nRunning this analysis from N = 100 to N = 2000, we can see the effect of the inner\r\ndimension increasing and visualize it in Figure 3.\r\nThe ECM prediction (stacked areas from TnOL + TL1−L2 + TL2−L3 + TL3−MEM)\r\nfollows the trend of the measured throughput (black plus signs). The Roofline pre\u0002diction (green dashed line) is generally too optimistic due to the evenly distributed\r\nruntime contribution from multiple memory hierarchy levels, which is not correctly\r\nmodeled in this particular case. The cache simulator, taking the associativity of all\r\ncache levels into account, correctly identifies L1 thrashing and a corresponding run\u0002time increase near N = 1792 = 7·256. The corresponding increase in traffic between\r\nL1 and L2 of more than 50% can be shown using performance counter measure\u0002ments. Many more such “pathological” sizes exist, of course, but the size range\r\nwas not scanned with a step size of one. In Figure 4 the same parameter study was\r\ndone with the LC predictor. Since it knows nothing about cache organization, the\r\nprediction is much smoother.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/cbbfd216-b485-40bd-beee-bf549f90152e.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8e4ce55c53612ee5f31f204de2d6eac83cab8bb127207bb76a1a994576fd82db",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 406
      },
      {
        "segments": [
          {
            "segment_id": "a16f58bd-f907-4c16-bb1d-58262920fffa",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 18,
            "page_width": 612,
            "page_height": 792,
            "content": "18 J. Hammer, J. Eitzinger, G. Hager, and G. Wellein\r\n2\r\n7 2\r\n8 29 210\r\nN\r\n0\r\n50\r\n100\r\n150\r\n200\r\n250\r\ncyles per eight iterations [cy]\r\nECM TnOL (stacked)\r\nECM TL1 ¡ L2 (stacked)\r\nECM TL2 ¡ L3 (stacked)\r\nECM TL3 ¡ MEM (stacked)\r\nECM TOL\r\nmeasured\r\nRoofline\r\nFig. 3 Single-core parameter sweep of the long-range stencil for N = 100 to N = 2000 with M\r\nchosen such that the working set will never fit into any cache and needs to be loaded from main\r\nmemory.\r\n2\r\n7 2\r\n8 29 210\r\nN\r\n0\r\n50\r\n100\r\n150\r\n200\r\n250\r\ncyles per eight iterations [cy]\r\nECM TnOL (stacked)\r\nECM TL1 ¡ L2 (stacked)\r\nECM TL2 ¡ L3 (stacked)\r\nECM TL3 ¡ MEM (stacked)\r\nECM TOL\r\nmeasured\r\nRoofline\r\nFig. 4 Single-core parameter sweep, with layer condition cache prediction, of the long-rang stencil\r\nfor N = 100 to N = 2000 with M chosen such that the data will never fit into any cache and needs\r\nto be loaded from main memory.\r\n3.2 Single-Socket Scaling and Saturation Point\r\nFor multi-core scaling the ECM model assumes perfect scalability until a shared\r\nbandwidth bottleneck (usually the main memory bandwidth) is hit. It thus predicts\r\nthe number of cores where the loop performance ceases to scale:\r\nns =\r\nTECM,Mem\r\nTL3−Mem\r\n.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/a16f58bd-f907-4c16-bb1d-58262920fffa.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=fb216399802018042073263f93a3e620cb9a16afcb60312e8b7ab8394aa04373",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 218
      },
      {
        "segments": [
          {
            "segment_id": "6f41894d-359c-4781-a9da-7cad8c810794",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 19,
            "page_width": 612,
            "page_height": 792,
            "content": "Kerncraft: A Tool for Analytic Performance Modeling of Loop Kernels 19\r\nBy default, Kerncraft reports the saturation point in the ECM model, as seen in\r\nListing 4. The default report assumes that the total cache size and cache bandwidth\r\nscales with the number of cores. This is mostly true on current Intel microarchitec\u0002tures, but not for the last level cache (L3) size, which is shared among all cores in\r\na socket. To also take that change of cache sizes into account, Kerncraft can be run\r\nwith the --cores argument. In the case presented in Listing 4, a reduction of the\r\nL3 cache size by a factor of four (for 4 cores) does not change the predicted results,\r\nsince no layer condition changes.\r\nTo perform the single-socket scaling we added OpenMP pragmas to the outer\r\nloop in the code and ran with the same problem size as seen in Listing 4 (strong\r\nscaling). The result can be seen in Figure 5: By increasing the number of cores up to\r\nthe predicted saturation point (four cores), we expect perfect scaling (dashed gray\r\nline), and constant performance beyond (dotted line). The scaling model fits the\r\nobservations very well except right before the saturation point, which is a known\r\nweakness of the ECM model with data-bound kernels [17].\r\n3.3 Layer Conditions\r\nLayer conditions enable a much more efficient cache behavior prediction without\r\nextensive parameter studies through the simulator or benchmarks. As explained in\r\nSection 2.4.2, they are evaluated analytically and yield a prediction for transition\r\npoints from one cache state to another. Kerncraft generally employs analytic LCs\r\nwhen using the option --cache-predictor=LC, but it can also output the de\u00021 2 3 4 5 6 7 8 9 10\r\ncores\r\n0\r\n20\r\n40\r\n60\r\n80\r\n100\r\n120\r\n140\r\n160\r\n180\r\nmeasured time per eight iterations [cy]\r\nMeasured\r\nPerfect scaling\r\nBandwidth limit\r\nSaturation point\r\nFig. 5 Single-socket strong scaling of the long-range stencil for N = 1015 and M = 132 with all\r\ncores on same socket. The vertical line denotes the predicted saturation point. The horizontal line\r\nis the minumum runtime as given by the saturated memory bandwidth.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/6f41894d-359c-4781-a9da-7cad8c810794.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=119fef2d26cfbdea2b375bfd06cd852f8547db8c3cc141904a357e73b7abab62",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 353
      },
      {
        "segments": [
          {
            "segment_id": "ff0833ab-bb8a-4a8e-b047-6d2c312bf812",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 20,
            "page_width": 612,
            "page_height": 792,
            "content": "20 J. Hammer, J. Eitzinger, G. Hager, and G. Wellein\r\nListing 5 Excerpt from the kerncraft CLI (reformatted for brevity) showing LC transition points\r\nfrom the analysis of the long-range stencil\r\n$ kerncraft -p LC 3d-long-range.c -m IVY.yaml -D M 130 -D N 1015;\r\n=========================== kerncraft ===========================\r\n3d-long-range-stencil.c -m IVY.yaml\r\n-D M 130 -D N 1015\r\n------------------------------ LC -------------------------------\r\n2D Layer-Condition:\r\nL1: N <= 216\r\nL2: N <= 1725\r\nL3: N <= 172463\r\n3D Layer-Condition:\r\nL1: N <= 19\r\nL2: N <= 55\r\nL3: N <= 546\r\nrived transition points as shown in Listing 5. The predicted transition in L3 from the\r\n3D to the 2D layer condition at N = 546 is also clearly visible in Figures 3 and 4.\r\n4 Future Work\r\nDevelopment on Kerncraft will continue and strive to enhance usability and porta\u0002bility and to allow support of a broader range of kernels and architectures. One of\r\nthe major obstacles to supporting non-Intel CPUs is IACA, which is closed-source\r\nand only supports Intel microarchitectures. It is our goal to develop a model and tool\r\nwhich will be suitable for predictions on other architectures. In the near future we\r\nwill also integrate our layer condition model with the LLVM-Polly project [4]. This\r\nwill allow the Polyhedral model to automatically choose cache-efficient tiling sizes\r\nwithout user interaction.\r\nAs with all of our tools and libraries (Kerncraft, LIKWID [19], GHOST [12], and\r\nthe soon-to-be-published fault-tolerance package CRAFT), future work will be re\u0002leased under open source licenses and we will support and encourage other projects\r\nto build upon them.\r\nAcknowledgements This work was in part funded by the German Academic Exchange Ser\u0002vice’s (DAAD) FITweltweit program and the Federal Ministry of Education and Research (BMBF)\r\nSKAMPY grant.",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/ff0833ab-bb8a-4a8e-b047-6d2c312bf812.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=75e8272cb388c65aac66ec16abcc11df21f77c7a690b2fb54e7706c5fbb413c9",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 285
      },
      {
        "segments": [
          {
            "segment_id": "4f0afc9f-8348-43e8-b87d-0889f9b06589",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 21,
            "page_width": 612,
            "page_height": 792,
            "content": "Kerncraft: A Tool for Analytic Performance Modeling of Loop Kernels 21\r\nReferences\r\n[1] Kerncraft toolkit. https://github.com/RRZE-HPC/kerncraft\r\n[2] Djoudi, L., Barthou, D., Carribault, P., Lemuet, C., Acquaviva, J.T., Jalby,\r\nW., et al.: MAQAO: Modular assembler quality analyzer and optimizer for\r\nitanium 2. In: The 4th Workshop on EPIC architectures and compiler tech\u0002nology, San Jose (2005). http://www.prism.uvsq.fr/users/bad/\r\nResearch/ps/maqao.pdf\r\n[3] Evans, C., Ingerson, B., Ben-Kiki, O.: YAML Ain’t Markup Language.\r\nhttp://yaml.org\r\n[4] Grosser, T., Groesslinger, A., Lengauer, C.: Polly – performing polyhedral op\u0002timizations on a low-level intermediate representation. Parallel Processing\r\nLetters 22(04), 1250,010 (2012). DOI 10.1142/S0129626412500107\r\n[5] Hammer, J.: Layer conditions. URL https://rrze-hpc.github.io/\r\nlayer-condition/\r\n[6] Hammer, J.: pycachesim – a single-core cache hierarchy simulator written in\r\npython. URL https://github.com/RRZE-HPC/pycachesim\r\n[7] Hammer, J., Hager, G., Eitzinger, J., Wellein, G.: Automatic loop kernel anal\u0002ysis and performance modeling with kerncraft. In: Proceedings of the 6th\r\nInternational Workshop on Performance Modeling, Benchmarking, and Sim\u0002ulation of High Performance Computing Systems, PMBS ’15, pp. 4:1–4:11.\r\nACM, New York, NY, USA (2015). DOI 10.1145/2832087.2832092\r\n[8] Hockney, R.W., Curington, I.J.: f1/2: A parameter to characterize memory and\r\ncommunication bottlenecks. Parallel Computing 10(3), 277–286 (1989). DOI\r\n10.1016/0167-8191(89)90100-2\r\n[9] Hofmann, J., Fey, D., Riedmann, M., Eitzinger, J., Hager, G., Wellein, G.:\r\nPerformance analysis of the Kahan-enhanced scalar product on current multi\u0002core and many-core processors. Concurrency and Computation: Practice and\r\nExperience pp. n/a–n/a (2016). DOI 10.1002/cpe.3921\r\n[10] Intel Architecture Code Analyzer. URL https://software.intel.\r\ncom/en-us/articles/intel-architecture-code-analyzer.\r\nhttps://software.intel.com/en-us/articles/\r\nintel-architecture-code-analyzer\r\n[11] ISO: ISO C Standard 1999. Tech. rep. (1999). URL http://www.\r\nopen-std.org/jtc1/sc22/wg14/www/docs/n1124.pdf.\r\nISO/IEC 9899:1999 draft\r\n[12] Kreutzer, M., Thies, J., Rohrig-Z ¨ ollner, M., Pieper, A., Shahzad, F., Galgon, ¨\r\nM., Basermann, A., Fehske, H., Hager, G., Wellein, G.: GHOST: Building\r\nblocks for high performance sparse linear algebra on heterogeneous systems.\r\nInternational Journal of Parallel Programming pp. 1–27 (2016). DOI 10.1007/\r\ns10766-016-0464-z\r\n[13] Krishna Narayanan, S.H., Norris, B., Hovland, P.D.: Generating performance\r\nbounds from source code. In: Parallel Processing Workshops (ICPPW), 2010\r\n39th International Conference on, pp. 197–206 (2010). DOI 10.1109/ICPPW.\r\n2010.37",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/4f0afc9f-8348-43e8-b87d-0889f9b06589.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=3ee48b1d86c777b9aa5683ec07683df1a07dba467db452b7094e02731fe8e119",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 324
      },
      {
        "segments": [
          {
            "segment_id": "5074648c-c025-4c35-96b2-60f0608eb109",
            "bbox": {
              "left": 0,
              "top": 0,
              "width": 612,
              "height": 792
            },
            "page_number": 22,
            "page_width": 612,
            "page_height": 792,
            "content": "22 J. Hammer, J. Eitzinger, G. Hager, and G. Wellein\r\n[14] Lo, Y., Williams, S., Van Straalen, B., Ligocki, T., Cordery, M., Wright,\r\nN., Hall, M., Oliker, L.: Roofline model toolkit: A practical tool for archi\u0002tectural and program analysis. In: S.A. Jarvis, S.A. Wright, S.D. Ham\u0002mond (eds.) High Performance Computing Systems. Performance Model\u0002ing, Benchmarking, and Simulation, Lecture Notes in Computer Science,\r\nvol. 8966, pp. 129–148. Springer International Publishing (2015). DOI\r\n10.1007/978-3-319-17248-4\\ 7. DOI: 10.1007/978-3-319-17248-4 7\r\n[15] McCalpin, J.D.: STREAM: Sustainable memory bandwidth in high perfor\u0002mance computers. Tech. rep., University of Virginia, Charlottesville, VA\r\n(1991-2007). URL http://www.cs.virginia.edu/stream/. A\r\ncontinually updated technical report\r\n[16] Rivera, G., Tseng, C.W.: Tiling optimizations for 3D scientific computations.\r\nIn: Supercomputing, ACM/IEEE 2000 Conference, pp. 32–32 (2000). DOI\r\n10.1109/SC.2000.10015\r\n[17] Stengel, H., Treibig, J., Hager, G., Wellein, G.: Quantifying performance bot\u0002tlenecks of stencil computations using the execution-cache-memory model.\r\nIn: Proceedings of the 29th ACM International Conference on Supercom\u0002puting, ICS ’15, pp. 207–216. ACM, New York, NY, USA (2015). DOI\r\n10.1145/2751205.2751240\r\n[18] SymPy Development Team: SymPy: Python library for symbolic mathematics\r\n(2016). URL http://www.sympy.org\r\n[19] Treibig, J., Hager, G., Wellein, G.: Likwid: A lightweight performance\u0002oriented tool suite for x86 multicore environments. In: Proceedings of\r\nPSTI2010, the First International Workshop on Parallel Software Tools and\r\nTool Infrastructures. San Diego CA (2010)\r\n[20] Unat, D., Chan, C., Zhang, W., Williams, S., Bachan, J., Bell, J., Shalf, J.:\r\nExaSAT: An exascale co-design tool for performance modeling. International\r\nJournal of High Performance Computing Applications 29(2), 209–232 (2015).\r\nDOI 10.1177/1094342014568690. DOI: 10.1177/1094342014568690\r\n[21] Williams, S., Waterman, A., Patterson, D.: Roofline: An insightful visual per\u0002formance model for multicore architectures. Commun. ACM 52(4), 65–76\r\n(2009). DOI 10.1145/1498765.1498785\r\n[22] Wittmann, M., Hager, G., Zeiser, T., Treibig, J., Wellein, G.: Chip-level and\r\nmulti-node analysis of energy-optimized lattice Boltzmann CFD simulations.\r\nConcurrency and Computation: Practice and Experience 28(7), 2295–2315\r\n(2016). DOI 10.1002/cpe.3489",
            "segment_type": "Page",
            "ocr": null,
            "image": "https://storage.googleapis.com/chunkr-bucket-dev/ccf89702-e38e-4089-bd6b-77e3ba63c341/38aea59c-d72f-4bd7-ad4b-94b7fcd9a51a/images/5074648c-c025-4c35-96b2-60f0608eb109.jpg?x-id=GetObject&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=GOOG1E6ZKWCYPX4LV42MGE7WJ66QU2EMDPF3DJ2IFHNTQIGHNC2STOGTWF75E%2F20241112%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20241112T041539Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=c893064303dea6e1d27704a684368f80c81d0315c723dc67ed374416f4387123",
            "html": null,
            "markdown": null
          }
        ],
        "chunk_length": 304
      }
    ],
    "extracted_json": {
      "title": "Document Metadata",
      "schema_type": "object",
      "extracted_fields": [
        {
          "name": "title",
          "field_type": "string",
          "value": "```json\n{\n \"title\": \"Kerncraft: A Tool for Analytic Performance Modeling of Loop Kernels\"\n}\n```"
        },
        {
          "name": "author",
          "field_type": "string",
          "value": "J. Hammer, J. Eitzinger, G. Hager, and G. Wellein\n"
        },
        {
          "name": "date_published",
          "field_type": "string",
          "value": "2017\n"
        },
        {
          "name": "location",
          "field_type": "string",
          "value": "Germany\n"
        }
      ]
    }
  }
}