/*
 * Chunkr API
 *
 * API service for document layout analysis and chunking to convert document into RAG/LLM-ready data.
 *
 * The version of the OpenAPI document: 1.0.0
 * Contact: ishaan@lumina.sh
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct Chunk {
    /// The unique identifier for the chunk.
    #[serde(rename = "chunk_id", skip_serializing_if = "Option::is_none")]
    pub chunk_id: Option<String>,
    /// The total number of tokens in the chunk. Calculated by the `tokenizer`.
    #[serde(rename = "chunk_length")]
    pub chunk_length: i32,
    /// Suggested text to be embedded for the chunk. This text is generated by combining the embed content from each segment according to the configured embed sources (HTML, Markdown, LLM, or Content). Can be configured using `embed_sources` in the `SegmentProcessing` configuration.
    #[serde(rename = "embed", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub embed: Option<Option<String>>,
    /// Collection of document segments that form this chunk. When `target_chunk_length` > 0, contains the maximum number of segments that fit within that length (segments remain intact). Otherwise, contains exactly one segment.
    #[serde(rename = "segments")]
    pub segments: Vec<models::Segment>,
}

impl Chunk {
    pub fn new(chunk_length: i32, segments: Vec<models::Segment>) -> Chunk {
        Chunk {
            chunk_id: None,
            chunk_length,
            embed: None,
            segments,
        }
    }
}

