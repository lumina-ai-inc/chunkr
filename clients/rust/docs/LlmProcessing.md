# LlmProcessing

## Properties

Name | Type | Description | Notes
------------ | ------------- | ------------- | -------------
**fallback_strategy** | Option<[**models::LlmProcessingFallbackStrategy**](LlmProcessing_fallback_strategy.md)> |  | [optional]
**max_completion_tokens** | Option<**i32**> | The maximum number of tokens to generate. | [optional]
**model_id** | Option<**String**> | The ID of the model to use for the task. If not provided, the default model will be used. Please check the documentation for the model you want to use. | [optional]
**temperature** | Option<**f32**> | The temperature to use for the LLM. | [optional]

[[Back to Model list]](../README.md#documentation-for-models) [[Back to API list]](../README.md#documentation-for-api-endpoints) [[Back to README]](../README.md)


