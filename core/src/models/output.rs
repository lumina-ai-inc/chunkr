use crate::models::{search::SimpleChunk, task::Configuration};
use crate::utils::services::html::extract_cells_from_ranges;
use crate::utils::services::renderer::Capture;
use opentelemetry::trace::{Span, TraceContextExt, Tracer};
use postgres_types::{FromSql, ToSql};
use rayon::prelude::*;
use serde::{Deserialize, Serialize};
use std::error::Error;
use strum_macros::{Display, EnumString};
use thiserror::Error as ThisError;
use tiktoken_rs::cl100k_base;
use tokenizers::tokenizer::Tokenizer;
use utoipa::ToSchema;

#[derive(Debug, Clone, ThisError)]
pub enum SegmentCreationError {
    #[error("No bounding box: {0}")]
    NoBoundingBox(String),
    #[error("No image found: {0}")]
    NoImageFound(String),
    #[error("Cell extraction failed: {0}")]
    CellExtractionFailed(String),
    #[error("Other error: {0}")]
    Other(String),
}

/// Extract the alt text from an img tag HTML string
fn extract_alt_text_from_img(html: &str) -> Option<String> {
    // Simple regex-like extraction of alt text from img tag
    if let Some(alt_start) = html.find("alt=\"") {
        let alt_content_start = alt_start + 5; // "alt=\"".len()
        if let Some(alt_end) = html[alt_content_start..].find('"') {
            let alt_text = &html[alt_content_start..alt_content_start + alt_end];
            if !alt_text.is_empty() {
                return Some(alt_text.to_string());
            }
        }
    }

    // Try with single quotes
    if let Some(alt_start) = html.find("alt='") {
        let alt_content_start = alt_start + 5; // "alt='".len()
        if let Some(alt_end) = html[alt_content_start..].find('\'') {
            let alt_text = &html[alt_content_start..alt_content_start + alt_end];
            if !alt_text.is_empty() {
                return Some(alt_text.to_string());
            }
        }
    }

    None
}

fn generate_uuid() -> String {
    uuid::Uuid::new_v4().to_string()
}

fn generate_string() -> String {
    String::new()
}

#[derive(Serialize, Deserialize, Debug, Clone, ToSchema, Default)]
/// The processed results of a document analysis task
pub struct OutputResponse {
    /// Collection of document chunks, where each chunk contains one or more segments
    pub chunks: Vec<Chunk>,
    /// The name of the file.
    pub file_name: Option<String>,
    /// The MIME type of the file.
    pub mime_type: Option<String>,
    /// The pages of the file. Includes the image and metadata for each page.
    pub pages: Option<Vec<Page>>,
    /// The number of pages in the file.
    pub page_count: Option<u32>,
    /// The presigned URL of the PDF file.
    pub pdf_url: Option<String>,
    #[deprecated]
    /// The extracted JSON from the document.
    pub extracted_json: Option<serde_json::Value>,
}

#[derive(Serialize, Deserialize, Debug, Clone, ToSchema)]
pub struct Page {
    /// The presigned URL of the page/sheet image.
    pub image: String,
    /// The number of pages in the file.
    pub page_number: u32,
    /// The number of pages in the file.
    pub page_height: f32,
    /// The number of pages in the file.
    pub page_width: f32,
    /// The name of the sheet containing the page. Only used for Spreadsheets.
    pub ss_sheet_name: Option<String>,
}

#[derive(Serialize, Deserialize, Debug, Clone, ToSchema)]
pub struct Chunk {
    #[serde(default = "generate_uuid")]
    /// The unique identifier for the chunk.
    pub chunk_id: String,
    /// The total number of tokens in the chunk. Calculated by the `tokenizer`.
    pub chunk_length: u32,
    /// Collection of document segments that form this chunk.
    /// When `target_chunk_length` > 0, contains the maximum number of segments
    /// that fit within that length (segments remain intact).
    /// Otherwise, contains exactly one segment.
    pub segments: Vec<Segment>,
    /// Suggested text to be embedded for the chunk. This text is generated by combining the embed content
    /// from each segment according to the configured embed sources (HTML, Markdown, LLM, or Content).
    /// Can be configured using `embed_sources` in the `SegmentProcessing` configuration.
    pub embed: Option<String>,
}

impl Chunk {
    pub fn new(segments: Vec<Segment>) -> Self {
        let chunk_id = uuid::Uuid::new_v4().to_string();
        Self {
            chunk_id,
            chunk_length: 0,
            segments,
            embed: None,
        }
    }

    pub fn generate_embed_text(&mut self, configuration: &Configuration) {
        // Collect embed content from segments (should already be set)
        let embed_contents: Vec<String> = self
            .segments
            .iter()
            .filter_map(|s| s.embed.clone())
            .collect();

        self.embed = Some(embed_contents.join("\n"));

        // Calculate chunk length from segment embed lengths
        self.chunk_length = self
            .segments
            .iter()
            .map(|s| s.get_embed_length(configuration).unwrap_or(0))
            .sum();
    }

    /// Converts this Chunk into a SimpleChunk, containing just the ID and embed content
    pub fn to_simple(&self) -> std::result::Result<SimpleChunk, Box<dyn Error + Send + Sync>> {
        if self.embed.is_none() {
            return Err("Embed is not generated".into());
        }

        Ok(SimpleChunk {
            id: self.chunk_id.clone(),
            content: self.embed.clone().unwrap_or_default().to_string(),
        })
    }
}

#[derive(Serialize, Deserialize, Debug, Clone, ToSchema, PartialEq, Eq, EnumString, Display)]
#[strum(serialize_all = "lowercase")]
pub enum Alignment {
    Left,
    Center,
    Right,
    Justify,
}

#[derive(Serialize, Deserialize, Debug, Clone, ToSchema, PartialEq, Eq, EnumString, Display)]
#[strum(serialize_all = "lowercase")]
pub enum VerticalAlignment {
    Top,
    Middle,
    Bottom,
    Baseline,
}

#[derive(Serialize, Deserialize, Debug, Clone, ToSchema)]
pub struct CellStyle {
    /// Background color of the cell (e.g., "#FFFFFF" or "#DAE3F3").
    pub bg_color: Option<String>,
    /// Text color of the cell (e.g., "#000000" or "red").
    pub text_color: Option<String>,
    /// Font face/family of the cell (e.g., "Arial", "Daytona").
    pub font_face: Option<String>,
    /// Whether the cell content is bold.
    pub is_bold: Option<bool>,
    /// Alignment of the cell content.
    pub align: Option<Alignment>,
    /// Vertical alignment of the cell content.
    pub valign: Option<VerticalAlignment>,
}

impl Default for CellStyle {
    fn default() -> Self {
        Self::new()
    }
}

impl CellStyle {
    pub fn new() -> Self {
        Self {
            bg_color: None,
            text_color: None,
            font_face: None,
            is_bold: None,
            align: None,
            valign: None,
        }
    }

    pub fn with_colors(bg_color: Option<String>, text_color: Option<String>) -> Self {
        Self {
            bg_color,
            text_color,
            font_face: None,
            is_bold: None,
            align: None,
            valign: None,
        }
    }
}

#[derive(Serialize, Deserialize, Debug, Clone, ToSchema)]
pub struct Cell {
    /// The cell ID.
    pub cell_id: String,
    /// Text content of the cell.
    pub text: String,
    /// Range of the cell.
    pub range: String,
    /// Formula of the cell.
    pub formula: Option<String>,
    /// The computed/evaluated value of the cell. This represents the actual result after evaluating any formulas,
    /// as opposed to the raw text content. For cells with formulas, this is the calculated result;
    /// for cells with static content, this is typically the same as the text field.
    ///
    /// Example: text might show "3.14" (formatted to 2 decimal places) while value could be "3.141592653589793" (full precision).
    pub value: Option<String>,
    /// Hyperlink URL if the cell contains a link (e.g., "https://www.chunkr.ai").
    pub hyperlink: Option<String>,
    /// Styling information for the cell including colors, fonts, and formatting.
    pub style: Option<CellStyle>,
}

impl Cell {
    pub fn new(
        text: String,
        range: String,
        formula: Option<String>,
        value: Option<String>,
    ) -> Self {
        let cell_id = generate_uuid();
        Self {
            cell_id,
            text,
            range,
            formula,
            value,
            hyperlink: None,
            style: None,
        }
    }

    pub fn new_with_style(
        text: String,
        range: String,
        formula: Option<String>,
        value: Option<String>,
        hyperlink: Option<String>,
        style: Option<CellStyle>,
    ) -> Self {
        let cell_id = generate_uuid();
        Self {
            cell_id,
            text,
            range,
            formula,
            value,
            hyperlink,
            style,
        }
    }
}

#[derive(Serialize, Deserialize, Debug, Clone, ToSchema)]
pub struct Segment {
    pub bbox: BoundingBox,
    /// Confidence score of the layout analysis model
    pub confidence: Option<f32>,
    /// Content of the segment, will be either HTML or Markdown, depending on format chosen.
    #[serde(default = "generate_string")]
    pub content: String,
    /// Description of the segment, generated by the LLM.
    pub description: Option<String>,
    /// Embeddable content of the segment.
    pub embed: Option<String>,
    /// HTML representation of the segment.
    #[serde(default = "generate_string")]
    pub html: String,
    /// Presigned URL to the image of the segment.
    pub image: Option<String>,
    /// LLM representation of the segment.
    pub llm: Option<String>,
    #[serde(default = "generate_string")]
    /// Markdown representation of the segment.
    pub markdown: String,
    /// OCR results for the segment.
    pub ocr: Option<Vec<OCRResult>>,
    /// Height of the page/sheet containing the segment.
    pub page_height: f32,
    /// Width of the page/sheet containing the segment.
    pub page_width: f32,
    /// Page number/Sheet number of the segment.
    pub page_number: u32,
    /// Unique identifier for the segment.
    pub segment_id: String,
    pub segment_type: SegmentType,
    /// Length of the segment in tokens.
    pub segment_length: Option<u32>,
    /// Cells of the segment. Only used for Spreadsheets.
    pub ss_cells: Option<Vec<Cell>>,
    /// Bounding box of the header of the segment, if found. Only used for Spreadsheets.
    pub ss_header_bbox: Option<BoundingBox>,
    /// OCR results of the header of the segment, if found. Only used for Spreadsheets.
    pub ss_header_ocr: Option<Vec<OCRResult>>,
    /// Text content of the header of the segment, if found. Only used for Spreadsheets.
    pub ss_header_text: Option<String>,
    /// Header range of the segment, if found.
    /// The header can have overlap with the `segment.range` if the table contains the header,
    /// if the header is located in a different sheet, the header range will have no overlap with the `segment.range`.
    /// Only used for Spreadsheets.
    pub ss_header_range: Option<String>,
    /// Range of the segment in Excel notation (e.g., A1:B5). Only used for Spreadsheets.
    pub ss_range: Option<String>,
    /// Name of the sheet containing the segment. Only used for Spreadsheets.
    pub ss_sheet_name: Option<String>,
    /// Text content of the segment. Calculated by the OCR results.
    #[serde(default = "generate_string")]
    pub text: String,
}

impl Segment {
    pub fn new(
        bbox: BoundingBox,
        confidence: Option<f32>,
        ocr_results: Vec<OCRResult>,
        page_height: f32,
        page_width: f32,
        page_number: u32,
        segment_type: SegmentType,
    ) -> Self {
        let segment_id = generate_uuid();
        let text = ocr_results
            .iter()
            .map(|ocr_result| ocr_result.text.clone())
            .collect::<Vec<String>>()
            .join(" ");
        Self {
            bbox,
            confidence,
            content: String::new(),
            description: None,
            embed: None,
            llm: None,
            page_height,
            page_number,
            page_width,
            segment_id,
            segment_type,
            segment_length: None,
            ss_cells: None,
            ss_header_bbox: None,
            ss_header_ocr: None,
            ss_header_text: None,
            ss_header_range: None,
            ss_range: None,
            ss_sheet_name: None,
            ocr: Some(ocr_results),
            image: None,
            html: String::new(),
            markdown: String::new(),
            text,
        }
    }

    // Helper method to convert cells to OCR results
    fn cells_to_ocr_results(
        cells: &[Cell],
        capture: &Capture,
    ) -> Result<Vec<OCRResult>, Box<dyn Error + Send + Sync>> {
        cells
            .par_iter()
            .map(|cell| {
                let cell_ref_attr = format!("data-cell-ref=\"{}\"", cell.range);
                capture
                    .elements
                    .par_iter()
                    .find(|element| {
                        let has_cell_ref = element.html.contains(&cell_ref_attr);
                        let is_table_cell =
                            element.html.starts_with("<td") || element.html.starts_with("<th");
                        has_cell_ref && is_table_cell
                    })
                    .map(|element| OCRResult {
                        bbox: element.bbox.clone(),
                        text: cell.text.clone(),
                        confidence: Some(1.0),
                    })
                    .ok_or("No cell found".into())
            })
            .collect::<Result<Vec<OCRResult>, Box<dyn Error + Send + Sync>>>()
    }

    // Helper method to calculate bounding box from OCR results
    fn calculate_bbox_from_ocr(
        ocr_results: &[OCRResult],
    ) -> Result<BoundingBox, Box<dyn Error + Send + Sync>> {
        if ocr_results.is_empty() {
            return Err("OCR results are empty, can't calculate bbox".into());
        }

        // Filter out OCR results with NaN or infinite coordinates
        let valid_ocr_results: Vec<_> = ocr_results
            .iter()
            .filter(|ocr| {
                ocr.bbox.left.is_finite()
                    && ocr.bbox.top.is_finite()
                    && ocr.bbox.width.is_finite()
                    && ocr.bbox.height.is_finite()
                    && ocr.bbox.width >= 0.0
                    && ocr.bbox.height >= 0.0
            })
            .collect();

        if valid_ocr_results.is_empty() {
            return Err("No valid OCR results with finite coordinates found".into());
        }

        let min_left = valid_ocr_results
            .iter()
            .map(|ocr| ocr.bbox.left)
            .fold(f32::INFINITY, f32::min);
        let min_top = valid_ocr_results
            .iter()
            .map(|ocr| ocr.bbox.top)
            .fold(f32::INFINITY, f32::min);
        let max_right = valid_ocr_results
            .iter()
            .map(|ocr| ocr.bbox.left + ocr.bbox.width)
            .fold(f32::NEG_INFINITY, f32::max);
        let max_bottom = valid_ocr_results
            .iter()
            .map(|ocr| ocr.bbox.top + ocr.bbox.height)
            .fold(f32::NEG_INFINITY, f32::max);

        Ok(BoundingBox::new(
            min_left,
            min_top,
            max_right - min_left,
            max_bottom - min_top,
        ))
    }

    // Helper method to make OCR results relative to a bounding box
    fn make_ocr_relative(
        ocr_results: Vec<OCRResult>,
        reference_bbox: &BoundingBox,
    ) -> Vec<OCRResult> {
        ocr_results
            .into_iter()
            .map(|mut ocr_result| {
                ocr_result.bbox.left -= reference_bbox.left;
                ocr_result.bbox.top -= reference_bbox.top;
                ocr_result
            })
            .collect()
    }

    // Helper method to convert OCR results to text
    fn ocr_results_to_text(ocr_results: &[OCRResult]) -> String {
        ocr_results
            .iter()
            .map(|ocr_result| ocr_result.text.clone())
            .collect::<Vec<String>>()
            .join(" ")
    }

    // Helper method to adjust cell range by adding offset back
    pub fn adjust_cell_range(
        range: &str,
        row_offset: u32,
        col_offset: u32,
    ) -> Result<String, Box<dyn Error + Send + Sync>> {
        use crate::utils::services::html::{indices_to_range, parse_range};

        let indices = parse_range(range)?;
        let adjusted_indices = crate::models::pipeline::Indices {
            start_row: indices.start_row + row_offset as usize,
            start_col: indices.start_col + col_offset as usize,
            end_row: indices.end_row + row_offset as usize,
            end_col: indices.end_col + col_offset as usize,
        };
        Ok(indices_to_range(&adjusted_indices))
    }

    #[allow(clippy::too_many_arguments)]
    pub fn new_from_elements(
        segment_id: String,
        confidence: Option<f32>,
        header_range: Option<String>,
        page_height: f32,
        page_width: f32,
        page_number: u32,
        range: Option<String>,
        sheet_name: String,
        sheet_html: String,
        capture: Capture,
        segment_type: SegmentType,
        tracer: &opentelemetry::global::BoxedTracer,
        context: &opentelemetry::Context,
    ) -> Result<Self, SegmentCreationError> {
        let mut span = tracer.start_with_context(
            crate::configs::otel_config::SpanName::CreateSegmentFromTables.to_string(),
            context,
        );
        span.set_attribute(opentelemetry::KeyValue::new(
            "segment_id",
            segment_id.clone(),
        ));
        span.set_attribute(opentelemetry::KeyValue::new(
            "sheet_name",
            sheet_name.clone(),
        ));
        if let Some(ref range) = range {
            span.set_attribute(opentelemetry::KeyValue::new("table_range", range.clone()));
        }
        if let Some(ref header_range) = header_range {
            span.set_attribute(opentelemetry::KeyValue::new(
                "header_range",
                header_range.clone(),
            ));
        }

        let segment_context = context.with_span(span);
        let header_cells = if let Some(ref header_range) = header_range {
            let mut extract_span = tracer.start_with_context(
                crate::configs::otel_config::SpanName::ExtractCellsFromRanges.to_string(),
                &segment_context,
            );
            extract_span.set_attribute(opentelemetry::KeyValue::new("range_type", "header"));
            extract_span.set_attribute(opentelemetry::KeyValue::new("range", header_range.clone()));

            let result =
                extract_cells_from_ranges(&sheet_html, None, Some(header_range)).map_err(|e| {
                    let error =
                        SegmentCreationError::CellExtractionFailed(format!("Header cells: {e}"));
                    extract_span.set_status(opentelemetry::trace::Status::error(error.to_string()));
                    extract_span
                        .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
                    segment_context
                        .span()
                        .set_status(opentelemetry::trace::Status::error(error.to_string()));
                    segment_context
                        .span()
                        .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
                    error
                });

            if let Ok(ref cells) = result {
                extract_span.set_attribute(opentelemetry::KeyValue::new(
                    "cells_extracted",
                    cells.len() as i64,
                ));
            }
            extract_span.end();
            result?
        } else {
            Vec::new()
        };

        let table_cells = if let Some(ref table_range) = range {
            let mut extract_span = tracer.start_with_context(
                crate::configs::otel_config::SpanName::ExtractCellsFromRanges.to_string(),
                &segment_context,
            );
            extract_span.set_attribute(opentelemetry::KeyValue::new("range_type", "table"));
            extract_span.set_attribute(opentelemetry::KeyValue::new("range", table_range.clone()));

            let result =
                extract_cells_from_ranges(&sheet_html, Some(table_range), None).map_err(|e| {
                    let error =
                        SegmentCreationError::CellExtractionFailed(format!("Table cells: {e}"));
                    extract_span.set_status(opentelemetry::trace::Status::error(error.to_string()));
                    extract_span
                        .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
                    segment_context
                        .span()
                        .set_status(opentelemetry::trace::Status::error(error.to_string()));
                    segment_context
                        .span()
                        .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
                    error
                });

            if let Ok(ref cells) = result {
                extract_span.set_attribute(opentelemetry::KeyValue::new(
                    "cells_extracted",
                    cells.len() as i64,
                ));
            }
            extract_span.end();
            result?
        } else {
            let error = SegmentCreationError::Other("No table range found".to_string());
            segment_context
                .span()
                .set_status(opentelemetry::trace::Status::error(error.to_string()));
            segment_context
                .span()
                .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
            segment_context.span().end();
            return Err(error);
        };

        // Combine all cells (header + non-overlapping table cells)
        let mut all_cells = header_cells.clone();
        all_cells.extend(table_cells.clone());

        // Filter out cells that have duplicate ranges
        let mut seen_ranges = std::collections::HashSet::new();
        let filtered_cells: Vec<Cell> = all_cells
            .into_iter()
            .filter(|cell| seen_ranges.insert(cell.range.clone()))
            .collect();

        // Create OCR results from table and header cells
        let mut ocr_span = tracer.start_with_context(
            crate::configs::otel_config::SpanName::CellsToOcrResults.to_string(),
            &segment_context,
        );
        ocr_span.set_attribute(opentelemetry::KeyValue::new("cells_type", "table"));
        ocr_span.set_attribute(opentelemetry::KeyValue::new(
            "cells_count",
            table_cells.len() as i64,
        ));

        let ocr_results = Self::cells_to_ocr_results(&table_cells, &capture).map_err(|e| {
            let error = SegmentCreationError::Other(format!("Table OCR conversion: {e}"));
            ocr_span.set_status(opentelemetry::trace::Status::error(error.to_string()));
            ocr_span.set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
            segment_context
                .span()
                .set_status(opentelemetry::trace::Status::error(error.to_string()));
            segment_context
                .span()
                .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
            error
        });

        if let Ok(ref results) = ocr_results {
            ocr_span.set_attribute(opentelemetry::KeyValue::new(
                "ocr_results_count",
                results.len() as i64,
            ));
        }
        ocr_span.end();
        let ocr_results = ocr_results?;
        let header_ocr_results = if !header_cells.is_empty() {
            let mut header_ocr_span = tracer.start_with_context(
                crate::configs::otel_config::SpanName::CellsToOcrResults.to_string(),
                &segment_context,
            );
            header_ocr_span.set_attribute(opentelemetry::KeyValue::new("cells_type", "header"));
            header_ocr_span.set_attribute(opentelemetry::KeyValue::new(
                "cells_count",
                header_cells.len() as i64,
            ));

            let result = Self::cells_to_ocr_results(&header_cells, &capture).map_err(|e| {
                let error = SegmentCreationError::Other(format!("Header OCR conversion: {e}"));
                header_ocr_span.set_status(opentelemetry::trace::Status::error(error.to_string()));
                header_ocr_span
                    .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
                segment_context
                    .span()
                    .set_status(opentelemetry::trace::Status::error(error.to_string()));
                segment_context
                    .span()
                    .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
                error
            });

            if let Ok(ref results) = result {
                header_ocr_span.set_attribute(opentelemetry::KeyValue::new(
                    "ocr_results_count",
                    results.len() as i64,
                ));
            }
            header_ocr_span.end();
            Some(result?)
        } else {
            None
        };

        let mut bbox_span = tracer.start_with_context(
            crate::configs::otel_config::SpanName::CalculateBboxFromOcr.to_string(),
            &segment_context,
        );
        bbox_span.set_attribute(opentelemetry::KeyValue::new("bbox_type", "table"));
        bbox_span.set_attribute(opentelemetry::KeyValue::new(
            "ocr_results_count",
            ocr_results.len() as i64,
        ));

        let bbox = Self::calculate_bbox_from_ocr(&ocr_results).map_err(|e| {
            let error = SegmentCreationError::NoBoundingBox(format!(
                "Table bbox calculation for range {}: {}",
                range.as_deref().unwrap_or_default(),
                e
            ));
            bbox_span.set_status(opentelemetry::trace::Status::error(error.to_string()));
            bbox_span.set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
            segment_context
                .span()
                .set_status(opentelemetry::trace::Status::error(error.to_string()));
            segment_context
                .span()
                .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
            error
        });

        if let Ok(ref bb) = bbox {
            bbox_span.set_attribute(opentelemetry::KeyValue::new(
                "bbox_left",
                bb.left.to_string(),
            ));
            bbox_span.set_attribute(opentelemetry::KeyValue::new("bbox_top", bb.top.to_string()));
            bbox_span.set_attribute(opentelemetry::KeyValue::new(
                "bbox_width",
                bb.width.to_string(),
            ));
            bbox_span.set_attribute(opentelemetry::KeyValue::new(
                "bbox_height",
                bb.height.to_string(),
            ));
        }
        bbox_span.end();
        let bbox = bbox?;

        let mut relative_span = tracer.start_with_context(
            crate::configs::otel_config::SpanName::MakeOcrRelative.to_string(),
            &segment_context,
        );
        relative_span.set_attribute(opentelemetry::KeyValue::new("ocr_type", "table"));
        relative_span.set_attribute(opentelemetry::KeyValue::new(
            "ocr_results_count",
            ocr_results.len() as i64,
        ));
        let relative_ocr_results = Self::make_ocr_relative(ocr_results, &bbox);
        relative_span.end();

        let text = Self::ocr_results_to_text(&relative_ocr_results);

        let (header_bbox, relative_header_ocr, header_text) = if let Some(header_ocr) =
            header_ocr_results
        {
            let mut header_bbox_span = tracer.start_with_context(
                crate::configs::otel_config::SpanName::CalculateBboxFromOcr.to_string(),
                &segment_context,
            );
            header_bbox_span.set_attribute(opentelemetry::KeyValue::new("bbox_type", "header"));
            header_bbox_span.set_attribute(opentelemetry::KeyValue::new(
                "ocr_results_count",
                header_ocr.len() as i64,
            ));

            let header_bbox = Self::calculate_bbox_from_ocr(&header_ocr).map_err(|e| {
                let error = SegmentCreationError::NoBoundingBox(format!(
                    "Header bbox calculation for range {}: {}",
                    header_range.as_deref().unwrap_or_default(),
                    e
                ));
                header_bbox_span.set_status(opentelemetry::trace::Status::error(error.to_string()));
                header_bbox_span
                    .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
                segment_context
                    .span()
                    .set_status(opentelemetry::trace::Status::error(error.to_string()));
                segment_context
                    .span()
                    .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
                error
            });

            if let Ok(ref hb) = header_bbox {
                header_bbox_span.set_attribute(opentelemetry::KeyValue::new(
                    "bbox_left",
                    hb.left.to_string(),
                ));
                header_bbox_span
                    .set_attribute(opentelemetry::KeyValue::new("bbox_top", hb.top.to_string()));
                header_bbox_span.set_attribute(opentelemetry::KeyValue::new(
                    "bbox_width",
                    hb.width.to_string(),
                ));
                header_bbox_span.set_attribute(opentelemetry::KeyValue::new(
                    "bbox_height",
                    hb.height.to_string(),
                ));
            }
            header_bbox_span.end();
            let header_bbox = header_bbox?;

            let mut header_relative_span = tracer.start_with_context(
                crate::configs::otel_config::SpanName::MakeOcrRelative.to_string(),
                &segment_context,
            );
            header_relative_span.set_attribute(opentelemetry::KeyValue::new("ocr_type", "header"));
            header_relative_span.set_attribute(opentelemetry::KeyValue::new(
                "ocr_results_count",
                header_ocr.len() as i64,
            ));
            let relative_header_ocr = Self::make_ocr_relative(header_ocr, &bbox);
            header_relative_span.end();

            let header_text = Self::ocr_results_to_text(&relative_header_ocr);
            (
                Some(header_bbox),
                Some(relative_header_ocr),
                Some(header_text),
            )
        } else {
            (None, None, None)
        };

        segment_context
            .span()
            .set_attribute(opentelemetry::KeyValue::new(
                "cells_count",
                filtered_cells.len() as i64,
            ));
        segment_context.span().end();

        Ok(Self {
            bbox,
            confidence,
            content: String::new(),
            description: None,
            embed: None,
            llm: None,
            page_height,
            page_number,
            page_width,
            segment_id,
            segment_type,
            segment_length: None,
            ss_cells: Some(filtered_cells),
            ss_header_range: header_range,
            ss_header_bbox: header_bbox,
            ss_header_ocr: relative_header_ocr,
            ss_header_text: header_text,
            ss_sheet_name: Some(sheet_name),
            ss_range: range,
            ocr: Some(relative_ocr_results),
            image: None,
            html: String::new(),
            markdown: String::new(),
            text,
        })
    }

    #[allow(clippy::too_many_arguments)]
    pub fn new_from_images(
        segment_id: String,
        confidence: Option<f32>,
        page_height: f32,
        page_width: f32,
        page_number: u32,
        range: String,
        sheet_name: String,
        sheet_html: String,
        capture: Capture,
        html_reference: String,
        tracer: &opentelemetry::global::BoxedTracer,
        context: &opentelemetry::Context,
    ) -> Result<Self, SegmentCreationError> {
        let mut span = tracer.start_with_context(
            crate::configs::otel_config::SpanName::CreateSegmentFromImages.to_string(),
            context,
        );
        span.set_attribute(opentelemetry::KeyValue::new(
            "segment_id",
            segment_id.clone(),
        ));
        span.set_attribute(opentelemetry::KeyValue::new(
            "sheet_name",
            sheet_name.clone(),
        ));
        span.set_attribute(opentelemetry::KeyValue::new("range", range.clone()));
        span.set_attribute(opentelemetry::KeyValue::new(
            "html_reference",
            html_reference.clone(),
        ));

        let segment_context = context.with_span(span);

        let mut extract_span = tracer.start_with_context(
            crate::configs::otel_config::SpanName::ExtractCellsFromRanges.to_string(),
            &segment_context,
        );
        extract_span.set_attribute(opentelemetry::KeyValue::new("range_type", "image"));
        extract_span.set_attribute(opentelemetry::KeyValue::new("range", range.clone()));

        let cells = {
            let result = extract_cells_from_ranges(&sheet_html, Some(&range), None).map_err(|e| {
                let error = SegmentCreationError::CellExtractionFailed(format!("Image cells: {e}"));
                extract_span.set_status(opentelemetry::trace::Status::error(error.to_string()));
                extract_span
                    .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
                segment_context
                    .span()
                    .set_status(opentelemetry::trace::Status::error(error.to_string()));
                segment_context
                    .span()
                    .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
                error
            });

            if let Ok(ref cells) = result {
                extract_span.set_attribute(opentelemetry::KeyValue::new(
                    "cells_extracted",
                    cells.len() as i64,
                ));
            }
            extract_span.end();
            result?
        };

        // Find the img tag element in the capture using the html reference
        let mut find_image_span = tracer.start_with_context(
            crate::configs::otel_config::SpanName::FindImageElement.to_string(),
            &segment_context,
        );
        find_image_span.set_attribute(opentelemetry::KeyValue::new(
            "html_reference",
            html_reference.clone(),
        ));
        find_image_span.set_attribute(opentelemetry::KeyValue::new(
            "elements_count",
            capture.elements.len() as i64,
        ));

        let image_result = capture
            .elements
            .par_iter()
            .find(|element| {
                element.html.starts_with("<img") && element.html.contains(&html_reference)
            })
            .map(|element| {
                (
                    element.bbox.clone(),
                    extract_alt_text_from_img(&element.html).unwrap_or_default(),
                )
            })
            .ok_or_else(|| {
                let error = SegmentCreationError::NoImageFound(format!(
                    "No img tag found with reference: {html_reference}"
                ));
                find_image_span.set_status(opentelemetry::trace::Status::error(error.to_string()));
                find_image_span
                    .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
                segment_context
                    .span()
                    .set_status(opentelemetry::trace::Status::error(error.to_string()));
                segment_context
                    .span()
                    .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
                error
            });

        if let Ok((ref bb, ref alt)) = image_result {
            find_image_span.set_attribute(opentelemetry::KeyValue::new("image_found", true));
            find_image_span.set_attribute(opentelemetry::KeyValue::new(
                "bbox_left",
                bb.left.to_string(),
            ));
            find_image_span
                .set_attribute(opentelemetry::KeyValue::new("bbox_top", bb.top.to_string()));
            find_image_span.set_attribute(opentelemetry::KeyValue::new(
                "bbox_width",
                bb.width.to_string(),
            ));
            find_image_span.set_attribute(opentelemetry::KeyValue::new(
                "bbox_height",
                bb.height.to_string(),
            ));
            find_image_span.set_attribute(opentelemetry::KeyValue::new(
                "has_alt_text",
                !alt.is_empty(),
            ));
        }
        find_image_span.end();
        let (bbox, alt_text) = image_result?;

        segment_context
            .span()
            .set_attribute(opentelemetry::KeyValue::new(
                "cells_count",
                cells.len() as i64,
            ));
        segment_context.span().end();

        Ok(Self {
            bbox,
            confidence,
            content: String::new(),
            description: None,
            embed: None,
            ss_cells: Some(cells),
            ss_header_range: None,
            ss_header_text: None,
            llm: None,
            page_height,
            page_number,
            page_width,
            segment_id,
            segment_type: SegmentType::Picture,
            segment_length: None,
            ss_header_bbox: None,
            ss_header_ocr: None,
            ss_sheet_name: Some(sheet_name),
            ss_range: Some(range),
            ocr: None, // Images don't have OCR results
            image: None,
            html: String::new(),
            markdown: String::new(),
            text: alt_text,
        })
    }

    #[allow(clippy::too_many_arguments)]
    pub fn new_from_remaining_cells(
        segment_id: String,
        confidence: Option<f32>,
        page_height: f32,
        page_width: f32,
        page_number: u32,
        range: String,
        sheet_name: String,
        capture: Capture,
        cells: Vec<Cell>,
        tracer: &opentelemetry::global::BoxedTracer,
        context: &opentelemetry::Context,
    ) -> Result<Self, SegmentCreationError> {
        let mut span = tracer.start_with_context(
            crate::configs::otel_config::SpanName::CreateSegmentFromRemainingCells.to_string(),
            context,
        );
        span.set_attribute(opentelemetry::KeyValue::new(
            "segment_id",
            segment_id.clone(),
        ));
        span.set_attribute(opentelemetry::KeyValue::new(
            "sheet_name",
            sheet_name.clone(),
        ));
        span.set_attribute(opentelemetry::KeyValue::new("range", range.clone()));
        span.set_attribute(opentelemetry::KeyValue::new(
            "cells_count",
            cells.len() as i64,
        ));

        let segment_context = context.with_span(span);

        let mut ocr_span = tracer.start_with_context(
            crate::configs::otel_config::SpanName::CellsToOcrResults.to_string(),
            &segment_context,
        );
        ocr_span.set_attribute(opentelemetry::KeyValue::new("cells_type", "remaining"));
        ocr_span.set_attribute(opentelemetry::KeyValue::new(
            "cells_count",
            cells.len() as i64,
        ));

        let ocr_results = Self::cells_to_ocr_results(&cells, &capture).map_err(|e| {
            let error = SegmentCreationError::Other(format!("Remaining cells OCR conversion: {e}"));
            ocr_span.set_status(opentelemetry::trace::Status::error(error.to_string()));
            ocr_span.set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
            segment_context
                .span()
                .set_status(opentelemetry::trace::Status::error(error.to_string()));
            segment_context
                .span()
                .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
            error
        });

        if let Ok(ref results) = ocr_results {
            ocr_span.set_attribute(opentelemetry::KeyValue::new(
                "ocr_results_count",
                results.len() as i64,
            ));
        }
        ocr_span.end();
        let ocr_results = ocr_results?;

        let mut bbox_span = tracer.start_with_context(
            crate::configs::otel_config::SpanName::CalculateBboxFromOcr.to_string(),
            &segment_context,
        );
        bbox_span.set_attribute(opentelemetry::KeyValue::new("bbox_type", "remaining_cells"));
        bbox_span.set_attribute(opentelemetry::KeyValue::new(
            "ocr_results_count",
            ocr_results.len() as i64,
        ));

        let bbox = Self::calculate_bbox_from_ocr(&ocr_results.clone()).map_err(|e| {
            let error = SegmentCreationError::NoBoundingBox(format!(
                "Remaining cells bbox calculation: {e}"
            ));
            bbox_span.set_status(opentelemetry::trace::Status::error(error.to_string()));
            bbox_span.set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
            segment_context
                .span()
                .set_status(opentelemetry::trace::Status::error(error.to_string()));
            segment_context
                .span()
                .set_attribute(opentelemetry::KeyValue::new("error", error.to_string()));
            error
        });

        if let Ok(ref bb) = bbox {
            bbox_span.set_attribute(opentelemetry::KeyValue::new(
                "bbox_left",
                bb.left.to_string(),
            ));
            bbox_span.set_attribute(opentelemetry::KeyValue::new("bbox_top", bb.top.to_string()));
            bbox_span.set_attribute(opentelemetry::KeyValue::new(
                "bbox_width",
                bb.width.to_string(),
            ));
            bbox_span.set_attribute(opentelemetry::KeyValue::new(
                "bbox_height",
                bb.height.to_string(),
            ));
        }
        bbox_span.end();
        let bbox = bbox?;

        let mut relative_span = tracer.start_with_context(
            crate::configs::otel_config::SpanName::MakeOcrRelative.to_string(),
            &segment_context,
        );
        relative_span.set_attribute(opentelemetry::KeyValue::new("ocr_type", "remaining_cells"));
        relative_span.set_attribute(opentelemetry::KeyValue::new(
            "ocr_results_count",
            ocr_results.len() as i64,
        ));
        let relative_ocr_results = Self::make_ocr_relative(ocr_results.clone(), &bbox);
        relative_span.end();

        let text = Self::ocr_results_to_text(&relative_ocr_results.clone());

        segment_context.span().end();

        Ok(Self {
            bbox,
            confidence,
            content: String::new(),
            description: None,
            embed: None,
            ss_cells: Some(cells),
            ss_header_range: None,
            ss_header_text: None,
            llm: None,
            page_height,
            page_number,
            page_width,
            segment_id,
            segment_type: SegmentType::Text,
            segment_length: None,
            ss_header_bbox: None,
            ss_header_ocr: None,
            ss_sheet_name: Some(sheet_name),
            ss_range: Some(range),
            ocr: Some(relative_ocr_results),
            image: None,
            html: String::new(),
            markdown: String::new(),
            text,
        })
    }

    pub fn scale(&mut self, scaling_factor: f32) {
        self.bbox.scale(scaling_factor);

        self.page_width *= scaling_factor;
        self.page_height *= scaling_factor;

        if let Some(ocr_results) = &mut self.ocr {
            for ocr_result in ocr_results {
                ocr_result.bbox.scale(scaling_factor);
            }
        }
    }

    fn get_embed_content(&self) -> String {
        let mut content = self.content.clone();
        if self.description.is_some() {
            content.push_str(&format!("\n\n{}", self.description.clone().unwrap()));
        }
        content
    }

    fn count_with_huggingface_tokenizer(
        content: &str,
        model_name: &str,
    ) -> std::result::Result<u32, Box<dyn Error>> {
        let tokenizer = match Tokenizer::from_pretrained(model_name, None) {
            Ok(tokenizer) => tokenizer,
            Err(e) => return Err(e.to_string().into()),
        };

        let tokens = tokenizer.encode(content, true).map_err(|e| e.to_string())?;
        Ok(tokens.len() as u32)
    }

    /// Sets the embed field for this segment and calculates its length
    pub fn set_embed_field(
        &mut self,
        configuration: &Configuration,
    ) -> std::result::Result<u32, Box<dyn Error>> {
        let content = self.get_embed_content();
        self.embed = Some(content);
        let length = self.get_embed_length(configuration)?;
        self.segment_length = Some(length);
        Ok(length)
    }

    /// Gets the length of the embed field if it exists, otherwise calculates it
    pub fn get_embed_length(
        &self,
        configuration: &Configuration,
    ) -> std::result::Result<u32, Box<dyn Error>> {
        if let Some(embed_content) = &self.embed {
            // Calculate length from embed content directly
            match &configuration.chunk_processing.tokenizer {
                crate::models::chunk_processing::TokenizerType::Enum(tokenizer) => {
                    match tokenizer {
                        crate::models::chunk_processing::Tokenizer::Word => {
                            Ok(embed_content.split_whitespace().count() as u32)
                        }
                        crate::models::chunk_processing::Tokenizer::Cl100kBase => {
                            let bpe = cl100k_base().unwrap();
                            let tokens = bpe.encode_with_special_tokens(embed_content);
                            Ok(tokens.len() as u32)
                        }
                        _ => {
                            let tokenizer_name = tokenizer.to_string();
                            Self::count_with_huggingface_tokenizer(embed_content, &tokenizer_name)
                        }
                    }
                }
                crate::models::chunk_processing::TokenizerType::String(model_name) => {
                    Self::count_with_huggingface_tokenizer(embed_content, model_name)
                }
            }
        } else {
            // Fallback to segment_length if embed not set
            self.segment_length
                .map(|l| Ok(l))
                .unwrap_or_else(|| Err("Neither embed nor segment_length is set".into()))
        }
    }
}

#[derive(Serialize, Deserialize, Debug, Clone, ToSchema)]
/// Bounding box for an item. It is used for chunks, segments and OCR results.
pub struct BoundingBox {
    /// The left coordinate of the bounding box.
    pub left: f32,
    /// The top coordinate of the bounding box.
    pub top: f32,
    /// The width of the bounding box.
    pub width: f32,
    /// The height of the bounding box.
    pub height: f32,
}

impl BoundingBox {
    pub fn new(left: f32, top: f32, width: f32, height: f32) -> Self {
        Self {
            left,
            top,
            width,
            height,
        }
    }

    fn intersects(&self, other: &BoundingBox) -> bool {
        if self.left + self.width < other.left || other.left + other.width < self.left {
            return false;
        }

        if self.top + self.height < other.top || other.top + other.height < self.top {
            return false;
        }

        true
    }

    pub fn intersection_area(&self, other: &BoundingBox) -> f32 {
        if !self.intersects(other) {
            return 0.0;
        }

        let x_left = self.left.max(other.left);
        let x_right = (self.left + self.width).min(other.left + other.width);
        let y_top = self.top.max(other.top);
        let y_bottom = (self.top + self.height).min(other.top + other.height);

        (x_right - x_left) * (y_bottom - y_top)
    }

    pub fn scale(&mut self, scaling_factor: f32) {
        self.left *= scaling_factor;
        self.top *= scaling_factor;
        self.width *= scaling_factor;
        self.height *= scaling_factor;
    }

    /// Calculate the centroid (center point) of the bounding box
    /// Returns (x, y) coordinates of the center
    pub fn centroid(&self) -> (f32, f32) {
        let center_x = self.left + (self.width / 2.0);
        let center_y = self.top + (self.height / 2.0);
        (center_x, center_y)
    }
}

#[derive(Serialize, Deserialize, Debug, Clone, ToSchema)]
/// OCR results for a segment
pub struct OCRResult {
    pub bbox: BoundingBox,
    /// The recognized text of the OCR result.
    pub text: String,
    /// The confidence score of the recognized text.
    pub confidence: Option<f32>,
}

#[derive(
    Serialize,
    Deserialize,
    Debug,
    Clone,
    PartialEq,
    EnumString,
    Display,
    ToSchema,
    ToSql,
    FromSql,
    Eq,
    Hash,
)]
/// All the possible types for a segment.
/// Note: Different configurations will produce different types.
/// Please refer to the documentation for more information.
pub enum SegmentType {
    Caption,
    Footnote,
    Formula,
    #[serde(alias = "List item")]
    ListItem,
    Page,
    #[serde(alias = "Page footer")]
    PageFooter,
    #[serde(alias = "Page header")]
    PageHeader,
    Picture,
    #[serde(alias = "Section header")]
    SectionHeader,
    Table,
    Text,
    Title,
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::models::chunk_processing::{ChunkProcessing, Tokenizer, TokenizerType};
    use crate::models::llm::LlmProcessing;
    use crate::models::segment_processing::SegmentProcessing;
    use crate::models::upload::{ErrorHandlingStrategy, OcrStrategy, SegmentationStrategy};

    fn create_test_segment() -> Segment {
        Segment {
            bbox: BoundingBox::new(0.0, 0.0, 100.0, 100.0),
            confidence: Some(0.9),
            content: "This is content text".to_string(),
            description: None,
            embed: None,
            html: "<p>This is HTML text</p>".to_string(),
            image: None,
            llm: Some("This is LLM text".to_string()),
            markdown: "This is *Markdown* text".to_string(),
            ocr: None,
            page_height: 1000.0,
            page_width: 800.0,
            page_number: 1,
            segment_id: "test-id".to_string(),
            segment_type: SegmentType::Table,
            segment_length: None,
            ss_cells: None,
            ss_header_range: None,
            ss_header_text: None,
            ss_header_bbox: None,
            ss_header_ocr: None,
            ss_range: None,
            ss_sheet_name: None,
            text: "This is content text".to_string(),
        }
    }

    fn create_test_config() -> Configuration {
        let config = Configuration {
            chunk_processing: ChunkProcessing {
                ignore_headers_and_footers: true,
                target_length: 512,
                tokenizer: TokenizerType::Enum(Tokenizer::Cl100kBase),
            },
            expires_in: None,
            high_resolution: Some(true),
            input_file_url: None,
            ocr_strategy: OcrStrategy::All,
            segment_processing: SegmentProcessing::default(),
            segmentation_strategy: SegmentationStrategy::LayoutAnalysis,
            target_chunk_length: None,
            error_handling: ErrorHandlingStrategy::default(),
            llm_processing: LlmProcessing::default(),
            #[cfg(feature = "azure")]
            pipeline: None,
        };

        config
    }

    #[test]
    fn test_get_embed_content() {
        let segment = create_test_segment();
        // Test with all sources enabled
        let content = segment.get_embed_content();
        println!("Content: {content}");
        assert!(content.contains("This is HTML text"));
        assert!(content.contains("This is *Markdown* text"));
    }

    #[test]
    fn test_count_embed_words() {
        let segment = create_test_segment();
        let config = create_test_config();

        // When using the Word tokenizer, we should get the word count
        let word_count = segment.get_embed_length(&config).unwrap();
        println!("Word count: {word_count}");
        // The exact count will depend on the whitespace tokenizer, but it should be reasonable
        // Expected to be the sum of words from content, HTML, markdown, and LLM
        assert!(word_count > 0);
    }

    #[test]
    fn test_count_embed_words_with_many_tokenizers() {
        let segment = create_test_segment();
        let mut config = create_test_config();
        let identifiers = vec![
            TokenizerType::Enum(Tokenizer::Word),
            TokenizerType::Enum(Tokenizer::Cl100kBase),
            TokenizerType::Enum(Tokenizer::XlmRobertaBase),
            TokenizerType::Enum(Tokenizer::BertBaseUncased),
            TokenizerType::String("Qwen/Qwen-tokenizer".to_string()),
            TokenizerType::String("facebook/bart-large".to_string()),
        ];

        for identifier in identifiers {
            config.chunk_processing.tokenizer = identifier.clone();
            let word_count = segment.get_embed_length(&config).unwrap();
            println!("Word count for {identifier:?}: {word_count}");
            // The exact count will depend on the whitespace tokenizer, but it should be reasonable
            // Expected to be the sum of words from content, HTML, markdown, and LLM
            assert!(word_count > 0);
        }
    }

    #[test]
    fn test_f32_overflow_causes_nan_in_centroid() {
        // Simulate extreme coordinates that can come from browser getBoundingClientRect()
        // These values are typical of elements positioned way off-screen
        let huge_f64 = 1.797_693_134_862_315_6e200_f64; // Large but valid f64

        // Current f32 implementation - this will overflow
        let bbox_f32 = BoundingBox::new(
            huge_f64 as f32, // This cast overflows to f32::INFINITY or NaN
            huge_f64 as f32,
            100.0,
            100.0,
        );

        // Check that the overflow creates infinite values (not NaN in this case)
        assert!(bbox_f32.left.is_infinite());
        assert!(bbox_f32.top.is_infinite());

        // Centroid calculation propagates the infinity
        let (center_x, center_y) = bbox_f32.centroid();
        assert!(center_x.is_infinite());
        assert!(center_y.is_infinite());

        // This is what can break the sorting algorithm - infinity comparisons
        // While they return Some(), they can still cause total order violations
        let bbox2 = BoundingBox::new(0.0, 0.0, 100.0, 100.0);
        let (normal_x, normal_y) = bbox2.centroid();

        println!("Current f32 implementation creates infinity from large coordinates:");
        println!("bbox_f32.left: {}", bbox_f32.left);
        println!("center_x: {center_x}, center_y: {center_y}");

        // The real issue is when the browser returns actual NaN values
        // Let's test that scenario
        let nan_bbox = BoundingBox::new(f32::NAN, f32::NAN, 100.0, 100.0);
        let (nan_x, nan_y) = nan_bbox.centroid();

        assert!(nan_x.is_nan());
        assert!(nan_y.is_nan());

        // These comparisons will return None, causing the sorting panic
        assert!(nan_x.partial_cmp(&normal_x).is_none());
        assert!(nan_y.partial_cmp(&normal_y).is_none());

        println!("NaN coordinates break comparisons:");
        println!("nan_x: {nan_x}, nan_y: {nan_y}");
    }

    #[test]
    fn test_f64_handles_extreme_coordinates() {
        // Same extreme coordinates but with f64 (this is what we want to implement)
        let huge_f64 = 1.797_693_134_862_315_6e200_f64;

        // This would be the f64 implementation - no casting, no overflow
        let left_f64 = huge_f64;
        let top_f64 = huge_f64;
        let width_f64 = 100.0_f64;
        let height_f64 = 100.0_f64;

        // All values remain finite
        assert!(left_f64.is_finite());
        assert!(top_f64.is_finite());

        // Centroid calculation works correctly
        let center_x = left_f64 + (width_f64 / 2.0);
        let center_y = top_f64 + (height_f64 / 2.0);

        assert!(center_x.is_finite());
        assert!(center_y.is_finite());

        // Comparisons work properly
        let normal_x = 50.0_f64;
        let normal_y = 50.0_f64;

        assert!(center_x.partial_cmp(&normal_x).is_some());
        assert!(center_y.partial_cmp(&normal_y).is_some());

        println!("f64 implementation handles extreme coordinates properly:");
        println!("left_f64: {left_f64}");
        println!("center_x: {center_x}, center_y: {center_y}");
    }

    #[test]
    fn test_sorting_with_nan_coordinates_panics() {
        // This test demonstrates the actual panic that occurs in production
        use std::panic;

        let mut chunks = vec![
            // Chunk with NaN coordinates (from f32 overflow)
            Chunk::new(vec![Segment {
                bbox: BoundingBox::new(f32::NAN, f32::NAN, 100.0, 100.0),
                confidence: Some(0.9),
                content: "Test content 1".to_string(),
                description: None,
                embed: None,
                html: "<p>Test1</p>".to_string(),
                image: None,
                llm: None,
                markdown: "Test1".to_string(),
                ocr: None,
                page_height: 1000.0,
                page_width: 800.0,
                page_number: 1,
                segment_id: "test-id-1".to_string(),
                segment_type: SegmentType::Text,
                segment_length: None,
                ss_cells: None,
                ss_header_range: None,
                ss_header_text: None,
                ss_header_bbox: None,
                ss_header_ocr: None,
                ss_range: None,
                ss_sheet_name: None,
                text: "Test content 1".to_string(),
            }]),
            // Another chunk with different NaN coordinates
            Chunk::new(vec![Segment {
                bbox: BoundingBox::new(f32::NAN, 50.0, 100.0, 100.0),
                confidence: Some(0.9),
                content: "Test content 2".to_string(),
                description: None,
                embed: None,
                html: "<p>Test2</p>".to_string(),
                image: None,
                llm: None,
                markdown: "Test2".to_string(),
                ocr: None,
                page_height: 1000.0,
                page_width: 800.0,
                page_number: 1,
                segment_id: "test-id-2".to_string(),
                segment_type: SegmentType::Text,
                segment_length: None,
                ss_cells: None,
                ss_header_range: None,
                ss_header_text: None,
                ss_header_bbox: None,
                ss_header_ocr: None,
                ss_range: None,
                ss_sheet_name: None,
                text: "Test content 2".to_string(),
            }]),
            // Third chunk with mixed NaN/normal coordinates
            Chunk::new(vec![Segment {
                bbox: BoundingBox::new(25.0, f32::NAN, 100.0, 100.0),
                confidence: Some(0.9),
                content: "Test content 3".to_string(),
                description: None,
                embed: None,
                html: "<p>Test3</p>".to_string(),
                image: None,
                llm: None,
                markdown: "Test3".to_string(),
                ocr: None,
                page_height: 1000.0,
                page_width: 800.0,
                page_number: 1,
                segment_id: "test-id-3".to_string(),
                segment_type: SegmentType::Text,
                segment_length: None,
                ss_cells: None,
                ss_header_range: None,
                ss_header_text: None,
                ss_header_bbox: None,
                ss_header_ocr: None,
                ss_range: None,
                ss_sheet_name: None,
                text: "Test content 3".to_string(),
            }]),
        ];

        // This should panic with "user-provided comparison function does not correctly implement a total order"
        let result = panic::catch_unwind(move || {
            chunks.sort_by(|a, b| {
                let bbox_a = &a.segments[0].bbox;
                let bbox_b = &b.segments[0].bbox;
                let (x_a, y_a) = bbox_a.centroid();
                let (x_b, y_b) = bbox_b.centroid();

                // This is the EXACT problematic comparison logic from production
                // Sort by row first, then by column (RowBased pattern)
                if (y_a - y_b).abs() <= 20.0 {
                    // This breaks with NaN: NaN - NaN = NaN, NaN <= 20.0 = false
                    x_a.partial_cmp(&x_b).unwrap_or(std::cmp::Ordering::Equal)
                } else {
                    y_a.partial_cmp(&y_b).unwrap_or(std::cmp::Ordering::Equal) // NaN.partial_cmp(NaN) = None -> Equal
                }
            });
        });

        // Verify that the sort panics with NaN coordinates
        assert!(result.is_err());
        println!("Confirmed: Sorting with NaN coordinates causes panic");
    }

    #[test]
    fn test_nan_tolerance_check_behavior() {
        // Demonstrate how NaN breaks the tolerance check
        let nan_y_a = f32::NAN;
        let nan_y_b = f32::NAN;
        let normal_y = 50.0;

        // NaN arithmetic produces NaN
        let nan_diff = (nan_y_a - nan_y_b).abs();
        assert!(nan_diff.is_nan());

        // NaN comparisons return None from partial_cmp, making them incomparable
        assert!(nan_diff.partial_cmp(&20.0).is_none()); // NaN is incomparable
        assert!(nan_diff.partial_cmp(&20.0).is_none()); // Same result - NaN is incomparable

        // This means NaN coordinates always take the "else" branch
        // And then partial_cmp returns None -> Equal
        assert!(nan_y_a.partial_cmp(&nan_y_b).is_none());
        assert!(nan_y_a.partial_cmp(&normal_y).is_none());

        println!(
            "NaN tolerance check: (NaN - NaN).abs() <= 20.0 = {}",
            nan_diff <= 20.0
        );
        println!("This forces the else branch, causing total order violations");
    }

    #[test]
    fn test_minimal_total_order_violation() {
        use std::panic;

        // Create a simple vector that will trigger the total order violation
        // The key is to have values where the comparison function is inconsistent
        let mut values = [
            (f32::NAN, 1.0),
            (2.0, f32::NAN),
            (f32::NAN, f32::NAN),
            (3.0, 4.0),
        ];

        // This comparison function mimics the production logic
        let comparison_fn = |a: &(f32, f32), b: &(f32, f32)| {
            let (x_a, y_a) = *a;
            let (x_b, y_b) = *b;

            // Exact same logic as production code
            if (y_a - y_b).abs() <= 20.0 {
                x_a.partial_cmp(&x_b).unwrap_or(std::cmp::Ordering::Equal)
            } else {
                y_a.partial_cmp(&y_b).unwrap_or(std::cmp::Ordering::Equal)
            }
        };

        // Try to trigger the panic
        let result = panic::catch_unwind(move || {
            values.sort_by(comparison_fn);
        });

        // If it doesn't panic, let's at least verify our tests work
        match result {
            Ok(_) => {
                println!("Sort completed without panic - the specific pattern may not trigger it every time");
                // Let's verify our comparison logic is broken
                let nan_pair1 = (f32::NAN, f32::NAN);
                let nan_pair2 = (f32::NAN, f32::NAN);
                let normal_pair = (1.0, 2.0);

                // These should violate transitivity
                println!("NaN vs NaN: {:?}", comparison_fn(&nan_pair1, &nan_pair2));
                println!(
                    "NaN vs Normal: {:?}",
                    comparison_fn(&nan_pair1, &normal_pair)
                );
                println!(
                    "Normal vs NaN: {:?}",
                    comparison_fn(&normal_pair, &nan_pair1)
                );
            }
            Err(_) => {
                println!("Successfully reproduced the total order violation panic!");
            }
        }
    }

    #[test]
    fn test_calculate_bbox_filters_nan_coordinates() {
        use super::*;

        // Create OCR results with mixed valid and NaN coordinates
        let ocr_results = vec![
            OCRResult {
                bbox: BoundingBox::new(f32::NAN, 10.0, 50.0, 20.0), // NaN left
                text: "invalid1".to_string(),
                confidence: Some(0.9),
            },
            OCRResult {
                bbox: BoundingBox::new(10.0, f32::NAN, 50.0, 20.0), // NaN top
                text: "invalid2".to_string(),
                confidence: Some(0.9),
            },
            OCRResult {
                bbox: BoundingBox::new(20.0, 30.0, 40.0, 50.0), // Valid coordinates
                text: "valid1".to_string(),
                confidence: Some(0.9),
            },
            OCRResult {
                bbox: BoundingBox::new(f32::INFINITY, 40.0, 30.0, 25.0), // Infinite left
                text: "invalid3".to_string(),
                confidence: Some(0.9),
            },
            OCRResult {
                bbox: BoundingBox::new(70.0, 80.0, 20.0, 15.0), // Valid coordinates
                text: "valid2".to_string(),
                confidence: Some(0.9),
            },
            OCRResult {
                bbox: BoundingBox::new(50.0, 60.0, -10.0, 20.0), // Negative width
                text: "invalid4".to_string(),
                confidence: Some(0.9),
            },
        ];

        // This should succeed by filtering out invalid coordinates
        let result = Segment::calculate_bbox_from_ocr(&ocr_results);

        assert!(result.is_ok());
        let bbox = result.unwrap();

        // Verify the result uses only the valid coordinates
        // valid1: (20, 30, 40, 50) -> right=60, bottom=80
        // valid2: (70, 80, 20, 15) -> right=90, bottom=95
        // So bbox should be: left=20, top=30, width=70, height=65
        assert!(bbox.left.is_finite());
        assert!(bbox.top.is_finite());
        assert!(bbox.width.is_finite());
        assert!(bbox.height.is_finite());

        // Check that it calculated the correct bounding box from valid coordinates only
        assert_eq!(bbox.left, 20.0); // min left from valid coordinates
        assert_eq!(bbox.top, 30.0); // min top from valid coordinates
        assert_eq!(bbox.width, 70.0); // max_right (90) - min_left (20) = 70
        assert_eq!(bbox.height, 65.0); // max_bottom (95) - min_top (30) = 65

        println!("✅ calculate_bbox_from_ocr successfully filtered out NaN coordinates");
        println!(
            "   Calculated bbox: left={}, top={}, width={}, height={}",
            bbox.left, bbox.top, bbox.width, bbox.height
        );
    }

    #[test]
    fn test_calculate_bbox_fails_with_all_invalid_coordinates() {
        use super::*;

        // Create OCR results with only invalid coordinates
        let ocr_results = vec![
            OCRResult {
                bbox: BoundingBox::new(f32::NAN, 10.0, 50.0, 20.0),
                text: "invalid1".to_string(),
                confidence: Some(0.9),
            },
            OCRResult {
                bbox: BoundingBox::new(10.0, f32::INFINITY, 50.0, 20.0),
                text: "invalid2".to_string(),
                confidence: Some(0.9),
            },
            OCRResult {
                bbox: BoundingBox::new(20.0, 30.0, f32::NAN, 50.0),
                text: "invalid3".to_string(),
                confidence: Some(0.9),
            },
        ];

        // This should fail gracefully with a descriptive error
        let result = Segment::calculate_bbox_from_ocr(&ocr_results);

        assert!(result.is_err());
        let error_msg = result.unwrap_err().to_string();
        assert!(error_msg.contains("No valid OCR results with finite coordinates found"));

        println!("✅ calculate_bbox_from_ocr properly rejects all-invalid coordinates");
        println!("   Error message: {error_msg}");
    }
}
