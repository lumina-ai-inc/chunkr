
# List of allowed LLM models
# Copy this file to models.yaml and fill in the values
# Only one must be default (and you must have one default)
# Only one can have fallback set to true (one must be true)
models:
  - id: gemini-flash-2.0
    model: google/gemini-2.0-flash-001
    provider_url: https://openrouter.ai/api/v1/chat/completions
    api_key: "your_openrouter_api_key_here"
    default: true
    fallback: false
  - id: qwen-2.5-vl-7b-instruct
    model: qwen/qwen-2.5-vl-7b-instruct
    provider_url: https://openrouter.ai/api/v1/chat/completions
    api_key: "your_openrouter_api_key_here"
    default: false
    fallback: true
  - id: gpt-4o-mini
    model: gpt-4o-mini
    provider_url: https://api.openai.com/v1/chat/completions
    api_key: "your_openai_api_key_here"
    default: false
    fallback: false
