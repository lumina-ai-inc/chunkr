{
  "metadata": {
    "tags": [],
    "concepts": []
  },
  "sys": {
    "space": {
      "sys": {
        "type": "Link",
        "linkType": "Space",
        "id": "grf9ilg5id1c"
      }
    },
    "id": "6oLVnm3mpaFQqgNMBchQhi",
    "type": "Entry",
    "createdAt": "2025-05-20T23:38:06.578Z",
    "updatedAt": "2025-05-21T21:34:02.791Z",
    "environment": {
      "sys": {
        "id": "master",
        "type": "Link",
        "linkType": "Environment"
      }
    },
    "publishedVersion": 57,
    "revision": 5,
    "contentType": {
      "sys": {
        "type": "Link",
        "linkType": "ContentType",
        "id": "blogPage"
      }
    },
    "locale": "en-US"
  },
  "fields": {
    "title": "Precision PDF Parsing with Configurable LLMs and Extended Context",
    "authorInfo": {
      "sys": {
        "type": "Link",
        "linkType": "Entry",
        "id": "2ZnvY32NvYw15iXCiResD5"
      }
    },
    "subheadings": "Chunkr is the best way to hook up LLMs with document intelligence infrastructure. ",
    "body": {
      "data": {},
      "content": [
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "We're excited to announce a major update to Chunkr's API that makes it easier than ever to use LLMs for document processing. This release introduces a configurable way to leverage LLMs across your document extraction pipeline, letting you choose when to use classical OCR (AUTO) versus LLM-powered extraction for different content types.",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "The new API lets you specify a primary LLM for your extraction tasks and control exactly how it's used. For each segment type (tables, images, formulas, etc.), you can decide whether to process it using traditional OCR methods or harness the power of your configured LLM. This granular control means you can optimize your pipeline, for example, using fast OCR for basic text while engaging LLM processing for complex tables and charts where accuracy is critical. To help you make a decision on what LLM to use we have benchmarked all available LLMs over the Chunkr API for document extraction (detailed below).",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "The release also introduces Extended Context, a feature that gives models full-page visibility when processing individual elements. This approach significantly improves accuracy on challenging content like dense tables, charts, and multi-column layouts by helping models understand the broader document context.",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "How LLM Processing Works",
              "nodeType": "text"
            }
          ],
          "nodeType": "heading-2"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "LLM processing in Chunkr refers to the use of vision language models to extract and structure content from documents. With LLMs, you can accurately convert tables, images, and formulas into clean, structured HTML or Markdown. You can also interpret visual cues such as legends or footnotes, and generate custom summaries or explanations for each segment. This approach goes far beyond what traditional OCR or rule-based methods can achieve.",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "Chunkr's API gives you fine-grained control over when and how LLMs are used in your extraction pipeline. You can specify which segment types (such as tables, pictures, or formulas) should be processed by an LLM, choose the model to use, and provide custom prompts for specialized tasks. This flexibility lets you optimize for speed, cost, or extraction quality depending on your workflow needs.",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "Below, we explain the default LLM processing behavior and how you can customize it for your use case.",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "Default LLM Processing for Tables, Pictures, and Formulas",
              "nodeType": "text"
            }
          ],
          "nodeType": "heading-3"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "By default, Chunkr uses LLMs for HTML and Markdown generation on tables, pictures, and formulas. This delivers much higher fidelity for complex elements, at the cost of some speed. For example:",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "from chunkr_ai.models import Configuration, GenerationConfig, GenerationStrategy, SegmentProcessing",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "config = Configuration(\n    segment_processing=SegmentProcessing(\n        Table=GenerationConfig(\n            html=GenerationStrategy.LLM,  # Uses Chunkr's default prompt\n            markdown=GenerationStrategy.LLM\n        ),\n        Picture=GenerationConfig(\n            html=GenerationStrategy.LLM,\n            markdown=GenerationStrategy.LLM\n        ),\n        Formula=GenerationConfig(\n            html=GenerationStrategy.LLM,\n            markdown=GenerationStrategy.LLM\n        )\n    )\n)",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [
                {
                  "type": "bold"
                }
              ],
              "value": "Note:",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [],
              "value": " When you use ",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "GenerationStrategy.LLM",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [],
              "value": "for ",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "html",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [],
              "value": "or ",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "markdown",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [],
              "value": ", Chunkr applies its own optimized prompts for that segment type. This is the recommended approach for most users.",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "Custom LLM Prompts with the ",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "llm",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [],
              "value": "Field",
              "nodeType": "text"
            }
          ],
          "nodeType": "heading-3"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "You can also provide your own custom prompt using the ",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "llm",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [],
              "value": "field. For example, to ask for a summary of each table:",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "from chunkr_ai.models import Configuration, GenerationConfig, SegmentProcessing",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "config = Configuration(\n    segment_processing=SegmentProcessing(\n        Table=GenerationConfig(\n            llm=\"Summarize the key trends in this table.\"\n        )\n    )\n)",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "content": [
                {
                  "data": {},
                  "marks": [
                    {
                      "type": "bold"
                    }
                  ],
                  "value": "Tip:",
                  "nodeType": "text"
                },
                {
                  "data": {},
                  "marks": [],
                  "value": " The ",
                  "nodeType": "text"
                },
                {
                  "data": {},
                  "marks": [
                    {
                      "type": "code"
                    }
                  ],
                  "value": "llm",
                  "nodeType": "text"
                },
                {
                  "data": {},
                  "marks": [],
                  "value": "field is powerful for advanced use cases, but be aware that custom prompts may affect output consistency or cause refusals if not well-formed.",
                  "nodeType": "text"
                }
              ],
              "nodeType": "paragraph"
            }
          ],
          "nodeType": "blockquote"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "Where does the output of the ",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "llm",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [],
              "value": "field go?",
              "nodeType": "text"
            }
          ],
          "nodeType": "heading-4"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "When you use the ",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "llm",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [],
              "value": "field, the LLM's response is returned in the ",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "segment.llm",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [],
              "value": "field for each segment in the output. This is in addition to the standard ",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "html",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [],
              "value": "and ",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [
                {
                  "type": "code"
                }
              ],
              "value": "markdown",
              "nodeType": "text"
            },
            {
              "data": {},
              "marks": [],
              "value": "fields. You can access it like this:",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "Extended Context in Action",
              "nodeType": "text"
            }
          ],
          "nodeType": "heading-3"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "The Extended Context feature significantly improves extraction quality on complex visual elements by providing LLMs with surrounding page imagery in addition to raw text. This is especially valuable when extracting information from charts, diagrams, and multi-column layoutsâ€”where key context (like legends or footnotes) may be physically separated from the main content.",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "In the example below, the left image shows a complex project status table with color-coded status icons and a separate legend explaining the meaning of each icon. Without Extended Context, an LLM processing just the table segment would miss the meaning of the colored shapes, leading to incomplete or incorrect extraction.",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "With Extended Context enabled, as shown in the right image, the LLM receives both the table and the legend in its context window. This allows it to accurately interpret the status icons (e.g., green circles for \"On target\", yellow diamonds for \"Possible problem\", red triangles for \"Significant Impact\") and include this information in the extracted output. As a result, the model can generate a much more faithful and useful representation of the original document, correctly mapping visual cues to their real-world meanings.",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        },
        {
          "data": {
            "target": {
              "sys": {
                "id": "31Z6lFsiJ1TFLwfyi29wMy",
                "type": "Link",
                "linkType": "Asset"
              }
            }
          },
          "content": [],
          "nodeType": "embedded-asset-block"
        },
        {
          "data": {},
          "content": [
            {
              "data": {},
              "marks": [],
              "value": "",
              "nodeType": "text"
            }
          ],
          "nodeType": "paragraph"
        }
      ],
      "nodeType": "document"
    },
    "image": {
      "sys": {
        "type": "Link",
        "linkType": "Asset",
        "id": "1VEF8B13cpsJmk5P6n7bX4"
      }
    },
    "publishedDate": "2025-05-20T00:00-07:00",
    "slug": "precision-pdf-parsing-with-configurable-llms"
  }
}
